local variable 'data' referenced before assignmentlocal variable 'self' referenced before assignmentlocal variable 'c' referenced before assignmentglobal name 'socket' is not definedlocal variable 'host' referenced before assignmentlocal variable 'port' referenced before assignmentglobal name 'threading' is not definedlocal variable 'vec' referenced before assignmentlocal variable 's' referenced before assignmentname '_binary' is not definedname 'ImageFile' is not definedname 'BmpImageFile' is not definedname 'Image' is not definedname '_accept' is not definedname '_save' is not definedlocal variable 'prefix' referenced before assignmentlocal variable 'header' referenced before assignmentglobal name 'ImageFile' is not definedglobal name 'i32' is not definedglobal name 'i16' is not definedglobal name 'i8' is not definedlocal variable 'colors' referenced before assignmentlocal variable 'bits' referenced before assignmentglobal name 'BIT2MODE' is not definedlocal variable 'compression' referenced before assignmentlocal variable 'read' referenced before assignmentlocal variable 'mask' referenced before assignmentlocal variable 'indices' referenced before assignmentlocal variable 'lutsize' referenced before assignmentglobal name 'o8' is not definedlocal variable 'palette' referenced before assignmentlocal variable 'greyscale' referenced before assignmentglobal name 'ImagePalette' is not definedlocal variable 'offset' referenced before assignmentlocal variable 'rawmode' referenced before assignmentlocal variable 'direction' referenced before assignmentglobal name 'math' is not definedlocal variable 'x' referenced before assignmentglobal name 'SAVE' is not definedlocal variable 'im' referenced before assignmentlocal variable 'check' referenced before assignmentlocal variable 'fp' referenced before assignmentglobal name 'o32' is not definedglobal name 'o16' is not definedlocal variable 'stride' referenced before assignmentname 'GifImageFile' is not definedlocal variable 'p' referenced before assignmentlocal variable 'i' referenced before assignmentlocal variable 'frame' referenced before assignmentlocal variable 'block' referenced before assignmentlocal variable 'x0' referenced before assignmentlocal variable 'y0' referenced before assignmentlocal variable 'x1' referenced before assignmentlocal variable 'y1' referenced before assignmentglobal name 'Image' is not definedglobal name '_imaging_gif' is not definedlocal variable 'filename' referenced before assignmentglobal name 'RAWMODE' is not definedglobal name 'getheader' is not definedlocal variable 'imOut' referenced before assignmentlocal variable 'interlace' referenced before assignmentlocal variable 'flags' referenced before assignmentlocal variable 'transparency' referenced before assignmentlocal variable 'usedPaletteColors' referenced before assignmentlocal variable 'transparentColorExists' referenced before assignmentlocal variable 'os' referenced before assignmentlocal variable 'file' referenced before assignmentlocal variable 'info' referenced before assignmentlocal variable 'optimize' referenced before assignmentlocal variable 'paletteBytes' referenced before assignmentlocal variable 'sourcePalette' referenced before assignmentlocal variable 'newPositions' referenced before assignmentlocal variable 'oldPosition' referenced before assignmentlocal variable 'imageBytes' referenced before assignmentlocal variable 'collector' referenced before assignmentlocal variable 'params' referenced before assignmentname 'linear' is not definedname 'curved' is not definedname 'sine' is not definedname 'sphere_increasing' is not definedname 'sphere_decreasing' is not definedname 'GradientFile' is not definedlocal variable 'pos' referenced before assignmentlocal variable 'middle' referenced before assignmentglobal name 'EPSILON' is not definedglobal name 'log' is not definedglobal name 'sin' is not definedglobal name 'pi' is not definedglobal name 'linear' is not definedglobal name 'sqrt' is not definedlocal variable 'entries' referenced before assignmentlocal variable 'ix' referenced before assignmentlocal variable 'segment' referenced before assignmentlocal variable 'xm' referenced before assignmentlocal variable 'rgb1' referenced before assignmentlocal variable 'rgb0' referenced before assignmentlocal variable 'w' referenced before assignmentglobal name 'SEGMENTS' is not definedlocal variable 'gradient' referenced before assignmentglobal name 're' is not definedlocal variable 'v' referenced before assignmentname 'RuntimeWarning' is not definedname 'PILLOW_VERSION' is not definedname 'core' is not definedname '_imaging_not_installed' is not definedname 'v' is not definedname 'warnings' is not definedname '__builtin__' is not definedname 'sys' is not definedname '_ENDIAN' is not definedname '_MODEINFO' is not definedname '_fromarray_typemap' is not definedlocal variable 't' referenced before assignmentglobal name '_MODE_CONV' is not definedlocal variable 'extra' referenced before assignmentlocal variable 'shape' referenced before assignmentlocal variable 'typ' referenced before assignmentglobal name 'ImageMode' is not definedlocal variable 'mode' referenced before assignmentglobal name '_initialized' is not definedglobal name '_plugins' is not definedglobal name 'DEBUG' is not definedlocal variable 'plugin' referenced before assignmentglobal name 'sys' is not definedglobal name 'OPEN' is not definedlocal variable 'args' referenced before assignmentglobal name 'core' is not definedlocal variable 'decoder_name' referenced before assignmentlocal variable 'encoder_name' referenced before assignmentlocal variable 'value' referenced before assignmentglobal name '_E' is not definedglobal name 'coerce_e' is not definedlocal variable 'other' referenced before assignmentlocal variable 'expr' referenced before assignmentlocal variable 'a' referenced before assignmentlocal variable 'stub' referenced before assignmentlocal variable 'b' referenced before assignmentglobal name 'numbers' is not definedlocal variable 'd' referenced before assignmentlocal variable 'e' referenced before assignmentglobal name 'WEB' is not definedglobal name 'NEAREST' is not definedglobal name 'ANTIALIAS' is not definedglobal name 'NORMAL' is not definedlocal variable 'new' referenced before assignmentlocal variable 'k' referenced before assignmentglobal name 'deferred_error' is not definedlocal variable 'format' referenced before assignmentglobal name 'os' is not definedlocal variable 'f' referenced before assignmentlocal variable 'name' referenced before assignmentglobal name '_conv_type_shape' is not definedlocal variable 'typestr' referenced before assignmentlocal variable 'state' referenced before assignmentlocal variable 'size' referenced before assignmentglobal name '_getencoder' is not definedglobal name 'warnings' is not definedglobal name 'DeprecationWarning' is not definedlocal variable 'kw' referenced before assignmentglobal name '_getdecoder' is not definedglobal name 'HAS_CFFI' is not definedglobal name 'USE_CFFI_ACCESS' is not definedlocal variable 'matrix' referenced before assignmentglobal name 'ADAPTIVE' is not definedlocal variable 'delete_trns' referenced before assignmentlocal variable 'trns' referenced before assignmentlocal variable 'dither' referenced before assignmentglobal name 'FLOYDSTEINBERG' is not definedglobal name 'getmodebase' is not definedlocal variable 'new_im' referenced before assignmentlocal variable 'method' referenced before assignmentlocal variable 'kmeans' referenced before assignmentlocal variable 'box' referenced before assignmentglobal name '_ImageCrop' is not definedlocal variable 'ymargin' referenced before assignmentlocal variable 'xmargin' referenced before assignmentlocal variable 'filter' referenced before assignmentglobal name 'collections' is not definedlocal variable 'ims' referenced before assignmentglobal name 'merge' is not definedlocal variable 'h' referenced before assignmentlocal variable 'out' referenced before assignmentlocal variable 'maxcolors' referenced before assignmentlocal variable 'band' referenced before assignmentlocal variable 'extrema' referenced before assignmentlocal variable 'xy' referenced before assignmentlocal variable 'y' referenced before assignmentlocal variable 'xoffset' referenced before assignmentlocal variable 'yoffset' referenced before assignmentglobal name 'isImageType' is not definedglobal name 'isStringType' is not definedlocal variable 'lut' referenced before assignmentglobal name 'ImagePointHandler' is not definedglobal name '_getscaleoffset' is not definedlocal variable 'scale' referenced before assignmentlocal variable 'alpha' referenced before assignmentglobal name 'new' is not definedlocal variable '__iterator' referenced before assignmentlocal variable 'resample' referenced before assignmentglobal name 'BILINEAR' is not definedglobal name 'BICUBIC' is not definedlocal variable 'expand' referenced before assignmentlocal variable 'angle' referenced before assignmentlocal variable 'transform' referenced before assignmentlocal variable 'xx' referenced before assignmentlocal variable 'yy' referenced before assignmentlocal variable 'math' referenced before assignmentglobal name 'AFFINE' is not definedglobal name 'isPath' is not definedglobal name 'preinit' is not definedglobal name 'EXTENSION' is not definedglobal name 'init' is not definedlocal variable 'ext' referenced before assignmentglobal name 'builtins' is not definedlocal variable 'save_handler' referenced before assignmentglobal name '_show' is not definedlocal variable 'title' referenced before assignmentlocal variable 'command' referenced before assignmentlocal variable 'fill' referenced before assignmentglobal name 'ImageTransformHandler' is not definedglobal name 'MESH' is not definedglobal name 'QUAD' is not definedlocal variable 'quad' referenced before assignmentglobal name 'EXTENT' is not definedglobal name 'PERSPECTIVE' is not definedlocal variable 'ne' referenced before assignmentlocal variable 'sw' referenced before assignmentlocal variable 'se' referenced before assignmentlocal variable 'image' referenced before assignmentlocal variable 'distance' referenced before assignmentlocal variable 'color' referenced before assignmentglobal name 'frombytes' is not definedglobal name 'RuntimeWarning' is not definedglobal name '_MAPMODES' is not definedlocal variable 'obj' referenced before assignmentlocal variable 'arr' referenced before assignmentglobal name '_fromarray_typemap' is not definedlocal variable 'ndim' referenced before assignmentlocal variable 'ndmax' referenced before assignmentlocal variable 'strides' referenced before assignmentglobal name 'frombuffer' is not definedglobal name 'MAX_IMAGE_PIXELS' is not definedglobal name 'DecompressionBombWarning' is not definedglobal name 'ID' is not definedlocal variable 'accept' referenced before assignmentlocal variable 'factory' referenced before assignmentglobal name '_decompression_bomb_check' is not definedlocal variable 'im1' referenced before assignmentlocal variable 'im2' referenced before assignmentlocal variable 'image2' referenced before assignmentlocal variable 'image1' referenced before assignmentglobal name 'getmodebands' is not definedlocal variable 'bands' referenced before assignmentglobal name 'getmodetype' is not definedlocal variable 'id' referenced before assignmentlocal variable 'mimetype' referenced before assignmentglobal name 'MIME' is not definedlocal variable 'driver' referenced before assignmentlocal variable 'extension' referenced before assignmentglobal name '_showxv' is not definedlocal variable 'options' referenced before assignmentlocal variable 'extent' referenced before assignmentlocal variable 'quality' referenced before assignmentlocal variable 'sigma' referenced before assignmentglobal name 'colormap' is not definedlocal variable 'rgb' referenced before assignmentglobal name 'getrgb' is not definedlocal variable 'r' referenced before assignmentlocal variable 'g' referenced before assignmentlocal variable 'error' referenced before assignmentglobal name 'ERRORS' is not definedlocal variable 'message' referenced before assignmentglobal name 'MAXBLOCK' is not definedglobal name 'traceback' is not definedlocal variable 'use_mmap' referenced before assignmentlocal variable 'o' referenced before assignmentglobal name '_tilesort' is not definedlocal variable 'seek' referenced before assignmentglobal name 'LOAD_TRUNCATED_IMAGES' is not definedlocal variable 'n' referenced before assignmentlocal variable 'readonly' referenced before assignmentglobal name 'raise_ioerror' is not definedglobal name 'io' is not definedlocal variable 'flag' referenced before assignmentlocal variable 'tile' referenced before assignmentlocal variable 'bufsize' referenced before assignmentlocal variable 'fh' referenced before assignmentglobal name 'SAFEBLOCK' is not definedname 'Filter' is not definedname 'Kernel' is not definedname 'RankFilter' is not definedname 'BuiltinFilter' is not definedglobal name 'reduce' is not definedlocal variable 'kernel' referenced before assignmentlocal variable 'rank' referenced before assignmentlocal variable 'radius' referenced before assignmentlocal variable 'percent' referenced before assignmentlocal variable 'threshold' referenced before assignmentlocal variable 'basemode' referenced before assignmentlocal variable 'basetype' referenced before assignmentglobal name '_modes' is not definedglobal name 'ModeDescriptor' is not definedlocal variable 'm' referenced before assignmentglobal name 'array' is not definedglobal name 'make_linear_lut' is not definedlocal variable 'black' referenced before assignmentlocal variable 'white' referenced before assignmentglobal name 'make_gamma_lut' is not definedlocal variable 'exp' referenced before assignmentlocal variable 'randint' referenced before assignmentglobal name 'ImageColor' is not definedname 'Viewer' is not definedname 'register' is not definedname 'WindowsViewer' is not definedname 'MacViewer' is not definedname 'UnixViewer' is not definedname 'which' is not definedname 'DisplayViewer' is not definedname 'XVViewer' is not definedlocal variable 'viewer' referenced before assignmentglobal name 'Viewer' is not definedlocal variable 'order' referenced before assignmentglobal name '_viewers' is not definedlocal variable 'base' referenced before assignmentglobal name 'quote' is not definedlocal variable 'executable' referenced before assignmentname 'SOF' is not definedname 'Skip' is not definedname 'DQT' is not definedname 'APP' is not definedname 'COM' is not definedname 'jpeg_factory' is not definedlocal variable 'marker' referenced before assignmentlocal variable 'version' referenced before assignmentlocal variable 'jfif_unit' referenced before assignmentlocal variable 'jfif_density' referenced before assignmentlocal variable 'adobe_transform' referenced before assignmentlocal variable 'profile' referenced before assignmentglobal name 'MARKER' is not definedlocal variable 'handler' referenced before assignmentlocal variable 'subprocess' referenced before assignmentlocal variable 'path' referenced before assignmentglobal name '_getexif' is not definedglobal name '_getmp' is not definedglobal name 'TiffImagePlugin' is not definedglobal name '_fixup' is not definedlocal variable 'exif' referenced before assignmentlocal variable 'key' referenced before assignmentlocal variable 'head' referenced before assignmentlocal variable 'gps' referenced before assignmentlocal variable 'mp' referenced before assignmentlocal variable 'quant' referenced before assignmentglobal name 'unpack' is not definedlocal variable 'endianness' referenced before assignmentlocal variable 'mpentries' referenced before assignmentlocal variable 'qtables' referenced before assignmentglobal name 'zigzag_index' is not definedlocal variable 'table' referenced before assignmentlocal variable 'idx' referenced before assignmentglobal name 'samplings' is not definedglobal name 'presets' is not definedlocal variable 'subsampling' referenced before assignmentglobal name 'get_sampling' is not definedlocal variable 'icc_profile' referenced before assignmentglobal name 'struct' is not definedlocal variable 'ICC_OVERHEAD_LEN' referenced before assignmentlocal variable 'markers' referenced before assignmentlocal variable 'dpi' referenced before assignmentlocal variable 'lines' referenced before assignmentglobal name 'convert_dict_qtables' is not definedglobal name 'JpegImageFile' is not definedname 'JpegImagePlugin' is not definedglobal name 'JpegImagePlugin' is not definedname 'ChunkStream' is not definedname 'putchunk' is not definedname 'PngImageFile' is not definedglobal name 'is_cid' is not definedlocal variable 'cid' referenced before assignmentlocal variable 'length' referenced before assignmentlocal variable 'endchunk' referenced before assignmentlocal variable 'cids' referenced before assignmentlocal variable 'cls' referenced before assignmentlocal variable 'text' referenced before assignmentlocal variable 'lang' referenced before assignmentlocal variable 'tkey' referenced before assignmentlocal variable 'zip' referenced before assignmentglobal name 'iTXt' is not definedglobal name 'ChunkStream' is not definedglobal name 'zlib' is not definedglobal name '_MODES' is not definedglobal name '_simple_palette' is not definedlocal variable 'px' referenced before assignmentlocal variable 'py' referenced before assignmentlocal variable 'zlib' referenced before assignmentlocal variable 'cf' referenced before assignmentlocal variable 'cm' referenced before assignmentlocal variable 'tk' referenced before assignmentglobal name '_MAGIC' is not definedglobal name 'PngStream' is not definedlocal variable 'read_bytes' referenced before assignmentlocal variable 'hi' referenced before assignmentlocal variable 'lo' referenced before assignmentlocal variable 'chunk' referenced before assignmentglobal name '_OUTMODES' is not definedlocal variable 'palette_bytes' referenced before assignmentlocal variable 'red' referenced before assignmentlocal variable 'green' referenced before assignmentlocal variable 'blue' referenced before assignmentglobal name '_idat' is not definedglobal name '_save' is not definedname 'string' is not definedname 'locale' is not definedname 'locale_enc' is not definedname 'b_whitespace' is not definedname 'PpmImageFile' is not definedglobal name 'b_whitespace' is not definedglobal name 'MODES' is not definedlocal variable 'xsize' referenced before assignmentlocal variable 'ysize' referenced before assignmentname 'FFI' is not definedname 'ffi' is not definedname 'defs' is not definedname 'PyAccess' is not definedname '_PyAccess8' is not definedname '_PyAccess32_2' is not definedname '_PyAccess32_3' is not definedname '_PyAccess32_4' is not definedname '_PyAccessF' is not definedname '_PyAccessI32_N' is not definedname '_PyAccessI16_N' is not definedname 'mode_map' is not definedname '_PyAccessI16_B' is not definedname '_PyAccessI32_Swap' is not definedname '_PyAccessI16_L' is not definedlocal variable 'img' referenced before assignmentglobal name 'ffi' is not definedlocal variable 'pixel' referenced before assignmentlocal variable 'chars' referenced before assignmentglobal name 'mode_map' is not definedname 'II' is not definedname 'MM' is not definedname 'COMPRESSION_INFO' is not definedname 'k' is not definedname 'TiffImageFile' is not definedglobal name 'PREFIXES' is not definedglobal name 'II' is not definedglobal name 'MM' is not definedglobal name 'ib16' is not definedglobal name 'ib32' is not definedglobal name 'ob16' is not definedglobal name 'ob32' is not definedglobal name 'il16' is not definedglobal name 'il32' is not definedglobal name 'ol16' is not definedglobal name 'ol32' is not definedlocal variable 'TiffTags' referenced before assignmentlocal variable 'tag_code' referenced before assignmentlocal variable 'result' referenced before assignmentlocal variable 'tag' referenced before assignmentglobal name 'SAMPLEFORMAT' is not definedlocal variable 'default' referenced before assignmentglobal name 'itertools' is not definedlocal variable 'keys' referenced before assignmentlocal variable 'values' referenced before assignmentlocal variable 'l' referenced before assignmentglobal name 'native_prefix' is not definedlocal variable 'i16' referenced before assignmentlocal variable 'dispatch' referenced before assignmentlocal variable 'i32' referenced before assignmentlocal variable 'ifd' referenced before assignmentglobal name 'COLORMAP' is not definedglobal name 'IPTC_NAA_CHUNK' is not definedglobal name 'PHOTOSHOP_CHUNK' is not definedglobal name 'ICCPROFILE' is not definedglobal name 'XMP' is not definedglobal name 'STRIPOFFSETS' is not definedlocal variable 'directory' referenced before assignmentglobal name 'X_RESOLUTION' is not definedglobal name 'Y_RESOLUTION' is not definedlocal variable 'o16' referenced before assignmentlocal variable 'o32' referenced before assignmentlocal variable 'append' referenced before assignmentlocal variable 'stripoffsets' referenced before assignmentlocal variable 'count' referenced before assignmentglobal name 'ImageFileDirectory' is not definedlocal variable 'ifh' referenced before assignmentlocal variable 'layer' referenced before assignmentglobal name 'JPEGTABLES' is not definedglobal name 'PREDICTOR' is not definedlocal variable 'extents' referenced before assignmentlocal variable 'decoder' referenced before assignmentlocal variable 'err' referenced before assignmentglobal name 'COMPRESSION_INFO' is not definedglobal name 'COMPRESSION' is not definedglobal name 'PLANAR_CONFIGURATION' is not definedglobal name 'PHOTOMETRIC_INTERPRETATION' is not definedglobal name 'FILLORDER' is not definedglobal name 'IMAGEWIDTH' is not definedglobal name 'IMAGELENGTH' is not definedglobal name 'BITSPERSAMPLE' is not definedglobal name 'EXTRASAMPLES' is not definedglobal name 'OPEN_INFO' is not definedlocal variable 'getscalar' referenced before assignmentlocal variable 'xres' referenced before assignmentlocal variable 'yres' referenced before assignmentglobal name 'RESOLUTION_UNIT' is not definedglobal name 'ROWSPERSTRIP' is not definedglobal name 'READ_LIBTIFF' is not definedlocal variable 'fillorder' referenced before assignmentlocal variable 'photo' referenced before assignmentlocal variable 'offsets' referenced before assignmentglobal name 'TILEOFFSETS' is not definedglobal name 'SAVE_INFO' is not definedglobal name 'WRITE_LIBTIFF' is not definedlocal variable 'libtiff' referenced before assignmentglobal name 'IMAGEDESCRIPTION' is not definedglobal name '_cvt_res' is not definedglobal name 'SOFTWARE' is not definedglobal name 'DATE_TIME' is not definedglobal name 'ARTIST' is not definedglobal name 'COPYRIGHT' is not definedglobal name 'SAMPLESPERPIXEL' is not definedglobal name 'STRIPBYTECOUNTS' is not definedglobal name 'COMPRESSION_INFO_REV' is not definedlocal variable 'atts' referenced before assignmentlocal variable 'blocklist' referenced before assignmentlocal variable '_fp' referenced before assignmentlocal variable 'ex' referenced before assignmentname '__version__' is not definedname '__version_extra__' is not definedname 'PointerRoot' is not definedname 'load_keysym_group' is not definedlocal variable 'keysym' referenced before assignmentglobal name 'NoSymbol' is not definedlocal variable 'group' referenced before assignmentlocal variable 'keysyms' referenced before assignmentlocal variable 'mod' referenced before assignmentlocal variable 'G' referenced before assignmentglobal name 'XK_BackSpace' is not definedglobal name 'XK_Tab' is not definedglobal name 'XK_Clear' is not definedglobal name 'XK_Return' is not definedglobal name 'XK_Pause' is not definedglobal name 'XK_Scroll_Lock' is not definedglobal name 'XK_Escape' is not definedglobal name 'XK_Delete' is not definedname 'PPosition' is not definedname 'PSize' is not definedname 'PMinSize' is not definedname 'PMaxSize' is not definedname 'PResizeInc' is not definedname 'PAspect' is not definedname 'InputHint' is not definedname 'StateHint' is not definedname 'IconPixmapHint' is not definedname 'IconWindowHint' is not definedname 'IconPositionHint' is not definedname 'IconMaskHint' is not definedname 'WindowGroupHint' is not definedname 'MessageHint' is not definedname 'UrgencyHint' is not definedname 'Xlib' is not definedname 'display' is not definedglobal name '_resource_baseclasses' is not definedglobal name 'display' is not definedlocal variable 'atomname' referenced before assignmentglobal name 'request' is not definedlocal variable 'only_if_exists' referenced before assignmentglobal name 'X' is not definedglobal name '_BaseDisplay' is not definedlocal variable 'display' referenced before assignmentglobal name 'rq' is not definedglobal name 'ext' is not definedlocal variable 'extname' referenced before assignmentlocal variable 'exts' referenced before assignmentlocal variable 'modname' referenced before assignmentlocal variable 'type_' referenced before assignmentlocal variable 'dict' referenced before assignmentlocal variable 'type' referenced before assignmentlocal variable 'attr' referenced before assignmentglobal name 'types' is not definedlocal variable 'sno' referenced before assignmentlocal variable 'object' referenced before assignmentglobal name 'error' is not definedlocal variable 'function' referenced before assignmentglobal name '_resource_hierarchy' is not definedlocal variable 'evt' referenced before assignmentlocal variable 'code' referenced before assignmentlocal variable 'keycode' referenced before assignmentlocal variable 'index' referenced before assignmentglobal name 'event' is not definedlocal variable 'first_keycode' referenced before assignmentlocal variable 'codes' referenced before assignmentlocal variable 'lastcode' referenced before assignmentlocal variable 'newstring' referenced before assignmentlocal variable 'atom' referenced before assignmentlocal variable 'selection' referenced before assignmentlocal variable 'onerror' referenced before assignmentlocal variable 'propagate' referenced before assignmentlocal variable 'destination' referenced before assignmentlocal variable 'event_mask' referenced before assignmentlocal variable 'event' referenced before assignmentlocal variable 'time' referenced before assignmentlocal variable 'cursor' referenced before assignmentlocal variable 'src_window' referenced before assignmentlocal variable 'src_x' referenced before assignmentlocal variable 'src_y' referenced before assignmentlocal variable 'src_width' referenced before assignmentlocal variable 'src_height' referenced before assignmentlocal variable 'revert_to' referenced before assignmentlocal variable 'focus' referenced before assignmentglobal name 'Xlib' is not definedlocal variable 'max_names' referenced before assignmentlocal variable 'pattern' referenced before assignmentlocal variable 'accel' referenced before assignmentlocal variable 'do_accel' referenced before assignmentlocal variable 'accel_num' referenced before assignmentlocal variable 'accel_denum' referenced before assignmentlocal variable 'timeout' referenced before assignmentlocal variable 'interval' referenced before assignmentlocal variable 'prefer_blank' referenced before assignmentlocal variable 'allow_exposures' referenced before assignmentlocal variable 'host_family' referenced before assignmentlocal variable 'map' referenced before assignmentlocal variable 'keycodes' referenced before assignmentname 'DisplayError' is not definedname 'XError' is not definedname 'XResourceError' is not definedname 'BadRequest' is not definedname 'BadValue' is not definedname 'BadWindow' is not definedname 'BadPixmap' is not definedname 'BadAtom' is not definedname 'BadCursor' is not definedname 'BadFont' is not definedname 'BadMatch' is not definedname 'BadDrawable' is not definedname 'BadAccess' is not definedname 'BadAlloc' is not definedname 'BadColor' is not definedname 'BadGC' is not definedname 'BadIDChoice' is not definedname 'BadName' is not definedname 'BadLength' is not definedname 'BadImplementation' is not definedlocal variable 'msg' referenced before assignmentlocal variable 'whom' referenced before assignmentlocal variable 'errors' referenced before assignmentlocal variable 'request' referenced before assignmentname '__extensions__' is not definedname 'Record_Range8' is not definedname 'Record_Range16' is not definedname 'Record_ExtRange' is not definedname 'Record_Range' is not definedlocal variable 'val' referenced before assignmentglobal name 'GetVersion' is not definedglobal name 'extname' is not definedlocal variable 'major' referenced before assignmentlocal variable 'minor' referenced before assignmentglobal name 'Record_Range' is not definedglobal name 'CreateContext' is not definedlocal variable 'datum_flags' referenced before assignmentlocal variable 'clients' referenced before assignmentlocal variable 'ranges' referenced before assignmentglobal name 'RegisterClients' is not definedlocal variable 'context' referenced before assignmentlocal variable 'element_header' referenced before assignmentglobal name 'UnregisterClients' is not definedglobal name 'Record_ClientInfo' is not definedglobal name 'GetContext' is not definedglobal name 'RawField' is not definedlocal variable 'callback' referenced before assignmentglobal name 'StartOfData' is not definedglobal name 'EndOfData' is not definedglobal name 'EnableContext' is not definedglobal name 'DisableContext' is not definedglobal name 'FreeContext' is not definedlocal variable 'disp' referenced before assignmentglobal name 'get_version' is not definedglobal name 'create_context' is not definedglobal name 'register_clients' is not definedglobal name 'unregister_clients' is not definedglobal name 'get_context' is not definedglobal name 'enable_context' is not definedglobal name 'disable_context' is not definedglobal name 'free_context' is not definedglobal name 'CurrentCursor' is not definedglobal name 'CompareCursor' is not definedglobal name 'FakeInput' is not definedlocal variable 'event_type' referenced before assignmentlocal variable 'detail' referenced before assignmentlocal variable 'root' referenced before assignmentglobal name 'GrabControl' is not definedlocal variable 'impervious' referenced before assignmentglobal name 'compare_cursor' is not definedglobal name 'fake_input' is not definedglobal name 'grab_control' is not definedname 'VisualType' is not definedname 'Depth' is not definedglobal name 'connect' is not definedlocal variable 'screenno' referenced before assignmentlocal variable 'displayno' referenced before assignmentglobal name 'lock' is not definedglobal name 'ConnectionSetupRequest' is not definedlocal variable 'auth_name' referenced before assignmentlocal variable 'auth_data' referenced before assignmentlocal variable 'rid' referenced before assignmentlocal variable 'class_name' referenced before assignmentlocal variable 'wait_for_response' referenced before assignmentlocal variable 'flush' referenced before assignmentlocal variable 'recv' referenced before assignmentlocal variable 'wait_lock' referenced before assignmentlocal variable 'sending' referenced before assignmentlocal variable 'req' referenced before assignmentlocal variable 'wait' referenced before assignmentlocal variable 'flush_bytes' referenced before assignmentglobal name 'select' is not definedlocal variable 'writeset' referenced before assignmentglobal name 'errno' is not definedlocal variable 'ws' referenced before assignmentlocal variable 'rs' referenced before assignmentlocal variable 'recieving' referenced before assignmentlocal variable 'bytes_recv' referenced before assignmentlocal variable 'gotreq' referenced before assignmentglobal name '_bytes_item' is not definedlocal variable 'etype' referenced before assignmentlocal variable 'adj' referenced before assignmentlocal variable 'last' referenced before assignmentlocal variable 'reqpos' referenced before assignmentlocal variable 'alen' referenced before assignmentglobal name 'PixmapFormat' is not definedglobal name 'Screen' is not definedname 'KeyButtonPointer' is not definedname 'EnterLeave' is not definedname 'Focus' is not definedname 'Circulate' is not definedname 'KeyPress' is not definedname 'KeyRelease' is not definedname 'ButtonPress' is not definedname 'ButtonRelease' is not definedname 'MotionNotify' is not definedname 'EnterNotify' is not definedname 'LeaveNotify' is not definedname 'FocusIn' is not definedname 'FocusOut' is not definedname 'KeymapNotify' is not definedname 'Expose' is not definedname 'GraphicsExpose' is not definedname 'NoExpose' is not definedname 'VisibilityNotify' is not definedname 'CreateNotify' is not definedname 'DestroyNotify' is not definedname 'UnmapNotify' is not definedname 'MapNotify' is not definedname 'MapRequest' is not definedname 'ReparentNotify' is not definedname 'ConfigureNotify' is not definedname 'ConfigureRequest' is not definedname 'GravityNotify' is not definedname 'ResizeRequest' is not definedname 'CirculateNotify' is not definedname 'CirculateRequest' is not definedname 'PropertyNotify' is not definedname 'SelectionClear' is not definedname 'SelectionRequest' is not definedname 'SelectionNotify' is not definedname 'ColormapNotify' is not definedname 'ClientMessage' is not definedname 'MappingNotify' is not definedname 'CreateWindow' is not definedname 'ChangeWindowAttributes' is not definedname 'GetWindowAttributes' is not definedname 'DestroyWindow' is not definedname 'DestroySubWindows' is not definedname 'ChangeSaveSet' is not definedname 'ReparentWindow' is not definedname 'MapWindow' is not definedname 'MapSubwindows' is not definedname 'UnmapWindow' is not definedname 'UnmapSubwindows' is not definedname 'ConfigureWindow' is not definedname 'CirculateWindow' is not definedname 'GetGeometry' is not definedname 'QueryTree' is not definedname 'InternAtom' is not definedname 'GetAtomName' is not definedname 'ChangeProperty' is not definedname 'DeleteProperty' is not definedname 'GetProperty' is not definedname 'ListProperties' is not definedname 'SetSelectionOwner' is not definedname 'GetSelectionOwner' is not definedname 'ConvertSelection' is not definedname 'SendEvent' is not definedname 'GrabPointer' is not definedname 'UngrabPointer' is not definedname 'GrabButton' is not definedname 'UngrabButton' is not definedname 'ChangeActivePointerGrab' is not definedname 'GrabKeyboard' is not definedname 'UngrabKeyboard' is not definedname 'GrabKey' is not definedname 'UngrabKey' is not definedname 'AllowEvents' is not definedname 'GrabServer' is not definedname 'UngrabServer' is not definedname 'QueryPointer' is not definedname 'GetMotionEvents' is not definedname 'TranslateCoords' is not definedname 'WarpPointer' is not definedname 'SetInputFocus' is not definedname 'GetInputFocus' is not definedname 'QueryKeymap' is not definedname 'OpenFont' is not definedname 'CloseFont' is not definedname 'QueryFont' is not definedname 'QueryTextExtents' is not definedname 'ListFonts' is not definedname 'ListFontsWithInfo' is not definedname 'SetFontPath' is not definedname 'GetFontPath' is not definedname 'CreatePixmap' is not definedname 'FreePixmap' is not definedname 'CreateGC' is not definedname 'ChangeGC' is not definedname 'CopyGC' is not definedname 'SetDashes' is not definedname 'SetClipRectangles' is not definedname 'FreeGC' is not definedname 'ClearArea' is not definedname 'CopyArea' is not definedname 'CopyPlane' is not definedname 'PolyPoint' is not definedname 'PolyLine' is not definedname 'PolySegment' is not definedname 'PolyRectangle' is not definedname 'PolyArc' is not definedname 'FillPoly' is not definedname 'PolyFillRectangle' is not definedname 'PolyFillArc' is not definedname 'PutImage' is not definedname 'GetImage' is not definedname 'PolyText8' is not definedname 'PolyText16' is not definedname 'ImageText8' is not definedname 'ImageText16' is not definedname 'CreateColormap' is not definedname 'FreeColormap' is not definedname 'CopyColormapAndFree' is not definedname 'InstallColormap' is not definedname 'UninstallColormap' is not definedname 'ListInstalledColormaps' is not definedname 'AllocColor' is not definedname 'AllocNamedColor' is not definedname 'AllocColorCells' is not definedname 'AllocColorPlanes' is not definedname 'FreeColors' is not definedname 'StoreColors' is not definedname 'StoreNamedColor' is not definedname 'QueryColors' is not definedname 'LookupColor' is not definedname 'CreateCursor' is not definedname 'CreateGlyphCursor' is not definedname 'FreeCursor' is not definedname 'RecolorCursor' is not definedname 'QueryBestSize' is not definedname 'QueryExtension' is not definedname 'ListExtensions' is not definedname 'ChangeKeyboardMapping' is not definedname 'GetKeyboardMapping' is not definedname 'ChangeKeyboardControl' is not definedname 'GetKeyboardControl' is not definedname 'Bell' is not definedname 'ChangePointerControl' is not definedname 'GetPointerControl' is not definedname 'SetScreenSaver' is not definedname 'GetScreenSaver' is not definedname 'ChangeHosts' is not definedname 'ListHosts' is not definedname 'SetAccessControl' is not definedname 'SetCloseDownMode' is not definedname 'KillClient' is not definedname 'RotateProperties' is not definedname 'ForceScreenSaver' is not definedname 'SetPointerMapping' is not definedname 'GetPointerMapping' is not definedname 'SetModifierMapping' is not definedname 'GetModifierMapping' is not definedname 'NoOperation' is not definedglobal name 'structs' is not definedglobal name 'ReplyRequest' is not definedlocal variable 'item' referenced before assignmentname '_PY3' is not definedname 'c' is not definedname 'array_unsigned_codes' is not definedname 'size' is not definedname 'struct_to_array_codes' is not definedname 'signed_codes' is not definedname 'unsigned_codes' is not definedname 'Field' is not definedname 'ConstantField' is not definedname 'LengthField' is not definedname 'TotalLengthField' is not definedname 'FormatField' is not definedname 'ValueField' is not definedname 'Card32' is not definedname 'Resource' is not definedname 'Set' is not definedname 'List' is not definedname 'PropertyData' is not definedname 'ScalarObj' is not definedname 'ResourceObj' is not definedname 'StrClass' is not definedname 'TextElements8' is not definedname 'GetAttrData' is not definedglobal name 'unsigned_codes' is not definedglobal name 'Card32' is not definedglobal name 'ValueField' is not definedglobal name 'Set' is not definedlocal variable 'pad' referenced before assignmentglobal name '_PY3' is not definedlocal variable 'slen' referenced before assignmentlocal variable 'ret' referenced before assignmentlocal variable 'scode' referenced before assignmentglobal name 'struct_to_array_codes' is not definedglobal name 'List' is not definedglobal name 'BadDataError' is not definedglobal name 'DictWrapper' is not definedlocal variable 'vals' referenced before assignmentglobal name 'array_unsigned_codes' is not definedlocal variable 'fmt' referenced before assignmentglobal name 'PropertyData' is not definedlocal variable 'dlen' referenced before assignmentlocal variable 'fields' referenced before assignmentlocal variable 'arg' referenced before assignmentlocal variable 'field' referenced before assignmentglobal name 'Event' is not definedlocal variable 'total_length' referenced before assignmentlocal variable 'joins' referenced before assignmentlocal variable 'pack_args' referenced before assignmentlocal variable 'defargs' referenced before assignmentlocal variable 'kwarg' referenced before assignmentlocal variable 'varargs' referenced before assignmentlocal variable 'vno' referenced before assignmentlocal variable 'fno' referenced before assignmentlocal variable 'rawdict' referenced before assignmentlocal variable 'lengths' referenced before assignmentlocal variable 'formats' referenced before assignmentglobal name 'Struct' is not definedglobal name 'LengthOf' is not definedglobal name 'Int8' is not definedglobal name 'String8' is not definedlocal variable 'delta' referenced before assignmentglobal name 'String16' is not definedglobal name 'call_error_handler' is not definedlocal variable 'defer' referenced before assignmentlocal variable 'binarydata' referenced before assignmentlocal variable 'kwlist' referenced before assignmentname '_parts' is not definedglobal name '_display_mods' is not definedglobal name 'platform' is not definedglobal name '_default_display_mod' is not definedglobal name '_socket_mods' is not definedglobal name '_default_socket_mod' is not definedlocal variable 'dname' referenced before assignmentlocal variable 'dno' referenced before assignmentglobal name '_auth_mods' is not definedglobal name '_default_auth_mod' is not definedlocal variable 'sock' referenced before assignmentname '_DummyLock' is not definedglobal name '_dummy_lock' is not definedname 'resource' is not definedglobal name 'resource' is not definedglobal name 'src_cmap' is not definedglobal name 'Colormap' is not definedglobal name 'rgb_res' is not definedglobal name 'string' is not definedlocal variable 'contiguous' referenced before assignmentlocal variable 'planes' referenced before assignmentlocal variable 'plane_mask' referenced before assignmentlocal variable 'pixels' referenced before assignmentlocal variable 'items' referenced before assignmentlocal variable 'b_rgb' referenced before assignmentlocal variable 'f_rgb' referenced before assignmentlocal variable 'fore_red' referenced before assignmentlocal variable 'fore_green' referenced before assignmentlocal variable 'fore_blue' referenced before assignmentlocal variable 'back_red' referenced before assignmentlocal variable 'back_green' referenced before assignmentlocal variable 'back_blue' referenced before assignmentname 'Drawable' is not definedlocal variable 'depth' referenced before assignmentlocal variable 'width' referenced before assignmentlocal variable 'height' referenced before assignmentglobal name 'Pixmap' is not definedglobal name 'fontable' is not definedlocal variable 'src_drawable' referenced before assignmentlocal variable 'gc' referenced before assignmentlocal variable 'dst_x' referenced before assignmentlocal variable 'dst_y' referenced before assignmentlocal variable 'bit_plane' referenced before assignmentlocal variable 'coord_mode' referenced before assignmentlocal variable 'points' referenced before assignmentlocal variable 'x2' referenced before assignmentlocal variable 'y2' referenced before assignmentlocal variable 'segments' referenced before assignmentlocal variable 'rectangles' referenced before assignmentlocal variable 'arcs' referenced before assignmentlocal variable 'angle1' referenced before assignmentlocal variable 'angle2' referenced before assignmentlocal variable 'left_pad' referenced before assignmentglobal name 'roundup' is not definedlocal variable 'subimage' referenced before assignmentlocal variable 'string' referenced before assignmentlocal variable 'item_class' referenced before assignmentlocal variable 'border_width' referenced before assignmentlocal variable 'window_class' referenced before assignmentlocal variable 'visual' referenced before assignmentglobal name 'Window' is not definedlocal variable 'parent' referenced before assignmentlocal variable 'property' referenced before assignmentlocal variable 'delete' referenced before assignmentlocal variable 'sizehint' referenced before assignmentlocal variable 'target' referenced before assignmentlocal variable 'owner_events' referenced before assignmentlocal variable 'pointer_mode' referenced before assignmentlocal variable 'keyboard_mode' referenced before assignmentlocal variable 'confine_to' referenced before assignmentlocal variable 'button' referenced before assignmentlocal variable 'modifiers' referenced before assignmentlocal variable 'start' referenced before assignmentlocal variable 'stop' referenced before assignmentlocal variable 'exposures' referenced before assignmentlocal variable 'alloc' referenced before assignmentlocal variable 'properties' referenced before assignmentglobal name 'Xatom' is not definedlocal variable 'inst' referenced before assignmentlocal variable 'window' referenced before assignmentlocal variable 'protocols' referenced before assignmentlocal variable 'windows' referenced before assignmentglobal name 'icccm' is not definedlocal variable 'hints' referenced before assignmentlocal variable 'pname' referenced before assignmentlocal variable 'ptype' referenced before assignmentlocal variable 'pstruct' referenced before assignmentglobal name 'cursor' is not definedlocal variable 'unit' referenced before assignmentname 'Fontable' is not definedlocal variable 'src_gc' referenced before assignmentlocal variable 'dashes' referenced before assignmentlocal variable 'ordering' referenced before assignmentlocal variable 'x_origin' referenced before assignmentlocal variable 'y_origin' referenced before assignmentlocal variable 'source_char' referenced before assignmentlocal variable 'mask_char' referenced before assignmentname 'Aspect' is not definedname 'Xutil' is not definedlocal variable 'owner' referenced before assignmentglobal name 'Resource' is not definedlocal variable 'star_arg_list' referenced before assignmentlocal variable 'called' referenced before assignmentlocal variable 'star_arg_dict' referenced before assignmentname 'PyKeyboard' is not definedname 'MatlabSender' is not definedname 'list' is not definedname 'devices' is not definedname 'serial' is not definedname 'd' is not definedname 'time' is not definedname 's' is not definedname 'aux' is not definedname 'p2m' is not definedname 'scipy' is not definedname 'a' is not definedname 'i' is not definedname 'integrate' is not definedname 'pos' is not definedglobal name 'compile' is not definedname 'python_implementation' is not definedname '_VARS' is not definedname 'var' is not definedname 'ast' is not definedname 'weakref' is not definedglobal name '_VARS' is not definedglobal name 'ast' is not definedlocal variable 'ALLOWED' referenced before assignmentlocal variable 'statement' referenced before assignmentlocal variable 'node' referenced before assignmentglobal name 'ASTWhitelist' is not definedglobal name '_builtin_compile' is not definedlocal variable 'parsed_marker' referenced before assignmentglobal name '_cache' is not definedglobal name 'compile_marker' is not definedglobal name 'parse_marker' is not definedlocal variable 'override' referenced before assignmentlocal variable 'environment' referenced before assignmentglobal name 'default_environment' is not definedlocal variable 'compiled_marker' referenced before assignmentname '_GeneratorContextManager' is not definedname '__call__' is not definedname 'GeneratorContextManager' is not definedname '__init__' is not definedname 'decorator' is not definedname 'ContextManager' is not definedglobal name 'inspect' is not definedlocal variable 'signature' referenced before assignmentlocal variable 'func' referenced before assignmentglobal name 'getfullargspec' is not definedlocal variable 'argspec' referenced before assignmentlocal variable 'allargs' referenced before assignmentlocal variable 'allshortargs' referenced before assignmentlocal variable 'defaults' referenced before assignmentlocal variable 'doc' referenced before assignmentlocal variable 'module' referenced before assignmentlocal variable 'funcdict' referenced before assignmentlocal variable 'src_templ' referenced before assignmentlocal variable 'evaldict' referenced before assignmentname 'DEF' is not definedlocal variable 'src' referenced before assignmentlocal variable 'addsource' referenced before assignmentlocal variable 'attrs' referenced before assignmentlocal variable 'rest' referenced before assignmentlocal variable 'body' referenced before assignmentlocal variable 'caller' referenced before assignmentglobal name 'FunctionMaker' is not definedglobal name 'get_init' is not definedlocal variable 'callerfunc' referenced before assignmentglobal name 'decorator' is not definedlocal variable 'fun' referenced before assignmentglobal name 'GeneratorContextManager' is not definedname '__NUMPY_SETUP__' is not definedname '_sys' is not definedname 'msg' is not definedname 'PackageLoader' is not definedname 'pkgload' is not definedname 'Tester' is not definedname 'str' is not definedname '__all__' is not definedname '_mat' is not definedname 'lib' is not definedglobal name 'PackageLoader' is not definedlocal variable 'packages' referenced before assignmentlocal variable 'info_dict' referenced before assignmentname 'PackageLoaderDebug' is not definedlocal variable 'infunc' referenced before assignmentlocal variable 'parent_path' referenced before assignmentlocal variable 'package_dir' referenced before assignmentlocal variable 'files' referenced before assignmentlocal variable 'parent_package' referenced before assignmentlocal variable 'info_files' referenced before assignmentlocal variable 'package_name' referenced before assignmentname 'info' is not definedlocal variable 'info_modules' referenced before assignmentlocal variable 'info_file' referenced before assignmentlocal variable 'imp' referenced before assignmentlocal variable 'info_module' referenced before assignmentlocal variable 'depend_dict' referenced before assignmentlocal variable 'package_names' referenced before assignmentlocal variable 'lst' referenced before assignmentlocal variable 'new_lst' referenced before assignmentlocal variable 'postpone' referenced before assignmentlocal variable 'postpone_import' referenced before assignmentlocal variable 'verbose' referenced before assignmentlocal variable 'new_object' referenced before assignmentlocal variable 'old_object' referenced before assignmentlocal variable 'global_symbols' referenced before assignmentlocal variable 'symbols' referenced before assignmentlocal variable 'old_objects' referenced before assignmentlocal variable 'symbol' referenced before assignmentlocal variable 'cmdstr' referenced before assignmentlocal variable 'mess' referenced before assignmentlocal variable 'titles' referenced before assignmentlocal variable 'max_length' referenced before assignmentlocal variable 'colsep' referenced before assignmentlocal variable 'line' referenced before assignmentlocal variable 'display_window_width' referenced before assignmentlocal variable 'sys' referenced before assignmentlocal variable 'retstr' referenced before assignmentname 'add_newdoc' is not definedname '_inspect' is not definedname 'py3k' is not definedname 'joinseq' is not definedglobal name 'iscode' is not definedlocal variable 'co' referenced before assignmentlocal variable 'step' referenced before assignmentglobal name 'dis' is not definedlocal variable 'remain' referenced before assignmentlocal variable 'stack' referenced before assignmentlocal variable 'names' referenced before assignmentglobal name 'CO_VARARGS' is not definedlocal variable 'nargs' referenced before assignmentglobal name 'CO_VARKEYWORDS' is not definedglobal name 'ismethod' is not definedglobal name 'isfunction' is not definedglobal name 'getargs' is not definedlocal variable 'varkw' referenced before assignmentlocal variable 'seq' referenced before assignmentlocal variable 'join' referenced before assignmentglobal name 'strseq' is not definedlocal variable 'convert' referenced before assignmentlocal variable 'formatarg' referenced before assignmentlocal variable 'firstdefault' referenced before assignmentlocal variable 'spec' referenced before assignmentlocal variable 'formatvalue' referenced before assignmentlocal variable 'specs' referenced before assignmentlocal variable 'formatvarargs' referenced before assignmentlocal variable 'formatvarkw' referenced before assignmentlocal variable 'locals' referenced before assignmentname 'bytes' is not definedname 'long' is not definedname 'basestring' is not definedname 'unicode' is not definedglobal name 'bytes' is not definedglobal name 'unicode' is not definedglobal name 'asbytes_nested' is not definedglobal name 'asbytes' is not definedglobal name 'asunicode_nested' is not definedglobal name 'asunicode' is not definedname 'multiarray' is not definedname 'nt' is not definedname 'numeric' is not definedname 'fromnumeric' is not definedname 'rec' is not definedname 'function_base' is not definedname 'machar' is not definedname 'getlimits' is not definedname 'shape_base' is not definedname 'copyreg' is not definedname 'ufunc' is not definedname '_ufunc_reduce' is not definedname '_ufunc_reconstruct' is not definedglobal name '_ufunc_reconstruct' is not definedname '_nbo' is not definedname '_getintp_ctype' is not definedname '_pep3118_native_map' is not definedname '_pep3118_standard_map' is not definedlocal variable 'adict' referenced before assignmentlocal variable 'fname' referenced before assignmentlocal variable 'dtype' referenced before assignmentlocal variable 'align' referenced before assignmentlocal variable 'allfields' referenced before assignmentglobal name '_makenames_list' is not definedlocal variable 'descriptor' referenced before assignmentglobal name '_array_descr' is not definedlocal variable 'ordered_fields' referenced before assignmentlocal variable 'tup' referenced before assignmentlocal variable 'subtype' referenced before assignmentlocal variable 'startindex' referenced before assignmentlocal variable 'astr' referenced before assignmentglobal name 'format_re' is not definedlocal variable 'mo' referenced before assignmentglobal name 'space_re' is not definedglobal name 'sep_re' is not definedlocal variable 'order2' referenced before assignmentlocal variable 'order1' referenced before assignmentglobal name '_convorder' is not definedglobal name '_nbo' is not definedlocal variable 'repeats' referenced before assignmentglobal name '_getintp_ctype' is not definedlocal variable 'num' referenced before assignmentglobal name '_missing_ctypes' is not definedlocal variable 'array' referenced before assignmentlocal variable 'ptr' referenced before assignmentlocal variable 'datatype' referenced before assignmentlocal variable 'nameslist' referenced before assignmentlocal variable 'ary' referenced before assignmentlocal variable 'dt' referenced before assignmentlocal variable 'byteorder' referenced before assignmentglobal name '_pep3118_native_map' is not definedglobal name '_pep3118_native_typechars' is not definedglobal name '_pep3118_standard_map' is not definedglobal name '_pep3118_standard_typechars' is not definedlocal variable 'j' referenced before assignmentglobal name '_dtype_from_pep3118' is not definedlocal variable 'type_map_chars' referenced before assignmentlocal variable 'type_map' referenced before assignmentlocal variable 'dtypechar' referenced before assignmentlocal variable 'intra_padding' referenced before assignmentlocal variable 'itemsize' referenced before assignmentglobal name '_prod' is not definedglobal name '_add_trailing_padding' is not definedlocal variable 'extra_offset' referenced before assignmentlocal variable 'common_alignment' referenced before assignmentglobal name '_gcd' is not definedlocal variable 'get_dummy_name' referenced before assignmentlocal variable 'is_padding' referenced before assignmentlocal variable 'this_explicit_name' referenced before assignmentlocal variable 'next_dummy_name' referenced before assignmentlocal variable 'next_byteorder' referenced before assignmentlocal variable 'explicit_name' referenced before assignmentlocal variable 'is_subdtype' referenced before assignmentlocal variable 'padding' referenced before assignmentlocal variable 'dummy_name_index' referenced before assignmentlocal variable 'vfields' referenced before assignmentglobal name 'um' is not definedlocal variable 'axis' referenced before assignmentlocal variable 'keepdims' referenced before assignmentglobal name 'asanyarray' is not definedglobal name '_count_reduce_items' is not definedglobal name 'nt' is not definedglobal name 'mu' is not definedlocal variable 'rcount' referenced before assignmentlocal variable 'ddof' referenced before assignmentglobal name '_var' is not definedlocal variable 'linewidth' referenced before assignmentlocal variable 'edgeitems' referenced before assignmentlocal variable 'precision' referenced before assignmentlocal variable 'suppress' referenced before assignmentlocal variable 'nanstr' referenced before assignmentlocal variable 'infstr' referenced before assignmentlocal variable 'formatter' referenced before assignmentglobal name '_float_output_precision' is not definedglobal name '_summaryThreshold' is not definedglobal name '_summaryEdgeItems' is not definedglobal name '_line_width' is not definedglobal name '_float_output_suppress_small' is not definedglobal name '_nan_str' is not definedglobal name '_inf_str' is not definedglobal name '_formatter' is not definedglobal name '_leading_trailing' is not definedlocal variable '_nc' referenced before assignmentlocal variable 'max_line_width' referenced before assignmentlocal variable 'suppress_small' referenced before assignmentglobal name 'ravel' is not definedglobal name '_boolFormatter' is not definedglobal name 'IntegerFormat' is not definedglobal name 'FloatFormat' is not definedglobal name 'LongFloatFormat' is not definedglobal name 'ComplexFormat' is not definedglobal name 'LongComplexFormat' is not definedglobal name 'DatetimeFormat' is not definedglobal name 'TimedeltaFormat' is not definedglobal name 'repr_format' is not definedlocal variable 'fkeys' referenced before assignmentlocal variable 'formatdict' referenced before assignmentglobal name '_nt' is not definedglobal name '_formatArray' is not definedlocal variable 'format_function' referenced before assignmentlocal variable 'next_line_prefix' referenced before assignmentlocal variable 'separator' referenced before assignmentlocal variable 'summary_insert' referenced before assignmentglobal name '_convert_arrays' is not definedlocal variable 'newtup' referenced before assignmentlocal variable 'style' referenced before assignmentglobal name 'product' is not definedglobal name '_array2string' is not definedlocal variable 'word' referenced before assignmentlocal variable 'max_line_len' referenced before assignmentlocal variable 'edge_items' referenced before assignmentlocal variable 'leading_items' referenced before assignmentglobal name '_extendLine' is not definedlocal variable 'summary_insert1' referenced before assignmentlocal variable 'trailing_items' referenced before assignmentlocal variable 'sep' referenced before assignmentlocal variable 'sign' referenced before assignmentglobal name 'isnan' is not definedglobal name 'isinf' is not definedglobal name 'not_equal' is not definedglobal name 'absolute' is not definedglobal name 'maximum' is not definedglobal name 'minimum' is not definedlocal variable 'min_val' referenced before assignmentlocal variable 'max_val' referenced before assignmentlocal variable 'non_zero' referenced before assignmentglobal name '_digits' is not definedlocal variable 'special' referenced before assignmentlocal variable 'strip_zeros' referenced before assignmentglobal name '_MININT' is not definedglobal name '_MAXINT' is not definedglobal name 'format_longfloat' is not definedglobal name 'datetime_data' is not definedlocal variable 'timezone' referenced before assignmentlocal variable 'casting' referenced before assignmentglobal name 'datetime_as_string' is not definedname 'ndarray' is not definedglobal name '_unicode' is not definedglobal name 'numpy' is not definedglobal name 'unicode_' is not definedglobal name 'string_' is not definedlocal variable 'newargs' referenced before assignmentglobal name 'compare_chararrays' is not definedglobal name '_vec_string' is not definedglobal name 'integer' is not definedglobal name '_get_num_chars' is not definedglobal name '_use_unicode' is not definedglobal name 'long' is not definedglobal name '_to_string_or_unicode_array' is not definedglobal name 'object_' is not definedlocal variable 'fillchar' referenced before assignmentlocal variable 'sub' referenced before assignmentglobal name '_clean_args' is not definedlocal variable 'end' referenced before assignmentlocal variable 'encoding' referenced before assignmentglobal name 'bool_' is not definedlocal variable 'suffix' referenced before assignmentlocal variable 'tabsize' referenced before assignmentlocal variable 'old' referenced before assignmentlocal variable 'maxsplit' referenced before assignmentlocal variable 'keepends' referenced before assignmentlocal variable 'deletechars' referenced before assignmentglobal name 'ndarray' is not definedlocal variable 'unicode' referenced before assignmentlocal variable 'buffer' referenced before assignmentlocal variable 'filler' referenced before assignmentglobal name '_globalvar' is not definedglobal name 'character' is not definedglobal name '_len' is not definedglobal name 'equal' is not definedglobal name 'greater_equal' is not definedglobal name 'less_equal' is not definedglobal name 'greater' is not definedglobal name 'less' is not definedglobal name 'asarray' is not definedglobal name 'add' is not definedglobal name 'multiply' is not definedglobal name 'mod' is not definedlocal variable 'kind' referenced before assignmentglobal name 'capitalize' is not definedglobal name 'center' is not definedglobal name 'count' is not definedglobal name 'decode' is not definedglobal name 'encode' is not definedglobal name 'endswith' is not definedglobal name 'expandtabs' is not definedglobal name 'find' is not definedglobal name 'index' is not definedglobal name 'isalnum' is not definedglobal name 'isalpha' is not definedglobal name 'isdigit' is not definedglobal name 'islower' is not definedglobal name 'isspace' is not definedglobal name 'istitle' is not definedglobal name 'isupper' is not definedglobal name 'join' is not definedglobal name 'ljust' is not definedglobal name 'lower' is not definedglobal name 'lstrip' is not definedglobal name 'partition' is not definedglobal name 'replace' is not definedglobal name 'rfind' is not definedglobal name 'rindex' is not definedglobal name 'rjust' is not definedglobal name 'rpartition' is not definedglobal name 'rsplit' is not definedglobal name 'rstrip' is not definedglobal name 'split' is not definedglobal name 'splitlines' is not definedglobal name 'startswith' is not definedglobal name 'strip' is not definedglobal name 'swapcase' is not definedglobal name 'title' is not definedglobal name 'translate' is not definedglobal name 'upper' is not definedglobal name 'zfill' is not definedglobal name 'isnumeric' is not definedglobal name 'isdecimal' is not definedglobal name '_bytes' is not definedglobal name 'chararray' is not definedlocal variable 'copy' referenced before assignmentglobal name 'narray' is not definedname 'sum' is not definedlocal variable 'kwds' referenced before assignmentlocal variable 'wrap' referenced before assignmentglobal name '_wrapit' is not definedlocal variable 'take' referenced before assignmentlocal variable 'newshape' referenced before assignmentlocal variable 'reshape' referenced before assignmentlocal variable 'choices' referenced before assignmentlocal variable 'choose' referenced before assignmentlocal variable 'repeat' referenced before assignmentlocal variable 'ind' referenced before assignmentlocal variable 'axis1' referenced before assignmentlocal variable 'axis2' referenced before assignmentlocal variable 'swapaxes' referenced before assignmentlocal variable 'axes' referenced before assignmentlocal variable 'transpose' referenced before assignmentlocal variable 'kth' referenced before assignmentlocal variable 'argsort' referenced before assignmentlocal variable 'argmax' referenced before assignmentlocal variable 'argmin' referenced before assignmentlocal variable 'side' referenced before assignmentlocal variable 'sorter' referenced before assignmentlocal variable 'searchsorted' referenced before assignmentlocal variable 'new_shape' referenced before assignmentglobal name 'concatenate' is not definedglobal name 'reshape' is not definedlocal variable 'squeeze' referenced before assignmentlocal variable 'nonzero' referenced before assignmentlocal variable 'res' referenced before assignmentlocal variable 'condition' referenced before assignmentlocal variable 'compress' referenced before assignmentlocal variable 'a_min' referenced before assignmentlocal variable 'a_max' referenced before assignmentlocal variable 'clip' referenced before assignmentglobal name '_gentype' is not definedglobal name '_sum_' is not definedglobal name '_methods' is not definedlocal variable 'sum' referenced before assignmentlocal variable 'cumsum' referenced before assignmentlocal variable 'cumprod' referenced before assignmentlocal variable 'ptp' referenced before assignmentlocal variable 'amax' referenced before assignmentlocal variable 'amin' referenced before assignmentlocal variable 'prod' referenced before assignmentlocal variable 'decimals' referenced before assignmentlocal variable 'round' referenced before assignmentlocal variable 'endpoint' referenced before assignmentglobal name '_nx' is not definedlocal variable 'retstep' referenced before assignmentglobal name 'linspace' is not definedname 'ntypes' is not definedglobal name 'numeric' is not definedglobal name '_convert_to_float' is not definedglobal name 'ntypes' is not definedglobal name 'MachAr' is not definedlocal variable 'precname' referenced before assignmentlocal variable 'machar' referenced before assignmentglobal name '_frz' is not definedlocal variable 'itype' referenced before assignmentlocal variable 'int_type' referenced before assignmentglobal name 'iinfo' is not definedglobal name 'errstate' is not definedlocal variable 'float_conv' referenced before assignmentlocal variable 'int_conv' referenced before assignmentlocal variable 'float_to_float' referenced before assignmentlocal variable 'float_to_str' referenced before assignmentlocal variable 'one' referenced before assignmentglobal name 'any' is not definedlocal variable 'zero' referenced before assignmentlocal variable '_' referenced before assignmentlocal variable 'max_iterN' referenced before assignmentlocal variable 'itemp' referenced before assignmentlocal variable 'it' referenced before assignmentlocal variable 'beta' referenced before assignmentlocal variable 'two' referenced before assignmentlocal variable 'betah' referenced before assignmentlocal variable 'betain' referenced before assignmentlocal variable 'negep' referenced before assignmentlocal variable 'machep' referenced before assignmentlocal variable 'irnd' referenced before assignmentlocal variable 'eps' referenced before assignmentlocal variable 'z' referenced before assignmentlocal variable 'temp' referenced before assignmentlocal variable 'ibeta' referenced before assignmentlocal variable 'iz' referenced before assignmentlocal variable 'iexp' referenced before assignmentlocal variable 'mx' referenced before assignmentlocal variable 'minexp' referenced before assignmentlocal variable 'nxres' referenced before assignmentlocal variable 'maxexp' referenced before assignmentlocal variable 'epsneg' referenced before assignmentlocal variable 'xmin' referenced before assignmentlocal variable 'xmax' referenced before assignmentlocal variable 'ngrd' referenced before assignmentname 'dtype' is not definedglobal name 'uint8' is not definedglobal name 'mode_equivalents' is not definedglobal name 'valid_filemodes' is not definedlocal variable 'fid' referenced before assignmentglobal name 'dtypedescr' is not definedlocal variable '_dbytes' referenced before assignmentlocal variable 'flen' referenced before assignmentlocal variable 'bytes' referenced before assignmentglobal name 'np' is not definedlocal variable 'mmap' referenced before assignmentlocal variable 'acc' referenced before assignmentlocal variable 'descr' referenced before assignmentglobal name 'basestring' is not definedlocal variable 'own_file' referenced before assignmentname 'pickle' is not definedname 'invert' is not definedname 'extend_all' is not definedname 'umath' is not definedname 'numerictypes' is not definedname 'int_' is not definedname 'float_' is not definedname 'complex_' is not definedname 'intc' is not definedname '_typelessdata' is not definedname 'longlong' is not definedname 'set_string_function' is not definedname 'array_str' is not definedname 'array_repr' is not definedname 'ERR_IGNORE' is not definedname 'ERR_WARN' is not definedname 'ERR_RAISE' is not definedname 'ERR_CALL' is not definedname 'ERR_PRINT' is not definedname 'ERR_LOG' is not definedname '_errdict' is not definedname 'key' is not definedname '_errdict_rev' is not definedname '_unspecified' is not definedname '_setdef' is not definedname 'PINF' is not definedname 'NAN' is not definedglobal name 'empty_like' is not definedlocal variable 'subok' referenced before assignmentglobal name 'multiarray' is not definedglobal name 'empty' is not definedlocal variable 'fill_value' referenced before assignmentglobal name '__all__' is not definedlocal variable 'mall' referenced before assignmentlocal variable 'requirements' referenced before assignmentlocal variable 'copychar' referenced before assignmentglobal name 'transpose' is not definedglobal name '_mode_from_name_dict' is not definedglobal name '_mode_from_name' is not definedlocal variable 'old_behavior' referenced before assignmentglobal name 'newaxis' is not definedglobal name 'dot' is not definedlocal variable 'axes_a' referenced before assignmentlocal variable 'axes_b' referenced before assignmentlocal variable 'na' referenced before assignmentlocal variable 'nb' referenced before assignmentlocal variable 'as_' referenced before assignmentlocal variable 'bs' referenced before assignmentlocal variable 'nda' referenced before assignmentlocal variable 'ndb' referenced before assignmentlocal variable 'equal' referenced before assignmentlocal variable 'notin' referenced before assignmentlocal variable 'N2' referenced before assignmentlocal variable 'newaxes_a' referenced before assignmentlocal variable 'newshape_a' referenced before assignmentlocal variable 'newaxes_b' referenced before assignmentlocal variable 'newshape_b' referenced before assignmentlocal variable 'olda' referenced before assignmentlocal variable 'oldb' referenced before assignmentlocal variable 'shift' referenced before assignmentglobal name 'arange' is not definedglobal name 'rollaxis' is not definedlocal variable 'axisa' referenced before assignmentlocal variable 'axisb' referenced before assignmentlocal variable 'axisc' referenced before assignmentglobal name 'array2string' is not definedglobal name '_typelessdata' is not definedlocal variable 'skipdtype' referenced before assignmentlocal variable 'cName' referenced before assignmentlocal variable 'typename' referenced before assignmentglobal name 'flexible' is not definedlocal variable 'repr' referenced before assignmentglobal name 'array_repr' is not definedglobal name 'array_str' is not definedlocal variable 'dimensions' referenced before assignmentlocal variable 'dim' referenced before assignmentlocal variable 'N' referenced before assignmentglobal name 'zeros' is not definedlocal variable 'kwargs' referenced before assignmentglobal name 'indices' is not definedglobal name 'generic' is not definedglobal name 'ScalarType' is not definedglobal name '_lkup' is not definedlocal variable 'number' referenced before assignmentglobal name 'pickle' is not definedglobal name 'dtype' is not definedglobal name '_maketup' is not definedlocal variable 'xinf' referenced before assignmentlocal variable 'yinf' referenced before assignmentlocal variable 'atol' referenced before assignmentlocal variable 'rtol' referenced before assignmentglobal name 'isfinite' is not definedlocal variable 'within_tol' referenced before assignmentlocal variable 'xfin' referenced before assignmentlocal variable 'yfin' referenced before assignmentglobal name 'zeros_like' is not definedglobal name 'ones_like' is not definedlocal variable 'equal_nan' referenced before assignmentglobal name 'isscalar' is not definedlocal variable 'a1' referenced before assignmentlocal variable 'a2' referenced before assignmentglobal name 'umath' is not definedglobal name 'geterr' is not definedlocal variable 'divide' referenced before assignmentlocal variable 'all' referenced before assignmentlocal variable 'over' referenced before assignmentlocal variable 'under' referenced before assignmentlocal variable 'invalid' referenced before assignmentglobal name '_errdict' is not definedglobal name 'SHIFT_DIVIDEBYZERO' is not definedglobal name 'SHIFT_OVERFLOW' is not definedglobal name 'SHIFT_UNDERFLOW' is not definedglobal name 'SHIFT_INVALID' is not definedlocal variable 'pyvals' referenced before assignmentglobal name '_errdict_rev' is not definedglobal name 'getbufsize' is not definedglobal name 'geterrcall' is not definedglobal name '_Unspecified' is not definedglobal name 'seterr' is not definedglobal name 'seterrcall' is not definedglobal name 'UFUNC_BUFSIZE_DEFAULT' is not definedglobal name 'ERR_DEFAULT2' is not definedname '_m' is not definedname '_all_chars' is not definedname '_ascii_lower' is not definedname '_ascii_upper' is not definedname '_add_types' is not definedname '_add_aliases' is not definedname '_add_integer_aliases' is not definedname 'allTypes' is not definedname '_set_up_aliases' is not definedname '_construct_char_code_lookup' is not definedname 'bool' is not definedname 'object' is not definedname 'void' is not definedname '_set_array_types' is not definedname '_types' is not definedname 'int' is not definedname 'float' is not definedname 'complex' is not definedname 'buffer_type' is not definedname '_typedict' is not definedname '_construct_lookups' is not definedname '_sctype2char_dict' is not definedname 'cast' is not definedname '_typestr' is not definedname 'val' is not definedname 'sctypeDict' is not definedname '_toadd' is not definedname 'name' is not definedname 'sctypeNA' is not definedname 'typecodes' is not definedname '__test_types' is not definedglobal name 'LOWER_TABLE' is not definedglobal name 'UPPER_TABLE' is not definedglobal name 'english_upper' is not definedglobal name 'int' is not definedglobal name 'typeinfo' is not definedglobal name '_evalname' is not definedlocal variable 'char' referenced before assignmentglobal name 'english_lower' is not definedglobal name 'allTypes' is not definedglobal name 'sctypeDict' is not definedglobal name 'bitname' is not definedlocal variable 'bit' referenced before assignmentlocal variable 'myname' referenced before assignmentlocal variable 'typeobj' referenced before assignmentglobal name 'english_capitalize' is not definedglobal name 'sctypeNA' is not definedlocal variable 'na_name' referenced before assignmentlocal variable 'alias' referenced before assignmentglobal name '_sctype2char_dict' is not definedglobal name 'sctypes' is not definedglobal name '_add_array_type' is not definedlocal variable 'fbytes' referenced before assignmentlocal variable 'indx' referenced before assignmentlocal variable '_gi' referenced before assignmentglobal name 'obj2sctype' is not definedglobal name '_python_types' is not definedglobal name '_types' is not definedlocal variable 'rep' referenced before assignmentglobal name '_python_type' is not definedlocal variable 'arg1' referenced before assignmentlocal variable 'arg2' referenced before assignmentglobal name 'issubclass_' is not definedglobal name 'nbytes' is not definedglobal name '_alignment' is not definedglobal name '_maxvals' is not definedglobal name '_minvals' is not definedlocal variable 'sctype' referenced before assignmentglobal name '__test_types' is not definedglobal name '_can_coerce_all' is not definedlocal variable 'thisind' referenced before assignmentlocal variable 'dtypelist' referenced before assignmentglobal name '__len_test_types' is not definedlocal variable 'newdtype' referenced before assignmentlocal variable 'array_types' referenced before assignmentlocal variable 'scalar_types' referenced before assignmentglobal name '_kind_list' is not definedlocal variable 'index_sc' referenced before assignmentlocal variable 'index_a' referenced before assignmentglobal name '_find_common_coerce' is not definedlocal variable 'maxsc' referenced before assignmentlocal variable 'maxa' referenced before assignmentname 'sb' is not definedlocal variable 'list' referenced before assignmentlocal variable 'dup' referenced before assignmentlocal variable 'aligned' referenced before assignmentglobal name 'sb' is not definedglobal name 'find_duplicate' is not definedglobal name '_byteorderconv' is not definedlocal variable 'rows' referenced before assignmentglobal name 'format_parser' is not definedlocal variable 'buf' referenced before assignmentglobal name 'record' is not definedlocal variable 'fielddict' referenced before assignmentlocal variable 'exctype' referenced before assignmentlocal variable 'newattr' referenced before assignmentlocal variable 'arrayList' referenced before assignmentglobal name '_typestr' is not definedglobal name 'recarray' is not definedlocal variable '_array' referenced before assignmentlocal variable '_names' referenced before assignmentlocal variable 'recList' referenced before assignmentlocal variable 'nfields' referenced before assignmentglobal name 'fromarrays' is not definedlocal variable 'arrlist' referenced before assignmentlocal variable 'retval' referenced before assignmentlocal variable 'datastring' referenced before assignmentlocal variable 'fd' referenced before assignmentlocal variable 'fn' referenced before assignmentglobal name 'get_remaining_size' is not definedglobal name 'isfileobj' is not definedglobal name 'fromstring' is not definedglobal name 'fromrecords' is not definedglobal name 'fromfile' is not definedlocal variable 'arys' referenced before assignmentglobal name 'atleast_2d' is not definedglobal name 'atleast_1d' is not definedlocal variable 'arrs' referenced before assignmentname 'ctypes' is not definedname '_dummy' is not definedname 'nic' is not definedname 'deprecate' is not definedname 'load_library' is not definedname '_ndptr_base' is not definedname 'ct' is not definedname 'simple_types' is not definedname 'prep_simple' is not definedname 'tp' is not definedname 'code' is not definedglobal name 'ctypes' is not definedlocal variable 'libname' referenced before assignmentlocal variable 'loader_path' referenced before assignmentlocal variable 'libname_ext' referenced before assignmentlocal variable 'libdir' referenced before assignmentlocal variable 'flaglist' referenced before assignmentglobal name '_flagdict' is not definedglobal name '_flagnames' is not definedglobal name '_flags_fromnum' is not definedglobal name '_dtype' is not definedglobal name 'flagsobj' is not definedglobal name '_num_fromflags' is not definedglobal name '_pointer_type_cache' is not definedlocal variable 'strshape' referenced before assignmentglobal name '_ndptr' is not definedlocal variable 'simple_type' referenced before assignmentglobal name '_typecodes' is not definedglobal name 'ct' is not definedlocal variable 'array_type' referenced before assignmentlocal variable 'ob' referenced before assignmentglobal name '_ARRAY_TYPE' is not definedlocal variable 'pointer_obj' referenced before assignmentglobal name 'prep_pointer' is not definedglobal name 'prep_array' is not definedlocal variable 'tp' referenced before assignmentlocal variable 'ai' referenced before assignmentlocal variable 'addr' referenced before assignmentname '_INSTALLED' is not definedname 'replace_method' is not definedname 'CCompiler' is not definedname 'CCompiler_spawn' is not definedname 'CCompiler_object_filenames' is not definedname 'CCompiler_compile' is not definedname 'CCompiler_customize_cmd' is not definedname 'CCompiler_show_customization' is not definedname 'CCompiler_customize' is not definedname 'CCompiler_get_version' is not definedname 'CCompiler_cxx_compiler' is not definedname 'compiler_class' is not definedname 'ccompiler' is not definedname 'mingw32' is not definedname 'new_compiler' is not definedname 'gen_lib_options' is not definedname '_cc' is not definedname 'gen_preprocess_options' is not definedname 'split_quoted' is not definedlocal variable 'klass' referenced before assignmentlocal variable 'method_name' referenced before assignmentlocal variable 'cmd' referenced before assignmentglobal name 'is_sequence' is not definedglobal name 'exec_command' is not definedglobal name 'DistutilsExecError' is not definedlocal variable 'output_dir' referenced before assignmentlocal variable 'source_filenames' referenced before assignmentglobal name 'UnknownFileError' is not definedlocal variable 'src_name' referenced before assignmentlocal variable 'strip_dir' referenced before assignmentlocal variable 'obj_names' referenced before assignmentlocal variable 'sources' referenced before assignmentlocal variable 'macros' referenced before assignmentlocal variable 'include_dirs' referenced before assignmentlocal variable 'depends' referenced before assignmentlocal variable 'extra_postargs' referenced before assignmentlocal variable 'pp_opts' referenced before assignmentlocal variable 'debug' referenced before assignmentlocal variable 'extra_preargs' referenced before assignmentlocal variable 'FCompiler' referenced before assignmentlocal variable 'build' referenced before assignmentlocal variable 'objects' referenced before assignmentlocal variable 'objects_to_build' referenced before assignmentglobal name 'cyg2win32' is not definedlocal variable 'cc_args' referenced before assignmentlocal variable 'allow' referenced before assignmentlocal variable 'ignore' referenced before assignmentlocal variable 'compiler' referenced before assignmentlocal variable 'props' referenced before assignmentglobal name '_compiler_to_string' is not definedglobal name 'customize_compiler' is not definedlocal variable 'need_cxx' referenced before assignmentlocal variable 'version_string' referenced before assignmentlocal variable 'pat' referenced before assignmentlocal variable 'force' referenced before assignmentlocal variable 'version_cmd' referenced before assignmentlocal variable 'status' referenced before assignmentlocal variable 'ok_status' referenced before assignmentlocal variable 'matcher' referenced before assignmentlocal variable 'output' referenced before assignmentglobal name 'LooseVersion' is not definedglobal name 'copy' is not definedlocal variable 'cxx' referenced before assignmentlocal variable 'plat' referenced before assignmentglobal name 'get_default_compiler' is not definedglobal name 'compiler_class' is not definedglobal name 'DistutilsPlatformError' is not definedlocal variable 'module_name' referenced before assignmentglobal name 'get_exception' is not definedglobal name 'DistutilsModuleError' is not definedlocal variable 'dry_run' referenced before assignmentglobal name 'quote_args' is not definedlocal variable 'library_dirs' referenced before assignmentlocal variable 'runtime_library_dirs' referenced before assignmentglobal name '_distutils_gen_lib_options' is not definedlocal variable 'libraries' referenced before assignmentlocal variable 'lib_opts' referenced before assignmentglobal name '_distutils_gen_preprocess_options' is not definedglobal name '_wordchars_re' is not definedglobal name '_squote_re' is not definedglobal name '_dquote_re' is not definedglobal name '_has_white_re' is not definedlocal variable 'beg' referenced before assignmentlocal variable 'words' referenced before assignmentname 'distutils_all' is not definedglobal name 'assert_raises' is not definedname 'old_bdist_rpm' is not definedglobal name 'old_bdist_rpm' is not definedlocal variable 'setup_py' referenced before assignmentlocal variable 'new_spec_file' referenced before assignmentname 'old_build' is not definedglobal name 'old_build' is not definedglobal name 'show_fortran_compilers' is not definedglobal name 'get_platform' is not definedname 'old_build_clib' is not definedname '_l' is not definedname '_i' is not definedglobal name 'old_build_clib' is not definedglobal name 'has_f_sources' is not definedlocal variable 'build_info' referenced before assignmentglobal name 'has_cxx_sources' is not definedlocal variable 'languages' referenced before assignmentglobal name 'shutil' is not definedlocal variable 'filenames' referenced before assignmentglobal name 'get_lib_source_files' is not definedlocal variable 'lib_name' referenced before assignmentglobal name 'DistutilsSetupError' is not definedglobal name 'filter_sources' is not definedlocal variable 'fmodule_sources' referenced before assignmentlocal variable 'c_sources' referenced before assignmentlocal variable 'cxx_sources' referenced before assignmentlocal variable 'requiref90' referenced before assignmentlocal variable 'f_sources' referenced before assignmentglobal name 'newer_group' is not definedlocal variable 'fcompiler' referenced before assignmentlocal variable 'config_fc' referenced before assignmentglobal name 'DistutilsError' is not definedglobal name 'get_numpy_include_dirs' is not definedlocal variable 'lib_file' referenced before assignmentglobal name 'glob' is not definedlocal variable 'module_dirs' referenced before assignmentlocal variable 'module_build_dir' referenced before assignmentlocal variable 'f_objects' referenced before assignmentlocal variable 'existing_modules' referenced before assignmentglobal name 'DistutilsFileError' is not definedlocal variable 'lname' referenced before assignmentlocal variable 'clib_libraries' referenced before assignmentlocal variable 'binfo' referenced before assignmentname 'set' is not definedname 'old_build_ext' is not definedglobal name 'old_build_ext' is not definedlocal variable 'build_clib' referenced before assignmentlocal variable 'clibs' referenced before assignmentglobal name 'set' is not definedlocal variable 'c_libs' referenced before assignmentlocal variable 'c_lib_dirs' referenced before assignmentlocal variable 'ext_languages' referenced before assignmentlocal variable 'ext_language' referenced before assignmentlocal variable 'all_languages' referenced before assignmentlocal variable 'new_compiler' referenced before assignmentlocal variable 'compiler_type' referenced before assignmentlocal variable 'new_fcompiler' referenced before assignmentlocal variable 'ctype' referenced before assignmentlocal variable 'need_f90_compiler' referenced before assignmentlocal variable 'extra_args' referenced before assignmentlocal variable 'cxx_compiler' referenced before assignmentlocal variable 'fullname' referenced before assignmentlocal variable 'c_objects' referenced before assignmentlocal variable 'linker' referenced before assignmentlocal variable 'ext_filename' referenced before assignmentlocal variable 'c_libraries' referenced before assignmentlocal variable 'c_library_dirs' referenced before assignmentlocal variable 'fileexists' referenced before assignmentglobal name 'copy_file' is not definedlocal variable 'f_lib_dirs' referenced before assignmentlocal variable 'dir' referenced before assignmentglobal name 'combine_paths' is not definedglobal name 'get_ext_source_files' is not definedlocal variable 'outputs' referenced before assignmentname 'old_build_py' is not definedlocal variable 'build_src' referenced before assignmentglobal name 'old_build_py' is not definedlocal variable 'package' referenced before assignmentlocal variable 'modules' referenced before assignmentglobal name 'is_string' is not definedlocal variable 'new_py_modules' referenced before assignmentlocal variable 'old_py_modules' referenced before assignmentname 'old_build_scripts' is not definedlocal variable 'scripts' referenced before assignmentlocal variable 'new_scripts' referenced before assignmentlocal variable 'func_scripts' referenced before assignmentlocal variable 'build_dir' referenced before assignmentlocal variable 'script' referenced before assignmentglobal name 'old_build_scripts' is not definedname 'build_ext' is not definedlocal variable 'source' referenced before assignmentlocal variable 'var' referenced before assignmentlocal variable 'ft' referenced before assignmentlocal variable 'fs' referenced before assignmentglobal name 'shlex' is not definedlocal variable 'build_ext' referenced before assignmentlocal variable 'new_data_files' referenced before assignmentlocal variable 'funcs' referenced before assignmentlocal variable 'get_data_files' referenced before assignmentlocal variable 'template' referenced before assignmentlocal variable 'gd' referenced before assignmentlocal variable 'subst_dict' referenced before assignmentlocal variable 'template_dir' referenced before assignmentlocal variable 'install_dir' referenced before assignmentglobal name 'subst_vars' is not definedglobal name 'get_cmd' is not definedlocal variable 'build_npkg' referenced before assignmentlocal variable 'pkg' referenced before assignmentlocal variable 'top_prefix' referenced before assignmentlocal variable 'infos' referenced before assignmentlocal variable 'generated' referenced before assignmentlocal variable 'module_base' referenced before assignmentlocal variable 'h_files' referenced before assignmentlocal variable 'py_files' referenced before assignmentlocal variable 'new_sources' referenced before assignmentlocal variable 'func_sources' referenced before assignmentglobal name 'appendpath' is not definedglobal name '_f_pyf_ext_match' is not definedlocal variable 'target_file' referenced before assignmentglobal name 'process_f_file' is not definedglobal name 'process_c_file' is not definedglobal name '_header_ext_match' is not definedlocal variable 'ext_name' referenced before assignmentglobal name 'have_pyrex' is not definedlocal variable 'target_dir' referenced before assignmentglobal name 'get_f2py_modulename' is not definedlocal variable 'target_dirs' referenced before assignmentlocal variable 'f2py_sources' referenced before assignmentlocal variable 'f2py_targets' referenced before assignmentglobal name 'fortran_ext_match' is not definedlocal variable 'f2py_options' referenced before assignmentlocal variable 'skip_f2py' referenced before assignmentglobal name 'newer' is not definedlocal variable 'target_c' referenced before assignmentlocal variable 'source_c' referenced before assignmentlocal variable 'source_h' referenced before assignmentlocal variable 'target_h' referenced before assignmentglobal name 'get_swig_modulename' is not definedglobal name 'get_swig_target' is not definedlocal variable 'is_cpp' referenced before assignmentlocal variable 'target_ext' referenced before assignmentglobal name '_find_swig_target' is not definedlocal variable 'swig_sources' referenced before assignmentlocal variable 'swig_targets' referenced before assignmentlocal variable 'skip_swig' referenced before assignmentlocal variable 'swig' referenced before assignmentlocal variable 'swig_cmd' referenced before assignmentlocal variable 'py_target_dir' referenced before assignmentglobal name '_has_cpp_header' is not definedglobal name '_has_c_header' is not definedglobal name '_swig_module_name_match' is not definedglobal name '_f2py_module_name_match' is not definedglobal name '_f2py_user_module_name_match' is not definedname 'LANG_EXT' is not definedname 'old_config' is not definedglobal name 'old_config' is not definedlocal variable 'headers' referenced before assignmentglobal name 'distutils' is not definedlocal variable 'mth' referenced before assignmentlocal variable 'DistutilsExecError' referenced before assignmentlocal variable 'CompileError' referenced before assignmentlocal variable 'save_compiler' referenced before assignmentglobal name 'generate_manifest' is not definedlocal variable 'type_name' referenced before assignmentlocal variable 'st' referenced before assignmentlocal variable 'expected' referenced before assignmentglobal name 'CompileError' is not definedlocal variable 'mid' referenced before assignmentlocal variable 'low' referenced before assignmentlocal variable 'high' referenced before assignmentlocal variable 'decl' referenced before assignmentlocal variable 'call' referenced before assignmentlocal variable 'call_args' referenced before assignmentglobal name 'check_inline' is not definedglobal name 'check_compiler_gcc4' is not definedglobal name 'GrabStdout' is not definedlocal variable 'grabber' referenced before assignmentlocal variable 'exe' referenced before assignmentlocal variable 'use_tee' referenced before assignmentlocal variable 'exitstatus' referenced before assignmentglobal name 'signal' is not definedlocal variable 'LinkError' referenced before assignmentlocal variable 'exitcode' referenced before assignmentname 'Command' is not definedlocal variable '_cache' referenced before assignmentlocal variable 'cmd_list' referenced before assignmentlocal variable 'v1' referenced before assignmentname 'old_develop' is not definedglobal name 'old_develop' is not definedname '_egg_info' is not definedglobal name '_egg_info' is not definedname 'old_install_mod' is not definedname 'old_install' is not definedglobal name 'old_install' is not definedglobal name 'old_install_mod' is not definedglobal name 'have_setuptools' is not definedlocal variable 'need_rewrite' referenced before assignmentglobal name 'write_file' is not definedglobal name 'new_compiler' is not definedname 'old_install_data' is not definedglobal name 'old_install_data' is not definedname 'old_install_headers' is not definedname 'old_sdist' is not definedglobal name 'old_sdist' is not definedglobal name 'get_data_files' is not definedlocal variable 'dist' referenced before assignmentlocal variable 'level' referenced before assignmentlocal variable 'spanlist' referenced before assignmentlocal variable 'start2' referenced before assignmentlocal variable 'fini1' referenced before assignmentlocal variable 'fini2' referenced before assignmentglobal name 'parenrep' is not definedglobal name 'paren_repl' is not definedglobal name 'plainrep' is not definedglobal name 'stripast' is not definedlocal variable 'loophead' referenced before assignmentglobal name 'named_re' is not definedglobal name 'parse_values' is not definedlocal variable 'nsub' referenced before assignmentglobal name 'exclude_re' is not definedglobal name 'exclude_vars_re' is not definedlocal variable 'excludes' referenced before assignmentlocal variable 'tmp' referenced before assignmentlocal variable 'dlist' referenced before assignmentglobal name 'parse_structure' is not definedlocal variable 'oldend' referenced before assignmentglobal name 'replace_re' is not definedlocal variable 'replace' referenced before assignmentglobal name 'parse_loop_header' is not definedlocal variable 'newline' referenced before assignmentlocal variable 'envlist' referenced before assignmentlocal variable 'env' referenced before assignmentglobal name 'parse_string' is not definedlocal variable 'newlevel' referenced before assignmentlocal variable 'match' referenced before assignmentglobal name 'header' is not definedglobal name 'global_names' is not definedglobal name 'include_src_re' is not definedglobal name 'resolve_includes' is not definedglobal name 'process_str' is not definedlocal variable 'sourcefile' referenced before assignmentlocal variable 'done' referenced before assignmentlocal variable 'allkeys' referenced before assignmentlocal variable 'newkey' referenced before assignmentname 'build' is not definedname 'build_src' is not definedname 'build_scripts' is not definedname 'config_compiler' is not definedname 'config' is not definedname 'build_py' is not definedname 'build_clib' is not definedname 'sdist' is not definedname 'install_data' is not definedname 'install_headers' is not definedname 'install_clib' is not definedname 'install' is not definedname 'bdist_rpm' is not definedname 'bdist_egg' is not definedname 'numpy_cmdclass' is not definedname 'develop' is not definedname 'easy_install' is not definedname 'egg_info' is not definedlocal variable 'kws' referenced before assignmentglobal name '_dict_append' is not definedglobal name 'Distribution' is not definedlocal variable 'display_opts' referenced before assignmentlocal variable 'ok' referenced before assignmentlocal variable 'always' referenced before assignmentglobal name 'NumpyDistribution' is not definedglobal name 'numpy_cmdclass' is not definedglobal name 'setup' is not definedglobal name '_command_line_ok' is not definedlocal variable 'configuration' referenced before assignmentlocal variable 'new_attr' referenced before assignmentglobal name '_check_append_ext_library' is not definedlocal variable 'new_libraries' referenced before assignmentglobal name '_check_append_library' is not definedglobal name 'old_setup' is not definedname 'CPUInfoBase' is not definedname 'LinuxCPUInfo' is not definedname 'IRIXCPUInfo' is not definedname 'DarwinCPUInfo' is not definedname 'SunOSCPUInfo' is not definedname 'Win32CPUInfo' is not definedname 'cpuinfo' is not definedglobal name 'getstatusoutput' is not definedglobal name 'UserWarning' is not definedlocal variable 'stacklevel' referenced before assignmentlocal variable 'successful_status' referenced before assignmentglobal name 'getoutput' is not definedglobal name 'command_by_line' is not definedlocal variable 'fo' referenced before assignmentlocal variable 'name_value' referenced before assignmentglobal name 'key_value_from_command' is not definedglobal name 'command_info' is not definedlocal variable 'pnum' referenced before assignmentlocal variable 'winreg' referenced before assignmentlocal variable 'proc' referenced before assignmentlocal variable 'chnd' referenced before assignmentlocal variable 'pidx' referenced before assignmentlocal variable 'prgx' referenced before assignmentlocal variable 'distutils_section' referenced before assignmentlocal variable 'hook' referenced before assignmentlocal variable 'envvar' referenced before assignmentlocal variable 'confvar' referenced before assignmentlocal variable 'conf_desc' referenced before assignmentlocal variable 'hook_handler' referenced before assignmentname 'test_posix' is not definedname 'test_nt' is not definedglobal name 'make_temp_file' is not definedlocal variable 'fdir' referenced before assignmentlocal variable 'paths' referenced before assignmentlocal variable 'suffixes' referenced before assignmentlocal variable 'realpath' referenced before assignmentlocal variable 'f_ext' referenced before assignmentlocal variable 'orig_exe' referenced before assignmentlocal variable 'stream' referenced before assignmentlocal variable 'use_shell' referenced before assignmentlocal variable 'execute_in' referenced before assignmentglobal name '__file__' is not definedglobal name '_preserve_environment' is not definedglobal name '_update_environment' is not definedlocal variable '_with_python' referenced before assignmentglobal name '_supports_fileno' is not definedglobal name '_exec_command_python' is not definedlocal variable 'exec_dir' referenced before assignmentglobal name '_exec_command_posix' is not definedglobal name '_exec_command' is not definedlocal variable 'oldcwd' referenced before assignmentlocal variable 'oldenv' referenced before assignmentglobal name 'temp_file_name' is not definedglobal name 'open_latin1' is not definedglobal name 'get_pythonexe' is not definedlocal variable 'exec_command_dir' referenced before assignmentglobal name 'find_executable' is not definedlocal variable 'argv' referenced before assignmentlocal variable 'using_command' referenced before assignmentlocal variable 'spawn_command' referenced before assignmentglobal name 'quote_arg' is not definedlocal variable 'so_fileno' referenced before assignmentlocal variable 'ferr' referenced before assignmentlocal variable 'se_fileno' referenced before assignmentlocal variable 'so_flush' referenced before assignmentlocal variable 'se_flush' referenced before assignmentlocal variable '_so_has_fileno' referenced before assignmentlocal variable 'so_dup' referenced before assignmentlocal variable '_se_has_fileno' referenced before assignmentlocal variable 'se_dup' referenced before assignmentlocal variable 'fout' referenced before assignmentlocal variable 'outfile' referenced before assignmentlocal variable 'errfile' referenced before assignmentlocal variable 'errmess' referenced before assignmentlocal variable 'pythonexe' referenced before assignmentlocal variable 'tmpdir' referenced before assignmentlocal variable 'tmpfile' referenced before assignmentname 'old_Extension' is not definedglobal name 'old_Extension' is not definedlocal variable 'define_macros' referenced before assignmentlocal variable 'undef_macros' referenced before assignmentlocal variable 'extra_objects' referenced before assignmentlocal variable 'extra_compile_args' referenced before assignmentlocal variable 'extra_link_args' referenced before assignmentlocal variable 'export_symbols' referenced before assignmentlocal variable 'swig_opts' referenced before assignmentglobal name 'SyntaxWarning' is not definedlocal variable 'language' referenced before assignmentlocal variable 'extra_f77_compile_args' referenced before assignmentlocal variable 'extra_f90_compile_args' referenced before assignmentglobal name 'cxx_ext_re' is not definedglobal name 'fortran_pyf_ext_re' is not definedglobal name 'split_quoted' is not definedglobal name 'strtobool' is not definedglobal name 'all_strings' is not definedglobal name 'EnvironmentConfig' is not definedglobal name 'str2bool' is not definedglobal name 'flaglist' is not definedglobal name 'get_shared_lib_extension' is not definedglobal name 'CCompiler' is not definedglobal name 'is_sequence_of_strings' is not definedglobal name 'CompilerNotFound' is not definedlocal variable 'exe_cache' referenced before assignmentlocal variable 'fc_exe' referenced before assignmentlocal variable 'exe_key' referenced before assignmentlocal variable 'f90' referenced before assignmentlocal variable 'f77' referenced before assignmentlocal variable 'seen' referenced before assignmentlocal variable 'unique_possibles' referenced before assignmentlocal variable 'cached_find_executable' referenced before assignmentlocal variable 'fix' referenced before assignmentlocal variable 'f90flags' referenced before assignmentlocal variable 'noopt' referenced before assignmentlocal variable 'oflags' referenced before assignmentlocal variable 'noarch' referenced before assignmentlocal variable 'aflags' referenced before assignmentlocal variable 'dflags' referenced before assignmentlocal variable 'f77flags' referenced before assignmentlocal variable 'freeflags' referenced before assignmentlocal variable 'fixflags' referenced before assignmentglobal name 'get_python_lib' is not definedlocal variable 'this_get' referenced before assignmentlocal variable 'flagvar' referenced before assignmentglobal name 'FancyGetopt' is not definedglobal name 'is_f_file' is not definedglobal name 'has_f90_header' is not definedglobal name 'get_f77flags' is not definedglobal name 'is_free_format' is not definedlocal variable 'flavor' referenced before assignmentlocal variable 'src_flags' referenced before assignmentlocal variable 'lib' referenced before assignmentglobal name 'gen_lib_options' is not definedlocal variable 'output_filename' referenced before assignmentlocal variable 'target_desc' referenced before assignmentglobal name 'LinkError' is not definedlocal variable 'hook_name' referenced before assignmentglobal name 'fcompiler_class' is not definedglobal name 'fcompiler_aliases' is not definedlocal variable 'desc' referenced before assignmentlocal variable 'compiler_types' referenced before assignmentglobal name 'new_fcompiler' is not definedlocal variable 'platform' referenced before assignmentlocal variable 'c_compiler' referenced before assignmentlocal variable 'osname' referenced before assignmentglobal name '_default_compilers' is not definedlocal variable 'matching_compiler_types' referenced before assignmentglobal name 'available_fcompilers_for_platform' is not definedglobal name '_find_existing_fcompiler' is not definedglobal name 'failed_fcompiler' is not definedglobal name 'load_all_fcompiler_classes' is not definedglobal name 'get_default_fcompiler' is not definedlocal variable 'compilers_na' referenced before assignmentlocal variable 'compilers' referenced before assignmentlocal variable 'platform_compilers' referenced before assignmentlocal variable 'compilers_ni' referenced before assignmentglobal name '_has_f_header' is not definedglobal name '_has_f90_header' is not definedglobal name '_free_f90_start' is not definedglobal name '_has_fix_header' is not definedglobal name '_f77flags_re' is not definedname 'find_repl_patterns' is not definedglobal name 'routine_start_re' is not definedglobal name 'function_start_re' is not definedglobal name 'routine_end_re' is not definedglobal name 'unique_key' is not definedglobal name 'conv' is not definedglobal name 'item_re' is not definedlocal variable 'substr' referenced before assignmentglobal name 'find_repl_patterns' is not definedglobal name 'list_re' is not definedglobal name 'template_re' is not definedlocal variable 'rules' referenced before assignmentlocal variable 'lnames' referenced before assignmentlocal variable 'thelist' referenced before assignmentlocal variable 'rule' referenced before assignmentlocal variable 'numsubs' referenced before assignmentlocal variable 'base_rule' referenced before assignmentlocal variable 'newstr' referenced before assignmentlocal variable 'namerepl' referenced before assignmentlocal variable 'mobj' referenced before assignmentglobal name 'template_name_re' is not definedlocal variable 'allstr' referenced before assignmentglobal name '_special_names' is not definedlocal variable 'writestr' referenced before assignmentglobal name 'expand_sub' is not definedname 'old_Log' is not definedname 'Log' is not definedname '_global_log' is not definedname 'cyan_text' is not definedname 'default_text' is not definedname 'INFO' is not definedname 'red_text' is not definedname 'WARN' is not definedname 'ERROR' is not definedname 'FATAL' is not definedname 'set_verbosity' is not definedglobal name '_fix_args' is not definedglobal name '_global_color_map' is not definedglobal name 'WARN' is not definedglobal name 'green_text' is not definedglobal name '_global_log' is not definedglobal name 'info' is not definedlocal variable 'prev_level' referenced before assignmentglobal name 'set_threshold' is not definedglobal name 'ERROR' is not definedglobal name 'INFO' is not definedglobal name 'FATAL' is not definedname '_MSVCRVER_TO_FULLVER' is not definedname 'msvcrt' is not definedname 'major' is not definedname 'minor' is not definedname 'rest' is not definedglobal name 'subprocess' is not definedglobal name 'StrictVersion' is not definedglobal name 'build_import_library' is not definedglobal name 'build_msvcr_library' is not definedglobal name 'msvc_runtime_library' is not definedglobal name 'get_build_architecture' is not definedlocal variable 'entry_point' referenced before assignmentlocal variable 'build_temp' referenced before assignmentlocal variable 'target_lang' referenced before assignmentglobal name 'UnixCCompiler' is not definedlocal variable 'drv' referenced before assignmentlocal variable 'maj' referenced before assignmentlocal variable 'min' referenced before assignmentlocal variable 'lib_dirs' referenced before assignmentlocal variable 'dllname' referenced before assignmentlocal variable 'dll' referenced before assignmentglobal name 'dump_table' is not definedglobal name '_START' is not definedlocal variable 'dump' referenced before assignmentglobal name '_TABLE' is not definedlocal variable 'syms' referenced before assignmentlocal variable 'dfile' referenced before assignmentlocal variable 'dll_name' referenced before assignmentlocal variable 'arch' referenced before assignmentlocal variable 'msvcr_name' referenced before assignmentglobal name 'find_dll' is not definedglobal name 'generate_def' is not definedglobal name '_build_import_library_amd64' is not definedglobal name '_build_import_library_x86' is not definedglobal name 'find_python_dll' is not definedlocal variable 'lib2def' referenced before assignmentlocal variable 'flist' referenced before assignmentlocal variable 'def_file' referenced before assignmentlocal variable 'out_file' referenced before assignmentglobal name '_MSVCRVER_TO_FULLVER' is not definedlocal variable 'fullver' referenced before assignmentlocal variable 'rctype' referenced before assignmentlocal variable 'msver' referenced before assignmentlocal variable 'config' referenced before assignmentglobal name 'configtest_name' is not definedglobal name 'get_build_msvc_version' is not definedglobal name 'check_embedded_msvcr_match_linked' is not definedglobal name 'msvc_manifest_xml' is not definedglobal name 'manifest_name' is not definedname 'terminal_has_colors' is not definedglobal name 'rel_path' is not definedglobal name 'njoin' is not definedglobal name 'minrelpath' is not definedlocal variable 'joined' referenced before assignmentlocal variable 'dirs' referenced before assignmentlocal variable 'config_file' referenced before assignmentlocal variable 'mathlibs' referenced before assignmentlocal variable 'local_path' referenced before assignmentlocal variable 'new_paths' referenced before assignmentlocal variable 'include_non_existing' referenced before assignmentglobal name '_fix_paths' is not definedglobal name '_temporary_directory' is not definedglobal name 'tempfile' is not definedglobal name 'atexit' is not definedglobal name 'clean_up_temporary_directory' is not definedlocal variable 'curses' referenced before assignmentlocal variable 'bold' referenced before assignmentlocal variable 'fg' referenced before assignmentglobal name '_colour_codes' is not definedlocal variable 'bg' referenced before assignmentglobal name 'colour_text' is not definedglobal name 'f90_ext_match' is not definedglobal name 'f90_module_name_match' is not definedglobal name 'cxx_ext_match' is not definedglobal name '_get_f90_modules' is not definedlocal variable 'directory_list' referenced before assignmentlocal variable 'list_of_sources' referenced before assignmentlocal variable 'direcs' referenced before assignmentglobal name '_get_headers' is not definedglobal name '_get_directories' is not definedlocal variable 'new_dir' referenced before assignmentlocal variable 'top_path' referenced before assignmentlocal variable 'dirnames' referenced before assignmentlocal variable 'pruned_directories' referenced before assignmentlocal variable 'pruned' referenced before assignmentlocal variable 'prune_file_pat' referenced before assignmentlocal variable 'dirpath' referenced before assignmentlocal variable 'dpath' referenced before assignmentlocal variable 'rpath' referenced before assignmentglobal name 'get_dependencies' is not definedglobal name 'is_local_src_dir' is not definedglobal name 'general_source_files' is not definedlocal variable 'is_python_ext' referenced before assignmentlocal variable 'confvars' referenced before assignmentlocal variable 'so_ext' referenced before assignmentglobal name 'dot_join' is not definedlocal variable 'parent_name' referenced before assignmentglobal name 'get_frame' is not definedlocal variable 'caller_level' referenced before assignmentglobal name 'get_path_from_frame' is not definedlocal variable 'package_path' referenced before assignmentglobal name 'as_list' is not definedlocal variable 'known_keys' referenced before assignmentlocal variable 'caller_instance' referenced before assignmentlocal variable 'setup_name' referenced before assignmentlocal variable 'subpackage_name' referenced before assignmentlocal variable 'config_list' referenced before assignmentglobal name 'imp' is not definedlocal variable 'setup_module' referenced before assignmentglobal name 'Configuration' is not definedlocal variable 'subpackage_path' referenced before assignmentlocal variable 'standalone' referenced before assignmentlocal variable 'data_path' referenced before assignmentglobal name 'is_glob_pattern' is not definedglobal name 'allpath' is not definedlocal variable 'pattern_list' referenced before assignmentlocal variable 'path_list' referenced before assignmentlocal variable 'target_list' referenced before assignmentglobal name 'general_source_directories_files' is not definedlocal variable 'd1' referenced before assignmentlocal variable 'data_files' referenced before assignmentlocal variable 'data_dict' referenced before assignmentlocal variable 'filepat' referenced before assignmentglobal name 'gpaths' is not definedglobal name 'dict_append' is not definedlocal variable 'ext_args' referenced before assignmentlocal variable 'lpath' referenced before assignmentlocal variable 'libnames' referenced before assignmentglobal name 'InstallableLib' is not definedlocal variable 'pformat' referenced before assignmentlocal variable 'extlib' referenced before assignmentlocal variable 'cwd' referenced before assignmentlocal variable 'revision' referenced before assignmentlocal variable 'revision1' referenced before assignmentlocal variable 'revision0' referenced before assignmentlocal variable 'branch1' referenced before assignmentlocal variable 'branch_map' referenced before assignmentlocal variable 'branch0' referenced before assignmentlocal variable 'version_file' referenced before assignmentlocal variable 'version_variable' referenced before assignmentlocal variable 'version_module' referenced before assignmentlocal variable 'version_vars' referenced before assignmentglobal name 'generate_config_py' is not definedlocal variable 'dict_append' referenced before assignmentlocal variable 'get_info' referenced before assignmentlocal variable 'cmdname' referenced before assignmentglobal name 'get_npy_pkg_dir' is not definedlocal variable 'pkgname' referenced before assignmentglobal name 'get_pkg_info' is not definedlocal variable 'absprefix' referenced before assignmentlocal variable 'drive' referenced before assignmentlocal variable 'subpath' referenced before assignmentlocal variable 'lexer' referenced before assignmentlocal variable 'description' referenced before assignmentlocal variable 'requires' referenced before assignmentlocal variable 'sections' referenced before assignmentlocal variable 'vars' referenced before assignmentlocal variable 'section' referenced before assignmentglobal name '_escape_backslash' is not definedglobal name '_VAR' is not definedglobal name 'FormatError' is not definedglobal name 'VariableSet' is not definedglobal name 'meta_d' is not definedglobal name 'r' is not definedlocal variable 'pkg_name' referenced before assignmentglobal name 'ConfigParser' is not definedglobal name 'SafeConfigParser' is not definedglobal name 'PkgNotFound' is not definedglobal name 'parse_meta' is not definedlocal variable 'secs' referenced before assignmentlocal variable 'meta' referenced before assignmentlocal variable '_read_config' referenced before assignmentglobal name 'LibraryInfo' is not definedglobal name 'parse_config' is not definedlocal variable 'reqs' referenced before assignmentglobal name 'pkg_to_filename' is not definedlocal variable 'rvalue' referenced before assignmentlocal variable 'nvars' referenced before assignmentlocal variable 'nsections' referenced before assignmentlocal variable 'rname' referenced before assignmentlocal variable 'ovalue' referenced before assignmentlocal variable 'oname' referenced before assignmentglobal name '_CACHE' is not definedglobal name '_read_config_imp' is not definedname '_bits' is not definedname 'libpaths' is not definedname 'platform_bits' is not definedname 'globbed_x11_dir' is not definedname 'default_x11_lib_dirs' is not definedname 'x11_so_dir' is not definedname 'default_x11_include_dirs' is not definedname 'sp' is not definedname 'tmp' is not definedname 'p' is not definedname 'triplet' is not definedname 'default_lib_dirs' is not definedname 'default_include_dirs' is not definedname 'default_src_dirs' is not definedname 'NotFoundError' is not definedname 'LapackNotFoundError' is not definedname 'BlasNotFoundError' is not definedname 'system_info' is not definedname 'fftw_info' is not definedname 'mkl_info' is not definedname 'atlas_info' is not definedname 'atlas_blas_info' is not definedname 'atlas_threads_info' is not definedname 'blas_info' is not definedname '_numpy_info' is not definedname '_pkg_config_info' is not definedglobal name 'atlas_info' is not definedglobal name 'atlas_threads_info' is not definedglobal name 'atlas_blas_info' is not definedglobal name 'atlas_blas_threads_info' is not definedglobal name 'lapack_atlas_info' is not definedglobal name 'lapack_atlas_threads_info' is not definedglobal name 'mkl_info' is not definedglobal name 'openblas_info' is not definedglobal name 'lapack_mkl_info' is not definedglobal name 'blas_mkl_info' is not definedglobal name 'x11_info' is not definedglobal name 'fft_opt_info' is not definedglobal name 'fftw_info' is not definedglobal name 'fftw2_info' is not definedglobal name 'fftw3_info' is not definedglobal name 'dfftw_info' is not definedglobal name 'sfftw_info' is not definedglobal name 'fftw_threads_info' is not definedglobal name 'dfftw_threads_info' is not definedglobal name 'sfftw_threads_info' is not definedglobal name 'djbfft_info' is not definedglobal name 'blas_info' is not definedglobal name 'lapack_info' is not definedglobal name 'lapack_src_info' is not definedglobal name 'blas_src_info' is not definedglobal name 'numpy_info' is not definedglobal name 'f2py_info' is not definedglobal name 'Numeric_info' is not definedglobal name 'numarray_info' is not definedglobal name 'numerix_info' is not definedglobal name 'lapack_opt_info' is not definedglobal name 'blas_opt_info' is not definedglobal name 'boost_python_info' is not definedglobal name 'agg2_info' is not definedglobal name 'wx_info' is not definedglobal name 'gdk_pixbuf_xlib_2_info' is not definedglobal name 'gdk_pixbuf_2_info' is not definedglobal name 'gdk_info' is not definedglobal name 'gdk_2_info' is not definedglobal name 'gdk_x11_2_info' is not definedglobal name 'gtkp_x11_2_info' is not definedglobal name 'gtkp_2_info' is not definedglobal name 'xft_info' is not definedglobal name 'freetype2_info' is not definedglobal name 'umfpack_info' is not definedglobal name 'amd_info' is not definedglobal name 'system_info' is not definedlocal variable 'notfound_action' referenced before assignmentglobal name 'NotFoundError' is not definedglobal name 'default_lib_dirs' is not definedglobal name 'default_include_dirs' is not definedlocal variable 'default_lib_dirs' referenced before assignmentlocal variable 'default_include_dirs' referenced before assignmentglobal name 'default_src_dirs' is not definedglobal name 'get_standard_file' is not definedlocal variable 'env_var' referenced before assignmentlocal variable 'e0' referenced before assignmentlocal variable 'ds2' referenced before assignmentglobal name 'NoOptionError' is not definedlocal variable 'libs' referenced before assignmentglobal name 'so_ext' is not definedlocal variable 'opt_libs' referenced before assignmentlocal variable 'lib_dir' referenced before assignmentlocal variable 'lib_prefixes' referenced before assignmentlocal variable 'liblist' referenced before assignmentlocal variable 'found_libs' referenced before assignmentlocal variable 'dir_' referenced before assignmentlocal variable 'found_dirs' referenced before assignmentglobal name 'get_info' is not definedlocal variable 'fftw_info' referenced before assignmentglobal name 'FFTWNotFoundError' is not definedlocal variable 'ver_param' referenced before assignmentglobal name 'DJBFFTNotFoundError' is not definedlocal variable 'incl_dirs' referenced before assignmentlocal variable 'path_atoms' referenced before assignmentlocal variable 'intel_mkl_dirs' referenced before assignmentlocal variable 'plt' referenced before assignmentglobal name 'AtlasNotFoundError' is not definedlocal variable 'atlas_libs' referenced before assignmentlocal variable 'lapack_libs' referenced before assignmentlocal variable 'atlas' referenced before assignmentlocal variable 'atlas_1' referenced before assignmentlocal variable 'lapack' referenced before assignmentlocal variable 'lapack_dir' referenced before assignmentlocal variable 'lapack_name' referenced before assignmentlocal variable 'lapack_lib' referenced before assignmentglobal name 'get_atlas_version' is not definedlocal variable 'atlas_extra_info' referenced before assignmentglobal name 'LapackNotFoundError' is not definedglobal name 'LapackSrcNotFoundError' is not definedlocal variable 'src_dir' referenced before assignmentlocal variable 'dzlaux' referenced before assignmentlocal variable 'dlasrc' referenced before assignmentlocal variable 'clasrc' referenced before assignmentlocal variable 'zlasrc' referenced before assignmentlocal variable 'allaux' referenced before assignmentlocal variable 'oclasrc' referenced before assignmentlocal variable 'ozlasrc' referenced before assignmentlocal variable 'src_dir2' referenced before assignmentglobal name '_cached_atlas_version' is not definedglobal name 'cmd_config' is not definedglobal name 'atlas_version_c_text' is not definedlocal variable 'atlas_version' referenced before assignmentlocal variable 'intel' referenced before assignmentlocal variable 'link_args' referenced before assignmentlocal variable 'atlas_info' referenced before assignmentlocal variable 'need_lapack' referenced before assignmentlocal variable 'need_blas' referenced before assignmentglobal name 'BlasNotFoundError' is not definedglobal name 'BlasSrcNotFoundError' is not definedglobal name 'X11NotFoundError' is not definedglobal name 'default_x11_lib_dirs' is not definedglobal name 'default_x11_include_dirs' is not definedlocal variable 'inc_dir' referenced before assignmentglobal name 'NumericNotFoundError' is not definedlocal variable 'py_incl_dir' referenced before assignmentlocal variable 'msg1' referenced before assignmentlocal variable 'msg2' referenced before assignmentlocal variable 'which' referenced before assignmentlocal variable 'f2py' referenced before assignmentlocal variable 'py_incl_dirs' referenced before assignmentlocal variable 'bpl_srcs' referenced before assignmentlocal variable 'agg2_srcs' referenced before assignmentlocal variable 'config_exe' referenced before assignmentlocal variable 'option' referenced before assignmentglobal name 'UmfpackNotFoundError' is not definedlocal variable 'a0' referenced before assignmentglobal name 'inv_language_map' is not definedglobal name 'language_map' is not definedlocal variable 'opts' referenced before assignmentglobal name 'parseCmdLine' is not definedlocal variable 'show_only' referenced before assignmentlocal variable 'inspect' referenced before assignmentlocal variable 'show_all' referenced before assignmentname 'UnixCCompiler__compile' is not definedname 'UnixCCompiler_create_static_lib' is not definedlocal variable 'ccomp' referenced before assignmentlocal variable 'output_libname' referenced before assignmentlocal variable 'tmp_objects' referenced before assignmentglobal name 'LibError' is not definedname 'fftpkg' is not definedname 'linpkg' is not definedglobal name '_restore_dict' is not definedglobal name 'restore_func' is not definedname 'f2py2e' is not definedlocal variable 'source_fn' referenced before assignmentlocal variable 'modulename' referenced before assignmentname 'version' is not definedname 'version_info' is not definedname 'pprint' is not definedname 'isintent_in' is not definedname 'isintent_inout' is not definedname 'isintent_out' is not definedname 'isintent_hide' is not definedname 'isintent_cache' is not definedname 'isintent_c' is not definedname 'isoptional' is not definedname 'isintent_inplace' is not definedname 'isintent_aligned4' is not definedname 'isintent_aligned8' is not definedname 'isintent_aligned16' is not definedglobal name 'options' is not definedglobal name 'debugoptions' is not definedglobal name 'isexternal' is not definedglobal name '_isstring' is not definedglobal name 'isarray' is not definedglobal name 'isstring' is not definedglobal name 'isstringarray' is not definedglobal name 'get_kind' is not definedglobal name 'iscomplex' is not definedlocal variable 'rout' referenced before assignmentglobal name 'isintent_c' is not definedglobal name 'wrapfuncs' is not definedglobal name 'issubroutine' is not definedglobal name 'hasassumedshape' is not definedglobal name 'islogical' is not definedglobal name 'islong_long' is not definedglobal name 'islong_double' is not definedglobal name 'iscomplexfunction' is not definedglobal name 'outmess' is not definedglobal name 'isintent_nothide' is not definedglobal name 'isoptional' is not definedglobal name 'l_or' is not definedglobal name 'isintent_inout' is not definedglobal name 'isintent_inplace' is not definedglobal name 'isintent_hide' is not definedglobal name 'hasinitvalue' is not definedglobal name 'hasnote' is not definedglobal name 'hascommon' is not definedglobal name 'hasbody' is not definedglobal name 'containscommon' is not definedglobal name 'ismodule' is not definedglobal name 'containsmodule' is not definedglobal name 'getcallstatement' is not definedglobal name 'F2PYError' is not definedlocal variable 'l2' referenced before assignmentglobal name 'errmess' is not definedlocal variable 'blockname' referenced before assignmentlocal variable 'counter' referenced before assignmentlocal variable 'comment' referenced before assignmentglobal name 'getmultilineblock' is not definedglobal name 'hascallstatement' is not definedglobal name 'l_and' is not definedglobal name 'isstringfunction' is not definedglobal name 'l_not' is not definedglobal name 'isfunction_wrap' is not definedlocal variable 'arg_types' referenced before assignmentglobal name 'isintent_callback' is not definedlocal variable 'cb_map' referenced before assignmentlocal variable 'getctype' referenced before assignmentglobal name 'isarrayofstrings' is not definedlocal variable 'arg_types2' referenced before assignmentlocal variable 'sortargs' referenced before assignmentglobal name 'isintent_aux' is not definedlocal variable 'auxvars' referenced before assignmentglobal name 'flatlist' is not definedlocal variable 'str' referenced before assignmentlocal variable 'defaultsep' referenced before assignmentlocal variable 'ar' referenced before assignmentglobal name 'dictappend' is not definedlocal variable 'rd' referenced before assignmentglobal name 'applyrules' is not definedglobal name 'cfuncs' is not definedlocal variable 'k1' referenced before assignmentname 'using_newcore' is not definedname 'c2buildvalue_map' is not definedname 'f' is not definedname 'd1' is not definedname 'k1' is not definedname 'f2cmap_all' is not definedname 'c2py_map' is not definedglobal name 'getctype' is not definedglobal name 'f2cmap_all' is not definedlocal variable 'typespec' referenced before assignmentlocal variable 'f2cmap' referenced before assignmentglobal name 'getstrlength' is not definedlocal variable 'len' referenced before assignmentglobal name 'depargs' is not definedglobal name 'isintent_in' is not definedglobal name 'getpydocsign' is not definedglobal name 'isintent_out' is not definedglobal name 'getinit' is not definedlocal variable 'showinit' referenced before assignmentlocal variable 'opt' referenced before assignmentglobal name 'c2py_map' is not definedglobal name 'c2pycode_map' is not definedlocal variable 'out_a' referenced before assignmentglobal name 'lcb_map' is not definedglobal name 'lcb2_map' is not definedlocal variable 'ua' referenced before assignmentlocal variable 'sig' referenced before assignmentlocal variable 'sigout' referenced before assignmentglobal name 'iscomplexarray' is not definedglobal name 'markoutercomma' is not definedlocal variable 'init' referenced before assignmentglobal name 'isintent_dict' is not definedlocal variable 'intent_flags' referenced before assignmentglobal name 'c2buildvalue_map' is not definedglobal name 'getarrdims' is not definedglobal name 'c2capi_map' is not definedglobal name 'debugcapi' is not definedglobal name 'isrequired' is not definedlocal variable 'il' referenced before assignmentlocal variable 'rl' referenced before assignmentglobal name 'cformat_map' is not definedglobal name 'getfortranname' is not definedglobal name 'gentitle' is not definedglobal name 'getusercode' is not definedglobal name 'getusercode1' is not definedglobal name 'cb_rules' is not definedlocal variable 'u' referenced before assignmentlocal variable 'un' referenced before assignmentlocal variable 'ln' referenced before assignmentglobal name 'getcallprotoargument' is not definedglobal name 'hasresultnote' is not definedglobal name 'getrestdoc' is not definedglobal name 'getpymethoddef' is not definedlocal variable 'um' referenced before assignmentlocal variable 'nofargs' referenced before assignmentlocal variable 'nofoptargs' referenced before assignmentglobal name 'getarrdocsign' is not definedname 'throw_error' is not definedglobal name 'cb_map' is not definedglobal name 'buildcallback' is not definedlocal variable 'depargs' referenced before assignmentlocal variable 'capi_maps' referenced before assignmentglobal name 'cb_rout_rules' is not definedlocal variable 'vrd' referenced before assignmentlocal variable 'savevrd' referenced before assignmentglobal name 'cb_arg_rules' is not definedglobal name 'stripcomma' is not definedglobal name 'cb_routine_rules' is not definedname 'includes0' is not definedname 'includes' is not definedname 'needs' is not definedname 'typedefs' is not definedname 'cppmacros' is not definedlocal variable 'c2capi_map' referenced before assignmentglobal name 'cppmacros' is not definedlocal variable 'need' referenced before assignmentglobal name 'append_needs' is not definedglobal name 'includes0' is not definedglobal name 'includes' is not definedglobal name 'typedefs' is not definedglobal name 'typedefs_generated' is not definedglobal name 'callbacks' is not definedglobal name 'f90modhooks' is not definedglobal name 'commonhooks' is not definedglobal name 'outneeds' is not definedglobal name 'needs' is not definedlocal variable 'nn' referenced before assignmentlocal variable 'saveout' referenced before assignmentglobal name 'findcommonblocks' is not definedlocal variable 'top' referenced before assignmentlocal variable 'tret' referenced before assignmentlocal variable 'vnames' referenced before assignmentlocal variable 'hnames' referenced before assignmentlocal variable 'inames' referenced before assignmentlocal variable 'fadd' referenced before assignmentglobal name 'func2subr' is not definedlocal variable 'cadd' referenced before assignmentglobal name 'capi_maps' is not definedlocal variable 'idims' referenced before assignmentglobal name 'rmbadname' is not definedlocal variable 'inames1' referenced before assignmentlocal variable 'lower_name' referenced before assignmentlocal variable 'iadd' referenced before assignmentlocal variable 'dadd' referenced before assignmentlocal variable 'chooks' referenced before assignmentlocal variable 'ihooks' referenced before assignmentlocal variable 'fwrap' referenced before assignmentname 'groupcounter' is not definedname 'defaultimplicitrules' is not definedname 'n' is not definedname 'badnames' is not definedname 'invbadnames' is not definedname 'show' is not definedname 'beforethisafter' is not definedname 'fortrantypes' is not definedname 'groupbegins77' is not definedname 'groupbegins90' is not definedname 'groupends' is not definedname 'endifs' is not definedglobal name 'pprint' is not definedglobal name 'verbose' is not definedglobal name 'quiet' is not definedglobal name 'filepositiontext' is not definedglobal name 'badnames' is not definedglobal name 'rmbadname1' is not definedglobal name 'invbadnames' is not definedglobal name 'undo_rmbadname1' is not definedlocal variable 'istop' referenced before assignmentglobal name 'gotnextfile' is not definedglobal name 'currentfilename' is not definedglobal name 'sourcecodeform' is not definedglobal name 'strictf77' is not definedglobal name 'beginpattern' is not definedglobal name 'dolowercase' is not definedlocal variable 'ffile' referenced before assignmentlocal variable 'dowithline' referenced before assignmentglobal name 'fileinput' is not definedglobal name 'beginpattern77' is not definedglobal name 'beginpattern90' is not definedlocal variable 'commentline' referenced before assignmentlocal variable 'spacedigits' referenced before assignmentlocal variable 'cont' referenced before assignmentlocal variable 'll' referenced before assignmentlocal variable 'cont1' referenced before assignmentlocal variable 'cont2' referenced before assignmentlocal variable 'localdolowercase' referenced before assignmentlocal variable 'mline_mark' referenced before assignmentlocal variable 'fin' referenced before assignmentlocal variable 'l1' referenced before assignmentlocal variable 'includeline' referenced before assignmentlocal variable 'origfinalline' referenced before assignmentglobal name 'readfortrancode' is not definedglobal name 'include_paths' is not definedlocal variable 'foundfile' referenced before assignmentlocal variable 'finalline' referenced before assignmentlocal variable 'saveglobals' referenced before assignmentlocal variable 'argsline' referenced before assignmentglobal name 'f2pyenhancementspattern' is not definedglobal name 'multilinepattern' is not definedlocal variable 'reset' referenced before assignmentglobal name 'crackline' is not definedglobal name 'groupcounter' is not definedglobal name 'groupcache' is not definedglobal name 'f77modulename' is not definedglobal name 'neededmodule' is not definedlocal variable 'fl' referenced before assignmentglobal name 'groupname' is not definedglobal name 'grouplist' is not definedglobal name 'dimensionpattern' is not definedglobal name 'externalpattern' is not definedglobal name 'intentpattern' is not definedglobal name 'optionalpattern' is not definedglobal name 'requiredpattern' is not definedglobal name 'parameterpattern' is not definedglobal name 'datapattern' is not definedglobal name 'publicpattern' is not definedglobal name 'privatepattern' is not definedglobal name 'intrisicpattern' is not definedglobal name 'endifpattern' is not definedglobal name 'endpattern' is not definedglobal name 'formatpattern' is not definedglobal name 'functionpattern' is not definedglobal name 'subroutinepattern' is not definedglobal name 'implicitpattern' is not definedglobal name 'typespattern' is not definedglobal name 'commonpattern' is not definedglobal name 'callpattern' is not definedglobal name 'usepattern' is not definedglobal name 'containspattern' is not definedglobal name 'entrypattern' is not definedglobal name 'crackline_re_1' is not definedglobal name 'skipblocksuntil' is not definedglobal name 'markouterparen' is not definedlocal variable 're_1' referenced before assignmentglobal name '_simplifyargs' is not definedglobal name 'callfunpattern' is not definedglobal name 'analyzeline' is not definedlocal variable 'm1' referenced before assignmentglobal name 'skipemptyends' is not definedglobal name 'ignorecontains' is not definedlocal variable 'cc' referenced before assignmentlocal variable 'comma' referenced before assignmentlocal variable 'decl2' referenced before assignmentglobal name 'setattrspec' is not definedglobal name 'setkindselector' is not definedglobal name 'setcharselector' is not definedlocal variable 'vdecl' referenced before assignmentglobal name '_intentcallbackpattern' is not definedglobal name 'nameargspattern' is not definedglobal name 'callnameargspattern' is not definedlocal variable 'case' referenced before assignmentglobal name 'expectbegin' is not definedglobal name '_resolvenameargspattern' is not definedlocal variable 'needmodule' referenced before assignmentlocal variable 'needinterface' referenced before assignmentglobal name 'appenddecl' is not definedglobal name 'cracktypespec0' is not definedglobal name 'updatevars' is not definedlocal variable 'selector' referenced before assignmentlocal variable 'edecl' referenced before assignmentglobal name 'namepattern' is not definedlocal variable 'pl' referenced before assignmentlocal variable 'ap' referenced before assignmentlocal variable 'last_name' referenced before assignmentglobal name 'get_parameters' is not definedlocal variable 'initexpr' referenced before assignmentglobal name 'determineexprtype' is not definedglobal name 'real16pattern' is not definedlocal variable 'tt' referenced before assignmentglobal name 'typespattern4implicit' is not definedglobal name 'cracktypespec' is not definedlocal variable 'kindselect' referenced before assignmentlocal variable 'charselect' referenced before assignmentlocal variable 'begc' referenced before assignmentlocal variable 'endc' referenced before assignmentlocal variable 'impl' referenced before assignmentlocal variable 'inp' referenced before assignmentlocal variable 'fc' referenced before assignmentlocal variable 'dl' referenced before assignmentlocal variable 'llen' referenced before assignmentlocal variable 'bn' referenced before assignmentlocal variable 'cl' referenced before assignmentlocal variable 'ol' referenced before assignmentlocal variable 'commonkey' referenced before assignmentlocal variable 'mm' referenced before assignmentlocal variable 'isonly' referenced before assignmentglobal name 'previous_context' is not definedglobal name 'appendmultiline' is not definedlocal variable 'context_name' referenced before assignmentlocal variable 'ml' referenced before assignmentglobal name 'selectpattern' is not definedglobal name 'unmarkouterparen' is not definedlocal variable 'expr2' referenced before assignmentlocal variable 'cb' referenced before assignmentlocal variable 'attrspec' referenced before assignmentlocal variable 'entitydecl' referenced before assignmentlocal variable 'el' referenced before assignmentglobal name 'removespaces' is not definedglobal name 'markinnerspaces' is not definedlocal variable 'el1' referenced before assignmentlocal variable 'ename' referenced before assignmentlocal variable 'not_has_typespec' referenced before assignmentglobal name 'lenarraypattern' is not definedlocal variable 'dm' referenced before assignmentlocal variable 'dm1' referenced before assignmentglobal name 'kindselector' is not definedglobal name 'charselector' is not definedglobal name 'lenkindpattern' is not definedlocal variable 'lenkind' referenced before assignmentlocal variable 'sel' referenced before assignmentlocal variable 'unknown' referenced before assignmentglobal name 'get_usedict' is not definedlocal variable 'param_map' referenced before assignmentlocal variable 'usename' referenced before assignmentglobal name 'f90modulevars' is not definedlocal variable 'mapping' referenced before assignmentglobal name 'postcrack2' is not definedlocal variable 'tab' referenced before assignmentglobal name 'setmesstext' is not definedglobal name 'get_useparameters' is not definedlocal variable 'new_body' referenced before assignmentglobal name 'postcrack' is not definedlocal variable 'uret' referenced before assignmentlocal variable 'gret' referenced before assignmentglobal name 'analyzeargs' is not definedglobal name 'analyzecommon' is not definedglobal name 'analyzevars' is not definedglobal name 'sortvarnames' is not definedglobal name 'analyzebody' is not definedlocal variable 'userisdefined' referenced before assignmentlocal variable 'interfaced' referenced before assignmentlocal variable 'bb' referenced before assignmentlocal variable 'edef' referenced before assignmentlocal variable 'interface' referenced before assignmentlocal variable 'mvars' referenced before assignmentlocal variable 'mname' referenced before assignmentlocal variable 'useblock' referenced before assignmentglobal name 'usermodules' is not definedlocal variable 'dep' referenced before assignmentlocal variable 'indep' referenced before assignmentlocal variable 'dims' referenced before assignmentlocal variable 'commonvars' referenced before assignmentlocal variable 'comvars' referenced before assignmentglobal name 'skipfuncs' is not definedglobal name 'onlyfuncs' is not definedglobal name 'crack2fortrangen' is not definedglobal name 'defaultimplicitrules' is not definedlocal variable 'implicitrules' referenced before assignmentlocal variable 'attrrules' referenced before assignmentglobal name 'myeval' is not definedglobal name 'getlincoef_re_1' is not definedlocal variable 'xset' referenced before assignmentlocal variable 'len_e' referenced before assignmentlocal variable 'edl' referenced before assignmentglobal name 'getlincoef' is not definedlocal variable 'd2' referenced before assignmentglobal name '_varname_match' is not definedlocal variable 'c2' referenced before assignmentlocal variable 'c1' referenced before assignmentglobal name 'word_pattern' is not definedlocal variable 'deps' referenced before assignmentglobal name '_get_depend_dict' is not definedglobal name '_calc_depend_dict' is not definedglobal name 'real8pattern' is not definedlocal variable 'global_params' referenced before assignmentglobal name '_kind_func' is not definedglobal name '_selected_int_kind_func' is not definedglobal name '_selected_real_kind_func' is not definedlocal variable 'g_params' referenced before assignmentglobal name 'get_sorted_names' is not definedlocal variable 'param_names' referenced before assignmentlocal variable 'kind_re' referenced before assignmentlocal variable 'selected_int_kind_re' referenced before assignmentglobal name 'isinteger' is not definedlocal variable 'selected_kind_re' referenced before assignmentglobal name 'isdouble' is not definedglobal name '_eval_scalar' is not definedglobal name '_is_kind_number' is not definedglobal name 'buildimplicitrules' is not definedlocal variable 'gen' referenced before assignmentlocal variable 'svars' referenced before assignmentlocal variable 'name_match' referenced before assignmentlocal variable 'dep_matches' referenced before assignmentlocal variable 'ln0' referenced before assignmentlocal variable 'intent' referenced before assignmentlocal variable 'note' referenced before assignmentlocal variable 'depend' referenced before assignmentlocal variable 'star' referenced before assignmentglobal name 'getarrlen' is not definedlocal variable 'di' referenced before assignmentlocal variable 'savelindims' referenced before assignmentlocal variable 'ddeps' referenced before assignmentlocal variable 'ni' referenced before assignmentlocal variable 'pd' referenced before assignmentlocal variable 'shape_macro' referenced before assignmentlocal variable 'ad' referenced before assignmentglobal name '_eval_length' is not definedlocal variable 'ispure' referenced before assignmentlocal variable 'isrec' referenced before assignmentlocal variable 'neededvars' referenced before assignmentglobal name 'analyzeargs_re_1' is not definedlocal variable 'a_is_expr' referenced before assignmentlocal variable 'at' referenced before assignmentlocal variable 'orig_a' referenced before assignmentglobal name 'expr2name' is not definedlocal variable 'args1' referenced before assignmentglobal name '_ensure_exprdict' is not definedglobal name 'determineexprtype_re_1' is not definedglobal name 'determineexprtype_re_2' is not definedglobal name 'determineexprtype_re_3' is not definedglobal name 'determineexprtype_re_4' is not definedglobal name 'determineexprtype_re_5' is not definedlocal variable 'rn' referenced before assignmentlocal variable 'as_interface' referenced before assignmentlocal variable 'argsl' referenced before assignmentlocal variable 'f2pyenhancements' referenced before assignmentglobal name 'tabchar' is not definedlocal variable 'blocktype' referenced before assignmentlocal variable 'intent_lst' referenced before assignmentglobal name 'use2fortran' is not definedglobal name 'common2fortran' is not definedglobal name 'vars2fortran' is not definedlocal variable 'entry_stmts' referenced before assignmentlocal variable 'use' referenced before assignmentlocal variable 'common' referenced before assignmentlocal variable 'nout' referenced before assignmentglobal name 'show' is not definedlocal variable 'vardef' referenced before assignmentglobal name 'true_intent_list' is not definedglobal name 'f2py_version' is not definedlocal variable 'has_newnumpy' referenced before assignmentlocal variable 'numpy' referenced before assignmentlocal variable 'has_f2py2e' referenced before assignmentlocal variable 'f2py2e' referenced before assignmentlocal variable 'has_numpy_distutils' referenced before assignmentlocal variable 'numpy_distutils' referenced before assignmentlocal variable 'cpuinfo' referenced before assignmentlocal variable 'cpu' referenced before assignmentlocal variable '_path' referenced before assignmentname 'auxfuncs' is not definedname 'numpy_version' is not definedlocal variable 'buildpath' referenced before assignmentlocal variable 'inputline' referenced before assignmentlocal variable 'f2' referenced before assignmentlocal variable 'f3' referenced before assignmentlocal variable 'f6' referenced before assignmentlocal variable 'f7' referenced before assignmentlocal variable 'include_paths' referenced before assignmentlocal variable 'f8' referenced before assignmentlocal variable 'f9' referenced before assignmentlocal variable 'skipfuncs' referenced before assignmentlocal variable 'onlyfuncs' referenced before assignmentlocal variable 'f5' referenced before assignmentglobal name '__usage__' is not definedlocal variable 'signsfile' referenced before assignmentlocal variable 'dolc' referenced before assignmentlocal variable 'dolatexdoc' referenced before assignmentlocal variable 'dorestdoc' referenced before assignmentlocal variable 'wrapfuncs' referenced before assignmentglobal name 'rules' is not definedglobal name 'crackfortran' is not definedlocal variable 'postlist' referenced before assignmentlocal variable 'isusedby' referenced before assignmentlocal variable 'mnames' referenced before assignmentlocal variable 'd_in' referenced before assignmentlocal variable 'd_out' referenced before assignmentglobal name 'scaninputline' is not definedlocal variable 'comline_list' referenced before assignmentglobal name 'auxfuncs' is not definedglobal name 'callcrackfortran' is not definedglobal name 'f90mod_rules' is not definedglobal name 'buildmodules' is not definedlocal variable 'fobjcsrc' referenced before assignmentlocal variable 'fobjhsrc' referenced before assignmentlocal variable 'remove_prefix' referenced before assignmentlocal variable 'filtered' referenced before assignmentlocal variable 'tempfile' referenced before assignmentlocal variable '_reg1' referenced before assignmentlocal variable 'sysinfo_flags' referenced before assignmentlocal variable '_reg2' referenced before assignmentlocal variable 'f2py_flags' referenced before assignmentlocal variable 'f2py_flags2' referenced before assignmentlocal variable '_reg3' referenced before assignmentlocal variable 'flib_flags' referenced before assignmentlocal variable '_reg4' referenced before assignmentlocal variable 'fc_flags' referenced before assignmentlocal variable 'ov' referenced before assignmentlocal variable 'allowed_keys' referenced before assignmentlocal variable 'vmap' referenced before assignmentlocal variable 'nv' referenced before assignmentlocal variable 'del_list' referenced before assignmentlocal variable '_reg5' referenced before assignmentlocal variable 'setup_flags' referenced before assignmentglobal name 'filter_files' is not definedlocal variable 'pyf_files' referenced before assignmentlocal variable 'get_f2py_modulename' referenced before assignmentlocal variable 'Extension' referenced before assignmentlocal variable 'setup' referenced before assignmentlocal variable 'remove_build_dir' referenced before assignmentglobal name 'run_compile' is not definedglobal name 'run_main' is not definedlocal variable 'test_functions' referenced before assignmentglobal name 'memusage' is not definedglobal name 'jiffies' is not definedlocal variable 'runtest' referenced before assignmentlocal variable 'start_memusage' referenced before assignmentlocal variable 'diff_memusage' referenced before assignmentlocal variable 'start_jiffies' referenced before assignmentglobal name 'findf90modules' is not definedlocal variable 'pymod' referenced before assignmentlocal variable 'notvars' referenced before assignmentglobal name 'isprivate' is not definedlocal variable 'onlyvars' referenced before assignmentlocal variable 'mfargs' referenced before assignmentlocal variable 'modobjs' referenced before assignmentglobal name 'fgetdims2' is not definedlocal variable 'dms' referenced before assignmentglobal name 'fgetdims2_sa' is not definedglobal name 'isallocatable' is not definedlocal variable 'fargs' referenced before assignmentlocal variable 'efargs' referenced before assignmentlocal variable 'sargs' referenced before assignmentlocal variable 'sargsp' referenced before assignmentlocal variable 'fhooks' referenced before assignmentglobal name 'fgetdims1' is not definedlocal variable 'use_fgetdims2' referenced before assignmentglobal name 'isroutine' is not definedlocal variable 'ifargs' referenced before assignmentlocal variable 'api' referenced before assignmentglobal name 'undo_rmbadname' is not definedlocal variable 'fa' referenced before assignmentlocal variable 'f90mode' referenced before assignmentlocal variable 'lk' referenced before assignmentglobal name 'ismoduleroutine' is not definedglobal name 'var2fixfortran' is not definedlocal variable 'add' referenced before assignmentlocal variable 'dumped_args' referenced before assignmentlocal variable 'need_interface' referenced before assignmentglobal name 'islogicalfunction' is not definedlocal variable 'newname' referenced before assignmentlocal variable 'fortranname' referenced before assignmentlocal variable 'fvar' referenced before assignmentglobal name 'createfuncwrapper' is not definedglobal name 'issubroutine_wrap' is not definedglobal name 'createsubrwrapper' is not definedname 'sepdict' is not definedname 'isdummyroutine' is not definedname 'hasexternals' is not definedname 'isthreadsafe' is not definedname 'iscomplexfunction_warn' is not definedname 'islong_longfunction' is not definedname 'islong_doublefunction' is not definedname 'islong_complex' is not definedname 'isunsigned_char' is not definedname 'isunsigned_short' is not definedname 'isunsigned' is not definedname 'isunsigned_long_long' is not definedname 'isunsigned_chararray' is not definedname 'isunsigned_shortarray' is not definedname 'isunsigned_long_longarray' is not definedname 'issigned_long_longarray' is not definedname 'typedef_need_dict' is not definedname 'isint1array' is not definedname 'isintent_overwrite' is not definedname 'isintent_copy' is not definedglobal name 'defmod_rules' is not definedglobal name 'modsign2map' is not definedlocal variable 'nb_list' referenced before assignmentglobal name 'buildapi' is not definedlocal variable 'funcwrappers2' referenced before assignmentlocal variable 'funcwrappers' referenced before assignmentglobal name 'common_rules' is not definedlocal variable 'cr' referenced before assignmentlocal variable 'mr' referenced before assignmentglobal name 'use_rules' is not definedlocal variable 'needs' referenced before assignmentlocal variable 'mod_rules' referenced before assignmentglobal name 'module_rules' is not definedlocal variable 'wn' referenced before assignmentglobal name 'getargs2' is not definedglobal name 'routsign2map' is not definedglobal name 'rout_rules' is not definedglobal name 'sign2map' is not definedglobal name 'aux_rules' is not definedglobal name 'arg_rules' is not definedlocal variable 'nth' referenced before assignmentglobal name 'stnd' is not definedlocal variable 'nthk' referenced before assignmentglobal name 'check_rules' is not definedglobal name 'routine_rules' is not definedlocal variable 'revmap' referenced before assignmentlocal variable 'varsmap' referenced before assignmentglobal name 'buildusevar' is not definedlocal variable 'realname' referenced before assignmentlocal variable 'usemodulename' referenced before assignmentlocal variable 'nummap' referenced before assignmentglobal name 'usemodule_rules' is not definedname 'fftpack' is not definedname '_fft_cache' is not definedname 'fft' is not definedlocal variable 'fft_cache' referenced before assignmentlocal variable 'init_function' referenced before assignmentglobal name 'swapaxes' is not definedlocal variable 'work_function' referenced before assignmentlocal variable 'wsave' referenced before assignmentglobal name '_raw_fft' is not definedglobal name 'fftpack' is not definedglobal name '_fft_cache' is not definedglobal name 'shape' is not definedglobal name '_real_fft_cache' is not definedglobal name 'irfft' is not definedglobal name 'conjugate' is not definedglobal name 'rfft' is not definedglobal name 'take' is not definedlocal variable 'invreal' referenced before assignmentglobal name '_cook_nd_args' is not definedglobal name '_raw_fftnd' is not definedglobal name 'fft' is not definedglobal name 'ifft' is not definedglobal name 'rfftn' is not definedglobal name 'irfftn' is not definedname 'integer_types' is not definedglobal name 'integer_types' is not definedname 'type_check' is not definedname 'index_tricks' is not definedname 'stride_tricks' is not definedname 'twodim_base' is not definedname 'ufunclike' is not definedname 'arraypad' is not definedname 'polynomial' is not definedname 'utils' is not definedname 'arraysetops' is not definedname 'npyio' is not definedname 'financial' is not definedname 'nanfunctions' is not definedname 'open' is not definedname '_FileOpeners' is not definedname 'DataSource' is not definedglobal name 'open' is not definedglobal name 'DataSource' is not definedlocal variable 'destpath' referenced before assignmentglobal name 'rmtree' is not definedglobal name '_file_openers' is not definedlocal variable '_writemodes' referenced before assignmentlocal variable 'scheme' referenced before assignmentlocal variable 'netloc' referenced before assignmentglobal name '_open' is not definedglobal name 'copyfileobj' is not definedlocal variable 'URLError' referenced before assignmentlocal variable 'upath' referenced before assignmentlocal variable 'filelist' referenced before assignmentlocal variable 'netfile' referenced before assignmentlocal variable 'found' referenced before assignmentlocal variable 'baseurl' referenced before assignmentname 'ConverterError' is not definedglobal name 'complex' is not definedglobal name '_is_string_like' is not definedlocal variable 'return_opened' referenced before assignmentlocal variable 'fhd' referenced before assignmentlocal variable 'opened' referenced before assignmentlocal variable 'ndtype' referenced before assignmentlocal variable 'flatten_base' referenced before assignmentglobal name 'flatten_dtype' is not definedlocal variable 'types' referenced before assignmentlocal variable 'input' referenced before assignmentlocal variable 'comments' referenced before assignmentlocal variable 'delimiter' referenced before assignmentglobal name '_is_bytes_like' is not definedlocal variable 'autostrip' referenced before assignmentlocal variable '_handyman' referenced before assignmentlocal variable 'fixed' referenced before assignmentlocal variable 'slices' referenced before assignmentlocal variable 'excludelist' referenced before assignmentlocal variable 'case_sensitive' referenced before assignmentlocal variable 'replace_space' referenced before assignmentlocal variable 'nbfields' referenced before assignmentlocal variable 'case_converter' referenced before assignmentlocal variable 'defaultfmt' referenced before assignmentlocal variable 'nbempty' referenced before assignmentlocal variable 'validatednames' referenced before assignmentglobal name 'nx' is not definedglobal name 'float' is not definedglobal name '_bytes_to_complex' is not definedlocal variable 'dft' referenced before assignmentlocal variable 'fct' referenced before assignmentlocal variable 'missing_values' referenced before assignmentglobal name 'bool' is not definedlocal variable 'locked' referenced before assignmentlocal variable 'dtype_or_func' referenced before assignmentlocal variable 'deftype' referenced before assignmentlocal variable 'default_def' referenced before assignmentlocal variable '_status' referenced before assignmentglobal name 'ConverterLockError' is not definedglobal name 'ConverterError' is not definedlocal variable '_strict_call' referenced before assignmentlocal variable 'testing_value' referenced before assignmentlocal variable 'tester' referenced before assignmentglobal name 'NameValidator' is not definedlocal variable 'validationargs' referenced before assignmentlocal variable 'validate' referenced before assignmentlocal variable 'nbtypes' referenced before assignmentlocal variable 'reverse' referenced before assignmentlocal variable 'padarr' referenced before assignmentlocal variable 'pad_amt' referenced before assignmentglobal name '_arange_ndarray' is not definedglobal name '_round_ifneeded' is not definedlocal variable 'ramp_arr' referenced before assignmentglobal name '_prepend_edge' is not definedglobal name '_append_edge' is not definedlocal variable 'pad_singleton' referenced before assignmentlocal variable 'ref_chunk1' referenced before assignmentlocal variable 'edge_chunk' referenced before assignmentlocal variable 'ref_chunk2' referenced before assignmentlocal variable 'sym_chunk1' referenced before assignmentlocal variable 'rev_idx' referenced before assignmentlocal variable 'sym_chunk2' referenced before assignmentlocal variable 'narray' referenced before assignmentlocal variable 'shapelen' referenced before assignmentlocal variable 'normshp' referenced before assignmentglobal name '_normalize_shape' is not definedlocal variable 'number_elements' referenced before assignmentlocal variable 'chk' referenced before assignmentglobal name '_validate_lengths' is not definedlocal variable 'pad_width' referenced before assignmentlocal variable 'allowedkwargs' referenced before assignmentlocal variable 'kwdefaults' referenced before assignmentlocal variable 'total_dim_increase' referenced before assignmentlocal variable 'offset_slices' referenced before assignmentlocal variable 'newmat' referenced before assignmentglobal name '_prepend_const' is not definedlocal variable 'pad_before' referenced before assignmentlocal variable 'before_val' referenced before assignmentglobal name '_append_const' is not definedlocal variable 'pad_after' referenced before assignmentlocal variable 'after_val' referenced before assignmentglobal name '_prepend_ramp' is not definedglobal name '_append_ramp' is not definedglobal name '_prepend_max' is not definedlocal variable 'chunk_before' referenced before assignmentglobal name '_append_max' is not definedlocal variable 'chunk_after' referenced before assignmentglobal name '_prepend_mean' is not definedglobal name '_append_mean' is not definedglobal name '_prepend_med' is not definedglobal name '_append_med' is not definedglobal name '_prepend_min' is not definedglobal name '_append_min' is not definedlocal variable 'safe_pad' referenced before assignmentglobal name '_pad_ref' is not definedlocal variable 'pad_iter_a' referenced before assignmentlocal variable 'pad_iter_b' referenced before assignmentglobal name '_pad_sym' is not definedglobal name '_pad_wrap' is not definedlocal variable 'to_begin' referenced before assignmentlocal variable 'to_end' referenced before assignmentlocal variable 'return_inverse' referenced before assignmentlocal variable 'return_index' referenced before assignmentlocal variable 'assume_unique' referenced before assignmentglobal name 'unique' is not definedlocal variable 'ar1' referenced before assignmentlocal variable 'ar2' referenced before assignmentlocal variable 'invert' referenced before assignmentglobal name 'in1d' is not definedlocal variable 'buf_size' referenced before assignmentlocal variable 'slice_' referenced before assignmentglobal name 'mul' is not definedlocal variable 'ndims' referenced before assignmentlocal variable 'rundim' referenced before assignmentlocal variable 'when' referenced before assignmentglobal name '_when_to_num' is not definedglobal name '_convert_when' is not definedlocal variable 'rate' referenced before assignmentlocal variable 'nper' referenced before assignmentlocal variable 'pmt' referenced before assignmentlocal variable 'pv' referenced before assignmentlocal variable 'fv' referenced before assignmentlocal variable 'use_zero_rate' referenced before assignmentlocal variable 'per' referenced before assignmentglobal name 'pmt' is not definedglobal name '_rbl' is not definedlocal variable 'ipmt' referenced before assignmentglobal name 'fv' is not definedglobal name 'ipmt' is not definedlocal variable 'guess' referenced before assignmentlocal variable 'iter' referenced before assignmentlocal variable 'maxiter' referenced before assignmentlocal variable 'close' referenced before assignmentglobal name '_g_div_gp' is not definedlocal variable 'tol' referenced before assignmentlocal variable 'rnp1' referenced before assignmentglobal name 'npv' is not definedlocal variable 'reinvest_rate' referenced before assignmentlocal variable 'finance_rate' referenced before assignmentlocal variable 'neg' referenced before assignmentname 'MAGIC_PREFIX' is not definedglobal name 'MAGIC_PREFIX' is not definedglobal name '_read_bytes' is not definedglobal name 'MAGIC_LEN' is not definedglobal name 'dtype_to_descr' is not definedlocal variable 'struct' referenced before assignmentglobal name 'safe_eval' is not definedglobal name 'magic' is not definedglobal name 'write_array_header_1_0' is not definedglobal name 'header_data_from_array_1_0' is not definedglobal name 'read_magic' is not definedglobal name 'read_array_header_1_0' is not definedglobal name 'BUFFER_SIZE' is not definedlocal variable 'max_read_count' referenced before assignmentlocal variable 'fortran_order' referenced before assignmentlocal variable 'error_template' referenced before assignmentlocal variable 'weights' referenced before assignmentlocal variable 'range' referenced before assignmentlocal variable 'mn' referenced before assignmentglobal name 'iterable' is not definedlocal variable 'bins' referenced before assignmentglobal name 'sort' is not definedlocal variable 'density' referenced before assignmentlocal variable 'normed' referenced before assignmentlocal variable 'sample' referenced before assignmentlocal variable 'D' referenced before assignmentglobal name 'ones' is not definedlocal variable 'smin' referenced before assignmentlocal variable 'smax' referenced before assignmentlocal variable 'nbin' referenced before assignmentlocal variable 'edges' referenced before assignmentglobal name 'diff' is not definedlocal variable 'dedges' referenced before assignmentglobal name 'digitize' is not definedlocal variable 'Ncount' referenced before assignmentglobal name 'log10' is not definedglobal name 'around' is not definedglobal name 'where' is not definedglobal name 'bincount' is not definedlocal variable 'hist' referenced before assignmentlocal variable 'returned' referenced before assignmentglobal name 'typecodes' is not definedlocal variable 'funclist' referenced before assignmentlocal variable 'condlist' referenced before assignmentlocal variable 'n2' referenced before assignmentglobal name 'range' is not definedlocal variable 'totlist' referenced before assignmentlocal variable 'newcondlist' referenced before assignmentlocal variable 'zerod' referenced before assignmentlocal variable 'choicelist' referenced before assignmentlocal variable 'S' referenced before assignmentlocal variable 'pfac' referenced before assignmentglobal name 'choose' is not definedlocal variable 'otype' referenced before assignmentlocal variable 'slice1' referenced before assignmentlocal variable 'slice2' referenced before assignmentlocal variable 'slice3' referenced before assignmentlocal variable 'outvals' referenced before assignmentlocal variable 'dx' referenced before assignmentglobal name 'number' is not definedglobal name 'compiled_interp' is not definedlocal variable 'xp' referenced before assignmentlocal variable 'left' referenced before assignmentlocal variable 'right' referenced before assignmentlocal variable 'deg' referenced before assignmentglobal name 'arctan2' is not definedlocal variable 'discont' referenced before assignmentlocal variable 'trim' referenced before assignmentlocal variable 'filt' referenced before assignmentlocal variable 'first' referenced before assignmentglobal name 'nonzero' is not definedglobal name '_insert' is not definedlocal variable 'device' referenced before assignmentlocal variable 'linefeed' referenced before assignmentlocal variable 'mesg' referenced before assignmentlocal variable 'pyfunc' referenced before assignmentlocal variable 'cache' referenced before assignmentlocal variable 'otypes' referenced before assignmentlocal variable 'excluded' referenced before assignmentlocal variable 'inds' referenced before assignmentlocal variable 'vargs' referenced before assignmentlocal variable '_n' referenced before assignmentlocal variable 'the_args' referenced before assignmentlocal variable '_i' referenced before assignmentglobal name 'frompyfunc' is not definedlocal variable 'inputs' referenced before assignmentlocal variable '_func' referenced before assignmentlocal variable 'ufunc' referenced before assignmentlocal variable '_x' referenced before assignmentlocal variable '_t' referenced before assignmentlocal variable '_res' referenced before assignmentlocal variable 'rowvar' referenced before assignmentlocal variable 'X' referenced before assignmentlocal variable 'bias' referenced before assignmentglobal name 'cov' is not definedglobal name 'diag' is not definedlocal variable 'M' referenced before assignmentglobal name 'cos' is not definedlocal variable 'b1' referenced before assignmentlocal variable 'b0' referenced before assignmentlocal variable 'b2' referenced before assignmentglobal name 'exp' is not definedglobal name '_chbevl' is not definedglobal name '_i0A' is not definedglobal name '_i0B' is not definedglobal name '_i0_1' is not definedglobal name '_i0_2' is not definedlocal variable 'overwrite_input' referenced before assignmentlocal variable 'part' referenced before assignmentglobal name 'mean' is not definedlocal variable 'q' referenced before assignmentglobal name '_compute_qth_percentile' is not definedlocal variable 'sorted' referenced before assignmentlocal variable 'place' referenced before assignmentname 'add_docstring' is not definedlocal variable 'xi' referenced before assignmentlocal variable 's0' referenced before assignmentlocal variable 'indexing' referenced before assignmentlocal variable 'sparse' referenced before assignmentlocal variable 'copy_' referenced before assignmentlocal variable 'mult_fact' referenced before assignmentlocal variable 'slobj' referenced before assignmentlocal variable 'numtodel' referenced before assignmentglobal name 'FutureWarning' is not definedglobal name 'intp' is not definedlocal variable 'numnew' referenced before assignmentname 'matrix' is not definedname 'nd_grid' is not definedname 'mgrid' is not definedname 'ogrid' is not definedname 'AxisConcatenator' is not definedname 'RClass' is not definedname 'CClass' is not definedname 'IndexExpression' is not definedlocal variable 'baseshape' referenced before assignmentglobal name 'makemat' is not definedlocal variable 'trans1d' referenced before assignmentlocal variable 'ndmin' referenced before assignmentglobal name 'matrix' is not definedglobal name 'function_base' is not definedlocal variable 'scalars' referenced before assignmentlocal variable 'scalartypes' referenced before assignmentlocal variable 'tempobj' referenced before assignmentlocal variable 'k2' referenced before assignmentlocal variable 'newobj' referenced before assignmentlocal variable 'objs' referenced before assignmentlocal variable 'scalar' referenced before assignmentlocal variable 'arraytypes' referenced before assignmentglobal name 'find_common_type' is not definedlocal variable 'final_dtype' referenced before assignmentglobal name 'AxisConcatenator' is not definedglobal name 'as_strided' is not definedlocal variable 'maketuple' referenced before assignmentglobal name 'alltrue' is not definedglobal name 'cumprod' is not definedglobal name 'diag_indices' is not definedglobal name '_replace_nan' is not definedglobal name '_copyto' is not definedglobal name '_divide_by_count' is not definedlocal variable 'cnt' referenced before assignmentlocal variable 'avg' referenced before assignmentlocal variable 'dof' referenced before assignmentglobal name 'nanvar' is not definedlocal variable 'GzipFile' referenced before assignmentlocal variable 'gzip' referenced before assignmentlocal variable 'whence' referenced before assignmentglobal name 'weakref' is not definedglobal name 'zipfile_factory' is not definedlocal variable '_zip' referenced before assignmentglobal name 'BagObj' is not definedlocal variable 'own_fid' referenced before assignmentlocal variable 'member' referenced before assignmentglobal name 'format' is not definedglobal name 'seek_gzip_factory' is not definedglobal name 'NpzFile' is not definedlocal variable 'mmap_mode' referenced before assignmentglobal name '_savez' is not definedlocal variable 'namedict' referenced before assignmentlocal variable 'zipfile' referenced before assignmentlocal variable 'converters' referenced before assignmentlocal variable 'usecols' referenced before assignmentglobal name '_getconv' is not definedlocal variable 'skiprows' referenced before assignmentlocal variable 'first_vals' referenced before assignmentlocal variable 'split_line' referenced before assignmentlocal variable 'flatten_dtype' referenced before assignmentlocal variable 'dtype_types' referenced before assignmentlocal variable 'defconv' referenced before assignmentlocal variable 'user_converters' referenced before assignmentlocal variable 'conv' referenced before assignmentlocal variable 'first_line' referenced before assignmentlocal variable 'pack_items' referenced before assignmentlocal variable 'packing' referenced before assignmentlocal variable 'fown' referenced before assignmentlocal variable 'unpack' referenced before assignmentlocal variable 'flat_dt' referenced before assignmentlocal variable 'flat_packing' referenced before assignmentlocal variable 'subpacking' referenced before assignmentglobal name 'asstr' is not definedlocal variable 'ncol' referenced before assignmentglobal name 'map' is not definedlocal variable 'iscomplex_X' referenced before assignmentlocal variable 'n_fmt_chars' referenced before assignmentlocal variable 'row2' referenced before assignmentlocal variable 'footer' referenced before assignmentlocal variable 'own_fh' referenced before assignmentlocal variable 'regexp' referenced before assignmentlocal variable 'missing' referenced before assignmentlocal variable 'usemask' referenced before assignmentglobal name 'LineSplitter' is not definedlocal variable 'skip_header' referenced before assignmentlocal variable 'first_values' referenced before assignmentlocal variable 'validate_names' referenced before assignmentglobal name '_bytes_to_name' is not definedglobal name 'easy_dtype' is not definedlocal variable 'current' referenced before assignmentlocal variable 'nbcols' referenced before assignmentlocal variable 'user_missing_values' referenced before assignmentlocal variable 'entry' referenced before assignmentlocal variable 'user_value' referenced before assignmentlocal variable 'filling_values' referenced before assignmentlocal variable 'user_filling_values' referenced before assignmentglobal name 'StringConverter' is not definedlocal variable 'miss' referenced before assignmentlocal variable 'uc_update' referenced before assignmentlocal variable 'append_to_invalid' referenced before assignmentlocal variable 'nbvalues' referenced before assignmentlocal variable 'append_to_rows' referenced before assignmentlocal variable 'append_to_masks' referenced before assignmentlocal variable 'own_fhd' referenced before assignmentglobal name 'itemgetter' is not definedlocal variable 'converter' referenced before assignmentlocal variable 'current_column' referenced before assignmentlocal variable 'errmsg' referenced before assignmentlocal variable 'skip_footer' referenced before assignmentlocal variable 'nbrows' referenced before assignmentlocal variable 'nbinvalid' referenced before assignmentlocal variable 'invalid_raise' referenced before assignmentglobal name 'ConversionWarning' is not definedlocal variable 'masks' referenced before assignmentlocal variable 'loose' referenced before assignmentlocal variable 'column_types' referenced before assignmentlocal variable 'strcolidx' referenced before assignmentlocal variable 'ddtype' referenced before assignmentlocal variable 'mdtype' referenced before assignmentlocal variable 'dtype_flat' referenced before assignmentglobal name 'has_nested_fields' is not definedlocal variable 'make_mask_descr' referenced before assignmentlocal variable 'ishomogeneous' referenced before assignmentlocal variable 'ttype' referenced before assignmentlocal variable 'outputmask' referenced before assignmentlocal variable 'MaskedArray' referenced before assignmentglobal name 'genfromtxt' is not definedname 'RankWarning' is not definedlocal variable 'seq_of_zeros' referenced before assignmentglobal name 'eigvals' is not definedlocal variable 'sh' referenced before assignmentglobal name 'NX' is not definedglobal name 'sort_complex' is not definedglobal name 'hstack' is not definedglobal name 'poly1d' is not definedglobal name 'polyint' is not definedglobal name 'polyder' is not definedlocal variable 'rcond' referenced before assignmentglobal name 'finfo' is not definedglobal name 'vander' is not definedlocal variable 'rhs' referenced before assignmentlocal variable 'lhs' referenced before assignmentglobal name 'lstsq' is not definedlocal variable 'full' referenced before assignmentglobal name 'RankWarning' is not definedlocal variable 'resids' referenced before assignmentlocal variable 'cov' referenced before assignmentglobal name 'inv' is not definedlocal variable 'Vbase' referenced before assignmentglobal name 'abs' is not definedlocal variable 'truepoly' referenced before assignmentglobal name '_poly_mat' is not definedlocal variable 'line2' referenced before assignmentlocal variable 'line1' referenced before assignmentlocal variable 'toadd1' referenced before assignmentlocal variable 'toadd2' referenced before assignmentlocal variable 'partstr' referenced before assignmentlocal variable 'power' referenced before assignmentlocal variable 'c_or_r' referenced before assignmentlocal variable 'variable' referenced before assignmentglobal name 'poly' is not definedglobal name 'trim_zeros' is not definedlocal variable 'coeffs' referenced before assignmentlocal variable 'fmt_float' referenced before assignmentglobal name 'real' is not definedglobal name 'imag' is not definedlocal variable 'coefstr' referenced before assignmentlocal variable 'thestr' referenced before assignmentglobal name '_raise_power' is not definedglobal name 'polyval' is not definedglobal name 'polymul' is not definedglobal name 'polyadd' is not definedglobal name 'polysub' is not definedglobal name 'polydiv' is not definedglobal name 'roots' is not definedglobal name 'isreal' is not definedglobal name '_tocomplex' is not definedglobal name '_fix_real_lt_zero' is not definedglobal name '_fix_int_lt_zero' is not definedglobal name '_fix_real_abs_gt_1' is not definedname 'vstack' is not definedlocal variable 'nd' referenced before assignmentlocal variable 'func1d' referenced before assignmentlocal variable 'outshape' referenced before assignmentlocal variable 'indlist' referenced before assignmentlocal variable 'outarr' referenced before assignmentlocal variable 'holdshape' referenced before assignmentglobal name 'expand_dims' is not definedlocal variable 'arrays' referenced before assignmentglobal name 'atleast_3d' is not definedlocal variable 'sub_arys' referenced before assignmentlocal variable 'indices_or_sections' referenced before assignmentlocal variable 'Ntotal' referenced before assignmentlocal variable 'extras' referenced before assignmentlocal variable 'Neach_section' referenced before assignmentlocal variable 'Nsections' referenced before assignmentlocal variable 'div_points' referenced before assignmentlocal variable 'sary' referenced before assignmentglobal name '_replace_zero_by_x_arrays' is not definedglobal name 'array_split' is not definedglobal name 'outer' is not definedglobal name 'get_array_prepare' is not definedglobal name 'get_array_wrap' is not definedlocal variable 'reps' referenced before assignmentlocal variable 'A' referenced before assignmentlocal variable 'nrep' referenced before assignmentglobal name 'DummyArray' is not definedlocal variable 'shapes' referenced before assignmentlocal variable 'nds' referenced before assignmentlocal variable 'biggest' referenced before assignmentlocal variable 'common_shape' referenced before assignmentlocal variable 'new_length' referenced before assignmentlocal variable 'broadcasted' referenced before assignmentglobal name 'fliplr' is not definedglobal name 'flipud' is not definedglobal name 'subtract' is not definedglobal name 'tri' is not definedlocal variable 'xedges' referenced before assignmentlocal variable 'yedges' referenced before assignmentlocal variable 'histogramdd' referenced before assignmentlocal variable 'mask_func' referenced before assignmentglobal name 'mask_indices' is not definedglobal name 'tril' is not definedglobal name 'tril_indices' is not definedglobal name 'triu' is not definedglobal name 'triu_indices' is not definedlocal variable 'typechars' referenced before assignmentlocal variable 'typecodes' referenced before assignmentlocal variable 'typeset' referenced before assignmentlocal variable 'intersection' referenced before assignmentglobal name '_typecodes_by_elsize' is not definedglobal name 'nan_to_num' is not definedglobal name 'isposinf' is not definedglobal name 'isneginf' is not definedglobal name '_getmaxmin' is not definedlocal variable 'are_nan' referenced before assignmentlocal variable 'maxf' referenced before assignmentlocal variable 'are_inf' referenced before assignmentlocal variable 'minf' referenced before assignmentlocal variable 'are_neg_inf' referenced before assignmentglobal name '_namefromtype' is not definedglobal name 'iscomplexobj' is not definedglobal name 'array_precision' is not definedlocal variable 'is_complex' referenced before assignmentglobal name 'array_type' is not definedglobal name 'get_include' is not definedlocal variable 'old_name' referenced before assignmentlocal variable 'new_name' referenced before assignmentlocal variable 'depdoc' referenced before assignmentglobal name '_set_function_name' is not definedlocal variable 'newfunc' referenced before assignmentlocal variable 'warnings' referenced before assignmentglobal name '_Deprecate' is not definedlocal variable 'a_low' referenced before assignmentlocal variable 'a_high' referenced before assignmentlocal variable 'bytes_a' referenced before assignmentlocal variable 'vardict' referenced before assignmentlocal variable 'sta' referenced before assignmentlocal variable 'maxname' referenced before assignmentlocal variable 'maxshape' referenced before assignmentlocal variable 'maxbyte' referenced before assignmentlocal variable 'totalbytes' referenced before assignmentlocal variable 'sp1' referenced before assignmentlocal variable 'sp2' referenced before assignmentlocal variable 'sp3' referenced before assignmentlocal variable 'arguments' referenced before assignmentlocal variable 'firstwidth' referenced before assignmentlocal variable 'sepstr' referenced before assignmentlocal variable 'thisdict' referenced before assignmentlocal variable 'dictlist' referenced before assignmentlocal variable 'totraverse' referenced before assignmentlocal variable 'thedict' referenced before assignmentglobal name '_namedict' is not definedglobal name '_makenamedict' is not definedlocal variable 'toplevel' referenced before assignmentglobal name '_dictlist' is not definedlocal variable 'objlist' referenced before assignmentlocal variable 'maxwidth' referenced before assignmentlocal variable 'numfound' referenced before assignmentglobal name '_split_line' is not definedlocal variable 'pydoc' referenced before assignmentlocal variable 'meth' referenced before assignmentlocal variable 'methstr' referenced before assignmentglobal name '_lookfor_generate_cache' is not definedlocal variable 'import_modules' referenced before assignmentlocal variable 'regenerate' referenced before assignmentlocal variable 'what' referenced before assignmentlocal variable 'whats' referenced before assignmentlocal variable 'docstring' referenced before assignmentlocal variable 'doclines' referenced before assignmentglobal name '_function_signature_re' is not definedlocal variable 'help_text' referenced before assignmentlocal variable 'first_doc' referenced before assignmentlocal variable 'docstr' referenced before assignmentlocal variable 'kind_relevance' referenced before assignmentlocal variable 'relevance' referenced before assignmentglobal name '_lookfor_caches' is not definedlocal variable 'pth' referenced before assignmentlocal variable 'mod_path' referenced before assignmentlocal variable 'init_py' referenced before assignmentlocal variable 'to_import' referenced before assignmentlocal variable 'StringIO' referenced before assignmentlocal variable 'base_exc' referenced before assignmentglobal name '_getmembers' is not definedlocal variable 'item_name' referenced before assignmentlocal variable 'mod_name' referenced before assignmentglobal name 'ufunc' is not definedlocal variable '_all' referenced before assignmentlocal variable 'members' referenced before assignmentglobal name 'SafeEval' is not definedlocal variable 'walker' referenced before assignmentlocal variable 'ast' referenced before assignmentname '_determine_error_states' is not definedname 'single' is not definedname 'double' is not definedname 'csingle' is not definedname 'cdouble' is not definedname 'fastCopyAndTranspose' is not definedglobal name 'geterrobj' is not definedlocal variable 'invalid_call_errmask' referenced before assignmentglobal name 'LinAlgError' is not definedglobal name '_linalg_error_extobj' is not definedglobal name 'complexfloating' is not definedglobal name '_real_types_map' is not definedglobal name '_complex_types_map' is not definedglobal name 'double' is not definedglobal name 'single' is not definedglobal name 'inexact' is not definedglobal name 'isComplexType' is not definedglobal name '_realType' is not definedglobal name 'cdouble' is not definedlocal variable 'result_type' referenced before assignmentlocal variable 'cast_arrays' referenced before assignmentglobal name '_fastCT' is not definedglobal name '_makearray' is not definedlocal variable 'allaxes' referenced before assignmentlocal variable 'an' referenced before assignmentglobal name 'solve' is not definedlocal variable 'oldshape' referenced before assignmentglobal name '_assertRankAtLeast2' is not definedglobal name '_assertNdSquareness' is not definedglobal name '_commonType' is not definedglobal name 'broadcast' is not definedlocal variable 'result_t' referenced before assignmentglobal name '_umath_linalg' is not definedglobal name 'get_linalg_error_extobj' is not definedglobal name '_raise_linalgerror_singular' is not definedlocal variable 'invshape' referenced before assignmentglobal name '_raise_linalgerror_nonposdef' is not definedlocal variable 'gufunc' referenced before assignmentlocal variable 'extobj' referenced before assignmentglobal name '_assertRank2' is not definedglobal name '_assertNoEmpty2d' is not definedglobal name '_fastCopyAndTranspose' is not definedglobal name '_to_native_byte_order' is not definedglobal name 'lapack_lite' is not definedlocal variable 'mc' referenced before assignmentlocal variable 'tau' referenced before assignmentglobal name '_assertFinite' is not definedglobal name '_raise_linalgerror_eigenvalues_nonconvergence' is not definedglobal name 'all' is not definedglobal name '_complexType' is not definedlocal variable 'UPLO' referenced before assignmentlocal variable 'vt' referenced before assignmentglobal name '_raise_linalgerror_svd_nonconvergence' is not definedlocal variable 'compute_uv' referenced before assignmentlocal variable 'full_matrices' referenced before assignmentglobal name 'svd' is not definedglobal name 'norm' is not definedglobal name 'sum' is not definedlocal variable 'cutoff' referenced before assignmentlocal variable 'logdet' referenced before assignmentlocal variable 'real_t' referenced before assignmentglobal name '_linalgRealType' is not definedlocal variable 'ldb' referenced before assignmentlocal variable 'n_rhs' referenced before assignmentlocal variable 'bstar' referenced before assignmentglobal name 'fortran_int' is not definedlocal variable 'result_real_t' referenced before assignmentlocal variable 'is_1d' referenced before assignmentlocal variable 'results' referenced before assignmentlocal variable 'row_axis' referenced before assignmentlocal variable 'col_axis' referenced before assignmentlocal variable 'op' referenced before assignmentlocal variable 'ord' referenced before assignmentglobal name 'Inf' is not definedglobal name 'longdouble' is not definedglobal name 'asfarray' is not definedlocal variable 'absx' referenced before assignmentglobal name '_multi_svd_norm' is not definedglobal name 'amax' is not definedglobal name 'amin' is not definedname 'extras' is not definedname 'MaskType' is not definedname 'MAError' is not definedname 'max_filler' is not definedname 'min_filler' is not definedname 'getdata' is not definedname 'nomask' is not definedname '_MaskedUnaryOperation' is not definedname 'angle' is not definedname '_DomainGreaterEqual' is not definedname '_DomainGreater' is not definedname '_DomainTan' is not definedname '_DomainCheckInterval' is not definedname '_MaskedBinaryOperation' is not definedname 'logical_or' is not definedname '_DomainedBinaryOperation' is not definedname '_DomainSafeDivide' is not definedname 'getmask' is not definedname '_MaskedPrintOption' is not definedname 'MaskedArray' is not definedname 'isMaskedArray' is not definedname 'MaskedConstant' is not definedname 'masked_array' is not definedname '_extrema_operation' is not definedname 'min' is not definedname 'max' is not definedname 'ptp' is not definedname '_frommethod' is not definedname '_maximum_operation' is not definedname '_minimum_operation' is not definedname 'argsort' is not definedname 'argmin' is not definedname 'rank' is not definedname 'round_' is not definedname 'doc_note' is not definedname 'inner' is not definedname '_convert2ma' is not definedlocal variable 'initialdoc' referenced before assignmentglobal name 'formatargspec' is not definedglobal name 'getargspec' is not definedglobal name '_check_fill_value' is not definedglobal name 'default_filler' is not definedlocal variable 'defval' referenced before assignmentglobal name '_recursive_extremum_fill_value' is not definedlocal variable 'extremum' referenced before assignmentlocal variable 'deflist' referenced before assignmentglobal name 'min_filler' is not definedglobal name 'max_filler' is not definedlocal variable 'dtypedescr' referenced before assignmentglobal name '_recursive_set_default_fill_value' is not definedglobal name 'default_fill_value' is not definedlocal variable 'fillvalue' referenced before assignmentlocal variable 'output_value' referenced before assignmentglobal name '_recursive_set_fill_value' is not definedlocal variable 'fval' referenced before assignmentlocal variable 'fdtype' referenced before assignmentglobal name 'MaskedArray' is not definedglobal name 'get_fill_value' is not definedlocal variable 'arrcls' referenced before assignmentlocal variable 'rcls' referenced before assignmentglobal name 'masked_array' is not definedlocal variable 'tolerance' referenced before assignmentlocal variable 'critical_value' referenced before assignmentlocal variable 'mufunc' referenced before assignmentlocal variable 'domain' referenced before assignmentglobal name 'ufunc_domain' is not definedglobal name 'ufunc_fills' is not definedglobal name 'getdata' is not definedglobal name 'getmask' is not definedglobal name 'masked' is not definedglobal name 'nomask' is not definedlocal variable 'mbfunc' referenced before assignmentlocal variable 'fillx' referenced before assignmentlocal variable 'filly' referenced before assignmentlocal variable 'ma' referenced before assignmentlocal variable 'mb' referenced before assignmentglobal name 'getmaskarray' is not definedlocal variable 'da' referenced before assignmentlocal variable 'db' referenced before assignmentglobal name 'get_masked_subclass' is not definedglobal name 'filled' is not definedglobal name 'make_mask' is not definedlocal variable 'tclass' referenced before assignmentlocal variable 'dbfunc' referenced before assignmentglobal name '_recursive_make_descr' is not definedlocal variable 'newtype' referenced before assignmentglobal name 'make_mask_none' is not definedglobal name 'MaskType' is not definedglobal name 'make_mask_descr' is not definedlocal variable 'shrink' referenced before assignmentlocal variable 'm2' referenced before assignmentglobal name 'is_mask' is not definedlocal variable 'dtype1' referenced before assignmentlocal variable 'dtype2' referenced before assignmentlocal variable '_recursive_mask_or' referenced before assignmentlocal variable 'newmask' referenced before assignmentlocal variable '_flatsequence' referenced before assignmentglobal name 'flatten_mask' is not definedlocal variable 'sequence' referenced before assignmentlocal variable 'cshape' referenced before assignmentlocal variable 'ashape' referenced before assignmentglobal name 'mask_or' is not definedlocal variable 'cond' referenced before assignmentglobal name 'masked_where' is not definedlocal variable 'v2' referenced before assignmentglobal name 'isMaskedArray' is not definedlocal variable 'curdata' referenced before assignmentglobal name '_recursive_printoption' is not definedlocal variable 'curmask' referenced before assignmentlocal variable 'printopt' referenced before assignmentglobal name '_recursive_filled' is not definedlocal variable 'flatten_sequence' referenced before assignmentlocal variable 'inishape' referenced before assignmentlocal variable 'iterable' referenced before assignmentlocal variable 'funcname' referenced before assignmentlocal variable 'onmask' referenced before assignmentlocal variable 'methdoc' referenced before assignmentglobal name '_arraymethod' is not definedlocal variable '_data' referenced before assignmentlocal variable 'names_' referenced before assignmentlocal variable 'keep_mask' referenced before assignmentlocal variable 'nm' referenced before assignmentglobal name 'MaskError' is not definedlocal variable '_recursive_or' referenced before assignmentlocal variable 'hard_mask' referenced before assignmentlocal variable '_baseclass' referenced before assignmentlocal variable 'af' referenced before assignmentlocal variable 'bf' referenced before assignmentlocal variable '_mask' referenced before assignmentglobal name 'mvoid' is not definedlocal variable 'dout' referenced before assignmentlocal variable '_dtype' referenced before assignmentlocal variable 'dval' referenced before assignmentlocal variable 'mval' referenced before assignmentlocal variable 'dindx' referenced before assignmentlocal variable 'idtype' referenced before assignmentlocal variable 'current_mask' referenced before assignmentglobal name 'flatten_structured_array' is not definedglobal name 'MaskedIterator' is not definedglobal name 'masked_singleton' is not definedglobal name 'masked_print_option' is not definedglobal name '_print_templates' is not definedglobal name 'divide' is not definedglobal name 'true_divide' is not definedglobal name 'floor_divide' is not definedglobal name 'power' is not definedglobal name '_DomainSafeDivide' is not definedlocal variable 'dom_mask' referenced before assignmentlocal variable 'other_data' referenced before assignmentlocal variable 'new_mask' referenced before assignmentlocal variable 'other_mask' referenced before assignmentglobal name '_check_mask_axis' is not definedlocal variable 'outmask' referenced before assignmentlocal variable 'dsum' referenced before assignmentlocal variable 'danom' referenced before assignmentlocal variable 'dvar' referenced before assignmentglobal name 'minimum_fill_value' is not definedglobal name 'maximum_fill_value' is not definedlocal variable 'endwith' referenced before assignmentlocal variable 'shp' referenced before assignmentlocal variable 'isf' referenced before assignmentlocal variable 'raw' referenced before assignmentlocal variable 'msk' referenced before assignmentlocal variable 'flv' referenced before assignmentglobal name '_mareconstruct' is not definedlocal variable 'memo' referenced before assignmentlocal variable 'deepcopy' referenced before assignmentlocal variable 'copied' referenced before assignmentlocal variable 'baseclass' referenced before assignmentlocal variable 'hardmask' referenced before assignmentlocal variable '_m' referenced before assignmentglobal name 'logical_or' is not definedlocal variable 'methodname' referenced before assignmentlocal variable 'reversed' referenced before assignmentglobal name 'get_object_signature' is not definedlocal variable 'third' referenced before assignmentglobal name 'n_expand_dims' is not definedlocal variable 'valmask' referenced before assignmentlocal variable 'valdata' referenced before assignmentlocal variable 'notfc' referenced before assignmentlocal variable 'nmask' referenced before assignmentlocal variable 'fmask' referenced before assignmentlocal variable 'masked_equal' referenced before assignmentlocal variable 'F' referenced before assignmentlocal variable 'strg' referenced before assignmentlocal variable 'fxarray' referenced before assignmentlocal variable '_extras' referenced before assignmentlocal variable 'common_params' referenced before assignmentname '_fromnxfunction' is not definedname 'apply_along_axis' is not definedname 'apply_over_axes' is not definedname 'MAxisConcatenator' is not definedname 'mr_class' is not definedname 'ma' is not definedname 'polyfit' is not definedglobal name 'ma' is not definedlocal variable '_d' referenced before assignmentglobal name 'issequence' is not definedlocal variable 'asscalar' referenced before assignmentlocal variable 'dtypes' referenced before assignmentglobal name 'flatten_inplace' is not definedlocal variable 'asorted' referenced before assignmentglobal name 'apply_along_axis' is not definedlocal variable 'rmd' referenced before assignmentglobal name 'nxarray' is not definedlocal variable 'idxr' referenced before assignmentlocal variable 'masked' referenced before assignmentlocal variable 'idxc' referenced before assignmentglobal name 'compress_rowcols' is not definedglobal name 'mask_rowcols' is not definedlocal variable 'strict' referenced before assignmentglobal name 'mask_rows' is not definedglobal name 'mask_cols' is not definedlocal variable 'allow_masked' referenced before assignmentlocal variable 'xmask' referenced before assignmentlocal variable 'ymask' referenced before assignmentlocal variable 'xnotmask' referenced before assignmentglobal name '_covhelper' is not definedlocal variable 'diag' referenced before assignmentglobal name 'diagflat' is not definedglobal name 'vstack' is not definedlocal variable '_denom' referenced before assignmentglobal name 'MAError' is not definedlocal variable 'final_dtypedescr' referenced before assignmentglobal name 'MAxisConcatenator' is not definedglobal name 'flatnotmasked_edges' is not definedglobal name 'flatnotmasked_contiguous' is not definedglobal name '_ezclump' is not definedname 'MaskedRecords' is not definedlocal variable 'default_names' referenced before assignmentlocal variable 'new_names' referenced before assignmentlocal variable 'ndescr' referenced before assignmentglobal name 'reserved_fields' is not definedlocal variable 'mdescr' referenced before assignmentlocal variable '_localdict' referenced before assignmentlocal variable 'optinfo' referenced before assignmentglobal name 'mrecarray' is not definedlocal variable 'mstr' referenced before assignmentlocal variable 'reprstr' referenced before assignmentglobal name '_mrreconstruct' is not definedlocal variable 'arraylist' referenced before assignmentglobal name 'recfromarrays' is not definedlocal variable 'datalist' referenced before assignmentlocal variable 'masklist' referenced before assignmentlocal variable 'reclist' referenced before assignmentglobal name 'recfromrecords' is not definedlocal variable 'mrec' referenced before assignmentlocal variable 'vartypes' referenced before assignmentglobal name 'openfile' is not definedlocal variable 'commentchar' referenced before assignmentlocal variable 'delimitor' referenced before assignmentlocal variable 'varnames' referenced before assignmentglobal name '_guessvartypes' is not definedlocal variable '_variables' referenced before assignmentlocal variable 'missingchar' referenced before assignmentlocal variable 'mfillv' referenced before assignmentlocal variable '_datalist' referenced before assignmentlocal variable 'mrecord' referenced before assignmentlocal variable 'newfieldname' referenced before assignmentlocal variable 'newfield' referenced before assignmentlocal variable 'newdata' referenced before assignmentglobal name 'MaskedRecords' is not definedname 'defmatrix' is not definedname '_NumCharTable' is not definedname '_table' is not definedname '_numchars' is not definedname '_todelete' is not definedname 'N' is not definedname 'asmatrix' is not definedglobal name '_numchars' is not definedglobal name '_table' is not definedglobal name '_todelete' is not definedlocal variable 'newrow' referenced before assignmentglobal name '_eval' is not definedlocal variable 'Ncols' referenced before assignmentglobal name 'issubdtype' is not definedglobal name 'identity' is not definedglobal name 'N' is not definedglobal name 'binary_repr' is not definedlocal variable 'Z' referenced before assignmentglobal name '_convert_from_string' is not definedglobal name 'asmatrix' is not definedglobal name 'matrix_power' is not definedlocal variable 'ldict' referenced before assignmentlocal variable 'gdict' referenced before assignmentlocal variable 'col' referenced before assignmentlocal variable 'coltup' referenced before assignmentlocal variable 'thismat' referenced before assignmentlocal variable 'rowtup' referenced before assignmentglobal name '_from_string' is not definedlocal variable 'arr_rows' referenced before assignmentname '_msg' is not definedname 'ModuleDeprecationWarning' is not definedname 'util' is not definedname 'functions' is not definedname 'ufuncs' is not definedname 'compat' is not definedname 'session' is not definedname 'RAISE' is not definedname 'Warning' is not definedname 'STRICT' is not definedlocal variable 'use_default' referenced before assignmentlocal variable 'typecode' referenced before assignmentglobal name 'type2dtype' is not definedlocal variable 'digits' referenced before assignmentlocal variable 'population' referenced before assignmentlocal variable 'clipmode' referenced before assignmentlocal variable 'infile' referenced before assignmentlocal variable 'sizing' referenced before assignmentglobal name 'STRICT' is not definedlocal variable 'bytesleft' referenced before assignmentglobal name '_BLOCKSIZE' is not definedglobal name 'EarlyEOFError' is not definedlocal variable 'bytesread' referenced before assignmentlocal variable 'blocksize' referenced before assignmentlocal variable 'endpos' referenced before assignmentlocal variable 'curpos' referenced before assignmentlocal variable 'recsize' referenced before assignmentlocal variable 'initsize' referenced before assignmentglobal name '_resizebuf' is not definedglobal name 'SizeMismatchError' is not definedglobal name '_warnings' is not definedglobal name 'SizeMismatchWarning' is not definedglobal name 'FileSeekWarning' is not definedlocal variable 'newsize' referenced before assignmentglobal name 'typefrom' is not definedlocal variable 'byteswap' referenced before assignmentlocal variable 'def_axes' referenced before assignmentlocal variable 'work' referenced before assignmentname 'NumericType' is not definedname 'IntegralType' is not definedname 'SignedType' is not definedname 'UnsignedType' is not definedname 'AnyType' is not definedname '_tAny' is not definedname 'ObjectType' is not definedname '_tObject' is not definedname 'BooleanType' is not definedname '_tBool' is not definedname 'SignedIntegralType' is not definedname '_tInt8' is not definedname '_tInt16' is not definedname '_tInt32' is not definedname '_tInt64' is not definedname 'FloatingType' is not definedname '_tFloat32' is not definedname '_tFloat64' is not definedname 'UnsignedIntegralType' is not definedname '_tUInt8' is not definedname '_tUInt16' is not definedname '_tUInt32' is not definedname '_tUInt64' is not definedname 'ComplexType' is not definedname '_tComplex32' is not definedname '_tComplex64' is not definedname 'Object' is not definedname 'Bool' is not definedname 'Int16' is not definedname 'Int32' is not definedname 'Int64' is not definedname 'UInt8' is not definedname 'UInt16' is not definedname 'UInt32' is not definedname 'UInt64' is not definedname 'Float32' is not definedname 'Float64' is not definedname 'Complex32' is not definedname 'Complex64' is not definedname '_register' is not definedname 'LP64' is not definedname 'HasUInt64' is not definedname '_scipy_alias' is not definedname 'pythonTypeMap' is not definedname 'scalarTypeMap' is not definedname '_initGenericCoercions' is not definedname '_scipy_dtypechar' is not definedname '_scipy_dtypechar_inverse' is not definedname 'value' is not definedname '_val' is not definedglobal name 'NumericType' is not definedglobal name 'typeDict' is not definedlocal variable 'typeno' referenced before assignmentglobal name '_register' is not definedlocal variable 'scipy_type' referenced before assignmentlocal variable 'numarray_type' referenced before assignmentglobal name 'genericTypeRank' is not definedglobal name 'IntegralType' is not definedglobal name 'SignedIntegralType' is not definedlocal variable 'ntype2' referenced before assignmentlocal variable 'signedtype1' referenced before assignmentlocal variable 'signedtype2' referenced before assignmentlocal variable 'inttype1' referenced before assignmentlocal variable 'inttype2' referenced before assignmentlocal variable 'ntypesize2' referenced before assignmentlocal variable 'ntypesize1' referenced before assignmentglobal name 'MAX_INT_SIZE' is not definedlocal variable 'rank1' referenced before assignmentlocal variable 'rank2' referenced before assignmentlocal variable 'ntype1' referenced before assignmentlocal variable 'outtype' referenced before assignmentglobal name 'genericCoercions' is not definedglobal name 'pythonTypeRank' is not definedglobal name 'pythonTypeMap' is not definedlocal variable 'mapto' referenced before assignmentglobal name 'scalarTypeMap' is not definedlocal variable 'maptype1' referenced before assignmentglobal name '_MaximumType' is not definedglobal name '_scipy_dtypechar_inverse' is not definedname '_foo' is not definedname 'SAVEFILE' is not definedlocal variable '_type' referenced before assignmentglobal name '_PROXY_ALLOWED' is not definedglobal name '_caller' is not definedglobal name '_callers_globals' is not definedlocal variable 'mods' referenced before assignmentglobal name 'VERBOSE' is not definedglobal name '_errout' is not definedlocal variable 'save' referenced before assignmentglobal name '_verbose' is not definedglobal name '_loadmodule' is not definedglobal name '_unknown' is not definedlocal variable '_type2' referenced before assignmentglobal name '_ProxyingFailure' is not definedglobal name 'ObjectNotFound' is not definedglobal name '_update_proxy_types' is not definedlocal variable 'dictionary' referenced before assignmentlocal variable 'variables' referenced before assignmentglobal name '_callers_modules' is not definedglobal name '_ModuleProxy' is not definedglobal name '_locate' is not definedlocal variable 'source_modules' referenced before assignmentglobal name '_ObjectProxy' is not definedlocal variable 'proxy' referenced before assignmentglobal name '_SaveSession' is not definedlocal variable 'session' referenced before assignmentlocal variable 'errorStatus' referenced before assignmentlocal variable 'sourcemsg' referenced before assignmentglobal name 'MathDomainError' is not definedglobal name 'NumOverflowError' is not definedglobal name 'UnderflowError' is not definedname 'pu' is not definedname 'polytemplate' is not definedlocal variable 'zs' referenced before assignmentlocal variable 'z1' referenced before assignmentlocal variable 'z2' referenced before assignmentlocal variable 'len2' referenced before assignmentlocal variable 'quo' referenced before assignmentlocal variable 'scl' referenced before assignmentglobal name '_zseries_div' is not definedlocal variable 'ns' referenced before assignmentglobal name '_zseries_mul' is not definedlocal variable 'div' referenced before assignmentglobal name 'pu' is not definedlocal variable 'pol' referenced before assignmentglobal name 'chebadd' is not definedglobal name 'chebmulx' is not definedlocal variable 'c0' referenced before assignmentlocal variable 'polysub' referenced before assignmentlocal variable 'polyadd' referenced before assignmentlocal variable 'polymulx' referenced before assignmentlocal variable 'off' referenced before assignmentlocal variable 'roots' referenced before assignmentglobal name 'chebline' is not definedglobal name 'chebmul' is not definedlocal variable 'prd' referenced before assignmentglobal name '_cseries_to_zseries' is not definedglobal name '_zseries_to_cseries' is not definedlocal variable 'rem' referenced before assignmentlocal variable 'pow' referenced before assignmentlocal variable 'maxpower' referenced before assignmentlocal variable 'iaxis' referenced before assignmentlocal variable 'der' referenced before assignmentglobal name 'chebval' is not definedlocal variable 'lbnd' referenced before assignmentlocal variable 'tensor' referenced before assignmentlocal variable 'ideg' referenced before assignmentlocal variable 'is_valid' referenced before assignmentglobal name 'chebvander' is not definedlocal variable 'degx' referenced before assignmentlocal variable 'degy' referenced before assignmentlocal variable 'degz' referenced before assignmentglobal name 'la' is not definedlocal variable 'mat' referenced before assignmentglobal name 'chebcompanion' is not definedlocal variable 'npts' referenced before assignmentglobal name 'hermadd' is not definedglobal name 'hermmulx' is not definedglobal name 'hermline' is not definedglobal name 'hermmul' is not definedglobal name 'hermsub' is not definedlocal variable 'xs' referenced before assignmentglobal name 'hermval' is not definedglobal name 'hermvander' is not definedglobal name 'hermcompanion' is not definedglobal name 'hermder' is not definedlocal variable 'df' referenced before assignmentlocal variable 'fm' referenced before assignmentglobal name 'hermeadd' is not definedglobal name 'hermemulx' is not definedglobal name 'hermeline' is not definedglobal name 'hermemul' is not definedglobal name 'hermesub' is not definedglobal name 'hermeval' is not definedglobal name 'hermevander' is not definedglobal name 'hermecompanion' is not definedglobal name 'hermeder' is not definedglobal name 'lagadd' is not definedglobal name 'lagmulx' is not definedglobal name 'lagline' is not definedglobal name 'lagmul' is not definedglobal name 'lagsub' is not definedglobal name 'lagval' is not definedglobal name 'lagvander' is not definedglobal name 'lagcompanion' is not definedglobal name 'lagder' is not definedglobal name 'legadd' is not definedglobal name 'legmulx' is not definedglobal name 'legline' is not definedglobal name 'legmul' is not definedglobal name 'legsub' is not definedglobal name 'legval' is not definedglobal name 'legvander' is not definedglobal name 'legcompanion' is not definedglobal name 'legder' is not definedglobal name 'polyline' is not definedlocal variable 'cdt' referenced before assignmentglobal name 'polyvander' is not definedglobal name 'polycompanion' is not definedname 'PolyError' is not definedlocal variable 'alist' referenced before assignmentglobal name 'trimseq' is not definedglobal name 'as_series' is not definedlocal variable 'rmin' referenced before assignmentlocal variable 'imin' referenced before assignmentlocal variable 'rmax' referenced before assignmentlocal variable 'imax' referenced before assignmentglobal name 'mapparms' is not definedname 'random_sample' is not definedglobal name 'RandomState' is not definedlocal variable 'tf' referenced before assignmentlocal variable 'skip_condition' referenced before assignmentlocal variable 'nose' referenced before assignmentlocal variable 'skip_val' referenced before assignmentlocal variable 'get_msg' referenced before assignmentlocal variable 'fail_condition' referenced before assignmentlocal variable 'fail_val' referenced before assignmentlocal variable 'KnownFailureTest' referenced before assignmentlocal variable 'conditional' referenced before assignmentname 'doctest' is not definedname 'npd' is not definedname 'ErrorClassPlugin' is not definedname 'nose' is not definedglobal name 'doctest' is not definedlocal variable 'tests' referenced before assignmentlocal variable 'source_lines' referenced before assignmentlocal variable 'globs' referenced before assignmentlocal variable 'valname' referenced before assignmentlocal variable 'isroutine' referenced before assignmentlocal variable 'isclass' referenced before assignmentlocal variable 'valname1' referenced before assignmentlocal variable 'isfunction' referenced before assignmentlocal variable 'ismethod' referenced before assignmentlocal variable 'want' referenced before assignmentlocal variable 'got' referenced before assignmentlocal variable 'optionflags' referenced before assignmentlocal variable 'result_var' referenced before assignmentlocal variable 'test' referenced before assignmentlocal variable 'setUp' referenced before assignmentlocal variable 'tearDown' referenced before assignmentlocal variable 'checker' referenced before assignmentglobal name 'NumpyDocTestCase' is not definedglobal name 'NumpyOutputChecker' is not definedglobal name 'NumpyDocTestFinder' is not definedglobal name 'Plugin' is not definedlocal variable 'parser' referenced before assignmentglobal name 'get_package_name' is not definedglobal name '__builtins__' is not definedglobal name 'npd' is not definedglobal name 'src' is not definedlocal variable 'module_file' referenced before assignmentglobal name 'print_state' is not definedlocal variable 'to_unplug' referenced before assignmentglobal name 'ErrorClass' is not definedglobal name 'KnownFailureTest' is not definedlocal variable 'conf' referenced before assignmentglobal name 'nose' is not definedlocal variable 'filepath' referenced before assignmentlocal variable 'p2' referenced before assignmentlocal variable 'fullpath' referenced before assignmentlocal variable 'minimum_nose_version' referenced before assignmentlocal variable 'fine_nose' referenced before assignmentlocal variable 'file_to_run' referenced before assignmentglobal name 'import_nose' is not definedlocal variable 'raise_warnings' referenced before assignmentlocal variable 'label' referenced before assignmentlocal variable 'extra_argv' referenced before assignmentlocal variable 'coverage' referenced before assignmentlocal variable 'doctests' referenced before assignmentlocal variable 'doctest_argv' referenced before assignmentlocal variable 'plugins' referenced before assignmentlocal variable 'Unplugger' referenced before assignmentlocal variable 'plug' referenced before assignmentglobal name 'ModuleDeprecationWarning' is not definedlocal variable 'NumpyTestProgram' referenced before assignmentname 'importall' is not definedname 'm' is not definedname 'float32' is not definedlocal variable 'random' referenced before assignmentlocal variable '_load_time' referenced before assignmentlocal variable '_proc_pid_stat' referenced before assignmentlocal variable 'machine' referenced before assignmentlocal variable 'instance' referenced before assignmentlocal variable 'inum' referenced before assignmentlocal variable 'win32pdh' referenced before assignmentlocal variable 'hc' referenced before assignmentlocal variable 'hq' referenced before assignmentglobal name 'GetPerformanceAttributes' is not definedlocal variable 'processName' referenced before assignmentlocal variable 'err_msg' referenced before assignmentlocal variable 'desired' referenced before assignmentlocal variable 'actual' referenced before assignmentglobal name 'assert_equal' is not definedglobal name 'assert_array_equal' is not definedglobal name 'build_err_msg' is not definedlocal variable 'iscomplexobj' referenced before assignmentlocal variable 'usecomplex' referenced before assignmentlocal variable 'real' referenced before assignmentlocal variable 'imag' referenced before assignmentlocal variable 'isscalar' referenced before assignmentglobal name 'gisfinite' is not definedglobal name 'gisnan' is not definedlocal variable 'isdesnan' referenced before assignmentlocal variable 'isactnan' referenced before assignmentlocal variable 'signbit' referenced before assignmentglobal name 'StringIO' is not definedlocal variable 'test_string' referenced before assignmentlocal variable 'decimal' referenced before assignmentglobal name 'assert_almost_equal' is not definedlocal variable 'ndarray' referenced before assignmentglobal name 'assert_array_almost_equal' is not definedlocal variable 'np' referenced before assignmentlocal variable 'significant' referenced before assignmentlocal variable 'sc_desired' referenced before assignmentlocal variable 'sc_actual' referenced before assignmentlocal variable 'isnumber' referenced before assignmentlocal variable 'isnan' referenced before assignmentlocal variable 'isinf' referenced before assignmentlocal variable 'any' referenced before assignmentlocal variable 'x_isnan' referenced before assignmentlocal variable 'y_isnan' referenced before assignmentlocal variable 'chk_same_position' referenced before assignmentlocal variable 'x_isinf' referenced before assignmentlocal variable 'y_isinf' referenced before assignmentlocal variable 'inf' referenced before assignmentlocal variable 'x_id' referenced before assignmentlocal variable 'y_id' referenced before assignmentlocal variable 'comparison' referenced before assignmentlocal variable 'hasval' referenced before assignmentglobal name 'assert_array_compare' is not definedglobal name 'operator' is not definedlocal variable 'npany' referenced before assignmentglobal name 'gisinf' is not definedlocal variable 'xinfid' referenced before assignmentlocal variable 'yinfid' referenced before assignmentlocal variable 'issubdtype' referenced before assignmentlocal variable 'float_' referenced before assignmentlocal variable 'around' referenced before assignmentlocal variable 'pathname' referenced before assignmentlocal variable 'doctest' referenced before assignmentlocal variable 'raise_on_error' referenced before assignmentlocal variable 'runner' referenced before assignmentlocal variable 'testmatch' referenced before assignmentlocal variable 'methods' referenced before assignmentlocal variable 'decorator' referenced before assignmentlocal variable 'code_str' referenced before assignmentlocal variable 'times' referenced before assignmentlocal variable 'locs' referenced before assignmentlocal variable 'elapsed' referenced before assignmentglobal name 'assert_' is not definedlocal variable 'rc' referenced before assignmentlocal variable 'compare' referenced before assignmentlocal variable 'nulp' referenced before assignmentglobal name 'nulp_diff' is not definedlocal variable 'maxulp' referenced before assignmentglobal name 'integer_repr' is not definedlocal variable 'rx' referenced before assignmentlocal variable 'ry' referenced before assignmentlocal variable 'vdt' referenced before assignmentlocal variable 'comp' referenced before assignmentglobal name '_integer_repr' is not definedlocal variable 'local_values' referenced before assignmentlocal variable 'category' referenced before assignmentlocal variable 'record' referenced before assignmentlocal variable 'log' referenced before assignmentglobal name 'WarningMessage' is not definedlocal variable 'warning_class' referenced before assignmentlocal variable 'max_size' referenced before assignmentlocal variable 'ufmt' referenced before assignmentlocal variable 'bfmt' referenced before assignmentname 'release' is not definedname 'full_version' is not definedname 'frozenset' is not definedname 'ResolutionError' is not definedname 'get_build_platform' is not definedname 'run_script' is not definedname 'IMetadataProvider' is not definedname 'Environment' is not definedname 'MarkerEvaluation' is not definedname 'register_loader_type' is not definedname 'NullProvider' is not definedname 'EggProvider' is not definedname 'DefaultProvider' is not definedname 'importlib_bootstrap' is not definedname 'EmptyProvider' is not definedname 'ZipManifests' is not definedname 'zipfile' is not definedname 'zipimport' is not definedname 'ZipProvider' is not definedname '_declare_state' is not definedname 'register_finder' is not definedname 'find_eggs_in_zip' is not definedname 'find_nothing' is not definedname 'pkgutil' is not definedname 'find_on_path' is not definedname 'register_namespace_handler' is not definedname 'file_ns_handler' is not definedname 'null_ns_handler' is not definedname 'DistInfoDistribution' is not definedname 'ResourceManager' is not definedname '_initialize' is not definedname 'WorkingSet' is not definedname 'working_set' is not definedname 'add_activation_listener' is not definedglobal name 'WRITE_SUPPORT' is not definedlocal variable 'dirname' referenced before assignmentglobal name 'isdir' is not definedglobal name '_bypass_ensure_directory' is not definedglobal name 'mkdir' is not definedglobal name '_state_vars' is not definedlocal variable 'vartype' referenced before assignmentglobal name 'get_build_platform' is not definedglobal name 'macosVersionString' is not definedglobal name '_macosx_vers' is not definedlocal variable 'provider_factory' referenced before assignmentglobal name '_provider_factories' is not definedlocal variable 'loader_type' referenced before assignmentlocal variable 'moduleOrReq' referenced before assignmentglobal name 'Requirement' is not definedglobal name 'working_set' is not definedglobal name 'require' is not definedglobal name '_find_adapter' is not definedglobal name 'plistlib' is not definedlocal variable 'get_platform' referenced before assignmentglobal name '_macosx_arch' is not definedlocal variable 'provided' referenced before assignmentlocal variable 'required' referenced before assignmentglobal name 'darwinVersionString' is not definedlocal variable 'dversion' referenced before assignmentlocal variable 'macosversion' referenced before assignmentlocal variable 'provMac' referenced before assignmentlocal variable 'reqMac' referenced before assignmentlocal variable 'dist_spec' referenced before assignmentlocal variable 'script_name' referenced before assignmentglobal name 'get_provider' is not definedglobal name 'get_distribution' is not definedlocal variable '__requires__' referenced before assignmentglobal name 'VersionConflict' is not definedglobal name 'parse_requirements' is not definedlocal variable 'req_spec' referenced before assignmentglobal name 'Environment' is not definedglobal name 'find_distributions' is not definedlocal variable 'insert' referenced before assignmentlocal variable 'keys2' referenced before assignmentlocal variable 'replace_conflicting' referenced before assignmentglobal name 'WorkingSet' is not definedlocal variable 'installer' referenced before assignmentlocal variable 'best' referenced before assignmentglobal name 'DistributionNotFound' is not definedlocal variable 'to_activate' referenced before assignmentlocal variable 'processed' referenced before assignmentlocal variable 'plugin_env' referenced before assignmentlocal variable 'full_env' referenced before assignmentlocal variable 'plugin_projects' referenced before assignmentlocal variable 'shadow_set' referenced before assignmentglobal name 'ResolutionError' is not definedlocal variable 'error_info' referenced before assignmentlocal variable 'fallback' referenced before assignmentlocal variable 'resolvees' referenced before assignmentlocal variable 'distributions' referenced before assignmentlocal variable 'needed' referenced before assignmentlocal variable 'e_k_b_c' referenced before assignmentlocal variable 'by_key' referenced before assignmentlocal variable 'callbacks' referenced before assignmentglobal name 'get_supported_platform' is not definedglobal name 'PY_MAJOR' is not definedlocal variable 'python' referenced before assignmentlocal variable 'search_path' referenced before assignmentglobal name 'compatible_platforms' is not definedlocal variable 'project_name' referenced before assignmentlocal variable 'working_set' referenced before assignmentlocal variable 'requirement' referenced before assignmentlocal variable 'package_or_requirement' referenced before assignmentlocal variable 'resource_name' referenced before assignmentglobal name 'get_default_cache' is not definedglobal name 'ExtractionError' is not definedlocal variable 'old_exc' referenced before assignmentlocal variable 'cache_path' referenced before assignmentlocal variable 'extract_path' referenced before assignmentlocal variable 'archive_name' referenced before assignmentlocal variable 'target_path' referenced before assignmentglobal name 'stat' is not definedlocal variable 'tempname' referenced before assignmentlocal variable 'subdir' referenced before assignmentlocal variable 'exc' referenced before assignmentlocal variable 'nodelist' referenced before assignmentglobal name 'functools' is not definedglobal name 'token' is not definedlocal variable 'cop' referenced before assignmentglobal name 'symbol' is not definedglobal name 'parser' is not definedlocal variable '_markerlib' referenced before assignmentlocal variable 'cand' referenced before assignmentglobal name 'BytesIO' is not definedlocal variable 'manager' referenced before assignmentglobal name 'yield_lines' is not definedlocal variable 'namespace' referenced before assignmentglobal name 'NullProvider' is not definedglobal name 'ContextualZipFile' is not definedlocal variable 'zfile' referenced before assignmentlocal variable 'mtime' referenced before assignmentglobal name 'zipfile' is not definedglobal name 'MemoizedZipManifests' is not definedglobal name 'ZipManifests' is not definedglobal name 'EggProvider' is not definedlocal variable 'fspath' referenced before assignmentlocal variable 'zip_path' referenced before assignmentlocal variable 'zip_stat' referenced before assignmentglobal name 'time' is not definedglobal name '_mkstemp' is not definedlocal variable 'outf' referenced before assignmentglobal name 'utime' is not definedlocal variable 'tmpnam' referenced before assignmentlocal variable 'timestamp' referenced before assignmentlocal variable 'real_path' referenced before assignmentglobal name 'rename' is not definedglobal name 'unlink' is not definedlocal variable 'file_path' referenced before assignmentlocal variable 'zip_contents' referenced before assignmentlocal variable 'file_contents' referenced before assignmentlocal variable 'eagers' referenced before assignmentlocal variable 'metadata' referenced before assignmentlocal variable 'egg_info' referenced before assignmentlocal variable 'importer' referenced before assignmentlocal variable 'distribution_finder' referenced before assignmentglobal name '_distribution_finders' is not definedlocal variable 'importer_type' referenced before assignmentglobal name 'get_importer' is not definedlocal variable 'path_item' referenced before assignmentlocal variable 'only' referenced before assignmentglobal name 'EggMetadata' is not definedglobal name 'find_eggs_in_zip' is not definedglobal name 'zipimport' is not definedglobal name '_normalize_cached' is not definedglobal name 'PathMetadata' is not definedglobal name 'FileMetadata' is not definedglobal name 'DEVELOP_DIST' is not definedlocal variable 'lower' referenced before assignmentlocal variable 'entry_lines' referenced before assignmentlocal variable 'namespace_handler' referenced before assignmentglobal name '_namespace_handlers' is not definedlocal variable 'packageName' referenced before assignmentglobal name '_set_parent_ns' is not definedlocal variable 'loader' referenced before assignmentglobal name '_namespace_packages' is not definedglobal name 'declare_namespace' is not definedglobal name '_handle_ns' is not definedglobal name 'fixup_namespace_packages' is not definedlocal variable 'normalized' referenced before assignmentglobal name 'normalize_path' is not definedlocal variable 'strs' referenced before assignmentglobal name 'component_re' is not definedglobal name '_parse_version_parts' is not definedlocal variable 'parts' referenced before assignmentglobal name 'MODULE' is not definedlocal variable 'require' referenced before assignmentglobal name 'UnknownExtra' is not definedlocal variable 'this' referenced before assignmentglobal name 'split_sections' is not definedlocal variable 'maps' referenced before assignmentlocal variable 'location' referenced before assignmentglobal name 'urlparse' is not definedglobal name 'urlunparse' is not definedglobal name 'EGG_DIST' is not definedglobal name 'safe_name' is not definedglobal name 'safe_version' is not definedlocal variable 'py_version' referenced before assignmentlocal variable 'precedence' referenced before assignmentglobal name 'empty_provider' is not definedlocal variable 'basename' referenced before assignmentglobal name '_distributionImpl' is not definedglobal name 'EGG_NAME' is not definedglobal name '_remove_md5_fragment' is not definedglobal name 'parse_version' is not definedglobal name 'invalid_marker' is not definedglobal name 'evaluate_marker' is not definedglobal name 'safe_extra' is not definedglobal name 'to_filename' is not definedglobal name 'EntryPoint' is not definedlocal variable 'ep_map' referenced before assignmentlocal variable 'loc' referenced before assignmentlocal variable 'npath' referenced before assignmentlocal variable 'nloc' referenced before assignmentlocal variable 'bdir' referenced before assignmentlocal variable 'nsp' referenced before assignmentglobal name 'issue_warning' is not definedglobal name 'email' is not definedlocal variable 'requires_dist' referenced before assignmentglobal name 'next' is not definedlocal variable 'distvers' referenced before assignmentlocal variable 'compile_marker' referenced before assignmentlocal variable 'mark' referenced before assignmentglobal name 'frozenset' is not definedlocal variable 'reqs_for_extra' referenced before assignmentglobal name 'DISTRO' is not definedglobal name 'OBRACKET' is not definedlocal variable 'scan_list' referenced before assignmentglobal name 'CBRACKET' is not definedglobal name 'VERSION' is not definedglobal name 'LINE_END' is not definedlocal variable 'TERMINATOR' referenced before assignmentglobal name 'CONTINUE' is not definedlocal variable 'ITEM' referenced before assignmentlocal variable 'groups' referenced before assignmentglobal name 'COMMA' is not definedglobal name 'state_machine' is not definedlocal variable 'ver' referenced before assignmentlocal variable 'parsed' referenced before assignmentlocal variable 'trans' referenced before assignmentglobal name '_get_mro' is not definedlocal variable 'registry' referenced before assignmentlocal variable 'content' referenced before assignmentglobal name 'os_open' is not definedglobal name '_manager' is not definedname 'Thread' is not definedlocal variable 'character' referenced before assignmentlocal variable 'char_string' referenced before assignmentglobal name 'Thread' is not definedlocal variable 'capture' referenced before assignmentname 'PyKeyboardMeta' is not definedname 'PyKeyboardEventMeta' is not definedglobal name 'special_key_translate_table' is not definedglobal name 'character_translate_table' is not definedglobal name 'CGEventCreateKeyboardEvent' is not definedlocal variable 'down' referenced before assignmentglobal name 'CGEventPost' is not definedglobal name 'kCGHIDEventTap' is not definedglobal name 'NSEvent' is not definedglobal name 'NSSystemDefined' is not definedglobal name 'CGEventTapCreate' is not definedglobal name 'kCGSessionEventTap' is not definedglobal name 'kCGHeadInsertEventTap' is not definedglobal name 'kCGEventTapOptionDefault' is not definedglobal name 'CGEventMaskBit' is not definedglobal name 'kCGEventKeyDown' is not definedglobal name 'kCGEventKeyUp' is not definedglobal name 'CFMachPortCreateRunLoopSource' is not definedglobal name 'CFRunLoopGetCurrent' is not definedglobal name 'CFRunLoopAddSource' is not definedglobal name 'kCFRunLoopDefaultMode' is not definedglobal name 'CGEventTapEnable' is not definedglobal name 'CFRunLoopRunInMode' is not definedglobal name 'CGEventGetIntegerValueField' is not definedglobal name 'kCGKeyboardEventKeycode' is not definedglobal name 'CGEventSetType' is not definedglobal name 'kCGEventNull' is not definedglobal name 'PyKeyboardMeta' is not definedglobal name 'win32api' is not definedlocal variable 'shifted' referenced before assignmentglobal name 'KEYEVENTF_KEYUP' is not definedglobal name 'VK_BACK' is not definedglobal name 'VK_TAB' is not definedglobal name 'VK_CLEAR' is not definedglobal name 'VK_RETURN' is not definedglobal name 'VK_SHIFT' is not definedglobal name 'VK_LSHIFT' is not definedglobal name 'VK_RSHIFT' is not definedglobal name 'VK_CONTROL' is not definedglobal name 'VK_LCONTROL' is not definedglobal name 'VK_RCONTROL' is not definedglobal name 'VK_MENU' is not definedglobal name 'VK_LMENU' is not definedglobal name 'VK_RMENU' is not definedglobal name 'VK_PAUSE' is not definedglobal name 'VK_CAPITAL' is not definedglobal name 'VK_NUMLOCK' is not definedglobal name 'VK_SCROLL' is not definedglobal name 'VK_KANA' is not definedglobal name 'VK_HANGEUL' is not definedglobal name 'VK_HANGUL' is not definedglobal name 'VK_JUNJA' is not definedglobal name 'VK_FINAL' is not definedglobal name 'VK_HANJA' is not definedglobal name 'VK_KANJI' is not definedglobal name 'VK_CONVERT' is not definedglobal name 'VK_NONCONVERT' is not definedglobal name 'VK_ACCEPT' is not definedglobal name 'VK_MODECHANGE' is not definedglobal name 'VK_ESCAPE' is not definedglobal name 'VK_SPACE' is not definedglobal name 'VK_PRIOR' is not definedglobal name 'VK_NEXT' is not definedglobal name 'VK_HOME' is not definedglobal name 'VK_UP' is not definedglobal name 'VK_DOWN' is not definedglobal name 'VK_LEFT' is not definedglobal name 'VK_RIGHT' is not definedglobal name 'VK_END' is not definedglobal name 'VK_SELECT' is not definedglobal name 'VK_PRINT' is not definedglobal name 'VK_SNAPSHOT' is not definedglobal name 'VK_EXECUTE' is not definedglobal name 'VK_INSERT' is not definedglobal name 'VK_DELETE' is not definedglobal name 'VK_HELP' is not definedglobal name 'VK_LWIN' is not definedglobal name 'VK_RWIN' is not definedglobal name 'VK_APPS' is not definedglobal name 'VK_NUMPAD7' is not definedglobal name 'VK_NUMPAD4' is not definedglobal name 'VK_NUMPAD8' is not definedglobal name 'VK_NUMPAD6' is not definedglobal name 'VK_NUMPAD2' is not definedglobal name 'VK_NUMPAD9' is not definedglobal name 'VK_NUMPAD3' is not definedglobal name 'VK_NUMPAD1' is not definedglobal name 'VK_NUMPAD0' is not definedglobal name 'VK_DECIMAL' is not definedglobal name 'VK_MULTIPLY' is not definedglobal name 'VK_ADD' is not definedglobal name 'VK_SEPARATOR' is not definedglobal name 'VK_SUBTRACT' is not definedglobal name 'VK_DIVIDE' is not definedglobal name 'VK_NUMPAD5' is not definedglobal name 'VK_F1' is not definedglobal name 'VK_F2' is not definedglobal name 'VK_F3' is not definedglobal name 'VK_F4' is not definedglobal name 'VK_F5' is not definedglobal name 'VK_F6' is not definedglobal name 'VK_F7' is not definedglobal name 'VK_F8' is not definedglobal name 'VK_F9' is not definedglobal name 'VK_F10' is not definedglobal name 'VK_F11' is not definedglobal name 'VK_F12' is not definedglobal name 'VK_F13' is not definedglobal name 'VK_F14' is not definedglobal name 'VK_F15' is not definedglobal name 'VK_F16' is not definedglobal name 'VK_F17' is not definedglobal name 'VK_F18' is not definedglobal name 'VK_F19' is not definedglobal name 'VK_F20' is not definedglobal name 'VK_F21' is not definedglobal name 'VK_F22' is not definedglobal name 'VK_F23' is not definedglobal name 'VK_F24' is not definedglobal name 'VK_CANCEL' is not definedglobal name 'VK_BROWSER_BACK' is not definedglobal name 'VK_BROWSER_FORWARD' is not definedglobal name 'VK_PROCESSKEY' is not definedglobal name 'VK_ATTN' is not definedglobal name 'VK_CRSEL' is not definedglobal name 'VK_EXSEL' is not definedglobal name 'VK_EREOF' is not definedglobal name 'VK_PLAY' is not definedglobal name 'VK_ZOOM' is not definedglobal name 'VK_NONAME' is not definedglobal name 'VK_PA1' is not definedglobal name 'VK_OEM_CLEAR' is not definedglobal name 'VK_VOLUME_MUTE' is not definedglobal name 'VK_VOLUME_DOWN' is not definedglobal name 'VK_VOLUME_UP' is not definedglobal name 'VK_MEDIA_NEXT_TRACK' is not definedglobal name 'VK_MEDIA_PREV_TRACK' is not definedglobal name 'VK_MEDIA_PLAY_PAUSE' is not definedglobal name 'PyKeyboardEventMeta' is not definedglobal name 'pythoncom' is not definedlocal variable 'reply' referenced before assignmentglobal name 'pyHook' is not definedglobal name 'Display' is not definedglobal name 'special_X_keysyms' is not definedlocal variable 'press_bool' referenced before assignmentlocal variable 'keysym_index' referenced before assignmentlocal variable 'modifier_mapping' referenced before assignmentlocal variable 'mod_keycodes' referenced before assignmentlocal variable 'all_mod_keycodes' referenced before assignmentlocal variable 'lookup_keycode' referenced before assignmentlocal variable 'alt_keycodes' referenced before assignmentlocal variable 'num_lock_keycodes' referenced before assignmentlocal variable 'super_keycodes' referenced before assignmentlocal variable 'mode_switch_keycodes' referenced before assignmentlocal variable 'string_to_keysym_dict' referenced before assignmentlocal variable 'keysym_to_string_dict' referenced before assignmentname 'show_numpy_config' is not definedname '_num' is not definedname 'linalg' is not definedname '__SCIPY_SETUP__' is not definedname '_NumpyVersion' is not definedname '__numpy_version__' is not definedname 'ode' is not definedname 'IntegratorBase' is not definedname 'vode' is not definedname 'zvode' is not definedname 'dopri5' is not definedname 'dop853' is not definedname 'lsoda' is not definedlocal variable 'jac' referenced before assignmentglobal name 'find_integrator' is not definedlocal variable 'integrator_params' referenced before assignmentlocal variable 'relax' referenced before assignmentlocal variable 'solout' referenced before assignmentglobal name 'ode' is not definedlocal variable 'f_args' referenced before assignmentlocal variable 'jac_args' referenced before assignmentglobal name 'IntegratorBase' is not definedglobal name 'IntegratorConcurrencyError' is not definedglobal name '_vode' is not definedlocal variable 'with_jacobian' referenced before assignmentlocal variable 'uband' referenced before assignmentlocal variable 'lband' referenced before assignmentlocal variable 'nsteps' referenced before assignmentlocal variable 'max_step' referenced before assignmentlocal variable 'min_step' referenced before assignmentlocal variable 'first_step' referenced before assignmentlocal variable 'has_jac' referenced before assignmentlocal variable 'miter' referenced before assignmentlocal variable 'lrw' referenced before assignmentglobal name 'int32' is not definedlocal variable 'istate' referenced before assignmentlocal variable 'lzw' referenced before assignmentglobal name '_dop' is not definedlocal variable 'safety' referenced before assignmentlocal variable 'ifactor' referenced before assignmentlocal variable 'dfactor' referenced before assignmentlocal variable 'verbosity' referenced before assignmentlocal variable 'complex' referenced before assignmentlocal variable 't0' referenced before assignmentlocal variable 't1' referenced before assignmentlocal variable 'f_params' referenced before assignmentlocal variable 'idid' referenced before assignmentglobal name '_lsoda' is not definedlocal variable 'max_order_ns' referenced before assignmentlocal variable 'max_order_s' referenced before assignmentlocal variable 'ixpr' referenced before assignmentlocal variable 'max_hnil' referenced before assignmentlocal variable 'jt' referenced before assignmentlocal variable 'lrs' referenced before assignmentlocal variable 'jac_params' referenced before assignmentlocal variable 'mu' referenced before assignmentglobal name '_odepack' is not definedlocal variable 'Dfun' referenced before assignmentlocal variable 'col_deriv' referenced before assignmentlocal variable 'full_output' referenced before assignmentlocal variable 'tcrit' referenced before assignmentlocal variable 'h0' referenced before assignmentlocal variable 'hmax' referenced before assignmentlocal variable 'hmin' referenced before assignmentlocal variable 'mxstep' referenced before assignmentlocal variable 'mxhnil' referenced before assignmentlocal variable 'mxordn' referenced before assignmentlocal variable 'mxords' referenced before assignmentglobal name '_msgs' is not definedlocal variable 'printmessg' referenced before assignmentname '_quadpack' is not definedglobal name 'quad' is not definedlocal variable 'weight' referenced before assignmentglobal name '_quad' is not definedlocal variable 'epsabs' referenced before assignmentlocal variable 'epsrel' referenced before assignmentlocal variable 'limit' referenced before assignmentglobal name '_quad_weight' is not definedlocal variable 'limlst' referenced before assignmentlocal variable 'maxp1' referenced before assignmentlocal variable 'wvar' referenced before assignmentlocal variable 'wopts' referenced before assignmentlocal variable 'msgs' referenced before assignmentlocal variable 'ier' referenced before assignmentlocal variable 'explain' referenced before assignmentglobal name 'IntegrationWarning' is not definedlocal variable 'infbounds' referenced before assignmentglobal name '_quadpack' is not definedlocal variable 'bound' referenced before assignmentlocal variable 'integr' referenced before assignmentlocal variable 'strdict' referenced before assignmentlocal variable 'myargs' referenced before assignmentlocal variable 'gfun' referenced before assignmentlocal variable 'hfun' referenced before assignmentlocal variable 'more_args' referenced before assignmentglobal name '_infunc' is not definedlocal variable 'qfun' referenced before assignmentlocal variable 'rfun' referenced before assignmentglobal name 'dblquad' is not definedglobal name '_infunc2' is not definedglobal name '_RangeFunc' is not definedglobal name '_OptFunc' is not definedglobal name '_NQuad' is not definedlocal variable 'range_' referenced before assignmentglobal name 'partial' is not definedlocal variable 'abserr' referenced before assignmentglobal name 'p_roots' is not definedlocal variable 'ainf' referenced before assignmentlocal variable 'binf' referenced before assignmentlocal variable 'vec_func' referenced before assignmentglobal name 'xrange' is not definedglobal name 'vectorize1' is not definedlocal variable 'miniter' referenced before assignmentglobal name 'fixed_quad' is not definedlocal variable 'vfunc' referenced before assignmentglobal name 'AccuracyWarning' is not definedglobal name 'tupleset' is not definedlocal variable 'initial' referenced before assignmentlocal variable 'even' referenced before assignmentglobal name '_basic_simps' is not definedlocal variable 'first_dx' referenced before assignmentlocal variable 'returnshape' referenced before assignmentlocal variable 'saveshape' referenced before assignmentlocal variable 'Ninterv' referenced before assignmentlocal variable 'slice_R' referenced before assignmentlocal variable 'R' referenced before assignmentlocal variable 'show' referenced before assignmentlocal variable 'precis' referenced before assignmentlocal variable 'formstr' referenced before assignmentlocal variable 'numtraps' referenced before assignmentlocal variable 'resmat' referenced before assignmentglobal name '_difftrap' is not definedlocal variable 'divmax' referenced before assignmentlocal variable 'ordsum' referenced before assignmentlocal variable 'intrange' referenced before assignmentglobal name '_romberg_diff' is not definedglobal name '_printresmat' is not definedglobal name '_builtincoeffs' is not definedlocal variable 'vi' referenced before assignmentlocal variable 'Cinv' referenced before assignmentlocal variable 'C' referenced before assignmentlocal variable 'nvec' referenced before assignmentlocal variable 'BN' referenced before assignmentlocal variable 'yi' referenced before assignmentglobal name 'gammaln' is not definedlocal variable 'old_module_name' referenced before assignmentlocal variable 'new_module_name' referenced before assignmentlocal variable 'vstring' referenced before assignmentlocal variable 'ver_main' referenced before assignmentlocal variable 'pre_rel' referenced before assignmentlocal variable 'vercmp' referenced before assignmentglobal name 'string_types' is not definedglobal name 'NumpyVersion' is not definedname 'register_func' is not definedname 'pinv2' is not definedlocal variable 'vh' referenced before assignmentglobal name 'callable' is not definedlocal variable 'sort' referenced before assignmentlocal variable 'sfunction' referenced before assignmentlocal variable 'check_finite' referenced before assignmentglobal name 'asarray_chkfinite' is not definedlocal variable 'B' referenced before assignmentlocal variable 'a_m' referenced before assignmentlocal variable 'a_n' referenced before assignmentlocal variable 'b_m' referenced before assignmentlocal variable 'b_n' referenced before assignmentlocal variable 'typa' referenced before assignmentglobal name '_double_precision' is not definedlocal variable 'typb' referenced before assignmentlocal variable 'overwrite_a' referenced before assignmentglobal name '_datacopied' is not definedlocal variable 'overwrite_b' referenced before assignmentglobal name 'get_lapack_funcs' is not definedlocal variable 'lwork' referenced before assignmentlocal variable 'gges' referenced before assignmentglobal name '_select_function' is not definedlocal variable 'sort_t' referenced before assignmentlocal variable 'E' referenced before assignmentglobal name 'expm_frechet_algo_64' is not definedglobal name 'expm_frechet_block_enlarge' is not definedlocal variable 'compute_expm' referenced before assignmentlocal variable 'expm_A' referenced before assignmentlocal variable 'expm_frechet_AE' referenced before assignmentglobal name 'scipy' is not definedlocal variable 'ident' referenced before assignmentglobal name '_diff_pade3' is not definedglobal name '_diff_pade5' is not definedglobal name '_diff_pade7' is not definedglobal name '_diff_pade9' is not definedlocal variable 'A_norm_1' referenced before assignmentglobal name 'ell_table_61' is not definedlocal variable 'pade' referenced before assignmentlocal variable 'U' referenced before assignmentlocal variable 'V' referenced before assignmentlocal variable 'Lu' referenced before assignmentlocal variable 'Lv' referenced before assignmentlocal variable 'L' referenced before assignmentglobal name 'expm_frechet' is not definedlocal variable 'cols' referenced before assignmentglobal name 'vec' is not definedglobal name 'expm_frechet_kronform' is not definedname 'LogmRankWarning' is not definedname 'LinearOperator' is not definedglobal name '_MatrixM1PowerOperator' is not definedglobal name 'onenormest' is not definedlocal variable 'itmax' referenced before assignmentlocal variable 'compute_v' referenced before assignmentlocal variable 'compute_w' referenced before assignmentlocal variable 'z0' referenced before assignmentlocal variable 't12' referenced before assignmentglobal name '_unwindk' is not definedlocal variable 'f12' referenced before assignmentlocal variable 'T0' referenced before assignmentglobal name '_count_nonzero' is not definedlocal variable 'tmp_diag' referenced before assignmentlocal variable 'theta' referenced before assignmentglobal name '_sqrtm_triu' is not definedlocal variable 'T' referenced before assignmentglobal name '_onenormest_m1_power' is not definedlocal variable 'd3' referenced before assignmentlocal variable 'a3' referenced before assignmentlocal variable 'd4' referenced before assignmentlocal variable 'eta' referenced before assignmentglobal name '_briggs_helper_function' is not definedglobal name '_fractional_power_superdiag_entry' is not definedglobal name '_fractional_power_pade_constant' is not definedglobal name 'solve_triangular' is not definedlocal variable 'Y' referenced before assignmentglobal name '_inverse_squaring_helper' is not definedlocal variable 'm_to_theta' referenced before assignmentglobal name '_fractional_power_pade' is not definedlocal variable 'has_principal_branch' referenced before assignmentlocal variable 'T0_diag' referenced before assignmentglobal name 'schur' is not definedglobal name 'rsf2csf' is not definedglobal name 'FractionalMatrixPowerError' is not definedglobal name '_remainder_matrix_power_triu' is not definedglobal name 'svdvals' is not definedglobal name '_remainder_matrix_power' is not definedglobal name 'funm' is not definedlocal variable 'keep_it_real' referenced before assignmentlocal variable 'nodes' referenced before assignmentglobal name '_logm_superdiag_entry' is not definedglobal name 'LogmExactlySingularWarning' is not definedlocal variable 'inplace' referenced before assignmentlocal variable 'tri_eps' referenced before assignmentglobal name 'LogmNearlySingularWarning' is not definedglobal name '_logm_force_nonsingular_triangular_matrix' is not definedglobal name '_logm_triu' is not definedglobal name 'SqrtmError' is not definedglobal name 'LogmError' is not definedlocal variable 'T_diag' referenced before assignmentlocal variable 'bsmall' referenced before assignmentlocal variable 'nblocks' referenced before assignmentlocal variable 'nlarge' referenced before assignmentlocal variable 'start_stop_pairs' referenced before assignmentlocal variable 'istart' referenced before assignmentlocal variable 'jstart' referenced before assignmentlocal variable 'jstop' referenced before assignmentglobal name 'dtrsyl' is not definedglobal name 'ztrsyl' is not definedlocal variable 'failflag' referenced before assignmentlocal variable 'trsyl' referenced before assignmentglobal name 'solve_sylvester' is not definedglobal name 'kron' is not definedlocal variable 'ait' referenced before assignmentlocal variable 'sym_pos' referenced before assignmentlocal variable 'posv' referenced before assignmentlocal variable 'gesv' referenced before assignmentlocal variable 'trtrs' referenced before assignmentlocal variable 'unit_diagonal' referenced before assignmentlocal variable 'l_and_u' referenced before assignmentlocal variable 'ab' referenced before assignmentlocal variable 'gbsv' referenced before assignmentlocal variable 'pbsv' referenced before assignmentlocal variable 'overwrite_ab' referenced before assignmentlocal variable 'getrf' referenced before assignmentglobal name 'calc_lwork' is not definedlocal variable 'getri' referenced before assignmentlocal variable 'lu' referenced before assignmentlocal variable 'piv' referenced before assignmentlocal variable 'inv_a' referenced before assignmentglobal name 'get_flinalg_funcs' is not definedlocal variable 'fdet' referenced before assignmentlocal variable 'a_det' referenced before assignmentlocal variable 'nrhs' referenced before assignmentlocal variable 'gelss' referenced before assignmentlocal variable 'return_rank' referenced before assignmentglobal name 'decomp_svd' is not definedglobal name 'decomp' is not definedname 'empty_module' is not definedname '_DeprecatedImport' is not definedglobal name '_np' is not definedglobal name '_type_conv' is not definedlocal variable 'prefer_fortran' referenced before assignmentlocal variable 'cmodule' referenced before assignmentlocal variable 'cmodule_name' referenced before assignmentlocal variable 'fmodule' referenced before assignmentlocal variable 'fmodule_name' referenced before assignmentglobal name 'find_best_blas_type' is not definedlocal variable 'module2' referenced before assignmentlocal variable 'module1' referenced before assignmentglobal name '_get_funcs' is not definedglobal name '_fblas' is not definedglobal name '_cblas' is not definedglobal name '_blas_alias' is not definedlocal variable 'vin' referenced before assignmentglobal name 'flatnonzero' is not definedglobal name 'conj' is not definedlocal variable 'ggev' referenced before assignmentlocal variable 'cvl' referenced before assignmentlocal variable 'cvr' referenced before assignmentlocal variable 'alphar' referenced before assignmentglobal name '_I' is not definedlocal variable 'alphai' referenced before assignmentglobal name '_make_complex_eigvecs' is not definedlocal variable 'vl' referenced before assignmentlocal variable 'vr' referenced before assignmentglobal name '_geneig' is not definedlocal variable 'geev' referenced before assignmentlocal variable 'compute_vl' referenced before assignmentlocal variable 'compute_vr' referenced before assignmentlocal variable 'wr' referenced before assignmentlocal variable 'wi' referenced before assignmentlocal variable 'cplx' referenced before assignmentlocal variable 'eigvals_only' referenced before assignmentlocal variable 'eigvals' referenced before assignmentlocal variable 'evr' referenced before assignmentlocal variable 'uplo' referenced before assignmentlocal variable '_job' referenced before assignmentlocal variable 'w_tot' referenced before assignmentlocal variable 'gvx' referenced before assignmentlocal variable 'turbo' referenced before assignmentlocal variable 'gvd' referenced before assignmentlocal variable 'gv' referenced before assignmentlocal variable 'ifail' referenced before assignmentlocal variable 'overwrite_a_band' referenced before assignmentlocal variable 'a_band' referenced before assignmentlocal variable 'select' referenced before assignmentlocal variable 'bevd' referenced before assignmentlocal variable 'select_range' referenced before assignmentlocal variable 'iu' referenced before assignmentlocal variable 'max_ev' referenced before assignmentlocal variable 'lamch' referenced before assignmentlocal variable 'bevx' referenced before assignmentlocal variable 'vu' referenced before assignmentlocal variable 'abstol' referenced before assignmentlocal variable 'internal_name' referenced before assignmentglobal name 'eig' is not definedglobal name 'eigh' is not definedglobal name 'eig_banded' is not definedlocal variable 'gebal' referenced before assignmentlocal variable 'gehrd' referenced before assignmentlocal variable 'ba' referenced before assignmentlocal variable 'calc_q' referenced before assignmentglobal name 'get_blas_funcs' is not definedlocal variable 'ger' referenced before assignmentlocal variable 'gemm' referenced before assignmentlocal variable 'potrf' referenced before assignmentlocal variable 'clean' referenced before assignmentglobal name '_cholesky' is not definedlocal variable 'c_and_lower' referenced before assignmentlocal variable 'potrs' referenced before assignmentlocal variable 'pbtrf' referenced before assignmentlocal variable 'cb_and_lower' referenced before assignmentlocal variable 'pbtrs' referenced before assignmentglobal name 'warn' is not definedlocal variable 'lu_and_piv' referenced before assignmentlocal variable 'getrs' referenced before assignmentlocal variable 'flu' referenced before assignmentlocal variable 'permute_l' referenced before assignmentlocal variable 'pivoting' referenced before assignmentglobal name 'safecall' is not definedlocal variable 'geqp3' referenced before assignmentlocal variable 'jpvt' referenced before assignmentlocal variable 'geqrf' referenced before assignmentlocal variable 'qr' referenced before assignmentlocal variable 'gor_un_gqr' referenced before assignmentlocal variable 'Q' referenced before assignmentlocal variable 'Rj' referenced before assignmentlocal variable 'overwrite_c' referenced before assignmentglobal name 'qr' is not definedlocal variable 'gor_un_mqr' referenced before assignmentlocal variable 'conjugate' referenced before assignmentlocal variable 'lr' referenced before assignmentlocal variable 'cQ' referenced before assignmentlocal variable 'onedim' referenced before assignmentlocal variable 'gerqf' referenced before assignmentlocal variable 'rq' referenced before assignmentlocal variable 'gor_un_grq' referenced before assignmentlocal variable 'rq1' referenced before assignmentlocal variable 'gees' referenced before assignmentglobal name '_array_kind' is not definedglobal name '_array_precision' is not definedglobal name '_array_type' is not definedglobal name '_castCopy' is not definedglobal name 'eps' is not definedglobal name 'misc' is not definedlocal variable 'r_' referenced before assignmentlocal variable 'conj' referenced before assignmentlocal variable 'transp' referenced before assignmentlocal variable 'dot' referenced before assignmentlocal variable 'gesdd' referenced before assignmentglobal name 'r_' is not definedglobal name 'has_column_major_storage' is not definedlocal variable 'required_prefix' referenced before assignmentglobal name '_flinalg' is not definedlocal variable 'suffix1' referenced before assignmentlocal variable 'suffix2' referenced before assignmentglobal name '_flapack' is not definedglobal name '_clapack' is not definedglobal name '_lapack_alias' is not definedglobal name 'feps' is not definedglobal name '_asarray_square' is not definedglobal name 'expm' is not definedlocal variable 'errest' referenced before assignmentglobal name 'cast' is not definedlocal variable 'trm' referenced before assignmentlocal variable 'castfunc' referenced before assignmentlocal variable 'eA' referenced before assignmentglobal name '_maybe_real' is not definedglobal name 'cosm' is not definedglobal name 'sinm' is not definedglobal name 'coshm' is not definedglobal name 'sinhm' is not definedlocal variable 'minden' referenced before assignmentglobal name 'logical_not' is not definedlocal variable 'S0' referenced before assignmentlocal variable 'errtol' referenced before assignmentlocal variable 'prev_errest' referenced before assignmentglobal name 'sign' is not definedglobal name '_nrm2_prefix' is not definedglobal name 'blas' is not definedlocal variable 'original' referenced before assignmentlocal variable 'H' referenced before assignmentlocal variable 'bad_args' referenced before assignmentlocal variable 'rr' referenced before assignmentglobal name 'hankel' is not definedlocal variable 'exact' referenced before assignmentlocal variable 'comb' referenced before assignmentlocal variable 'invh' referenced before assignmentlocal variable 'L_n' referenced before assignmentname '_info' is not definedname 'pilutil' is not definedname 'common' is not definedglobal name '_info' is not definedlocal variable 'Np' referenced before assignmentlocal variable 'ndiv' referenced before assignmentlocal variable 'linalg' referenced before assignmentglobal name 'central_diff_weights' is not definedlocal variable 'ho' referenced before assignmentglobal name 'eye' is not definedlocal variable 'Bkj' referenced before assignmentlocal variable 'Akj' referenced before assignmentlocal variable 'ascent' referenced before assignmentlocal variable 'bz2' referenced before assignmentlocal variable 'rawdata' referenced before assignmentlocal variable 'gray' referenced before assignmentlocal variable 'docdict' referenced before assignmentglobal name 'indentcount_lines' is not definedlocal variable 'dstr' referenced before assignmentlocal variable 'newlines' referenced before assignmentlocal variable 'indent' referenced before assignmentlocal variable 'indented' referenced before assignmentlocal variable 'indentno' referenced before assignmentlocal variable 'unindent_params' referenced before assignmentglobal name 'unindent_dict' is not definedglobal name 'docformat' is not definedglobal name 'unindent_string' is not definedlocal variable 'can_dict' referenced before assignmentlocal variable 'icount' referenced before assignmentlocal variable 'cmin' referenced before assignmentlocal variable 'cmax' referenced before assignmentlocal variable 'cscale' referenced before assignmentglobal name 'fromimage' is not definedlocal variable 'flatten' referenced before assignmentglobal name 'toimage' is not definedlocal variable 'valid' referenced before assignmentglobal name 'bytescale' is not definedlocal variable 'pal' referenced before assignmentglobal name '_errstr' is not definedlocal variable 'channel_axis' referenced before assignmentlocal variable 'ca' referenced before assignmentlocal variable 'strdata' referenced before assignmentlocal variable 'interp' referenced before assignmentlocal variable 'fnum' referenced before assignmentglobal name 'ImageFilter' is not definedlocal variable 'ftype' referenced before assignmentname 'SparseWarning' is not definedname 'isspmatrix' is not definedglobal name 'MAXPRINT' is not definedlocal variable 'maxprint' referenced before assignmentglobal name '_formats' is not definedlocal variable 'tostr' referenced before assignmentlocal variable 'row' referenced before assignmentglobal name 'isscalarlike' is not definedglobal name 'issparse' is not definedlocal variable 'other_a' referenced before assignmentlocal variable 'tr' referenced before assignmentlocal variable 'rdivide' referenced before assignmentlocal variable 'true_divide' referenced before assignmentglobal name 'isdense' is not definedglobal name 'isspmatrix' is not definedlocal variable 'self_csr' referenced before assignmentglobal name 'isintlike' is not definedlocal variable 'csc_matrix' referenced before assignmentlocal variable 'csr_matrix' referenced before assignmentlocal variable 'res_dtype' referenced before assignmentlocal variable 'mean' referenced before assignmentglobal name 'spmatrix' is not definedname '_cs_matrix' is not definedname '_minmax_mixin' is not definedglobal name '_data_matrix' is not definedglobal name 'isspmatrix_bsr' is not definedglobal name 'isshape' is not definedglobal name 'getdtype' is not definedglobal name 'get_index_dtype' is not definedlocal variable 'indptr' referenced before assignmentglobal name 'to_native' is not definedlocal variable 'full_check' referenced before assignmentglobal name 'upcast' is not definedglobal name '_sparsetools' is not definedglobal name 'bsr_matvec' is not definedglobal name 'bsr_matvecs' is not definedglobal name 'csr_matmat_pass1' is not definedglobal name 'bsr_matmat_pass2' is not definedglobal name 'bsr_matrix' is not definedglobal name 'bsr_transpose' is not definedglobal name 'bsr_sort_indices' is not definedname 'IndexMixin' is not definedlocal variable 'major_dim' referenced before assignmentlocal variable 'minor_dim' referenced before assignmentglobal name '_compat_bincount' is not definedglobal name 'downcast_intp_index' is not definedlocal variable 'minor_name' referenced before assignmentlocal variable 'const' referenced before assignmentglobal name 'SparseEfficiencyWarning' is not definedlocal variable 'op_name' referenced before assignmentlocal variable 'bad_scalar_msg' referenced before assignmentglobal name 'dia_matrix' is not definedglobal name 'upcast_char' is not definedlocal variable 'dense_check' referenced before assignmentlocal variable 'npop' referenced before assignmentlocal variable 'major_index' referenced before assignmentlocal variable 'idx_dtype' referenced before assignmentglobal name '_compat_unique' is not definedlocal variable 'ui_indptr' referenced before assignmentglobal name 'izip' is not definedlocal variable 'ui' referenced before assignmentlocal variable 'prev' referenced before assignmentlocal variable 'ii' referenced before assignmentlocal variable 'indices_parts' referenced before assignmentlocal variable 'data_parts' referenced before assignmentlocal variable 'js' referenced before assignmentlocal variable 'je' referenced before assignmentlocal variable 'uj' referenced before assignmentlocal variable 'uj_indptr' referenced before assignmentlocal variable 'new_nnzs' referenced before assignmentlocal variable 'nnzs' referenced before assignmentlocal variable 'do_sort' referenced before assignmentlocal variable 'minor_index' referenced before assignmentlocal variable 'slice0' referenced before assignmentlocal variable 'shape0' referenced before assignmentlocal variable '_process_slice' referenced before assignmentlocal variable 'shape1' referenced before assignmentlocal variable '_in_bounds' referenced before assignmentlocal variable 'i0' referenced before assignmentlocal variable 'i1' referenced before assignmentlocal variable 'j0' referenced before assignmentlocal variable 'j1' referenced before assignmentlocal variable 'sl' referenced before assignmentlocal variable 'diags' referenced before assignmentlocal variable 'diagonals' referenced before assignmentlocal variable 'diagonal' referenced before assignmentlocal variable 'data_arr' referenced before assignmentglobal name 'csr_matrix' is not definedglobal name 'csc_matrix' is not definedglobal name 'coo_matrix' is not definedglobal name 'spdiags' is not definedlocal variable 'output_shape' referenced before assignmentlocal variable 'blocks' referenced before assignmentlocal variable 'other_axis' referenced before assignmentlocal variable 'constant_dim' referenced before assignmentlocal variable 'sum_dim' referenced before assignmentlocal variable 'last_indptr' referenced before assignmentglobal name 'bmat' is not definedglobal name '_compressed_sparse_stack' is not definedlocal variable 'block_mask' referenced before assignmentlocal variable 'brow_lengths' referenced before assignmentlocal variable 'bcol_lengths' referenced before assignmentlocal variable 'nnz' referenced before assignmentlocal variable 'row_offsets' referenced before assignmentlocal variable 'col_offsets' referenced before assignmentlocal variable 'mats' referenced before assignmentlocal variable 'nmat' referenced before assignmentlocal variable 'ia' referenced before assignmentlocal variable 'random_state' referenced before assignmentlocal variable 'gk' referenced before assignmentlocal variable '_gen_unique_rand' referenced before assignmentlocal variable 'rng' referenced before assignmentlocal variable '_gk' referenced before assignmentlocal variable 'ij' referenced before assignmentglobal name 'isspmatrix_coo' is not definedglobal name 'coo_todense' is not definedlocal variable 'fortran' referenced before assignmentglobal name 'coo_tocsr' is not definedglobal name 'coo_matvec' is not definedglobal name '_cs_matrix' is not definedlocal variable 'csr' referenced before assignmentglobal name 'csc_tocsr' is not definedname '_deprecate' is not definedname 'cs_graph_components' is not definedname '_msg0' is not definedglobal name '_msg0' is not definedglobal name '_msg1' is not definedglobal name '_cs_graph_components' is not definedlocal variable 'csgraph' referenced before assignmentglobal name '_laplacian_sparse' is not definedlocal variable 'return_diag' referenced before assignmentglobal name '_laplacian_dense' is not definedlocal variable 'graph' referenced before assignmentlocal variable 'lap' referenced before assignmentlocal variable 'w_zeros' referenced before assignmentlocal variable 'diag_mask' referenced before assignmentlocal variable 'n_nodes' referenced before assignmentlocal variable 'lil' referenced before assignmentlocal variable 'dat' referenced before assignmentglobal name 'csr_tocsc' is not definedglobal name 'csr_count_blocks' is not definedglobal name 'csr_tobsr' is not definedlocal variable 'bsr_matrix' referenced before assignmentlocal variable 'extractor' referenced before assignmentlocal variable 'asindices' referenced before assignmentlocal variable 'check_bounds' referenced before assignmentglobal name 'csr_sample_values' is not definedlocal variable 'min_indx' referenced before assignmentlocal variable 'cslice' referenced before assignmentlocal variable 'row_slice' referenced before assignmentlocal variable 'process_slice' referenced before assignmentlocal variable 'col_slice' referenced before assignmentglobal name 'get_csr_submatrix' is not definedname 'npfunc' is not definedname '_create_method' is not definedglobal name 'name' is not definedlocal variable 'min_or_max' referenced before assignmentglobal name 'isspmatrix_dia' is not definedglobal name 'dia_matvec' is not definedglobal name 'isspmatrix_dok' is not definedlocal variable 'i_intlike' referenced before assignmentlocal variable 'j_intlike' referenced before assignmentlocal variable 'i_indices' referenced before assignmentlocal variable 'j_indices' referenced before assignmentglobal name 'dok_matrix' is not definedlocal variable 'min_i' referenced before assignmentlocal variable 'min_j' referenced before assignmentlocal variable 'newdok' referenced before assignmentlocal variable 'jj' referenced before assignmentlocal variable 'i_start' referenced before assignmentlocal variable 'i_stride' referenced before assignmentlocal variable 'ra' referenced before assignmentlocal variable 'j_start' referenced before assignmentlocal variable 'j_stride' referenced before assignmentlocal variable 'rb' referenced before assignmentglobal name 'upcast_scalar' is not definedglobal name 'iteritems' is not definedglobal name '_list' is not definedlocal variable 'newM' referenced before assignmentlocal variable 'newN' referenced before assignmentglobal name 'isspmatrix_lil' is not definedglobal name 'lil_matrix' is not definedglobal name '_csparsetools' is not definedlocal variable 'rowvals' referenced before assignmentlocal variable 'j_max' referenced before assignmentlocal variable 'new_r' referenced before assignmentlocal variable 'new_c' referenced before assignmentglobal name '_expm_multiply_simple' is not definedglobal name '_expm_multiply_interval' is not definedlocal variable 'balance' referenced before assignmentglobal name '_ident_like' is not definedglobal name '_trace' is not definedglobal name '_exact_1_norm' is not definedglobal name 'LazyOperatorNormInfo' is not definedglobal name '_fragment_3_1' is not definedlocal variable 'n0' referenced before assignmentglobal name '_expm_multiply_simple_core' is not definedlocal variable 'm_star' referenced before assignmentglobal name '_exact_inf_norm' is not definedglobal name 'MatrixPowerOperator' is not definedlocal variable 'A_1_norm' referenced before assignmentlocal variable 'ell' referenced before assignmentglobal name '_onenormest_matrix_power' is not definedlocal variable 'norm_info' referenced before assignmentglobal name '_theta' is not definedlocal variable 'm_max' referenced before assignmentglobal name '_condition_3_13' is not definedlocal variable 'best_m' referenced before assignmentlocal variable 'best_s' referenced before assignmentglobal name '_compute_p_max' is not definedglobal name '_compute_cost_div_m' is not definedlocal variable 'samples' referenced before assignmentlocal variable 't_0' referenced before assignmentlocal variable 'status_only' referenced before assignmentglobal name '_expm_multiply_interval_core_0' is not definedglobal name '_expm_multiply_interval_core_1' is not definedglobal name '_expm_multiply_interval_core_2' is not definedlocal variable 'K' referenced before assignmentlocal variable 'high_p' referenced before assignmentglobal name 'aslinearoperator' is not definedglobal name 'elementary_vector' is not definedglobal name '_onenormest_core' is not definedlocal variable 'est' referenced before assignmentglobal name 'vectors_are_parallel' is not definedlocal variable 'AT' referenced before assignmentlocal variable 'A_linear_operator' referenced before assignmentglobal name 'norm_1d_1' is not definedglobal name 'sign_round_up' is not definedlocal variable 'AT_linear_operator' referenced before assignmentglobal name 'norm_1d_inf' is not definedglobal name 'less_than_or_close' is not definedlocal variable 'best_j' referenced before assignmentlocal variable 'g_prev' referenced before assignmentlocal variable 'h_prev' referenced before assignmentglobal name 'resample_column' is not definedglobal name 'column_needs_resampling' is not definedlocal variable 'nresamples' referenced before assignmentlocal variable 'nmults' referenced before assignmentlocal variable 'mags' referenced before assignmentlocal variable 'est_old' referenced before assignmentglobal name 'every_col_of_X_is_parallel_to_a_col_of_Y' is not definedlocal variable 'S_old' referenced before assignmentlocal variable 'ind_best' referenced before assignmentlocal variable 'ind_hist' referenced before assignmentlocal variable 'unused_entries' referenced before assignmentlocal variable 'used_entries' referenced before assignmentname 'noScikit' is not definedglobal name 'isspmatrix_csc' is not definedglobal name 'isspmatrix_csr' is not definedlocal variable 'use_umfpack' referenced before assignmentglobal name 'useUmfpack' is not definedlocal variable 'b_is_vector' referenced before assignmentlocal variable 'b_is_sparse' referenced before assignmentglobal name 'noScikit' is not definedglobal name 'umfpack' is not definedlocal variable 'permc_spec' referenced before assignmentglobal name '_superlu' is not definedglobal name 'MatrixRankWarning' is not definedglobal name 'factorized' is not definedlocal variable 'Afactsolve' referenced before assignmentlocal variable 'tempj' referenced before assignmentlocal variable 'diag_pivot_thresh' referenced before assignmentlocal variable 'panel_size' referenced before assignmentlocal variable 'drop_rule' referenced before assignmentlocal variable 'drop_tol' referenced before assignmentlocal variable 'fill_factor' referenced before assignmentlocal variable 'umf' referenced before assignmentglobal name 'splu' is not definedname 'DNAUPD_ERRORS' is not definedname 'ZNAUPD_ERRORS' is not definedname 'DSAUPD_ERRORS' is not definedname 'DNEUPD_ERRORS' is not definedname 'SNEUPD_ERRORS' is not definedname 'ZNEUPD_ERRORS' is not definedname 'CNEUPD_ERRORS' is not definedname 'DSEUPD_ERRORS' is not definedname 'SSEUPD_ERRORS' is not definedname 'SSAUPD_ERRORS' is not definedname 'SNAUPD_ERRORS' is not definedname 'CNAUPD_ERRORS' is not definedname 'ArpackError' is not definedname '_ArpackParams' is not definedglobal name '_NAUPD_ERRORS' is not definedlocal variable 'infodict' referenced before assignmentglobal name 'ArpackError' is not definedlocal variable 'eigenvalues' referenced before assignmentlocal variable 'eigenvectors' referenced before assignmentlocal variable 'v0' referenced before assignmentlocal variable 'ncv' referenced before assignmentglobal name 'ArpackNoConvergence' is not definedlocal variable 'num_iter' referenced before assignmentlocal variable 'k_ok' referenced before assignmentlocal variable 'ev' referenced before assignmentlocal variable 'matvec' referenced before assignmentlocal variable 'M_matvec' referenced before assignmentlocal variable 'Minv_matvec' referenced before assignmentglobal name '_SEUPD_WHICH' is not definedglobal name '_ArpackParams' is not definedglobal name '_arpack' is not definedglobal name '_SAUPD_ERRORS' is not definedglobal name '_SEUPD_ERRORS' is not definedlocal variable 'return_eigenvectors' referenced before assignmentlocal variable 'ierr' referenced before assignmentglobal name '_NEUPD_WHICH' is not definedglobal name '_NEUPD_ERRORS' is not definedlocal variable 'dr' referenced before assignmentlocal variable 'zr' referenced before assignmentlocal variable 'sigmai' referenced before assignmentlocal variable 'nreturned' referenced before assignmentglobal name '_ndigits' is not definedglobal name 'LinearOperator' is not definedglobal name 'lu_factor' is not definedglobal name 'lu_solve' is not definedglobal name 'gmres' is not definedlocal variable 'ifunc' referenced before assignmentglobal name 'LuInv' is not definedlocal variable 'symmetric' referenced before assignmentglobal name 'SpLuInv' is not definedglobal name 'IterInv' is not definedglobal name 'get_inv_matvec' is not definedglobal name 'IterOpInv' is not definedglobal name '_aslinearoperator_with_dtype' is not definedlocal variable 'OP' referenced before assignmentlocal variable 'OPinv' referenced before assignmentlocal variable 'OPpart' referenced before assignmentlocal variable 'Minv' referenced before assignmentglobal name 'get_OPinv_matvec' is not definedglobal name '_UnsymmetricArpackParams' is not definedglobal name 'eigs' is not definedglobal name '_SymmetricArpackParams' is not definedglobal name 'eigsh' is not definedlocal variable 'return_singular_vectors' referenced before assignmentlocal variable 'eigvec' referenced before assignmentlocal variable 'herm' referenced before assignmentlocal variable 'XH' referenced before assignmentlocal variable 'mtxA' referenced before assignmentlocal variable 'mtxB' referenced before assignmentlocal variable 'fileName' referenced before assignmentlocal variable 'operatorInput' referenced before assignmentlocal variable 'expectedShape' referenced before assignmentglobal name 'CallableLinearOperator' is not definedglobal name 'sp' is not definedlocal variable 'blockVectorBY' referenced before assignmentlocal variable 'blockVectorV' referenced before assignmentlocal variable 'factYBY' referenced before assignmentlocal variable 'blockVectorY' referenced before assignmentlocal variable 'blockVectorBV' referenced before assignmentlocal variable 'retInvR' referenced before assignmentlocal variable 'sizeX' referenced before assignmentglobal name 'makeOperator' is not definedlocal variable 'sizeY' referenced before assignmentlocal variable 'largest' referenced before assignmentglobal name 'symeig' is not definedlocal variable '_lambda' referenced before assignmentlocal variable 'eigBlockVector' referenced before assignmentlocal variable 'residualTolerance' referenced before assignmentlocal variable 'maxIterations' referenced before assignmentlocal variable 'verbosityLevel' referenced before assignmentlocal variable 'aux' referenced before assignmentlocal variable 'sla' referenced before assignmentglobal name 'applyConstraints' is not definedlocal variable 'blockVectorX' referenced before assignmentlocal variable 'gramYBY' referenced before assignmentglobal name 'b_orthonormalize' is not definedlocal variable 'blockVectorAX' referenced before assignmentlocal variable 'blockVectorBX' referenced before assignmentlocal variable 'residualNormsHistory' referenced before assignmentlocal variable 'activeMask' referenced before assignmentlocal variable 'previousBlockSize' referenced before assignmentglobal name 'as2d' is not definedlocal variable 'blockVectorP' referenced before assignmentlocal variable 'blockVectorAP' referenced before assignmentlocal variable 'blockVectorBP' referenced before assignmentlocal variable 'activeBlockVectorR' referenced before assignmentlocal variable 'iterationNumber' referenced before assignmentlocal variable 'activeBlockVectorP' referenced before assignmentlocal variable 'activeBlockVectorBP' referenced before assignmentlocal variable 'activeBlockVectorAP' referenced before assignmentlocal variable 'invR' referenced before assignmentlocal variable 'activeBlockVectorAR' referenced before assignmentlocal variable 'activeBlockVectorBR' referenced before assignmentlocal variable 'ident0' referenced before assignmentlocal variable 'gramA' referenced before assignmentlocal variable 'gramB' referenced before assignmentglobal name 'save' is not definedlocal variable 'lambdaHistory' referenced before assignmentglobal name 'pause' is not definedlocal variable 'currentBlockSize' referenced before assignmentlocal variable 'eigBlockVectorR' referenced before assignmentlocal variable 'eigBlockVectorP' referenced before assignmentlocal variable 'pp' referenced before assignmentlocal variable 'app' referenced before assignmentlocal variable 'bpp' referenced before assignmentlocal variable 'eigBlockVectorX' referenced before assignmentlocal variable 'retLambdaHistory' referenced before assignmentlocal variable 'retResidualNormsHistory' referenced before assignmentlocal variable 'rmatvec' referenced before assignmentlocal variable 'matmat' referenced before assignmentglobal name '_ProductLinearOperator' is not definedglobal name '_ScaledLinearOperator' is not definedglobal name '_PowerLinearOperator' is not definedglobal name '_SumLinearOperator' is not definedlocal variable 'operators' referenced before assignmentglobal name '_get_dtype' is not definedglobal name 'MatrixLinearOperator' is not definedglobal name 'IdentityOperator' is not definedname 'set_docstring' is not definedname 'non_reentrant' is not definedglobal name 'common_doc1' is not definedlocal variable 'Ainfo' referenced before assignmentglobal name 'common_doc2' is not definedglobal name 'make_system' is not definedlocal variable 'xtype' referenced before assignmentglobal name '_iterative' is not definedlocal variable 'iter_' referenced before assignmentlocal variable 'resid' referenced before assignmentlocal variable 'ndx1' referenced before assignmentlocal variable 'ndx2' referenced before assignmentlocal variable 'ijob' referenced before assignmentlocal variable 'olditer' referenced before assignmentlocal variable 'sclr2' referenced before assignmentlocal variable 'sclr1' referenced before assignmentlocal variable 'psolve' referenced before assignmentlocal variable 'rpsolve' referenced before assignmentlocal variable 'ftflag' referenced before assignmentlocal variable 'stoptest' referenced before assignmentlocal variable 'bnrm2' referenced before assignmentlocal variable 'postprocess' referenced before assignmentlocal variable 'restrt' referenced before assignmentlocal variable 'restart' referenced before assignmentlocal variable 'resid_ready' referenced before assignmentlocal variable 'first_pass' referenced before assignmentlocal variable 'old_ijob' referenced before assignmentlocal variable 'iter_num' referenced before assignmentlocal variable 'M1' referenced before assignmentlocal variable 'M2' referenced before assignmentlocal variable 'A_' referenced before assignmentlocal variable 'outer_v' referenced before assignmentglobal name 'norm2' is not definedlocal variable 'axpy' referenced before assignmentlocal variable 'r_outer' referenced before assignmentlocal variable 'b_norm' referenced before assignmentlocal variable 'scal' referenced before assignmentlocal variable 'inner_m' referenced before assignmentlocal variable 'vs0' referenced before assignmentlocal variable 'vs' referenced before assignmentlocal variable 'v_new' referenced before assignmentlocal variable 'hcur' referenced before assignmentlocal variable 'hs' referenced before assignmentlocal variable 'inner_res_0' referenced before assignmentlocal variable 'hess' referenced before assignmentlocal variable 'lstsq' referenced before assignmentlocal variable 'e1' referenced before assignmentlocal variable 'yc' referenced before assignmentlocal variable 'store_outer_Av' referenced before assignmentlocal variable 'ax' referenced before assignmentlocal variable 'qc' referenced before assignmentlocal variable 'nx' referenced before assignmentlocal variable 'outer_k' referenced before assignmentlocal variable 'damp' referenced before assignmentlocal variable 'conlim' referenced before assignmentlocal variable 'btol' referenced before assignmentlocal variable 'hdg1' referenced before assignmentlocal variable 'hdg2' referenced before assignmentlocal variable 'itn' referenced before assignmentglobal name '_sym_ortho' is not definedlocal variable 'alphabar' referenced before assignmentlocal variable 'rho' referenced before assignmentlocal variable 'alphahat' referenced before assignmentlocal variable 'rhobar' referenced before assignmentlocal variable 'zeta' referenced before assignmentlocal variable 'sbar' referenced before assignmentlocal variable 'cbar' referenced before assignmentlocal variable 'zetabar' referenced before assignmentlocal variable 'thetabar' referenced before assignmentlocal variable 'rhoold' referenced before assignmentlocal variable 'rhobarold' referenced before assignmentlocal variable 'hbar' referenced before assignmentlocal variable 'thetanew' referenced before assignmentlocal variable 'chat' referenced before assignmentlocal variable 'betadd' referenced before assignmentlocal variable 'shat' referenced before assignmentlocal variable 'thetatilde' referenced before assignmentlocal variable 'rhodold' referenced before assignmentlocal variable 'stildeold' referenced before assignmentlocal variable 'ctildeold' referenced before assignmentlocal variable 'betad' referenced before assignmentlocal variable 'betahat' referenced before assignmentlocal variable 'zetaold' referenced before assignmentlocal variable 'thetatildeold' referenced before assignmentlocal variable 'tautildeold' referenced before assignmentlocal variable 'rhotildeold' referenced before assignmentlocal variable 'betacheck' referenced before assignmentlocal variable 'normA2' referenced before assignmentlocal variable 'maxrbar' referenced before assignmentlocal variable 'minrbar' referenced before assignmentlocal variable 'rhotemp' referenced before assignmentlocal variable 'normb' referenced before assignmentglobal name 'infty' is not definedlocal variable 'ctol' referenced before assignmentlocal variable 'pcount' referenced before assignmentlocal variable 'pfreq' referenced before assignmentlocal variable 'normr' referenced before assignmentlocal variable 'normar' referenced before assignmentlocal variable 'test1' referenced before assignmentlocal variable 'test2' referenced before assignmentlocal variable 'normA' referenced before assignmentlocal variable 'condA' referenced before assignmentlocal variable 'normx' referenced before assignmentlocal variable 'str1' referenced before assignmentlocal variable 'str2' referenced before assignmentlocal variable 'str3' referenced before assignmentlocal variable 'str4' referenced before assignmentlocal variable 'iter_lim' referenced before assignmentlocal variable 'calc_var' referenced before assignmentlocal variable 'alfa' referenced before assignmentlocal variable 'anorm' referenced before assignmentlocal variable 'phibar' referenced before assignmentlocal variable 'sn' referenced before assignmentlocal variable 'cs' referenced before assignmentlocal variable 'ddnorm' referenced before assignmentlocal variable 'sn2' referenced before assignmentlocal variable 'cs2' referenced before assignmentlocal variable 'xxnorm' referenced before assignmentlocal variable 'res2' referenced before assignmentlocal variable 'psi' referenced before assignmentlocal variable 'dampsq' referenced before assignmentlocal variable 'bnorm' referenced before assignmentlocal variable 'prnt' referenced before assignmentname 'Ainfo' is not definedname 'footer' is not definedglobal name 'inner' is not definedlocal variable 'r1' referenced before assignmentlocal variable 'r2' referenced before assignmentlocal variable 'tnorm2' referenced before assignmentlocal variable 'beta1' referenced before assignmentlocal variable 'epsln' referenced before assignmentlocal variable 'dbar' referenced before assignmentlocal variable 'w2' referenced before assignmentlocal variable 'gmax' referenced before assignmentlocal variable 'gmin' referenced before assignmentlocal variable 'rhs1' referenced before assignmentlocal variable 'ynorm2' referenced before assignmentlocal variable 'rhs2' referenced before assignmentlocal variable 'Anorm' referenced before assignmentlocal variable 'Acond' referenced before assignmentlocal variable 'gbar' referenced before assignmentlocal variable 'rnorm' referenced before assignmentlocal variable 'ynorm' referenced before assignmentlocal variable 'Arnorm' referenced before assignmentglobal name '_coerce_rules' is not definedglobal name 'coerce' is not definedglobal name 'id' is not definedglobal name 'speye' is not definedglobal name 'spsolve' is not definedlocal variable 'structure' referenced before assignmentglobal name 'UPPER_TRIANGULAR' is not definedglobal name '_smart_matrix_product' is not definedglobal name 'ProductOperator' is not definedlocal variable 'T_args' referenced before assignmentlocal variable 'operator_seq' referenced before assignmentlocal variable 'use_exact_onenorm' referenced before assignmentglobal name '_onenorm' is not definedglobal name '_onenormest_product' is not definedglobal name '_is_upper_triangular' is not definedglobal name '_ExpmPadeHelper' is not definedglobal name '_ell' is not definedglobal name '_solve_P_Q' is not definedlocal variable 'eta_3' referenced before assignmentglobal name '_fragment_2_1' is not definedlocal variable 'lam_1' referenced before assignmentlocal variable 'lam_2' referenced before assignmentlocal variable 't_12' referenced before assignmentglobal name '_sinch' is not definedlocal variable 'exp_diag' referenced before assignmentlocal variable 'diag_T' referenced before assignmentglobal name '_eq_10_42' is not definedglobal name '_onenorm_matrix_power_nnm' is not definedlocal variable 'efficiency' referenced before assignmentglobal name 'count_blocks' is not definedlocal variable 'e22' referenced before assignmentlocal variable 'high_efficiency' referenced before assignmentlocal variable 'e33' referenced before assignmentlocal variable 'e44' referenced before assignmentname 'supported_dtypes' is not definedname 'x' is not definedname '_compat_unique_impl' is not definedname '_compat_bincount_impl' is not definedglobal name '_upcast_memo' is not definedglobal name 'supported_dtypes' is not definedlocal variable 'upcast' referenced before assignmentlocal variable 'maxval' referenced before assignmentlocal variable 'check_contents' referenced before assignmentlocal variable 'first_ellipsis' referenced before assignmentlocal variable 'tail' referenced before assignmentlocal variable 'minlength' referenced before assignmentname 'i0' is not definedname 'SpecialFunctionWarning' is not definedname 'vectorize' is not definedname '_sph_harmonic' is not definedname 'psi' is not definedglobal name 'floor' is not definedglobal name 'place' is not definedglobal name 'nan' is not definedglobal name 'extract' is not definedlocal variable 'nt' referenced before assignmentglobal name 'specfun' is not definedlocal variable 'zo' referenced before assignmentglobal name 'jnyn_zeros' is not definedlocal variable 'phase' referenced before assignmentglobal name 'jv' is not definedglobal name 'bessel_diff_formula' is not definedglobal name 'yv' is not definedglobal name 'kv' is not definedglobal name 'iv' is not definedglobal name 'hankel1' is not definedglobal name 'hankel2' is not definedlocal variable 'jn' referenced before assignmentlocal variable 'jnp' referenced before assignmentlocal variable 'n1' referenced before assignmentlocal variable 'yn' referenced before assignmentlocal variable 'ynp' referenced before assignmentlocal variable 'In' referenced before assignmentlocal variable 'Inp' referenced before assignmentlocal variable 'kn' referenced before assignmentlocal variable 'knp' referenced before assignmentlocal variable 'phi' referenced before assignmentglobal name 'lpmn' is not definedlocal variable 'Pmn' referenced before assignmentglobal name 'ndtri' is not definedglobal name 'gamma' is not definedlocal variable 'old_err' referenced before assignmentlocal variable 'den' referenced before assignmentglobal name 'orthogonal' is not definedglobal name 'zeta' is not definedglobal name 'psi' is not definedglobal name 'mathieu_a' is not definedglobal name 'mathieu_b' is not definedglobal name 'mgrid' is not definedglobal name 'errprint' is not definedlocal variable 'mf' referenced before assignmentlocal variable 'nf' referenced before assignmentlocal variable 'fixarr' referenced before assignmentlocal variable 'qd' referenced before assignmentlocal variable 'pn' referenced before assignmentlocal variable 'qn' referenced before assignmentlocal variable 'kf' referenced before assignmentlocal variable 'dv' referenced before assignmentlocal variable 'dp' referenced before assignmentlocal variable 'cpb' referenced before assignmentlocal variable 'cpd' referenced before assignmentglobal name 'ellipkm1' is not definedlocal variable 'repetition' referenced before assignmentglobal name 'comb' is not definedglobal name 'binom' is not definedglobal name 'poch' is not definedglobal name '_lambertw' is not definedname 'cephes' is not definedlocal variable 'wfunc' referenced before assignmentlocal variable 'equiv_weights' referenced before assignmentlocal variable 'limits' referenced before assignmentlocal variable 'hn' referenced before assignmentlocal variable 'monic' referenced before assignmentlocal variable 'eval_func' referenced before assignmentlocal variable 'evf' referenced before assignmentlocal variable 'sqrt_bn_func' referenced before assignmentlocal variable 'an_func' referenced before assignmentglobal name 'cephes' is not definedglobal name 'gen_roots_and_weights' is not definedlocal variable 'olderr' referenced before assignmentlocal variable 'mu0' referenced before assignmentglobal name 'orthopoly1d' is not definedglobal name 'j_roots' is not definedglobal name '_gam' is not definedlocal variable 'ab1' referenced before assignmentglobal name 'eval_jacobi' is not definedlocal variable 'p1' referenced before assignmentlocal variable 'q1' referenced before assignmentglobal name 'js_roots' is not definedglobal name 'eval_sh_jacobi' is not definedglobal name 'la_roots' is not definedglobal name 'inf' is not definedglobal name 'eval_genlaguerre' is not definedglobal name 'l_roots' is not definedglobal name 'eval_laguerre' is not definedlocal variable 'factor' referenced before assignmentglobal name 'linalg' is not definedglobal name '_h_gen_roots_and_weights' is not definedglobal name 'h_roots' is not definedglobal name 'eval_hermite' is not definedglobal name 'he_roots' is not definedglobal name 'eval_hermitenorm' is not definedglobal name 'jacobi' is not definedglobal name 'eval_gegenbauer' is not definedglobal name 't_roots' is not definedglobal name 'eval_chebyt' is not definedglobal name 'c_roots' is not definedglobal name 'eval_chebyc' is not definedglobal name 's_roots' is not definedglobal name 'eval_chebys' is not definedglobal name 'sh_jacobi' is not definedglobal name 'eval_legendre' is not definedglobal name 'ps_roots' is not definedglobal name 'eval_sh_legendre' is not definedglobal name 'loggam' is not definedglobal name 'Serial' is not definedlocal variable 'url' referenced before assignmentlocal variable 'url_nocase' referenced before assignmentglobal name 'protocol_handler_packages' is not definedlocal variable 'protocol' referenced before assignmentlocal variable 'do_open' referenced before assignmentname 'System' is not definedname 'SerialBase' is not definedname 'IronSerial' is not definedname 'FileLike' is not definedglobal name 'System' is not definedlocal variable 'portnum' referenced before assignmentglobal name 'sab' is not definedglobal name 'SerialException' is not definedglobal name 'FIVEBITS' is not definedglobal name 'SIXBITS' is not definedglobal name 'SEVENBITS' is not definedglobal name 'EIGHTBITS' is not definedglobal name 'PARITY_NONE' is not definedglobal name 'PARITY_EVEN' is not definedglobal name 'PARITY_ODD' is not definedglobal name 'PARITY_MARK' is not definedglobal name 'PARITY_SPACE' is not definedglobal name 'STOPBITS_ONE' is not definedglobal name 'STOPBITS_ONE_POINT_FIVE' is not definedglobal name 'STOPBITS_TWO' is not definedglobal name 'device' is not definedglobal name 'portNotOpenError' is not definedglobal name 'as_byte_array' is not definedglobal name 'writeTimeoutError' is not definedlocal variable 'duration' referenced before assignmentname 'detect_java_comm' is not definedname 'JavaSerial' is not definedglobal name 'my_import' is not definedglobal name 'comm' is not definedlocal variable 'portnumber' referenced before assignmentglobal name 'stopbits' is not definedlocal variable 'jflowout' referenced before assignmentlocal variable 'jflowin' referenced before assignmentlocal variable 'jdatabits' referenced before assignmentlocal variable 'jstopbits' referenced before assignmentlocal variable 'jparity' referenced before assignmentname 'termios' is not definedname 'fcntl' is not definedname 'plat' is not definedname 'TERMIOS' is not definedname 'TIOCM_CAR' is not definedname 'TIOCM_RNG' is not definedname 'TIOCM_RTS' is not definedname 'TIOCM_DTR' is not definedname 'PosixSerial' is not definedglobal name 'FCNTL' is not definedglobal name 'TERMIOS' is not definedlocal variable 'baudrate' referenced before assignmentglobal name 'ASYNC_SPD_MASK' is not definedglobal name 'ASYNC_SPD_CUST' is not definedglobal name 'termios' is not definedlocal variable 'cflag' referenced before assignmentlocal variable 'lflag' referenced before assignmentlocal variable 'oflag' referenced before assignmentlocal variable 'iflag' referenced before assignmentglobal name 'baudrate_constants' is not definedlocal variable 'custom_baud' referenced before assignmentlocal variable 'vmin' referenced before assignmentlocal variable 'vtime' referenced before assignmentlocal variable 'ispeed' referenced before assignmentlocal variable 'ospeed' referenced before assignmentlocal variable 'orig_attr' referenced before assignmentglobal name 'set_special_baudrate' is not definedglobal name 'fcntl' is not definedglobal name 'TIOCINQ' is not definedglobal name 'TIOCM_zero_str' is not definedlocal variable 'ready' referenced before assignmentglobal name 'TIOCSBRK' is not definedglobal name 'TIOCCBRK' is not definedglobal name 'TIOCMBIS' is not definedglobal name 'TIOCM_RTS_str' is not definedglobal name 'TIOCMBIC' is not definedglobal name 'TIOCM_DTR_str' is not definedglobal name 'TIOCMGET' is not definedglobal name 'TIOCM_CTS' is not definedglobal name 'TIOCM_DSR' is not definedglobal name 'TIOCM_RI' is not definedglobal name 'TIOCM_CD' is not definedlocal variable 'enable' referenced before assignmentname 'bytearray' is not definedname 'to_bytes' is not definedname 'SerialTimeoutException' is not definedglobal name 'bytearray' is not definedglobal name 'LF' is not definedlocal variable 'eol' referenced before assignmentlocal variable 'leneol' referenced before assignmentlocal variable 'bytesize' referenced before assignmentlocal variable 'parity' referenced before assignmentlocal variable 'stopbits' referenced before assignmentlocal variable 'writeTimeout' referenced before assignmentlocal variable 'xonxoff' referenced before assignmentlocal variable 'rtscts' referenced before assignmentlocal variable 'dsrdtr' referenced before assignmentlocal variable 'interCharTimeout' referenced before assignmentglobal name 'PARITY_NAMES' is not definedname 'Win32Serial' is not definedglobal name 'SerialBase' is not definedglobal name 'win32' is not definedlocal variable 'timeouts' referenced before assignmentglobal name 'XON' is not definedglobal name 'XOFF' is not definedlocal variable 'rtsToggle' referenced before assignmentglobal name 'comports' is not definedlocal variable 'hwid' referenced before assignmentglobal name 'grep' is not definedlocal variable 'hits' referenced before assignmentlocal variable 'so' referenced before assignmentlocal variable 'sysfs_path' referenced before assignmentglobal name 'read_line' is not definedglobal name 'popen' is not definedlocal variable 'bus' referenced before assignmentlocal variable 'dev' referenced before assignmentglobal name 're_group' is not definedlocal variable 'iManufacturer' referenced before assignmentlocal variable 'iProduct' referenced before assignmentlocal variable 'idProduct' referenced before assignmentlocal variable 'iSerial' referenced before assignmentglobal name 'base' is not definedglobal name 'usb_lsusb_string' is not definedglobal name 'usb_sysfs_hw_string' is not definedglobal name 'describe' is not definedglobal name 'hwinfo' is not definedname 'DWORD' is not definedname 'HKEY' is not definedname 'ACCESS_MASK' is not definedname 'SP_DEVINFO_DATA' is not definedname 'SP_DEVICE_INTERFACE_DATA' is not definedname 'setupapi' is not definedname 'HDEVINFO' is not definedname 'SetupDiDestroyDeviceInfoList' is not definedname 'BOOL' is not definedname 'GUID' is not definedname 'PCTSTR' is not definedname 'HWND' is not definedname 'SetupDiGetClassDevs' is not definedname 'ValidHandle' is not definedname 'PSP_DEVINFO_DATA' is not definedname 'PSP_DEVICE_INTERFACE_DATA' is not definedname 'SetupDiEnumDeviceInterfaces' is not definedname 'PSP_DEVICE_INTERFACE_DETAIL_DATA' is not definedname 'PDWORD' is not definedname 'SetupDiGetDeviceInterfaceDetail' is not definedname 'PBYTE' is not definedname 'SetupDiGetDeviceRegistryProperty' is not definedname 'REGSAM' is not definedname 'SetupDiOpenDevRegKey' is not definedname 'advapi32' is not definedname 'RegCloseKey' is not definedname 'LONG' is not definedname 'LPCSTR' is not definedname 'LPDWORD' is not definedname 'LPBYTE' is not definedname 'RegQueryValueEx' is not definedname 'BYTE' is not definedglobal name 'BYTE' is not definedglobal name 'DWORD' is not definedglobal name 'WORD' is not definedglobal name 'GUID' is not definedglobal name 'ULONG_PTR' is not definedglobal name 'SetupDiGetClassDevs' is not definedglobal name 'GUID_CLASS_COMPORT' is not definedglobal name 'NULL' is not definedglobal name 'DIGCF_PRESENT' is not definedglobal name 'DIGCF_DEVICEINTERFACE' is not definedglobal name 'SP_DEVICE_INTERFACE_DATA' is not definedglobal name 'SetupDiEnumDeviceInterfaces' is not definedlocal variable 'g_hdi' referenced before assignmentglobal name 'ERROR_NO_MORE_ITEMS' is not definedglobal name 'SetupDiGetDeviceInterfaceDetail' is not definedglobal name 'ERROR_INSUFFICIENT_BUFFER' is not definedlocal variable 'SP_DEVICE_INTERFACE_DETAIL_DATA_A' referenced before assignmentglobal name 'is_64bit' is not definedglobal name 'SP_DEVINFO_DATA' is not definedlocal variable 'did' referenced before assignmentlocal variable 'dwNeeded' referenced before assignmentglobal name 'byte_buffer' is not definedglobal name 'SetupDiGetDeviceRegistryProperty' is not definedglobal name 'SPDRP_HARDWAREID' is not definedglobal name 'GetLastError' is not definedglobal name 'SPDRP_FRIENDLYNAME' is not definedglobal name 'SetupDiOpenDevRegKey' is not definedglobal name 'DICS_FLAG_GLOBAL' is not definedglobal name 'DIREG_DEV' is not definedglobal name 'KEY_READ' is not definedglobal name 'ULONG' is not definedglobal name 'RegQueryValueEx' is not definedglobal name 'PortName' is not definedglobal name 'RegCloseKey' is not definedglobal name 'SetupDiDestroyDeviceInfoList' is not definedglobal name 'CHAR' is not definedname 'WinDLL' is not definedname '_stdcall_libraries' is not definedname 'HANDLE' is not definedname 'c_int64' is not definedname 'c_ulong' is not definedname 'Structure' is not definedname 'POINTER' is not definedname '_SECURITY_ATTRIBUTES' is not definedname 'CreateEventA' is not definedname 'LPSECURITY_ATTRIBUTES' is not definedname 'CreateFileA' is not definedname 'CreateEventW' is not definedname 'LPCWSTR' is not definedname 'CreateFileW' is not definedname '_OVERLAPPED' is not definedname '_COMSTAT' is not definedname '_DCB' is not definedname '_COMMTIMEOUTS' is not definedname 'GetOverlappedResult' is not definedname 'LPOVERLAPPED' is not definedname 'ResetEvent' is not definedname 'c_void_p' is not definedname 'WriteFile' is not definedname 'LPCVOID' is not definedname 'ReadFile' is not definedname 'LPVOID' is not definedname 'CloseHandle' is not definedname 'ClearCommBreak' is not definedname 'ClearCommError' is not definedname 'LPCOMSTAT' is not definedname 'SetupComm' is not definedname 'EscapeCommFunction' is not definedname 'GetCommModemStatus' is not definedname 'GetCommState' is not definedname 'LPDCB' is not definedname 'GetCommTimeouts' is not definedname 'LPCOMMTIMEOUTS' is not definedname 'PurgeComm' is not definedname 'SetCommBreak' is not definedname 'SetCommMask' is not definedname 'SetCommState' is not definedname 'SetCommTimeouts' is not definedname 'WaitForSingleObject' is not definedname 'Union' is not definedname 'N11_OVERLAPPED4DOLLAR_484DOLLAR_49E' is not definedname 'N11_OVERLAPPED4DOLLAR_48E' is not definedname 'PVOID' is not definedname 'c_char' is not definedglobal name 'sizeof' is not definedglobal name 'c_ulong' is not definedglobal name 'c_void_p' is not definedname 'setuptools' is not definedname 'PackageFinder' is not definedname '_get_unpatched' is not definedname '_Command' is not definedname 'findall' is not definedglobal name 'convert_path' is not definedlocal variable 'where' referenced before assignmentlocal variable 'include' referenced before assignmentlocal variable 'exclude' referenced before assignmentglobal name 'filterfalse' is not definedlocal variable 'base_path' referenced before assignmentlocal variable 'patterns' referenced before assignmentglobal name 'fnmatchcase' is not definedglobal name '_Command' is not definedlocal variable 'reinit_subcommands' referenced before assignmentlocal variable 'all_files' referenced before assignmentname 'default_filter' is not definedname 'unpack_directory' is not definedname 'unpack_zipfile' is not definedname 'unpack_tarfile' is not definedlocal variable 'dst' referenced before assignmentlocal variable 'drivers' referenced before assignmentglobal name 'extraction_drivers' is not definedlocal variable 'extract_dir' referenced before assignmentlocal variable 'progress_filter' referenced before assignmentglobal name 'UnrecognizedFormat' is not definedglobal name 'ensure_directory' is not definedglobal name 'tarfile' is not definedglobal name 'contextlib' is not definedlocal variable 'tarobj' referenced before assignmentglobal name 'posixpath' is not definedlocal variable 'prelim_dst' referenced before assignmentname 'bdist' is not definedglobal name 'get_path' is not definedglobal name 'textwrap' is not definedlocal variable 'pyfile' referenced before assignmentlocal variable 'resource' referenced before assignmentlocal variable 'ei_cmd' referenced before assignmentglobal name 'get_python_version' is not definedglobal name '_get_purelib' is not definedlocal variable 'site_packages' referenced before assignmentglobal name 'INSTALL_DIRECTORY_ATTRS' is not definedlocal variable 'old_root' referenced before assignmentlocal variable 'instcmd' referenced before assignmentlocal variable 'ext_outputs' referenced before assignmentglobal name 'strip_module' is not definedglobal name 'write_stub' is not definedlocal variable 'to_compile' referenced before assignmentlocal variable 'all_outputs' referenced before assignmentglobal name 'write_safety_flag' is not definedglobal name 'make_zipfile' is not definedglobal name 'remove_tree' is not definedglobal name 'walk_egg' is not definedglobal name 'analyze_egg' is not definedlocal variable 'ep' referenced before assignmentglobal name 'mkpath' is not definedglobal name 'NATIVE_EXTENSIONS' is not definedglobal name 'Library' is not definedlocal variable 'build_cmd' referenced before assignmentlocal variable 'egg_dir' referenced before assignmentglobal name 'safety_flags' is not definedglobal name 'can_scan' is not definedglobal name 'scan_module' is not definedlocal variable 'stubs' referenced before assignmentlocal variable 'safe' referenced before assignmentglobal name 'marshal' is not definedglobal name 'iter_symbols' is not definedglobal name 'CodeType' is not definedlocal variable 'zip_filename' referenced before assignmentlocal variable 'base_dir' referenced before assignmentlocal variable 'visit' referenced before assignmentname 'orig' is not definedglobal name 'orig' is not definedlocal variable 'line23' referenced before assignmentlocal variable 'line24' referenced before assignmentglobal name 'easy_install' is not definedglobal name 'DistutilsOptionError' is not definedglobal name 'PY3' is not definedglobal name 'setuptools' is not definedlocal variable 'egg_link_file' referenced before assignmentlocal variable 'contents' referenced before assignmentname 'PY2' is not definedname 'sys_executable' is not definedname '_remove_and_clear_zip_directory_cache_data' is not definedname 'ScriptWriter' is not definedname 'WindowsScriptWriter' is not definedname 'auto_chmod' is not definedlocal variable 'both_exist' referenced before assignmentlocal variable 'use_samefile' referenced before assignmentglobal name 'site' is not definedglobal name 'PackageIndex' is not definedlocal variable 'sitedir_name' referenced before assignmentlocal variable 'blockers' referenced before assignmentglobal name 'get_config_vars' is not definedlocal variable 'exec_prefix' referenced before assignmentglobal name 'get_site_dirs' is not definedlocal variable 'site_dirs' referenced before assignmentlocal variable 'normpath' referenced before assignmentlocal variable 'hosts' referenced before assignmentglobal name 'DistutilsArgError' is not definedlocal variable 'root_len' referenced before assignmentglobal name 'random' is not definedglobal name 'maxsize' is not definedlocal variable 'pid' referenced before assignmentlocal variable 'is_site_dir' referenced before assignmentglobal name 'PthDistributions' is not definedlocal variable 'pth_file' referenced before assignmentlocal variable 'instdir' referenced before assignmentlocal variable 'ok_file' referenced before assignmentlocal variable 'alt' referenced before assignmentglobal name 'URL_SCHEME' is not definedglobal name 'parse_requirement_arg' is not definedlocal variable 'install_needed' referenced before assignmentlocal variable 'download' referenced before assignmentlocal variable 'dists' referenced before assignmentglobal name 'INSTALL_SCHEMES' is not definedglobal name 'SCHEME_KEYS' is not definedlocal variable 'distreq' referenced before assignmentlocal variable 'distros' referenced before assignmentlocal variable 'setup_base' referenced before assignmentlocal variable 'dist_filename' referenced before assignmentglobal name 'get_script_args' is not definedglobal name 'is_python_script' is not definedlocal variable 'script_text' referenced before assignmentglobal name 'get_script_header' is not definedlocal variable 'dev_path' referenced before assignmentglobal name '_to_ascii' is not definedglobal name 'resource_string' is not definedglobal name 'current_umask' is not definedglobal name 'chmod' is not definedglobal name 'unpack_archive' is not definedlocal variable 'egg_path' referenced before assignmentglobal name 'samefile' is not definedglobal name 'dir_util' is not definedglobal name 'update_dist_caches' is not definedlocal variable 'new_dist_is_zipped' referenced before assignmentglobal name 'extract_wininst_cfg' is not definedlocal variable 'cfg' referenced before assignmentlocal variable '_egg_info' referenced before assignmentlocal variable 'script_dir' referenced before assignmentglobal name 'bdist_egg' is not definedlocal variable 'egg_tmp' referenced before assignmentglobal name 'get_exe_prefixes' is not definedlocal variable 'native_libs' referenced before assignmentlocal variable 'prefixes' referenced before assignmentlocal variable 'top_level' referenced before assignmentlocal variable 'setup_script' referenced before assignmentglobal name 'egg_info' is not definedglobal name 'run_setup' is not definedlocal variable 'all_eggs' referenced before assignmentlocal variable 'eggs' referenced before assignmentlocal variable 'dist_dir' referenced before assignmentlocal variable 'fetch_directives' referenced before assignmentlocal variable 'fetch_options' referenced before assignmentglobal name 'setopt' is not definedlocal variable 'to_chmod' referenced before assignmentglobal name '_dont_write_bytecode' is not definedlocal variable 'home' referenced before assignmentlocal variable 'config_vars' referenced before assignmentlocal variable 'scheme_name' referenced before assignmentlocal variable 'subst_vars' referenced before assignmentlocal variable 'sitedirs' referenced before assignmentlocal variable 'prepended' referenced before assignmentlocal variable 'cfglen' referenced before assignmentlocal variable 'ConfigParser' referenced before assignmentlocal variable 'exe_filename' referenced before assignmentlocal variable 'saw_import' referenced before assignmentlocal variable 'baselen' referenced before assignmentglobal name 'first_line_re' is not definedglobal name '_first_line_re' is not definedlocal variable 'wininst' referenced before assignmentglobal name 'nt_quote_arg' is not definedglobal name 'isascii' is not definedglobal name 'fix_jython_executable' is not definedglobal name 'reraise' is not definedlocal variable 'et' referenced before assignmentlocal variable 'dist_path' referenced before assignmentglobal name '_uncache' is not definedlocal variable 'fix_zipimporter_caches' referenced before assignmentglobal name '_replace_zip_directory_cache_data' is not definedglobal name '_remove_and_clear_zip_directory_cache_data' is not definedlocal variable 'normalized_path' referenced before assignmentlocal variable 'prefix_len' referenced before assignmentglobal name '_collect_zipimporter_cache_entries' is not definedlocal variable 'updater' referenced before assignmentlocal variable 'new_entry' referenced before assignmentglobal name '_update_zipimporter_cache' is not definedlocal variable 'old_entry' referenced before assignmentlocal variable 'magic' referenced before assignmentlocal variable 'needquote' referenced before assignmentglobal name 'is_python' is not definedglobal name '_chmod' is not definedglobal name 'is_sh' is not definedglobal name 'sys_executable' is not definedlocal variable 'gen_class' referenced before assignmentlocal variable 'force_windows' referenced before assignmentglobal name 'WindowsScriptWriter' is not definedglobal name 'WindowsExecutableLauncherWriter' is not definedlocal variable 'orig_header' referenced before assignmentlocal variable 'repl' referenced before assignmentlocal variable 'new_header' referenced before assignmentlocal variable 'hdr' referenced before assignmentglobal name 'get_win_launcher' is not definedlocal variable 'launcher_type' referenced before assignmentglobal name 'load_launcher_manifest' is not definedglobal name 'pkg_resources' is not definedglobal name 'PY2' is not definedlocal variable 'ignore_errors' referenced before assignmentglobal name 'main' is not definedlocal variable 'Distribution' referenced before assignmentlocal variable 'with_ei_usage' referenced before assignmentlocal variable 'USAGE' referenced before assignmentlocal variable 'distutils' referenced before assignmentlocal variable 'gen_usage' referenced before assignmentlocal variable 'DistributionWithoutHelpCommands' referenced before assignmentname '_FileList' is not definedglobal name 'iter_entry_points' is not definedglobal name 'svn_utils' is not definedglobal name 'manifest_maker' is not definedglobal name 'unicode_utils' is not definedlocal variable 'enc_warn' referenced before assignmentglobal name 'FileList' is not definedglobal name 'sdist' is not definedglobal name 'walk_revctrl' is not definedlocal variable 'oldname' referenced before assignmentlocal variable 'oldver' referenced before assignmentglobal name '_write_requirements' is not definedlocal variable 'extras_require' referenced before assignmentglobal name 'write_arg' is not definedname 'cmd' is not definedlocal variable 'run_frame' referenced before assignmentname 're_finder' is not definedlocal variable 'postproc' referenced before assignmentglobal name 'finders' is not definedlocal variable 'has_leaky_handle' referenced before assignmentlocal variable '__read_template_hack' referenced before assignmentlocal variable 'dist_files' referenced before assignmentglobal name 'READMES' is not definedlocal variable 'got_it' referenced before assignmentlocal variable 'alts' referenced before assignmentlocal variable 'dest' referenced before assignmentlocal variable 'manifest' referenced before assignmentname 'option_base' is not definedlocal variable 'settings' referenced before assignmentglobal name 'config_file' is not definedglobal name 'option_base' is not definedglobal name 'edit_config' is not definedname 'unichr' is not definedlocal variable 'tb' referenced before assignmentname '_update_globals' is not definedlocal variable 'requested_version' referenced before assignmentlocal variable 'attribute' referenced before assignmentglobal name 'find_module' is not definedglobal name 'get_module_constant' is not definedlocal variable 'extended_arg' referenced before assignmentlocal variable 'EXTENDED_ARG' referenced before assignmentglobal name 'compat' is not definedglobal name 'PKG_DIRECTORY' is not definedglobal name 'PY_COMPILED' is not definedglobal name 'PY_FROZEN' is not definedglobal name 'PY_SOURCE' is not definedglobal name 'extract_constant' is not definedglobal name '_iter_code' is not definedlocal variable 'LOAD_CONST' referenced before assignmentlocal variable 'name_idx' referenced before assignmentlocal variable 'STORE_NAME' referenced before assignmentlocal variable 'STORE_GLOBAL' referenced before assignmentname '_Distribution' is not definedname '_patch_distribution_metadata_write_pkg_info' is not definedname 'module' is not definedglobal name 'assert_string_list' is not definedlocal variable '_attrs_dict' referenced before assignmentglobal name 'Feature' is not definedglobal name '_Distribution' is not definedlocal variable 'keep' referenced before assignmentlocal variable 'easy_install' referenced before assignmentlocal variable 'feature' referenced before assignmentlocal variable 'go' referenced before assignmentlocal variable 'incdef' referenced before assignmentlocal variable 'excdef' referenced before assignmentlocal variable 'no' referenced before assignmentlocal variable 'cmdclass' referenced before assignmentlocal variable 'pfx' referenced before assignmentglobal name 'sequence' is not definedlocal variable 'aliases' referenced before assignmentlocal variable 'option_order' referenced before assignmentlocal variable 'io' referenced before assignmentlocal variable 'standard' referenced before assignmentlocal variable 'available' referenced before assignmentlocal variable 'optional' referenced before assignmentlocal variable 'require_features' referenced before assignmentglobal name 'Require' is not definedlocal variable 'er' referenced before assignmentlocal variable 'remove' referenced before assignmentname '_Extension' is not definedname 'Extension' is not definedglobal name '_Extension' is not definedname 'SOURCE_DIST' is not definedname 'unique_values' is not definedname 'ContentChecker' is not definedname 'urllib2' is not definedname 'socket_timeout' is not definedname '_SOCKET_TIMEOUT' is not definedname 'open_with_auth' is not definedlocal variable 'py_ver' referenced before assignmentglobal name 'unquote' is not definedlocal variable 'server' referenced before assignmentlocal variable 'fragment' referenced before assignmentglobal name 'egg_info_for_url' is not definedglobal name 'distros_for_location' is not definedglobal name 'EGG_FRAGMENT' is not definedglobal name 'interpret_distro_name' is not definedglobal name 'CHECKOUT_DIST' is not definedglobal name 'parse_bdist_wininst' is not definedlocal variable 'win_base' referenced before assignmentglobal name 'BINARY_DIST' is not definedglobal name 'EXTENSIONS' is not definedlocal variable 'seen_add' referenced before assignmentglobal name 'wraps' is not definedglobal name 'unique_everseen' is not definedglobal name 'REL' is not definedlocal variable 'page' referenced before assignmentlocal variable 'rel' referenced before assignmentglobal name 'HREF' is not definedglobal name 'urljoin' is not definedglobal name 'htmldecode' is not definedlocal variable 'hash_name' referenced before assignmentglobal name 'hashlib' is not definedglobal name 'ContentChecker' is not definedlocal variable 'reporter' referenced before assignmentlocal variable 'index_url' referenced before assignmentlocal variable 'verify_ssl' referenced before assignmentglobal name 'ssl_support' is not definedlocal variable 'ca_bundle' referenced before assignmentglobal name 'urllib2' is not definedlocal variable 'retrieve' referenced before assignmentglobal name 'distros_for_url' is not definedglobal name 'HTTPError' is not definedlocal variable 'charset' referenced before assignmentlocal variable 'nested' referenced before assignmentglobal name 'distros_for_filename' is not definedlocal variable 'fatal' referenced before assignmentglobal name 'SOURCE_DIST' is not definedlocal variable 'scan' referenced before assignmentglobal name 'find_external_links' is not definedlocal variable 'frag' referenced before assignmentlocal variable 'new_url' referenced before assignmentglobal name 'PYPI_MD5' is not definedlocal variable 'link' referenced before assignmentlocal variable 'tfp' referenced before assignmentlocal variable 'urls' referenced before assignmentlocal variable 'force_scan' referenced before assignmentlocal variable 'local_index' referenced before assignmentlocal variable 'find' referenced before assignmentlocal variable 'develop_ok' referenced before assignmentlocal variable 'skipped' referenced before assignmentglobal name 'HashChecker' is not definedglobal name 'strip_fragment' is not definedglobal name 'get_all_headers' is not definedlocal variable 'blocknum' referenced before assignmentglobal name 'local_open' is not definedglobal name 'open_with_auth' is not definedglobal name 'httplib' is not definedlocal variable 'warning' referenced before assignmentglobal name 'url2pathname' is not definedglobal name 'splituser' is not definedlocal variable 'auth' referenced before assignmentlocal variable 'user' referenced before assignmentlocal variable 'pw' referenced before assignmentlocal variable 'creds' referenced before assignmentglobal name 'urlsplit' is not definedglobal name 'urlunsplit' is not definedlocal variable 'query' referenced before assignmentlocal variable 'rev' referenced before assignmentglobal name 'unichr' is not definedglobal name 'name2codepoint' is not definedglobal name 'uchr' is not definedglobal name 'entity_sub' is not definedglobal name 'decode_entity' is not definedglobal name 'base64' is not definedlocal variable 'username' referenced before assignmentlocal variable 'password' referenced before assignmentlocal variable 'sections_with_repositories' referenced before assignmentglobal name 'Credential' is not definedlocal variable 'repository' referenced before assignmentlocal variable 'cred' referenced before assignmentglobal name 'PyPIConfig' is not definedglobal name '_encode_auth' is not definedglobal name 'user_agent' is not definedlocal variable 'opener' referenced before assignmentlocal variable 's2' referenced before assignmentlocal variable 'h2' referenced before assignmentlocal variable 'path2' referenced before assignmentlocal variable 'param2' referenced before assignmentlocal variable 'query2' referenced before assignmentlocal variable 'frag2' referenced before assignmentglobal name 'splittag' is not definedname 'unittest' is not definedname '_PY31' is not definedglobal name 'unittest' is not definedname '_EXCEPTIONS' is not definedname 'GetGeneratePath' is not definedname 'AbstractSandbox' is not definedname '_os' is not definedlocal variable 'globals' referenced before assignmentglobal name 'DirectorySandbox' is not definedlocal variable 'pr_state' referenced before assignmentlocal variable 'save_modules' referenced before assignmentlocal variable 'del_modules' referenced before assignmentlocal variable 'old_dir' referenced before assignmentlocal variable 'save_path' referenced before assignmentlocal variable 'save_argv' referenced before assignmentlocal variable 'save_tmp' referenced before assignmentglobal name '_execfile' is not definedglobal name '_os' is not definedlocal variable '_mk_dual_path_wrapper' referenced before assignmentglobal name '_file' is not definedlocal variable '_mk_single_path_wrapper' referenced before assignmentlocal variable '_mk_single_with_return' referenced before assignmentlocal variable '_mk_query' referenced before assignmentlocal variable 'operation' referenced before assignmentglobal name '_EXCEPTIONS' is not definedlocal variable 'sandbox' referenced before assignmentlocal variable 'exceptions' referenced before assignmentglobal name 'AbstractSandbox' is not definedglobal name 'SandboxViolation' is not definedlocal variable 'active' referenced before assignmentglobal name 'WRITE_FLAGS' is not definedname 'what' is not definedname 'ssl' is not definedname 'HTTPSHandler' is not definedname 'HTTPSConnection' is not definedname 'CertificateError' is not definedname 'match_hostname' is not definedlocal variable 'dn' referenced before assignmentlocal variable 'max_wildcards' referenced before assignmentglobal name 'CertificateError' is not definedlocal variable 'hostname' referenced before assignmentlocal variable 'pats' referenced before assignmentlocal variable 'leftmost' referenced before assignmentlocal variable 'remainder' referenced before assignmentlocal variable 'cert' referenced before assignmentglobal name '_dnsname_match' is not definedlocal variable 'dnsnames' referenced before assignmentglobal name 'HTTPSHandler' is not definedglobal name 'VerifyingHTTPSConn' is not definedglobal name 'HTTPSConnection' is not definedglobal name 'ssl' is not definedglobal name 'match_hostname' is not definedlocal variable 'actual_host' referenced before assignmentglobal name 'VerifyingHTTPSHandler' is not definedglobal name 'find_ca_bundle' is not definedglobal name '_wincerts' is not definedlocal variable 'CertFile' referenced before assignmentlocal variable 'MyCertFile' referenced before assignmentlocal variable 'stores' referenced before assignmentlocal variable 'certs' referenced before assignmentglobal name 'get_win_certfile' is not definedglobal name 'cert_paths' is not definedname '_PIPE' is not definedname 'determine_console_encoding' is not definedname 'SvnInfo' is not definedname 'Svn13Info' is not definedname 'SVNEntriesFile' is not definedglobal name '_Popen' is not definedlocal variable 'stdout' referenced before assignmentlocal variable 'stderr' referenced before assignmentglobal name 'decode_as_string' is not definedlocal variable 'decoded_str' referenced before assignmentglobal name 'locale' is not definedglobal name 'codecs' is not definedglobal name '_console_encoding' is not definedglobal name 'unicodedata' is not definedglobal name 'xml' is not definedglobal name '_get_xml_data' is not definedglobal name '_get_entry_schedule' is not definedglobal name '_get_target_property' is not definedglobal name 'parse_external_prop' is not definedlocal variable 'externals' referenced before assignmentglobal name 'joinpath' is not definedglobal name 'TemporaryDirectory' is not definedglobal name '_run_command' is not definedlocal variable 'normdir' referenced before assignmentlocal variable 'is_svn_wd' referenced before assignmentglobal name 'SvnInfo' is not definedlocal variable 'base_svn_version' referenced before assignmentglobal name 'SvnFileInfo' is not definedglobal name 'Svn13Info' is not definedglobal name 'Svn15Info' is not definedlocal variable 'include_root' referenced before assignmentglobal name 'parse_dir_entries' is not definedlocal variable 'folder' referenced before assignmentglobal name 'parse_externals_xml' is not definedglobal name 'SVNEntriesFile' is not definedlocal variable 'isfile' referenced before assignmentlocal variable 'dir_rev' referenced before assignmentlocal variable 'prop_files' referenced before assignmentlocal variable 'prop_file' referenced before assignmentglobal name 'parse_prop_file' is not definedlocal variable 'fileobj' referenced before assignmentglobal name 'SVNEntriesFileText' is not definedglobal name 'SVNEntriesFileXML' is not definedlocal variable 'revision_line_number' referenced before assignmentlocal variable 'rev_numbers' referenced before assignmentlocal variable 'undeleted' referenced before assignmentglobal name 'unescape' is not definedglobal name 'decoded_string' is not definedlocal variable 'enc' referenced before assignmentname '_LazyDescr' is not definedname '_SixMetaPathImporter' is not definedname '_LazyModule' is not definedname 'MovedAttribute' is not definedname 'MovedModule' is not definedname '_moved_attributes' is not definedname '_MovedItems' is not definedname 'attr' is not definedname '_importer' is not definedname 'moves' is not definedname '_urllib_parse_moved_attributes' is not definedname 'Module_six_moves_urllib_parse' is not definedname '_urllib_error_moved_attributes' is not definedname 'Module_six_moves_urllib_error' is not definedname '_urllib_request_moved_attributes' is not definedname 'Module_six_moves_urllib_request' is not definedname '_urllib_response_moved_attributes' is not definedname 'Module_six_moves_urllib_response' is not definedname '_urllib_robotparser_moved_attributes' is not definedname 'Module_six_moves_urllib_robotparser' is not definedname 'Module_six_moves_urllib' is not definedname 'advance_iterator' is not definedname '_add_doc' is not definedname 'get_unbound_function' is not definedname '_meth_func' is not definedname '_meth_self' is not definedname '_func_closure' is not definedname '_func_code' is not definedname '_func_defaults' is not definedname '_func_globals' is not definedname 'iterkeys' is not definedname 'itervalues' is not definedname 'iterlists' is not definedname 'b' is not definedname 'u' is not definedname 'exec_' is not definedname 'print_' is not definedname '__spec__' is not definedname 'importer' is not definedglobal name 'MovedModule' is not definedglobal name '_import_module' is not definedglobal name '_LazyModule' is not definedglobal name 'MovedAttribute' is not definedlocal variable 'new_mod' referenced before assignmentlocal variable 'old_attr' referenced before assignmentlocal variable 'old_mod' referenced before assignmentlocal variable 'six_module_name' referenced before assignmentlocal variable 'fullnames' referenced before assignmentglobal name '_importer' is not definedglobal name '_MovedItems' is not definedlocal variable 'move' referenced before assignmentglobal name 'moves' is not definedlocal variable 'unbound' referenced before assignmentlocal variable '_globs_' referenced before assignmentlocal variable '_locs_' referenced before assignmentlocal variable 'want_unicode' referenced before assignmentlocal variable 'write' referenced before assignmentlocal variable 'wrapped' referenced before assignmentlocal variable 'metaclass' referenced before assignmentlocal variable 'bases' referenced before assignmentlocal variable 'orig_vars' referenced before assignment/usr/lib/python2.7/dist-packages/PILcompat/Image.py/usr/lib/python2.7/dist-packages/PILcompat/ImageFilter.pysnums_workerlocalhostSOL_SOCKETsetsockoptSO_REUSEADDR_start_server/home/pol/workspace/driver/MatlabSender.py[*   s   BmpImagePlugins   BufrStubImagePlugins   CurImagePlugins   DcxImagePlugins   EpsImagePlugins   FitsStubImagePlugins   FliImagePlugins   FpxImagePlugins   GbrImagePlugins   GifImagePlugins   GribStubImagePlugins   Hdf5StubImagePlugins   IcnsImagePlugins   IcoImagePlugins   ImImagePlugins   ImtImagePlugins   IptcImagePlugins   JpegImagePlugins   Jpeg2KImagePlugins   McIdasImagePlugins   MicImagePlugins   MpegImagePlugins   MpoImagePlugins   MspImagePlugins   PalmImagePlugins   PcdImagePlugins   PcxImagePlugins   PdfImagePlugins   PixarImagePlugins   PngImagePlugins   PpmImagePlugins   PsdImagePlugins   SgiImagePlugins   SpiderImagePlugins   SunImagePlugins   TgaImagePlugins   TiffImagePlugins   WebPImagePlugins   WmfImagePlugins   XbmImagePlugins   XpmImagePlugins   XVThumbImagePlugin2.6.1/usr/lib/python2.7/dist-packages/PIL/__init__.py1.1.7BMo_C@BGRDIBpxperm_bitmapDibImageFileBGR;15.bmpcannot write mode %s as BMPWindows BitmapNot a BMP fileUnsupported BMP Size: (%dx%d)Unsupported BMP header type (%d)Unsupported BMP compression (%d)PIL.BmpImagePlugin/usr/lib/python2.7/dist-packages/PIL/BmpImagePlugin.py0.7Unsupported BMP Palette size (%d)BGR;16Unsupported BMP bitfields layoutUnsupported BMP pixel depth (%d)256GIFstdinGIF87aGIF89adisposeupdated_prev_imppmquantppmtogifquant_cmdtogif_cmdquant_proctogif_proc_save_netpbmdispose_bitspalette_sizeTemporaryFilecolorTableSizedispose_extentglobal_palettedisposal_methodnewPaletteBytes_GifImageFile__fpCalledProcessError_GifImageFile__frameactualTargetSizeDiff_GifImageFile__offset_GifImageFile__rewind.gifPIL.GifImagePluginNETSCAPE2.0cannot seek to frame %dReturn a list of strings representing this image.
       The first string is a local image header, the rest contains
       encoded image data./usr/lib/python2.7/dist-packages/PIL/GifImagePlugin.pyReturn a list of strings representing a GIF headerCompuserve GIFno more images in GIF filenot a GIF fileimage/gifcspace|=PIL.GimpGradientFile/usr/lib/python2.7/dist-packages/PIL/GimpGradientFile.pyGIMP Gradientcannot handle HSV colour spacenot a GIMP gradient fileName: /usr/lib/python2.7/dist-packages/PIL/GimpPaletteFile.pyGIMP Palettenot a GIMP palette filePIL.GimpPaletteFile\w+:|#bad palette entryxbmFIXEDFixTkgetim_wedgeORDEREDgetbandgetbboxputbandputdatasetmodestretchtrns_imtypekeyFILTEREDSEQUENCE_encoderfillbandgetbandsputalphapyaccessquantizesave_ppmtobitmapCONTAINERMEDIANCUTRASTERIZEROTATE_90_makeselfgetcolorsthumbnailFASTOCTREEROTATE_180ROTATE_270transform2MAXCOVERAGEHUFFMAN_ONLYeffect_noisepixel_access__transformereffect_spreadgetprojectionconvert_matrixFLIP_LEFT_RIGHTFLIP_TOP_BOTTOMalpha_compositepoint_transformputpalettealphaDEFAULT_STRATEGY_ImageCrop__crop_Image__iteratorgetmodebandnamesputpalettealphaseffect_mandelbrot_Image__transformerconvert_transparent{(   (   i   i   s   <i2(   t   Is   I;16(   (   i   i   i   s   |u1(   s   RGBAs   RGBA(   (   i   i   s   >i2(   R    s   I;16B(   (   i   i   s   >i4(   R    s   I;32B(   (   i   i   s   |u1(   t   LR   (   (   i   i   s   <i4(   R    s   I;32(   (   i   i   s   <f4(   t   Fs   F;32F(   (   i   i   s   <f8(   R   s   F;64F(   (   i   i   s   >f4(   R   s   F;32BF(   (   i   i   i   s   |u1(   s   RGBs   RGB(   (   i   i   s   >f8(   R   s   F;64BF(   (   i   i   s   |i1(   R    s   I;80{s   CMYK(   s   RGBt   L(   t   Ct   Mt   Yt   Kt   F(   R    R   (   R   t   I(   R    R   (   R   R    (   R    R    (   R    s   LAB(   s   RGBR    (   R    t   At   Bs   RGBX(   s   RGBR    (   t   Rt   GR   t   Xs   YCbCr(   s   RGBR    (   R   s   Cbs   Crt   P(   s   RGBR    (   R   s   RGB(   s   RGBR    (   R	   R
   R   t   1(   R    R    (   R   s   HSV(   s   RGBR    (   t   Ht   St   Vs   RGBA(   s   RGBR    (   R	   R
   R   R   0Module use of pythonTransparency for P mode should be bytes or intencoder %s not availableI;16LS
        Attaches a palette to this image.  The image must be a "P" or
        "L" image, and the palette sequence must contain 768 integer
        values, where each group of three values represent the red,
        green, and blue values for the corresponding pixel
        index. Instead of an integer sequence, you can use an 8-bit
        string.

        :param data: A palette sequence (either a list or a string).
        unsupported resampling filter
    Creates an image memory from an object exporting the array interface
    (using the buffer protocol).

    If obj is not contiguous, then the tobytes method is called
    and :py:func:`~PIL.Image.frombuffer` is used.

    :param obj: Object with array interface
    :param mode: Mode to use (will be determined from type if None)
    :returns: An image memory.

    .. versionadded:: 1.1.6
    unknown transformation methodImage: failed to importSymbol not found: _PyUnicodeUCS2_FromString
        Calculates the bounding box of the non-zero regions in the
        image.

        :returns: The bounding box is returned as a 4-tuple defining the
           left, upper, right, and lower pixel coordinate. If the image
           is completely empty, this method returns None.

        #define %s_width %d

    Gets the "base" mode for given mode.  This function returns "L" for
    images that contain grayscale data, and "RGB" for images that
    contain color data.

    :param mode: Input mode.
    :returns: "L" or "RGB".
    :exception KeyError: If the input mode was not a standard mode.
    missing method datawrong number of bandsI;32LSonly RGB or L mode images can be quantized to a palette
        Copies pixel data to this image.  This method copies data from a
        sequence object into the image, starting at the upper left
        corner (0, 0), and continuing until either the image or the
        sequence ends.  The scale and offset values are used to adjust
        the sequence values: **pixel = value*scale + offset**.

        :param data: A sequence object.
        :param scale: An optional scale value.  The default is 1.0.
        :param offset: An optional offset value.  The default is 0.0.
        Create greyscale wedge (for debugging only)
    Gets the storage type mode.  Given a mode, this function returns a
    single-layer mode suitable for storing individual bands.

    :param mode: Input mode.
    :returns: "L", "I", or "F".
    :exception KeyError: If the input mode was not a standard mode.
    };Explicitly load standard file format drivers.
    Opens and identifies the given image file.

    This is a lazy operation; this function identifies the file, but
    the file remains open and the actual image data is not read from
    the file until you try to process the data (or call the
    :py:meth:`~PIL.Image.Image.load` method).  See
    :py:func:`~PIL.Image.new`.

    :param file: A filename (string) or a file object.  The file object
       must implement :py:meth:`~file.read`, :py:meth:`~file.seek`, and
       :py:meth:`~file.tell` methods, and be opened in binary mode.
    :param mode: The mode.  If given, this argument must be "r".
    :returns: An :py:class:`~PIL.Image.Image` object.
    :exception IOError: If the file cannot be found, or the image cannot be
       opened and identified.
    fromstring() is deprecated. Please call frombytes() instead.
        Get projection to x and y axes

        :returns: Two sequences, indicating where there are non-zero
            pixels along the X-axis and the Y-axis, respectively.
        >u2Deprecated alias to frombytes.

        .. deprecated:: 2.0
        Couldn't allocate palette entry for transparencyThe _imaging extension was built for another  version of Pillow or PIL
        Maps this image through a lookup table or function.

        :param lut: A lookup table, containing 256 (or 65336 if
           self.mode=="I" and mode == "L") values per band in the
           image.  A function can be used instead, it should take a
           single argument. The function is called once for each
           possible pixel value, and the resulting table is applied to
           all bands of the image.
        :param mode: Output mode (default is same as input).  In the
           current version, this can only be used if the source image
           has mode "L" or "P", and the output has mode "1" or the
           source image mode is "I" and the output mode is "L".
        :returns: An :py:class:`~PIL.Image.Image` object.
        
    Checks if an object is an image object.

    .. warning::

       This function is for internal use only.

    :param t: object to check if it's an image
    :returns: True if the object is an image
    tostring() is deprecated. Please call tobytes() instead.cannot identify image file %r
    Registers an image MIME type.  This function should not be used
    in application code.

    :param id: An image format identifier.
    :param mimetype: The image MIME type for this format.
    
        Make this image into a thumbnail.  This method modifies the
        image to contain a thumbnail version of itself, no larger than
        the given size.  This method calculates an appropriate thumbnail
        size to preserve the aspect of the image, calls the
        :py:meth:`~PIL.Image.Image.draft` method to configure the file reader
        (where applicable), and finally resizes the image.

        Note that the bilinear and bicubic filters in the current
        version of PIL are not well-suited for thumbnail generation.
        You should use :py:attr:`PIL.Image.ANTIALIAS` unless speed is much more
        important than quality.

        Also note that this function modifies the :py:class:`~PIL.Image.Image`
        object in place.  If you need to use the full resolution image as well,
        apply this method to a :py:meth:`~PIL.Image.Image.copy` of the original
        image.

        :param size: Requested size.
        :param resample: Optional resampling filter.  This can be one
           of :py:attr:`PIL.Image.NEAREST`, :py:attr:`PIL.Image.BILINEAR`,
           :py:attr:`PIL.Image.BICUBIC`, or :py:attr:`PIL.Image.ANTIALIAS`
           (best quality).  If omitted, it defaults to
           :py:attr:`PIL.Image.ANTIALIAS`. (was :py:attr:`PIL.Image.NEAREST`
           prior to version 2.5.0)
        :returns: None
        
        Returns the pixel value at a given position.

        :param xy: The coordinate, given as (x, y).
        :returns: The pixel value.  If the image is a multi-layer image,
           this method returns a tuple.
        
        Returns a capsule that points to the internal image memory.

        :returns: A capsule object.
        
    Explicitly initializes the Python Imaging Library. This function
    loads all available file format drivers.
    PIL.%sCannot handle this data typeDeprecated alias to frombytes.

    .. deprecated:: 2.0
    bad mode %rfilter argument should be ImageFilter.Filter instance or class
        Returns the contents of this image as a sequence object
        containing pixel values.  The sequence object is flattened, so
        that values for line one follow directly after the values of
        line zero, and so on.

        Note that the sequence object returned by this method is an
        internal PIL data type, which only supports certain sequence
        operations.  To convert it to an ordinary sequence (e.g. for
        printing), use **list(im.getdata())**.

        :param band: What band to return.  The default is to return
           all bands.  To return a single band, pass in the index
           value (e.g. 0 to get the "R" band from an "RGB" image).
        :returns: A sequence-like object.
        not enough image data/usr/lib/python2.7/dist-packages/PIL/Image.pyencoder error %d in tobytes
    Creates a new image with the given mode and size.

    :param mode: The mode to use for the new image.
    :param size: A 2-tuple, containing (width, height) in pixels.
    :param color: What color to use for the image.  Default is black.
       If given, this should be a single integer or floating point value
       for single-band modes, and a tuple for multi-band modes (one value
       per band).  When creating RGB images, you can also use color
       strings as supported by the ImageColor module.  If the color is
       None, the image is not initialised.
    :returns: An :py:class:`~PIL.Image.Image` object.
    
        Saves this image under the given filename.  If no format is
        specified, the format to use is determined from the filename
        extension, if possible.

        Keyword options can be used to provide additional instructions
        to the writer. If a writer doesn't recognise an option, it is
        silently ignored. The available options are described later in
        this handbook.

        You can use a file object instead of a filename. In this case,
        you must always specify the format. The file object must
        implement the **seek**, **tell**, and **write**
        methods, and be opened in binary mode.

        :param file: File name or file object.
        :param format: Optional format override.  If omitted, the
           format to use is determined from the filename extension.
           If a file object was used instead of a filename, this
           parameter should always be used.
        :param options: Extra parameters to the image writer.
        :returns: None
        :exception KeyError: If the output format could not be determined
           from the file name.  Use the format option to solve this.
        :exception IOError: If the file could not be written.  The file
           may have been created, and may contain partial data.
        
        Transforms this image.  This method creates a new image with the
        given size, and the same mode as the original, and copies data
        to the new image using the given transform.

        :param size: The output size.
        :param method: The transformation method.  This is one of
          :py:attr:`PIL.Image.EXTENT` (cut out a rectangular subregion),
          :py:attr:`PIL.Image.AFFINE` (affine transform),
          :py:attr:`PIL.Image.PERSPECTIVE` (perspective transform),
          :py:attr:`PIL.Image.QUAD` (map a quadrilateral to a rectangle), or
          :py:attr:`PIL.Image.MESH` (map a number of source quadrilaterals
          in one operation).
        :param data: Extra data to the transformation method.
        :param resample: Optional resampling filter.  It can be one of
           :py:attr:`PIL.Image.NEAREST` (use nearest neighbour),
           :py:attr:`PIL.Image.BILINEAR` (linear interpolation in a 2x2
           environment), or :py:attr:`PIL.Image.BICUBIC` (cubic spline
           interpolation in a 4x4 environment). If omitted, or if the image
           has mode "1" or "P", it is set to :py:attr:`PIL.Image.NEAREST`.
        :returns: An :py:class:`~PIL.Image.Image` object.
        cannot determine region size; use 4-item box
    Creates a copy of an image memory from pixel data in a buffer.

    In its simplest form, this function takes three arguments
    (mode, size, and unpacked pixel data).

    You can also use any pixel decoder supported by PIL.  For more
    information on available decoders, see the section
    **Writing Your Own File Decoder**.

    Note that this function decodes pixel data only, not entire images.
    If you have an entire image in a string, wrap it in a
    :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load
    it.

    :param mode: The image mode.
    :param size: The image size.
    :param data: A byte buffer containing raw data for the given mode.
    :param decoder_name: What decoder to use.
    :param args: Additional parameters for the given decoder.
    :returns: An :py:class:`~PIL.Image.Image` object.
    The _imaging extension was built for another version of Python.
        NYI

        Configures the image file loader so it returns a version of the
        image that as closely as possible matches the given mode and
        size.  For example, you can use this method to convert a color
        JPEG to greyscale while loading it, or to extract a 128x192
        version from a PCD file.

        Note that this method modifies the :py:class:`~PIL.Image.Image` object
        in place.  If the image has already been loaded, this method has no
        effect.

        :param mode: The requested mode.
        :param size: The requested size.
        
        Adds or replaces the alpha layer in this image.  If the image
        does not have an alpha layer, it's converted to "LA" or "RGBA".
        The new layer must be either "L" or "1".

        :param alpha: The new alpha layer.  This can either be an "L" or "1"
           image having the same size as this image, or an integer or
           other color value.
        #define %s_height %d
bad mode for palette image
        Returns the image converted to an X11 bitmap.

        .. note:: This method only works for mode "1" images.

        :param name: The name prefix to use for the bitmap variables.
        :returns: A string containing an X11 bitmap.
        :raises ValueError: If the mode is not "1"
        cannot decode image dataDeprecated alias to tobytes.

        .. deprecated:: 2.0
        unknown resampling filterillegal image mode
        Returns a resized copy of this image.

        :param size: The requested size in pixels, as a 2-tuple:
           (width, height).
        :param resample: An optional resampling filter.  This can be
           one of :py:attr:`PIL.Image.NEAREST` (use nearest neighbour),
           :py:attr:`PIL.Image.BILINEAR` (linear interpolation in a 2x2
           environment), :py:attr:`PIL.Image.BICUBIC` (cubic spline
           interpolation in a 4x4 environment), or
           :py:attr:`PIL.Image.ANTIALIAS` (a high-quality downsampling filter).
           If omitted, or if the image has mode "1" or "P", it is
           set :py:attr:`PIL.Image.NEAREST`.
        :returns: An :py:class:`~PIL.Image.Image` object.
        
        Closes the file pointer, if possible.

        This operation will destroy the image core and release its memory.
        The image data will be unusable afterward.

        This function is only required to close images that have not
        had their file read and closed by the
        :py:meth:`~PIL.Image.Image.load` method.
        not a bitmap
        .. deprecated:: 2.0

        .. note:: New code should use :py:func:`PIL.ImageChops.offset`.

        Returns a copy of the image where the data has been offset by the given
        distances. Data wraps around the edges. If **yoffset** is omitted, it
        is assumed to be equal to **xoffset**.

        :param xoffset: The horizontal distance.
        :param yoffset: The vertical distance.  If omitted, both
           distances are set to the same value.
        :returns: An :py:class:`~PIL.Image.Image` object.
        Fast Octree (method == 2) is the  only valid method for quantizing RGBA images
        Pastes another image into this image. The box argument is either
        a 2-tuple giving the upper left corner, a 4-tuple defining the
        left, upper, right, and lower pixel coordinate, or None (same as
        (0, 0)).  If a 4-tuple is given, the size of the pasted image
        must match the size of the region.

        If the modes don't match, the pasted image is converted to the mode of
        this image (see the :py:meth:`~PIL.Image.Image.convert` method for
        details).

        Instead of an image, the source can be a integer or tuple
        containing pixel values.  The method then fills the region
        with the given color.  When creating RGB images, you can
        also use color strings as supported by the ImageColor module.

        If a mask is given, this method updates only the regions
        indicated by the mask.  You can use either "1", "L" or "RGBA"
        images (in the latter case, the alpha band is used as mask).
        Where the mask is 255, the given image is copied as is.  Where
        the mask is 0, the current value is preserved.  Intermediate
        values can be used for transparency effects.

        Note that if you paste an "RGBA" image, the alpha band is
        ignored.  You can work around this by using the same image as
        both source image and mask.

        :param im: Source image or pixel value (integer or tuple).
        :param box: An optional 4-tuple giving the region to paste into.
           If a 2-tuple is used instead, it's treated as the upper left
           corner.  If omitted or None, the source is pasted into the
           upper left corner.

           If an image is given as the second argument and there is no
           third, the box defaults to (0, 0), and the second argument
           is interpreted as a mask image.
        :param mask: An optional mask image.
        
    Creates an image memory referencing pixel data in a byte buffer.

    This function is similar to :py:func:`~PIL.Image.frombytes`, but uses data
    in the byte buffer, where possible.  This means that changes to the
    original buffer object are reflected in this image).  Not all modes can
    share memory; supported modes include "L", "RGBX", "RGBA", and "CMYK".

    Note that this function decodes pixel data only, not entire images.
    If you have an entire image file in a string, wrap it in a
    **BytesIO** object, and use :py:func:`~PIL.Image.open` to load it.

    In the current version, the default parameters used for the "raw" decoder
    differs from that used for :py:func:`~PIL.Image.fromstring`.  This is a
    bug, and will probably be fixed in a future release.  The current release
    issues a warning if you do this; to disable the warning, you should provide
    the full set of parameters.  See below for details.

    :param mode: The image mode.
    :param size: The image size.
    :param data: A bytes or other buffer object containing raw
        data for the given mode.
    :param decoder_name: What decoder to use.
    :param args: Additional parameters for the given decoder.  For the
        default encoder ("raw"), it's recommended that you provide the
        full set of parameters::

            frombuffer(mode, size, data, "raw", mode, 0, 1)

    :returns: An :py:class:`~PIL.Image.Image` object.

    .. versionadded:: 1.1.4
    
        Return image as a bytes object

        :param encoder_name: What encoder to use.  The default is to
                             use the standard "raw" encoder.
        :param args: Extra arguments to the encoder.
        :rtype: A bytes object.
        Error closing: %s
        Randomly spread pixels in an image.

        :param distance: Distance to spread pixels.
        
        Returns the current frame number. See :py:meth:`~PIL.Image.Image.seek`.

        :returns: Frame number, starting with 0.
        
    Alpha composite im2 over im1.

    :param im1: The first image.
    :param im2: The second image.  Must have the same mode and size as
       the first image.
    :returns: An :py:class:`~PIL.Image.Image` object.
    
    Registers an image save function.  This function should not be
    used in application code.

    :param id: An image format identifier.
    :param driver: A function to save images in this format.
    size mismatch
        Returns a converted copy of this image. For the "P" mode, this
        method translates pixels through the palette.  If mode is
        omitted, a mode is chosen so that all information in the image
        and the palette can be represented without a palette.

        The current version supports all possible conversions between
        "L", "RGB" and "CMYK." The **matrix** argument only supports "L"
        and "RGB".

        When translating a color image to black and white (mode "L"),
        the library uses the ITU-R 601-2 luma transform::

            L = R * 299/1000 + G * 587/1000 + B * 114/1000

        The default method of converting a greyscale ("L") or "RGB"
        image into a bilevel (mode "1") image uses Floyd-Steinberg
        dither to approximate the original image luminosity levels. If
        dither is NONE, all non-zero values are set to 255 (white). To
        use other thresholds, use the :py:meth:`~PIL.Image.Image.point`
        method.

        :param mode: The requested mode.
        :param matrix: An optional conversion matrix.  If given, this
           should be 4- or 16-tuple containing floating point values.
        :param dither: Dithering method, used when converting from
           mode "RGB" to "P" or from "RGB" or "L" to "1".
           Available methods are NONE or FLOYDSTEINBERG (default).
        :param palette: Palette to use when converting from mode "RGB"
           to "P".  Available palettes are WEB or ADAPTIVE.
        :param colors: Number of colors to use for the ADAPTIVE palette.
           Defaults to 256.
        :rtype: :py:class:`~PIL.Image.Image`
        :returns: An :py:class:`~PIL.Image.Image` object.
        
    Create composite image by blending images using a transparency mask.

    :param image1: The first image.
    :param image2: The second image.  Must have the same mode and
       size as the first image.
    :param mask: A mask image.  This image can can have mode
       "1", "L", or "RGBA", and must have the same size as the
       other two images.
    mode mismatch
        Returns a histogram for the image. The histogram is returned as
        a list of pixel counts, one for each pixel value in the source
        image. If the image has more than one band, the histograms for
        all bands are concatenated (for example, the histogram for an
        "RGB" image contains 768 values).

        A bilevel image (mode "1") is treated as a greyscale ("L") image
        by this method.

        If a mask is provided, the method returns a histogram for those
        parts of the image where the mask image is non-zero. The mask
        image must have the same size as the image, and be either a
        bi-level image (mode "1") or a greyscale image ("L").

        :param mask: An optional mask.
        :returns: A list containing pixel counts.
        
        Filters this image using the given filter.  For a list of
        available filters, see the :py:mod:`~PIL.ImageFilter` module.

        :param filter: Filter kernel.
        :returns: An :py:class:`~PIL.Image.Image` object.  
        Seeks to the given frame in this sequence file. If you seek
        beyond the end of the sequence, the method raises an
        **EOFError** exception. When a sequence file is opened, the
        library automatically seeks to frame 0.

        Note that in the current version of the library, most sequence
        formats only allows you to seek to the next frame.

        See :py:meth:`~PIL.Image.Image.tell`.

        :param frame: Frame number, starting at 0.
        :exception EOFError: If the call attempts to seek beyond the end
            of the sequence.
        
    Registers an image extension.  This function should not be
    used in application code.

    :param id: An image format identifier.
    :param extension: An extension used for this format.
    the frombuffer defaults may change in a future release; for portability, change the call to read:
  frombuffer(mode, size, data, 'raw', mode, 0, 1)
    Gets a list of individual band names.  Given a mode, this function returns
    a tuple containing the names of individual bands (use
    :py:method:`~PIL.Image.getmodetype` to get the mode used to store each
    individual band.

    :param mode: Input mode.
    :returns: A tuple containing band names.  The length of the tuple
        gives the number of bands in an image of the given mode.
    :exception KeyError: If the input mode was not a standard mode.
    
        Gets the the minimum and maximum pixel values for each band in
        the image.

        :returns: For a single-band image, a 2-tuple containing the
           minimum and maximum pixel value.  For a multi-band image,
           a tuple containing one 2-tuple for each band.
        Image size (%d pixels) exceeds limit of %d pixels, could be decompression bomb DOS attack.
        Allocates storage for the image and loads the pixel data.  In
        normal cases, you don't need to call this method, since the
        Image class automatically loads an opened image when it is
        accessed for the first time. This method will close the file
        associated with the image.

        :returns: An image access object.
        
        Copies this image. Use this method if you wish to paste things
        into an image, but still retain the original.

        :rtype: :py:class:`~PIL.Image.Image`
        :returns: An :py:class:`~PIL.Image.Image` object.
        The _imaging extension was built for Python with UCS4 support; recompile PIL or build Python --with-wide-unicode. 
        Transpose image (flip or rotate in 90 degree steps)

        :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,
          :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,
          :py:attr:`PIL.Image.ROTATE_180`, or :py:attr:`PIL.Image.ROTATE_270`.
        :returns: Returns a flipped or rotated copy of this image.
        Symbol not found: _PyUnicodeUCS4_FromString
    Register an image file plugin.  This function should not be used
    in application code.

    :param id: An image format identifier.
    :param factory: An image file factory method.
    :param accept: An optional function that can be used to quickly
       reject images having another format.
    
    Applies the function (which should take one argument) to each pixel
    in the given image. If the image has more than one band, the same
    function is applied to each band. Note that the function is
    evaluated once for each possible pixel value, so you cannot use
    random components or other generators.

    :param image: The input image.
    :param function: A function object, taking one integer argument.
    :returns: An :py:class:`~PIL.Image.Image` object.
    The _imaging C module is not installedThe _imaging extension was built for Python with UCS2 support; recompile PIL or build Python --without-wide-unicode. illegal expression
    Merge a set of single band images into a new multiband image.

    :param mode: The mode to use for the output image.
    :param bands: A sequence containing one single-band image for
        each band in the output image.  All bands must have the
        same size.
    :returns: An :py:class:`~PIL.Image.Image` object.
    
        Returns a rectangular region from this image. The box is a
        4-tuple defining the left, upper, right, and lower pixel
        coordinate.

        This is a lazy operation.  Changes to the source image may or
        may not be reflected in the cropped image.  To break the
        connection, call the :py:meth:`~PIL.Image.Image.load` method on
        the cropped copy.

        :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.
        :rtype: :py:class:`~PIL.Image.Image`
        :returns: An :py:class:`~PIL.Image.Image` object.
        
    Creates a new image by interpolating between two input images, using
    a constant alpha.::

        out = image1 * (1.0 - alpha) + image2 * alpha

    :param im1: The first image.
    :param im2: The second image.  Must have the same mode and size as
       the first image.
    :param alpha: The interpolation alpha factor.  If alpha is 0.0, a
       copy of the first image is returned. If alpha is 1.0, a copy of
       the second image is returned. There are no restrictions on the
       alpha value. If necessary, the result is clipped to fit into
       the allowed output range.
    :returns: An :py:class:`~PIL.Image.Image` object.
    <u4'offset' is deprecated; use 'ImageChops.offset' insteadOperation on closed image
        Verifies the contents of a file. For data read from a file, this
        method attempts to determine if the file is broken, without
        actually decoding the image data.  If this method finds any
        problems, it raises suitable exceptions.  If you need to load
        the image after using this method, you must reopen the image
        file.
        
        Returns a rotated copy of this image.  This method returns a
        copy of this image, rotated the given number of degrees counter
        clockwise around its centre.

        :param angle: In degrees counter clockwise.
        :param resample: An optional resampling filter.  This can be
           one of :py:attr:`PIL.Image.NEAREST` (use nearest neighbour),
           :py:attr:`PIL.Image.BILINEAR` (linear interpolation in a 2x2
           environment), or :py:attr:`PIL.Image.BICUBIC`
           (cubic spline interpolation in a 4x4 environment).
           If omitted, or if the image has mode "1" or "P", it is
           set :py:attr:`PIL.Image.NEAREST`.
        :param expand: Optional expansion flag.  If true, expands the output
           image to make it large enough to hold the entire rotated image.
           If false or omitted, make the output image the same size as the
           input image.
        :returns: An :py:class:`~PIL.Image.Image` object.
        
        Displays this image. This method is mainly intended for
        debugging purposes.

        On Unix platforms, this method saves the image to a temporary
        PPM file, and calls the **xv** utility.

        On Windows, it saves the image to a temporary BMP file, and uses
        the standard BMP display utility to show it (usually Paint).

        :param title: Optional title to use for the image window,
           where possible.
        :param command: command used to show the image
        
        Returns a list of colors used in this image.

        :param maxcolors: Maximum number of colors.  If this number is
           exceeded, this method returns None.  The default limit is
           256 colors.
        :returns: An unsorted list of (count, pixel) values.
        
        Loads this image with pixel data from a bytes object.

        This method is similar to the :py:func:`~PIL.Image.frombytes` function,
        but loads data into this image instead of creating a new image object.
        
        Returns a tuple containing the name of each band in this image.
        For example, **getbands** on an RGB image returns ("R", "G", "B").

        :returns: A tuple containing band names.
        :rtype: tuple
        point operation not supported for this modedecoder %s not available
    Generate a Mandelbrot set covering the given extent.

    :param size: The requested size in pixels, as a 2-tuple:
       (width, height).
    :param extent: The extent to cover, as a 4-tuple:
       (x0, y0, x1, y2).
    :param quality: Quality.
    >u4static char %s_bits[] = {
Importing %sillegal conversion
    Generate Gaussian noise centered around 128.

    :param size: The requested size in pixels, as a 2-tuple:
       (width, height).
    :param sigma: Standard deviation of noise.
    Too many dimensions: %d > %d.
        Returns the image palette as a list.

        :returns: A list of color values [r, g, b, ...], or None if the
           image has no palette.
        
    This class represents an image object.  To create
    :py:class:`~PIL.Image.Image` objects, use the appropriate factory
    functions.  There's hardly ever any reason to call the Image constructor
    directly.

    * :py:func:`~PIL.Image.open`
    * :py:func:`~PIL.Image.new`
    * :py:func:`~PIL.Image.frombytes`
    Palette images with Transparency   expressed in bytes should be converted to RGBA images
        Split this image into individual bands. This method returns a
        tuple of individual image bands from an image. For example,
        splitting an "RGB" image creates three new images each
        containing a copy of one of the original bands (red, green,
        blue).

        :returns: A tuple containing bands.
        
    Gets the number of individual bands for this mode.

    :param mode: Input mode.
    :returns: The number of bands in this mode.
    :exception KeyError: If the input mode was not a standard mode.
    <u2<%s.%s image mode=%s size=%dx%d at 0x%X>
        Modifies the pixel at the given position. The color is given as
        a single numerical value for single-band images, and a tuple for
        multi-band images.

        Note that this method is relatively slow.  For more extensive changes,
        use :py:meth:`~PIL.Image.Image.paste` or the :py:mod:`~PIL.ImageDraw`
        module instead.

        See:

        * :py:meth:`~PIL.Image.Image.paste`
        * :py:meth:`~PIL.Image.Image.putdata`
        * :py:mod:`~PIL.ImageDraw`

        :param xy: The pixel coordinate, given as (x, y).
        :param value: The pixel value.
        (   t   selft   boxt   imaget   methodt   datat   resamplet   fillt   wt   ht   x0t   y0t   x1t   y1t   xst   yst   nwt   swt   set   net   Ast   Atdarkerchop_orlighterchop_addchop_andchop_xoradd_modulochop_darkerchop_invertchop_screenchop_lighterchop_multiplychop_subtractchop_add_modulochop_differencesubtract_modulochop_subtract_modulo
    Invert an image (channel).

    .. code-block:: python

        out = MAX - image

    :rtype: :py:class:`~PIL.Image.Image`
    
    Superimposes two images on top of each other.

    If you multiply an image with a solid black image, the result is black. If
    you multiply with a solid white image, the image is unaffected.

    .. code-block:: python

        out = image1 * image2 / MAX

    :rtype: :py:class:`~PIL.Image.Image`
    Returns a copy of the image where data has been offset by the given
    distances. Data wraps around the edges. If **yoffset** is omitted, it
    is assumed to be equal to **xoffset**.

    :param xoffset: The horizontal distance.
    :param yoffset: The vertical distance.  If omitted, both
        distances are set to the same value.
    :rtype: :py:class:`~PIL.Image.Image`
    /usr/lib/python2.7/dist-packages/PIL/ImageChops.pyAdd two images, without clipping the result.

    .. code-block:: python

        out = ((image1 + image2) % MAX)

    :rtype: :py:class:`~PIL.Image.Image`
    Logical AND between two images.

    .. code-block:: python

        out = ((image1 and image2) % MAX)

    :rtype: :py:class:`~PIL.Image.Image`
    Fill a channel with a given grey level.

    :rtype: :py:class:`~PIL.Image.Image`
    Copy a channel. Alias for :py:meth:`PIL.Image.Image.copy`.

    :rtype: :py:class:`~PIL.Image.Image`
    Logical OR between two images.

    .. code-block:: python

        out = ((image1 or image2) % MAX)

    :rtype: :py:class:`~PIL.Image.Image`
    
    Superimposes two inverted images on top of each other.

    .. code-block:: python

        out = MAX - ((MAX - image1) * (MAX - image2) / MAX)

    :rtype: :py:class:`~PIL.Image.Image`
    
    Compares the two images, pixel by pixel, and returns a new image
    containing the darker values.

    .. code-block:: python

        out = min(image1, image2)

    :rtype: :py:class:`~PIL.Image.Image`
    Subtract two images, without clipping the result.

    .. code-block:: python

        out = ((image1 - image2) % MAX)

    :rtype: :py:class:`~PIL.Image.Image`
    
    Returns the absolute value of the pixel-by-pixel difference between the two
    images.

    .. code-block:: python

        out = abs(image1 - image2)

    :rtype: :py:class:`~PIL.Image.Image`
    Create composite using transparency mask. Alias for
    :py:meth:`PIL.Image.Image.composite`.

    :rtype: :py:class:`~PIL.Image.Image`
    Blend images using constant transparency weight. Alias for
    :py:meth:`PIL.Image.Image.blend`.

    :rtype: :py:class:`~PIL.Image.Image`
    
    Subtracts two images, dividing the result by scale and adding the
    offset. If omitted, scale defaults to 1.0, and offset to 0.0.

    .. code-block:: python

        out = ((image1 - image2) / scale + offset)

    :rtype: :py:class:`~PIL.Image.Image`
    
    Adds two images, dividing the result by scale and adding the
    offset. If omitted, scale defaults to 1.0, and offset to 0.0.

    .. code-block:: python

        out = ((image1 + image2) / scale + offset)

    :rtype: :py:class:`~PIL.Image.Image`
    
    Compares the two images, pixel by pixel, and returns a new image containing
    the lighter values.

    .. code-block:: python

        out = max(image1, image2)

    :rtype: :py:class:`~PIL.Image.Image`
    Logical XOR between two images.

    .. code-block:: python

        out = ((bool(image1) != bool(image2)) % MAX)

    :rtype: :py:class:`~PIL.Image.Image`
         v@colorsyshls_to_rgb{s   indigos   #4b0082s   golds   #ffd700s	   firebricks   #b22222s	   indianreds   #cd5c5cs   yellows   #ffff00s   darkolivegreens   #556b2fs   darkseagreens   #8fbc8fs	   slategreys   #708090s   darkslategreys   #2f4f4fs   greenyellows   #adff2fs   mediumorchids   #ba55d3s
   papayawhips   #ffefd5s   mediumslateblues   #7b68ees   blacks   #000000s   springgreens   #00ff7fs   oranges   #ffa500s   lightsalmons   #ffa07as   browns   #a52a2as	   turquoises   #40e0d0s   lightseagreens   #20b2aas   cyans   #00ffffs   silvers   #c0c0c0s   skyblues   #87ceebs   grays   #808080s   darkturquoises   #00ced1s	   goldenrods   #daa520s	   darkgreens   #006400s
   darkviolets   #9400d3s   darkgrays   #a9a9a9s   limes   #00ff00s	   lightpinks   #ffb6c1s   teals   #008080s   darkmagentas   #8b008bs   lightgoldenrodyellows   #fafad2s   lavenders   #e6e6fas   yellowgreens   #9acd32s   thistles   #d8bfd8s   violets   #ee82ees   navys   #000080s   darkblues   #00008bs   dimgreys   #696969s   orchids   #da70d6s   blues   #0000ffs
   ghostwhites   #f8f8ffs   honeydews   #f0fff0s   cornflowerblues   #6495eds   purples   #800080s	   darkkhakis   #bdb76bs   mediumpurples   #9370dbs   cornsilks   #fff8dcs   reds   #ff0000s   bisques   #ffe4c4s	   burlywoods   #deb887s   darkcyans   #008b8bs   khakis   #f0e68cs   wheats   #f5deb3s   deepskyblues   #00bfffs   darkreds   #8b0000s	   steelblues   #4682b4s	   aliceblues   #f0f8ffs   lightslategreys   #778899s	   gainsboros   #dcdcdcs   mediumturquoises   #48d1ccs   floralwhites   #fffaf0s   plums   #dda0dds	   lightgreys   #d3d3d3s	   mistyroses   #ffe4e1s
   darksalmons   #e9967as   beiges   #f5f5dcs   azures   #f0ffffs   lightsteelblues   #b0c4des   oldlaces   #fdf5e6s   mediumvioletreds   #c71585s   fuchsias   #ff00ffs	   olivedrabs   #6b8e23s   siennas   #a0522ds
   lightcorals   #f08080s	   orangereds   #ff4500s   navajowhites   #ffdeads	   slategrays   #708090s	   palegreens   #98fb98s	   lightcyans   #e0ffffs   seashells   #fff5ees   mediumspringgreens   #00fa9as	   royalblues   #4169e1s
   chartreuses   #7fff00s   blanchedalmonds   #ffebcds   perus   #cd853fs
   aquamarines   #7fffd4s   whites   #ffffffs   darkslategrays   #2f4f4fs   tomatos   #ff6347s   ivorys   #fffff0s   darkgoldenrods   #b8860bs	   lawngreens   #7cfc00s
   lightgreens   #90ee90s   crimsons   #dc143cs   forestgreens   #228b22s	   slateblues   #6a5acds   olives   #808000s	   mintcreams   #f5fffas   antiquewhites   #faebd7s
   darkoranges   #ff8c00s	   cadetblues   #5f9ea0s   moccasins   #ffe4b5s	   limegreens   #32cd32s   saddlebrowns   #8b4513s   greys   #808080s   darkslateblues   #483d8bs   lightskyblues   #87cefas   deeppinks   #ff1493s   corals   #ff7f50s   aquas   #00ffffs
   dodgerblues   #1e90ffs   maroons   #800000s
   sandybrowns   #f4a460s   tans   #d2b48cs   magentas   #ff00ffs	   rosybrowns   #bc8f8fs
   whitesmokes   #f5f5f5s	   lightblues   #add8e6s   palevioletreds   #db7093s   mediumseagreens   #3cb371s   dimgrays   #696969s
   powderblues   #b0e0e6s   seagreens   #2e8b57s   snows   #fffafas
   mediumblues   #0000cds   midnightblues   #191970s   paleturquoises   #afeeees   palegoldenrods   #eee8aas   pinks   #ffc0cbs
   darkorchids   #9932ccs   salmons   #fa8072s   lightslategrays   #778899s   lemonchiffons   #fffacds	   chocolates   #d2691es	   lightgrays   #d3d3d3s   hotpinks   #ff69b4s   lightyellows   #ffffe0s   lavenderblushs   #fff0f5s   linens   #faf0e6s   mediumaquamarines   #66cdaas   greens   #008000s
   blueviolets   #8a2be2s	   peachpuffs   #ffdab9s   darkgreys   #a9a9a90rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$
    Same as :py:func:`~PIL.ImageColor.getrgb`, but converts the RGB value to a
    greyscale value if the mode is not color or a palette image. If the string
    cannot be parsed, this function raises a :py:exc:`ValueError` exception.

    .. versionadded:: 1.1.4

    :param color: A color string
    :return: ``(graylevel [, alpha]) or (red, green, blue[, alpha])``
    #\w\w\w\w\w\w$/usr/lib/python2.7/dist-packages/PIL/ImageColor.pyrgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)$rgb\(\s*(\d+)%\s*,\s*(\d+)%\s*,\s*(\d+)%\s*\)$hsl\(\s*(\d+)\s*,\s*(\d+)%\s*,\s*(\d+)%\s*\)$#\w\w\w$
     Convert a color string to an RGB tuple. If the string cannot be parsed,
     this function raises a :py:exc:`ValueError` exception.

    .. versionadded:: 1.1.4

    :param color: A color string
    :return: ``(red, green, blue[, alpha])``
    cleanupfinishedreadimagehandles_eofincrementalStubImageFileencode_to_filegetcodecstatusdecodermaxblocktile_post_rotateUnsupportedOperationbad configurationimage buffer overrun errorunknown errordecoding errorout of memory error
        (Consumer) Close the stream.

        :returns: An image object.
        :exception IOError: If the parser failed to parse the image file either
                            because it cannot be identified or cannot be
                            decoded.
        
        (Consumer) Feed data to the parser.

        :param data: A string buffer.
        :exception IOError: If the parser failed to parse the image file.
        
        (Consumer) Reset the parser.  Note that you can only call this
        method immediately after you've created a parser; parser
        instances cannot be reused.
        PIL.ImageFilecannot parse this imagecannot reuse parsersStubImageFile subclass must implement _loadnot identified by this driverHelper to save image based on tile list

    :param im: Image object.
    :param fp: File object.
    :param tile: Tile list.
    :param bufsize: Optional buffer size
    
    Base class for stub image loaders.

    A stub loader is an image loader that can identify files of a
    certain format, but relies on external code to load the file.
    /usr/lib/python2.7/dist-packages/PIL/ImageFile.pyimage was incomplete(Hook) Find actual image loader.Load image data based on tile listCheck file integrity when reading image fileBase class for image file format handlers.StubImageFile subclass must implement _openimage file is truncated (%d bytes not processed)decoder error %d
    Reads large blocks in a safe way.  Unlike fp.read(n), this function
    doesn't trust the user.  If the requested size is larger than
    SAFEBLOCK, the file is read block by block.

    :param fp: File handle.  Must implement a <b>read</b> method.
    :param size: Number of bytes to read.
    :returns: A string containing up to <i>size</i> bytes of data.
    
    Incremental image parser.  This class implements the standard
    feed/close consumer interface.

    In Python 2.x, this is an old-style class.
    cannot find loader for this %s fileSet draft modeBlurEmbossMedianSmoothContourSharpenMaxFilterMinFilterModeFilterfilterargsmodefilterrankfilterUnsharpMaskGaussianBlurMedianFilterunsharp_maskgaussian_blurUnsharp mask filter.

    See Wikipedia's entry on `digital unsharp masking`_ for an explanation of
    the parameters.

    .. _digital unsharp masking:
    https://en.wikipedia.org/wiki/Unsharp_masking#Digital_unsharp_masking
    Edge-enhance More/usr/lib/python2.7/dist-packages/PIL/ImageFilter.py
    Create a min filter.  Picks the lowest pixel value in a window with the
    given size.

    :param size: The kernel size, in pixels.
    Gaussian blur filter.

    :param radius: Blur radius.
    

    Create a mode filter. Picks the most frequent pixel value in a box with the
    given size.  Pixel values that occur only once or twice are ignored; if no
    pixel value occurs more than twice, the original pixel value is preserved.

    :param size: The kernel size, in pixels.
    
    Create a median filter. Picks the median pixel value in a window with the
    given size.

    :param size: The kernel size, in pixels.
    Smooth Morecannot filter palette imagesFind Edgesnot enough coefficients in kernel
    Create a convolution kernel.  The current version only
    supports 3x3 and 5x5 integer and floating point kernels.

    In the current version, kernels can only be applied to
    "L" and "RGB" images.

    :param size: Kernel size, given as (width, height). In the current
                    version, this must be (3,3) or (5,5).
    :param kernel: A sequence containing kernel weights.
    :param scale: Scale factor. If given, the result for each pixel is
                    divided by this value.  the default is the sum of the
                    kernel weights.
    :param offset: Offset. If given, this value is added to the result,
                    after it has been divided by the scale factor.
    
    Create a max filter.  Picks the largest pixel value in a window with the
    given size.

    :param size: The kernel size, in pixels.
    
    Create a rank filter.  The rank filter sorts all pixels in
    a window of the given size, and returns the **rank**'th value.

    :param size: The kernel size, in pixels.
    :param rank: What pixel value to pick.  Use 0 for a min filter,
                 ``size * size / 2`` for a median filter, ``size * size - 1``
                 for a max filter, etc.
    (   (   i   i   i   i    (   i   i   i   i   i   i   i    i    i    i   i   i    i    i    i   i   i    i    i    i   i   i   i   i   i   (   (   i   i   id   i    (   i   i   i   i   i   i   i   i   i   i   i   i   i,   i   i   i   i   i   i   i   i   i   i   i   i   PIL.ImageMode/usr/lib/python2.7/dist-packages/PIL/ImageMode.py     o@sepia_make_gamma_lut_make_linear_lut_make_gamma_lut() is deprecated. Please call make_gamma_lut() instead.Given an rgb tuple, allocate palette entry.

        .. warning:: This method is experimental.
        wrong palette sizeConvert palette to bytes.

        .. warning:: This method is experimental.
        cannot load paletteSave palette to text file.

        .. warning:: This method is experimental.
        _make_linear_lut() is deprecated. Please call make_linear_lut() instead.# Palette
Color palette for palette mapped imagespalette contains raw palette data/usr/lib/python2.7/dist-packages/PIL/ImagePalette.py# Mode: %s
cannot allocate more than 256 colors;L#fff0c0
        Get palette contents in format suitable # for the low-level
        ``im.putpalette`` primitive.

        .. warning:: This method is experimental.
        PIL.ImagePalettepipesshow_fileget_formatsave_imageshow_imageget_commandget_command_ex -name %s/usr/lib/python2.7/dist-packages/PIL/ImageShow.py(%s %s; sleep 20; rm -f %s)&PIL.ImageShowstart "Pillow" /WAIT "%s" && ping -n 2 127.0.0.1 >NUL && del /f "%s"open -a /Applications/Preview.app(%s %s; rm -f %s)&DACDHPDHTDNLDRIEOIEXPJPGSOISOSAPP0APP1APP2APP3APP4APP5APP6APP7APP8APP9JFIFJPG0JPG1JPG2JPG3JPG4JPG5JPG6JPG7JPG8JPG9RST0RST1RST2RST3RST4RST5RST6RST7SOF0SOF1SOF2SOF3SOF5SOF6SOF7SOF9APP10APP11APP12APP13APP14APP15AdobeJPG10JPG11JPG12JPG13SOF10SOF11SOF13SOF14SOF15cjpegdjpegMPTypelabelslayersCommentapplisticclistmpentryEntryNo1EntryNo2entrynumflashpixmpheaderopen_ppmUndefinedmptypemaphuffman_achuffman_dcload_djpegrawmpentrystreamtype_save_cjpegmpentryattrprogressionprogressivejfif_versionquantizationunpackedentryImageDataFormatvalidate_qtablesMAX_BYTES_IN_MARKERDependentChildImageFlagRepresentativeImageFlagDependentParentImageFlagMAX_DATA_BYTES_IN_MARKERCMYK;I{(   i   i   i   i   i   i   i   (   i   i   i   i   i   i   i   (   i   i   i   i   i   i   i    0Baseline MP Primary ImageMulti-Frame Image (Panorama)Multi-Frame Image: (Disparity)Multi-Frame Image: (Multi-Angle)Large Thumbnail (VGA Equivalent)Large Thumbnail (Full HD Equivalent)cannot handle %d-bit layersDifferential progressive DCTExtension 6FPXR -outfileno marker foundExtension 1{0}LLLHH>HExtended sequential DCT (AC)cannot handle %d-layer images.jpgApplication segment 15APP%dcannot write mode %s as JPEGunsupported picture format in MPOStart of imageDefine number of linesExif Extension 3/usr/lib/python2.7/dist-packages/PIL/JpegImagePlugin.pyMPF Application segment 4Application segment 13ICC_PROFILE Restart 7.jpegCannot use 'keep' when original image is not a JPEGDifferential sequential DCT (AC)Differential progressive DCT (AC)Application segment 5not a JPEG fileRestart 2Define Huffman tableExtension 7Extension 9Restart 1Extension 10Application segment 2image/jpeg4:4:4Extension 0Progressive DCTExtension 12Extension 2Restart 3JPEG (ISO 10918)Define restart intervalApplication segment 6Spatial losslessInvalid quality settingNone or too many quantization tablesApplication segment 3Application segment 8PIL.JpegImagePluginmalformed MP Index (no number of images)Application segment 9Baseline DCTDefine quantization tableExtension 11Define arithmetic coding conditioningExpand reference componentDifferential spatial (AC)Application segment 12Restart 0Application segment 10Restart 6malformed MP Index (bad MP Entry)Application segment 14Extension 13Application segment 74:2:2Application segment 11Extension 4Start of scanSpatial lossless DCT (AC)Progressive DCT (AC)4:1:1Extension 80.6Extension 5Restart 5bad quantization table marker.jfifApplication segment 0Extended Sequential DCTEnd of imageInvalid FilenameInvalid quantization tableDefine hierarchical progressionRestart 4(@   i    i   i   i   i   i   i   i   i   i   i   i   i   i   i   i*   i   i   i   i   i   i   i)   i+   i	   i   i   i   i   i(   i,   i5   i
   i   i   i    i'   i-   i4   i6   i   i   i!   i&   i.   i3   i7   i<   i   i"   i%   i/   i2   i8   i;   i=   i#   i$   i0   i1   i9   i:   i>   i?   (   t   imt   fpt   filenamet   rawmodet   infot   dpit   qualityt   subsamplingt   qtablest   presett   validate_qtablest   extrat   icc_profilet   ICC_OVERHEAD_LENt   MAX_BYTES_IN_MARKERt   MAX_DATA_BYTES_IN_MARKERt   markerst   it   markert   sizet   bufsize{s   web_maximum{s   subsamplingi    s   quantization[   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s   medium{s   subsamplingi   s   quantization[   [@   i   i   i   i   i   i   i   i   i   i	   i	   i   i   i   i   i   i   i	   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s
   web_medium{s   subsamplingi   s   quantization[   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i#   i/   i   i   i   i   i   i%   i/   i@   i   i   i   i   i'   i3   i@   i@   i   i   i   i%   i3   i@   i@   i@   i   i   i#   i/   i@   i@   i@   i@   i   i   i/   i@   i@   i@   i@   i@   [@   i   i   i   i   i   i   i&   i0   i   i   i   i   i   i   i#   i+   i   i   i   i   i   i   i.   i5   i   i   i   i   i   i'   i5   i@   i   i   i   i   i'   i0   i@   i@   i   i   i   i'   i0   i?   i@   i@   i&   i#   i.   i5   i@   i@   i@   i@   i0   i+   i5   i@   i@   i@   i@   i@   0s   maximum{s   subsamplingi    s   quantization[   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i	   i   i   i   i   i   i   i	   i   i   i   i   i   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i	   i   i   i   i   i   i   i	   i   i   i   i   i   [@   i   i   i   i	   i   i   i   i   i   i   i   i
   i   i   i   i   i   i   i	   i   i   i   i   i   i	   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s   high{s   subsamplingi    s   quantization[   [@   i   i   i   i   i	   i   i   i   i   i   i   i   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i   i   i   i   i   i	   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s   low{s   subsamplingi   s   quantization[   [@   i   i   i   i   i   i#   i"   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i#   i   i   i   i   i   i   i   i"   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s   web_very_high{s   subsamplingi    s   quantization[   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i	   i   i   i   i   i   i   i	   i   i   i   i   i   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i	   i   i   i   i   i   i   i	   i   i   i   i   i   [@   i   i   i   i	   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i	   i   i   i   i   i   i	   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   0s   web_low{s   subsamplingi   s   quantization[   [@   i   i   i   i'   i2   i.   i>   iD   i   i   i   i&   i&   i5   iA   iD   i   i   i   i&   i5   iA   iD   iD   i'   i&   i&   i5   iA   iD   iD   iD   i2   i&   i5   iA   iD   iD   iD   iD   i.   i5   iA   iD   iD   iD   iD   iD   i>   iA   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   [@   i   i   i    i&   i6   iD   iD   iD   i   i   i   i&   i6   iD   iD   iD   i    i   i    i+   iB   iD   iD   iD   i&   i&   i+   i5   iD   iD   iD   iD   i6   i6   iB   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   iD   0s   web_high{s   subsamplingi    s   quantization[   [@   i   i   i   i   i	   i   i   i   i   i   i   i   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i   i   i   i   i   i	   i   i
   i   i   i   i   i   i   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   [@   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   00/usr/lib/python2.7/dist-packages/PIL/JpegPresets.py
JPEG quality settings equivalent to the Photoshop settings.

More presets can be added to the presets dict if needed.

Can be use when saving JPEG file.

To apply the preset, specify::

  quality="preset_name"

To apply only the quantization table::

  qtables="preset_name"

To apply only the subsampling setting::

  subsampling="preset_name"

Example::

  im.save("image_name.jpg", quality="web_high")


Subsampling
-----------

Subsampling is the practice of encoding images by implementing less resolution
for chroma information than for luma information.
(ref.: http://en.wikipedia.org/wiki/Chroma_subsampling)

Possible subsampling values are 0, 1 and 2 that correspond to 4:4:4, 4:2:2 and
4:1:1 (or 4:2:0?).

You can get the subsampling of a JPEG with the
`JpegImagePlugin.get_subsampling(im)` function.


Quantization tables
-------------------

They are values use by the DCT (Discrete cosine transform) to remove
*unnecessary* information from the image (the lossy part of the compression).
(ref.: http://en.wikipedia.org/wiki/Quantization_matrix#Quantization_matrices,
http://en.wikipedia.org/wiki/JPEG#Quantization)

You can get the quantization tables of a JPEG with::

  im.quantization

This will return a dict with a number of arrays. You can pass this dict
directly as the qtables argument when saving a JPEG.

The tables format between im.quantization and quantization in presets differ in
3 ways:

1. The base container of the preset is a list with sublists instead of dict.
   dict[0] -> list[0], dict[1] -> list[1], ...
2. Each table in a preset is a list instead of an array.
3. The zigzag order is remove in the preset (needed by libjpeg >= 6a).

You can convert the dict format to the preset format with the
`JpegImagePlugin.convert_dict_qtables(dict_qtables)` function.

Libjpeg ref.: http://www.jpegcameras.com/libjpeg/libjpeg-3.html

mpinfo_MpoImageFile__fp_MpoImageFile__frame_MpoImageFile__mpoffsets_MpoImageFile__framecountPIL.MpoImagePlugin.mpoimage/mpono more images in MPO file/usr/lib/python2.7/dist-packages/PIL/MpoImagePlugin.pyMPO (CIPA DC-007)PIL.PaletteFile/usr/lib/python2.7/dist-packages/PIL/PaletteFile.py
F%u?PNGcrcpng     j@DDATIDATIHDRPLTEcrc1crc2iCCPpHYspushtEXttRNSzTXtcrc32STREAMchunksPngInfoim_idatim_infoim_modeim_sizeim_textim_tilepnginfoadd_itxtadd_textcrc_skipgetchunkschunk_IDATchunk_IENDchunk_IHDRchunk_PLTEchunk_gAMAchunk_iCCPchunk_iTXtchunk_pHYschunk_tEXtchunk_tRNSchunk_zTXtim_paletteim_rawmodealpha_bytescomp_methodcompress_typecompress_levelgetpalettemode_PngImageFile__idatpalette_byte_number{t   1(   R    s    s   RGBA(   s   RGBAs   s   LA(   s   LAs   t   I(   s   I;16Bs    s   L;4(   s   L;4s    s   L;2(   s   L;2s    t   L(   R   s    s   L;1(   s   L;1s    s   P;2(   s   P;2s   t   P(   R   s   s   RGB(   s   RGBs   s   P;1(   s   P;1s   s   P;4(   s   P;4s   0{(   i   i   (   s   RGBAs   RGBA;16B(   i   i   (   t   PR    (   i   i   (   R    s   P;1(   i   i   (   s   RGBs   RGB(   i   i   (   s   RGBAs   LA;16B(   i   i    (   t   LR   (   i   i   (   s   RGBs   RGB;16B(   i   i    (   R   s   L;2(   i   i    (   t   Is   I;16B(   i   i   (   R    s   P;2(   i   i   (   R    s   P;4(   i   i   (   s   RGBAs   RGBA(   i   i    (   t   1R   (   i   i    (   R   s   L;4(   i   i   (   s   LAs   LA0(unknown)iCCP profile nameinternal: finished reading image dataVerify PNG filenot a PNG fileverify must be called directly after openReturn a list of PNG chunks representing this image.Unknown compression method %s in iCCP chunkUnknown compression method %s in zTXt chunkCompression methodcannot use transparency for this mode%s;%dFetch a new chunk. Returns header information.^+ *$ICC ProfileCall the appropriate chunk handlerbroken PNG file (chunk %s)internal: read more image dataPIL.PngImagePluginPortable network graphicsWrite a PNG chunk (including CRC field)image/pnginternal: prepare to read PNG fileRead checksum.  Used if the C module is not present/usr/lib/python2.7/dist-packages/PIL/PngImagePlugin.pybroken PNG file(bad header checksum in %s)cannot write mode %s as PNGRead and verify checksumPNG

unknown filter category(   t   imt   fpt   filenamet   chunkt   checkt   modet   colorst   bitst
   dictionaryt   rawmodet   palette_byte_numbert   palette_bytest   transparencyt   alpha_bytest   alphat   redt   greent   bluet   dpit   infot   cidt   datat   name0456yP0CMYKPyCMYKPyRGBA_tokengetlocalelocale_lang
%d %d
cannot write mode %s as PPMnot a PPM fileToo many colors for band: %sPIL.PpmImagePlugin0.22147483648
65535
.pgm/usr/lib/python2.7/dist-packages/PIL/PpmImagePlugin.pyExpected int, got > 9 digitsPbmplus image255
Expected ASCII value, found binary.pbm.ppmimage8image32check_xyget_pixelset_pixel_post_initaccess_typeunsafe_ptrs 32 bit float access 
struct Pixel_RGBA {
    unsigned char r,g,b,a;
};
struct Pixel_I16 {
    unsigned char l,r;
};
PyAccess Not Implemented: %spixel location out of rangeint **float ** PA, LA, stored in first and last bytes of a 32 bit word /usr/lib/python2.7/dist-packages/PIL/PyAccess.py RGBA etc, all 4 bytes of a 32 bit word unsigned short ** RGB and friends, stored in the first three bytes of a 32 bit word 
        Returns the pixel at x,y. The pixel is returned as a single
        value for single band images or a tuple for multiple band
        images

        :param xy: The pixel coordinate, given as (x, y).
         Signed Int32 access, native endian struct Pixel_RGBA **New PyAccess: %sunsigned char * 1, L, P, 8 bit images stored as uint8  I;16B access, with conversion struct Pixel_I16 ** I;16 access, native bitendian without conversion Attempt to putpixel a read only imagePIL.PyAccess I;32L/B access, with byteswapping conversion unsigned char **
        Modifies the pixel at x,y. The color is given as a single
        numerical value for single band images, and a tuple for
        multi-band images

        :param xy: The pixel coordinate, given as (x, y).
        :param value: The pixel value.
         I;16L access, with conversion RQ@fpfp_seek_tellartistgroup3group4EXIFIFDas_dicthas_keyresunittagdatatagnametagtypetypnameSequencesoftwaretag_nametiff_lzwtiffinfocopyrightignored_2load_byteload_longtiff_jpegcentimeterload_floatload_shorttiff_ccittload_doubleload_stringtiff_raw_16tiff_sgilog_compressiontiff_deflate_load_libtifffrom_iterableload_dispatchload_rationaltiff_sgilog24MutableMappingload_undefinedIMAGEJ_META_DATA_debug_multipagetiff_thunderscan_TiffImageFile__fptiff_adobe_deflate_TiffImageFile__next_TiffImageFile__first_TiffImageFile__frame_planar_configuration{i   s   rawi   s
   tiff_ccitti  s   tiff_raw_16i   s   group4i  s   packbitsi   s	   tiff_jpegi   s   jpegi   s   tiff_adobe_deflatei)  s   tiff_thunderscani  s   tiff_deflatei   s   group3it  s   tiff_sgilogiu  s   tiff_sgilog24i   s   tiff_lzw0IMAGEJ_META_DATA_BYTE_COUNTSII* II - fill_order:- planar_configuration:P;RP;1RSetup decoder contextsnot a TIFF fileSelect a given frame as current imagecannot write mode %s as TIFF/usr/lib/python2.7/dist-packages/PIL/TiffImagePlugin.pyOpen the first image in a TIFF fileimage/tiffI;12Data Location: %sformat key:not a TIFF IFD- photometric_interpretation:Return the current frame numberP;2RPIL.TiffImagePluginI;32NL;IRnot a scalary resolutiontiles: Windows Media Photo files not yet supportedI;16NNot exactly one tileSaving using libtiff encoder- raw mode:.tiff- __first: This class represents a TIFF tag directory.  To speed things
        up, we don't decode tags unless they're asked for.

        Exposes a dictionary interface of the tags in the directory
        ImageFileDirectory[key] = value
        value = ImageFileDirectory[key]

        Also contains a dictionary of tag types as read from the tiff
        image file, 'ImageFileDirectory.tagtype'


        Data Structures:
        'public'
        * self.tagtype = {} Key: numerical tiff tag number
                            Value: integer corresponding to the data type from
                            `TiffTags.TYPES`

        'internal'
        * self.tags = {}  Key: numerical tiff tag number
                          Value: Decoded data, Generally a tuple.
                            * If set from __setval__ -- always a tuple
                            * Numeric types -- always a tuple
                            * String type -- not a tuple, returned as string
                            * Undefined data -- not a tuple, returned as bytes
                            * Byte -- not a tuple, returned as byte.
        * self.tagdata = {} Key: numerical tiff tag number
                            Value: undecoded byte string from file


        Tags will be found in either self.tags or self.tagdata, but
        not both. The union of the two should contain all the tags
        from the Tiff image file.  External classes shouldn't
        reference these unless they're really sure what they're doing.
        - size:Tiffinfo Keys: %s
        :prefix: 'II'|'MM'  tiff endianness
        L;R- unsupported data organizationhave getvalue. just sending in a string from getvalue*** Summary ***- type: %s (%d)have fileno, calling fileno version of the decoder.P;4Rno more images in TIFF fileunknown data organization Overload method triggered when we detect a compressed tiff
            Calls out to libtiff don't have fileno or getvalue. just readingx resolutionLoading tags, location: %sRGB;Runknown pixel modePossibly corrupt EXIF data.  Expecting to read %d bytes but only got %d. Skipping tag %ssave: %s (%d)date time- ifh: 
        Returns the complete tag dictionary, with named tags where posible.
        - value:tag: %s (%d)Setup this image object based on current tagsCouldn't set the imagemultistrip support not yet implemented*** TiffImageFile._open ***- compression:- unsupported formatAdobe TIFFTag Location: %s1;IRSeeking to frame %s, on frame %s, __next %s, location: %sresolution unitRGB;L- value: <table: %d bytes>Return a dictionary of the image's tags.Tag %s, Type: %s, Value: %s1.3.5- pil mode:- unsupported type(   t   selft	   getscalart   photot	   fillordert   xsizet   ysizet   formatt   keyt   rawmodet   xrest   yrest   resunitt   xt   yt   lt   offsetst   ht   wt   fpt   at   it   ot   palette(   t   imt   fpt   filenamet   rawmodet   prefixt   photot   formatt   bitst   extrat   ifdt   compressiont   libtifft   infot   keyst   keyt   unitt   dpit   lutt   stridet   _fpt	   blocklistt   attst   kt   vt   eltt   at   et   lt   st   dt   offset{i   s   bytei   s   asciii   s   shorti   s   longi   s   rationali   s   signed bytei   s	   undefinedi   s   signed shorti	   s   signed longi
   s   signed rationali   s   floati   s   double0{i   s
   MPFVersioni  s   PanOrientationi  s   PanOverlap_Hi  s   PanOverlap_Vi  s   BaseViewpointNumi  s   FocalLengthIn35mmFilmi  s   BaselineLengthi  s   VerticalDivergencei  s   AxisDistance_Xi	  s   AxisDistance_Yi
  s   AxisDistance_Zi  s   YawAnglei  s
   PitchAnglei  s	   RollAnglei  s   FocalPlaneXResolutioni  s   FocalPlaneYResolutioni  s   FocalPlaneResolutionUniti  s   YCbCrCoefficientsi  s
   DNGVersioni  s   DNGBackwardVersioni  s   UniqueCameraModeli  s   LocalizedCameraModeli  s   CFAPlaneColori  s	   CFALayouti  s   LinearizationTablei  s   BlackLevelRepeatDimi  s
   BlackLeveli  s   BlackLevelDeltaHi  s   BlackLevelDeltaVi  s
   WhiteLeveli  s   DefaultScalei  s   DefaultCropOrigini   s   DefaultCropSizei!  s   ColorMatrix1i"  s   ColorMatrix2i#  s   CameraCalibration1i$  s   CameraCalibration2i%  s   ReductionMatrix1i&  s   ReductionMatrix2i'  s   AnalogBalancei(  s   AsShotNeutrali)  s   AsShotWhiteXYi*  s   BaselineExposurei+  s   BaselineNoisei,  s   BaselineSharpnessi-  s   BayerGreenSpliti.  s   LinearResponseLimiti/  s   CameraSerialNumberi0  s   LensInfoi1  s   ChromaBlurRadiusi2  s   AntiAliasStrengthi3  s   LensMakei4  s   DNGPrivateDatai5  s   MakerNoteSafetyi	  s
   Saturationi1  s   StandardOutputSensitivityi
  s	   Sharpnessi  s   DeviceSettingDescriptioni$  s	   T4Optionsi  s   SubjectDistanceRangei  s   BitsPerSamplei  s   JPEGInterchangeFormatLengthi  s   ImageDescriptioni	  s   FlashiZ  s   CalibrationIlluminant1i[  s   CalibrationIlluminant2i\  s   BestQualityScale(   i  i   s   CMYKi4  s   ISOSpeedLatitudeyyyi  s   FlashEnergy(   i  i#  s   CFA(   i  i   s   CieLABi  s   YCbCrSubSamplingi  s   ReferenceBlackWhitei   s   JPEGProci  s   JPEGRestartIntervali  s   YCbCrPositioningi  s   SubjectLocationi|  s	   MakerNotei5  s   ISOSpeedLatitudezzzi  s   SpatialFrequencyResponsei  s   ExposureIndexi  s   UserComment(   i  i   s   YCbCri  s   SensingMethodi2  s   RecommendedExposureIndexi  s   SubSeci  s   SubSecTimeOriginali  s   SubsecTimeDigitizedi  s   ImageJMetaDataByteCountsi  s   ImageJMetaDatai  s   Contrasti  s   ExposureTimei  s   FNumber(   i  i   s   Group 3 Faxi  s   ComponentsConfiguration(   i  i   s   RGB Palettei  s   ShutterSpeedValuei  s	   XPositioni  s	   YPositioni  s   XMPi  s   StripByteCountsi   s   ImageUniqueIDi  s   PhotometricInterpretationi   s   ExifVersioni!  s   FreeByteCountsi  s   CompressedBitsPerPixeli	  s
   CellHeighti"  s   ExposureProgrami  s   ApertureValuei$  s   SpectralSensitivityi  s   ImageLengthi%  s
   GPSInfoIFDi  s   DateTimeOriginali  s   JPEGQTables(   i  i   s   Group 4 Faxi'  s   ISOSpeedRatingsi  s   SubjectAreai
  s   FocalLengthi  s   BrightnessValuei(  s   OECF(   i  i|  s	   LinearRawi  s   DateTImeDigitizedi   s   SubfileTypei   s   Gammai  s   MPIndividualNumi  s
   CFAPatterni  s   Compressioni  s   JPEGInterchangeFormati   s   FlashPixVersioni  s   Thresholdingi  s	   CellWidthi  s   ConvergenceAnglei
  s	   FillOrderi  s   DocumentNamei  s   ExposureBiasValuei-  s   TransferFunctioni  s   Modeli  s   StripOffsetsi  s   Orientationi  s   SamplesPerPixeli  s   RowsPerStripi<  s   HostComputeri  s   MinSampleValuei  s   MaxSampleValuei  s   XResolutioni  s   YResolutioni  s   PlanarConfigurationi  s   PageNamei   s
   FileSourcei  s   JPEGDCTablesi   s   FreeOffsetsi0  s   CameraOwnerNamei"  s   GrayResponseUniti#  s   GrayResponseCurvei  s
   ColorSpacei%  s	   T6Optionsi1  s   BodySerialNumberi(  s   ResolutionUniti)  s
   PageNumberi  s   MaxApertureValuei2  s   LensSpecificationi1  s   Softwarei2  s   DateTimei3  s   ISOSpeedi4  s	   LensModeli;  s   Artisti  s	   SceneTypei=  s	   Predictori>  s
   WhitePointi5  s   LensSerialNumberi@  s   ColorMapiA  s   HalftoneHintsi  s   PixelXDimensioniC  s
   TileLengthi  s   CustomRenderediE  s   TileByteCountsi  s   SubjectDistanceiL  s   InkSetiM  s   InkNamesiN  s   NumberOfInksiP  s   DotRangeiQ  s   TargetPrinteriR  s   ExtraSamplesiS  s   SampleFormatiT  s   SMinSampleValueiU  s   SMaxSampleValueiV  s   TransferRangei[  s
   JPEGTablesi  s   JPEGLosslessPredictorsi  s   PixelYDimensioni  s   ExposureModei   s
   ImageWidthi  s   MeteringModeii  s   ExifIFD(   i  i   s   Uncompressedis  s
   ICCProfilei?  s   PrimaryChromaticies(   i  i   s   CCITT 1di  s   RelatedSoundFilei  s   WhiteBalancei  s   LightSourceiB  s	   TileWidthi  s	   Copyright(   i  i   s   RGB(   i  i   s	   ContigousiD  s   TileOffsetsi  s   InteroperabilityIFDi  s   DigitalZoomRatioi  s   NumberOfImages(   i  i   s   Separatei	  s   JPEGACTables(   i  i   s   JPEGiI  s   PhotoshopInfoi  s   IptcNaaInfo(   i  i   s   Transparency Maski  s   MPEntry(   i  i    s   WhiteIsZeroi  s   Make(   i  i   s   LZWi  s   SceneCaptureType(   i  i  s   PackBitsi  s   ImageUIDListi0  s   SensitivityType(   i  i   s   BlackIsZeroi  s   JPEGPointTransformsi   s   NewSubfileTypei  s   GainControli  s   TotalFrames0PIL.TiffTags/usr/lib/python2.7/dist-packages/PIL/TiffTags.py
    Converts a 2-bytes (16 bits) string to an integer.

    c: string containing bytes to convert
    o: offset of bytes to convert in string
    /usr/lib/python2.7/dist-packages/PIL/_binary.py
    Converts a 4-bytes (32 bits) string to an integer.

    c: string containing bytes to convert
    o: offset of bytes to convert in string
    isDirectory/usr/lib/python2.7/dist-packages/PIL/_util.pyrdbXcursorfont__version_string__/usr/lib/python2.7/dist-packages/Xlib/__init__.pyCWXCWYDoRedKBKeyKBLedAnyKeyDoBlueGCFontGCTileButton1Button2Button3Button4Button5CWWidthDoGreenSuccessCWCursorCWHeightLSBFirstLockMaskMSBFirstMod1MaskMod2MaskMod3MaskMod4MaskMod5MaskAnyButtonCWSiblingGCArcModeGCLastBitGCStippleGrayScaleKBLedModeLASTEventShiftMaskTrueColorCWColormapFontChangeGCCapStyleGCClipMaskGCDashListGCFillRuleGCFunctionGrabFrozenIsUnmappedIsViewableNotifyGrabNotifyHintPlaceOnTopStaticGrayAnyModifierButton1MaskButton2MaskButton3MaskButton4MaskButton5MaskCWBackPixelCWEventMaskCWSaveUnderCWStackModeControlMaskDirectColorGCFillStyleGCJoinStyleGCLineStyleGCLineWidthGCPlaneMaskGrabSuccessKBBellPitchMappingBusyNoEventMaskPseudoColorStaticColorAllTemporaryCWBackPixmapCWBitGravityCWWinGravityExposureMaskGCBackgroundGCDashOffsetGCForegroundIsUnviewableNotifyNormalNotifyUngrabUnmapGravityCWBorderPixelCWBorderWidthGCClipXOriginGCClipYOriginKBBellPercentMappingFailedNotifyPointerNotifyVirtualPlaceOnBottomPointerWindowAlreadyGrabbedCWBackingPixelCWBackingStoreCWBorderPixmapKBBellDurationMappingPointerMappingSuccessNotifyAncestorNotifyInferiorParentRelativePropertyDeleteAnyPropertyTypeButtonPressMaskCWBackingPlanesCWDontPropagateEnterWindowMaskFocusChangeMaskFontLeftToRightFontRightToLeftGCSubwindowModeGrabInvalidTimeGrabNotViewableKeymapStateMaskLeaveWindowMaskMappingModifierNotifyNonlinearButtonMotionMaskKBAutoRepeatModeNotifyDetailNonePropertyNewValueButton1MotionMaskButton2MotionMaskButton3MotionMaskButton4MotionMaskButton5MotionMaskButtonReleaseMaskColormapInstalledGCTileStipXOriginGCTileStipYOriginKBKeyClickPercentNotifyPointerRootPointerMotionMaskCWOverrideRedirectColormapChangeMaskDisableScreenSaverLastExtensionErrorNotifyWhileGrabbedPropertyChangeMaskResizeRedirectMaskColormapUninstalledFirstExtensionErrorGCGraphicsExposuresOwnerGrabButtonMaskStructureNotifyMaskVisibilityChangeMaskVisibilityUnobscuredDisableScreenIntervalPointerMotionHintMaskNotifyNonlinearVirtualSubstructureNotifyMaskVisibilityFullyObscuredSubstructureRedirectMaskVisibilityPartiallyObscured/usr/lib/python2.7/dist-packages/Xlib/X.pymiscellany_load_keysyms_into_XKXlib.keysymdef.%sReturn the (16 bit) numeric code of keysym.

    Given the name of a keysym as a string, return its numeric code.
    Don't include the 'XK_' prefix, just use the base, i.e. 'Delete'
    instead of 'XK_Delete'.Translate a keysym (16 bit number) into a python string.

    This will pass 0 to 0xff as well as XK_BackSpace, XK_Tab, XK_Clear,
    XK_Return, XK_Pause, XK_Scroll_Lock, XK_Escape, XK_Delete. For other
    values it returns None.Load all the keysyms in group.

    Given a group name such as 'latin1' or 'katakana' load the keysyms
    defined in module 'Xlib.keysymdef.group-name' into this XK module.keysym definition modules need no longer call Xlib.XK._load_keysyms_into_XK().
    You should remove any calls to that function from your keysym modules./usr/lib/python2.7/dist-packages/Xlib/XK.pyinvalid keysym group name: %sARCFONTBITMAPCURSORNOTICEPIXMAPWEIGHTINTEGERPRIMARYCARDINALDRAWABLEVISUALIDX_HEIGHTEND_SPACEFONT_NAMEFULL_NAMEMAX_SPACEMIN_SPACERECTANGLESECONDARYCAP_HEIGHTNORM_SPACEPOINT_SIZEQUAD_WIDTHWM_COMMANDCUT_BUFFER0CUT_BUFFER1CUT_BUFFER2CUT_BUFFER3CUT_BUFFER4CUT_BUFFER5CUT_BUFFER6CUT_BUFFER7FAMILY_NAMERGB_RED_MAPSUBSCRIPT_XSUBSCRIPT_YITALIC_ANGLERGB_BEST_MAPRGB_BLUE_MAPRGB_GRAY_MAPRGB_COLOR_MAPRGB_GREEN_MAPSUPERSCRIPT_XSUPERSCRIPT_YWM_ZOOM_HINTSLAST_PREDEFINEDRGB_DEFAULT_MAPRESOURCE_MANAGERSTRIKEOUT_ASCENTSTRIKEOUT_DESCENTUNDERLINE_POSITIONUNDERLINE_THICKNESS/usr/lib/python2.7/dist-packages/Xlib/Xatom.pyXlib.XatomUSSizeXValueYValueNoValueXCNOENTXCNOMEMAllHintsAllValuesPAllHintsPBaseSizeXCSUCCESSXNegativeYNegativeZoomStateUSPositionWidthValueHeightValuePWinGravityRectangleInRectangleOutVisualIDMaskVisualNoMaskBitmapSuccessDontCareStateInactiveStateRectanglePartVisualAllMaskBitmapNoMemoryVisualClassMaskVisualDepthMaskBitmapOpenFailedVisualScreenMaskBitmapFileInvalidVisualRedMaskMaskVisualBlueMaskMaskVisualGreenMaskMaskVisualBitsPerRGBMaskVisualColormapSizeMaskReleaseByFreeingColormapXlib.Xutil/usr/lib/python2.7/dist-packages/Xlib/Xutil.pybellnewevtorigclsxobjectdo_thressymcodesopen_fontlist_fontslist_hosts_atom_cachegrab_serverintern_atom_keymap_symsallow_eventschange_hostsdo_thresholdno_operationquery_keymapscreen_count_keymap_codesget_atom_nameget_font_pathhas_extensionlookup_stringrebind_stringset_font_pathungrab_server_update_keymapungrab_pointerextension_eventget_input_focuslist_extensionsquery_extensionget_screen_saverset_screen_saverforce_screen_saverkeysym_to_keycodesset_access_controlMethodOverrideErrorextension_add_eventget_pointer_controlget_pointer_mappingget_selection_ownerkeysym_translationsset_close_down_modeset_pointer_mappingget_keyboard_controlget_keyboard_mappinglist_fonts_with_infoset_modifier_mappingclass_extension_dictschange_pointer_controlcreate_resource_objectchange_keyboard_controlchange_keyboard_mappingrefresh_keyboard_mappingdisplay_extension_methodschange_active_pointer_grabChange the parameters provided as keyword arguments:

        key_click_percent
            The volume of key clicks between 0 (off) and 100 (load).
            -1 will restore default setting.
        bell_percent
            The base volume of the bell, coded as above.
        bell_pitch
            The pitch of the bell in Hz, -1 restores the default.
        bell_duration
            The duration of the bell in milliseconds, -1 restores
            the default.
        led

        led_mode
            led_mode should be X.LedModeOff or X.LedModeOn. If led is
            provided, it should be a 32-bit mask listing the LEDs that
            should change. If led is not provided, all LEDs are changed.
        key

        auto_repeat_mode
            auto_repeat_mode should be one of X.AutoRepeatModeOff,
            X.AutoRepeatModeOn, or X.AutoRepeatModeDefault. If key is
            provided, that key will be modified, otherwise the global
            state for the entire keyboard will be modified.Return an object with the attributes timeout, interval,
        prefer_blanking, allow_exposures. See XGetScreenSaver(3X11) for
        details.Internal function, called to refresh the keymap cache.
        Create a resource object of type for the integer id. type
        should be one of the following strings:

        resource
        drawable
        window
        pixmap
        fontable
        font
        gc
        colormap
        cursor

        This function can be used when a resource ID has been fetched
        e.g. from an resource or a command line argument. Resource
        objects should never be created by instantiating the appropriate
        class directly, since any X extensions dynamically added by the
        library will not be available.
        Return the number of events queued, i.e. the number of times
        that Display.next_event() can be called without blocking.Return the current font path as a list of strings.Ungrab a grabbed keyboard and any queued events. See
        XUngrabKeyboard(3X11).elease a grabbed pointer and any queued events. See
        XUngrabPointer(3X11).Xlib.ext.Return a list of fonts matching pattern. No more than
        max_names will be returned. Each list item represents one font
        and has the following properties:

        name
            The name of the font.
        min_bounds
        max_bounds
        min_char_or_byte2
        max_char_or_byte2
        default_char
        draw_direction
        min_byte1
        max_byte1
        all_chars_exist
        font_ascent
        font_descent
        replies_hint
            See the descripton of XFontStruct in XGetFontProperty(3X11)
            for details on these values.
        properties
            A list of properties. Each entry has two attributes:

            name
                The atom identifying this property.
            value
                A 32-bit unsigned value.
        Send a synthetic event to the window destination which can be
        a window object, or X.PointerWindow or X.InputFocus. event is the
        event object to send, instantiated from one of the classes in
        protocol.events. See XSendEvent(3X11) for details.

        There is also a Window.send_event() method.attempting to replace %s method: %sReturns the name used to connect to the server, either
        provided when creating the Display object, or fetched from the
        environmental variable $DISPLAY.Return an object with the following attributes:

mode
    X.EnableAccess if the access control list is used, X.DisableAccess otherwise.
hosts
    The hosts on the access list. Each entry has the following attributes:

    family
        X.FamilyInternet, X.FamilyDECnet, or X.FamilyChaos.
    name
        A list of byte values, the coding depends on family. For the Internet family, it is the 4 bytes of an IPv4 address.

Set the mapping of the pointer buttons. map is a list of
        logical button numbers. map must be of the same length as the
        list returned by Display.get_pointer_mapping().

        map[n] sets the
        logical number for the physical button n+1. Logical number 0
        disables the button. Two physical buttons cannot be mapped to the
        same logical number.

        If one of the buttons to be altered are
        logically in the down state, X.MappingBusy is returned and the
        mapping is not changed. Otherwise the mapping is changed and
        X.MappingSuccess is returned.Return the window that owns selection (an atom), or X.NONE if
        there is no owner for the selection. Can raise BadAtom./usr/lib/python2.7/dist-packages/Xlib/display.pyReturn an object with the following attributes:

        global_auto_repeat
            X.AutoRepeatModeOn or X.AutoRepeatModeOff.

        auto_repeats
            A list of 32 integers. List item N contains the bits for keys
            8N to 8N + 7 with the least significant bit in the byte
            representing key 8N. If a bit is on, autorepeat is enabled
            for the corresponding key.

        led_mask
            A 32-bit mask indicating which LEDs are on.

        key_click_percent
            The volume of key click, from 0 to 100.

        bell_percent

        bell_pitch

        bell_duration
            The volume, pitch and duration of the bell. Move the pointer relative its current position by the offsets
        (x, y). However, if src_window is a window the pointer is only
        moved if the specified rectangle in src_window contains it. If
        src_width is 0 it will be replaced with the width of src_window -
        src_x. src_height is treated in a similar way.

        To move the pointer to absolute coordinates, use Window.warp_pointer().Convert a keycode to a keysym, looking in entry index.
        Normally index 0 is unshifted, 1 is shifted, 2 is alt grid, and 3
        is shift+alt grid. If that key entry is not bound, X.NoSymbol is
        returned.Modify the keyboard mapping, starting with first_keycode.
        keysyms is a list of tuples of keysyms. keysyms[n][i] will be
        assigned to keycode first_keycode+n at index i.Returns the file descriptor number of the underlying socket.
        This method is provided to allow Display objects to be passed
        select.select().attempting to replace display method: %sDisable processing of requests on all other client connections
        until the server is ungrabbed. Server grabbing should be avoided
        as much as possible.Set input focus to focus, which should be a window,
        X.PointerRoot or X.NONE. revert_to specifies where the focus
        reverts to if the focused window becomes not visible, and should
        be X.RevertToParent, RevertToPointerRoot, or RevertToNone. See
        XSetInputFocus(3X11) for details.

        There is also a Window.set_input_focus().Do nothing but send a request to the server.Return a list of eight lists, one for each modifier. The list
        can be indexed using X.ShiftMapIndex, X.Mod1MapIndex, and so on.
        The sublists list the keycodes bound to that modifier.Look up the primary keycode that is bound to keysym. If
        several keycodes are found, the one with the lowest index and
        lowest code is returned. If keysym is not bound to any key, 0 is
        returned.add_extension_error(code, err)

        Add an extension error.  CODE is the numeric code, and ERR is
        the error class.
        Alias for intern_atom, using internal cacheReturn a list of all the extensions provided by the server.Return a string corresponding to KEYSYM, or None if no
        reasonable translation is found.
        Control what will happen with the client's resources at
        connection close. The default is X.DestroyAll, the other values
        are X.RetainPermanent and X.RetainTemporary.Return a list of the pointer button mappings. Entry N in the
        list sets the logical button number for the physical button N+1.Return the total number of screens on the display.Look up all the keycodes that is bound to keysym. A list of
        tuples (keycode, index) is returned, sorted primarily on the
        lowest index and secondarily on the lowest keycode.Flush the request queue, building and sending the queued
        requests. This can be necessary in applications that never wait
        for events, and in threaded applications.See XSetScreenSaver(3X11).Change the dynamic parameters of a pointer grab. See
        XChangeActivePointerGrab(3X11).extension_add_event(code, evt, [name])

        Add an extension event.  CODE is the numeric code, and EVT is
        the event class.  EVT will be cloned, and the attribute _code
        of the new event class will be set to CODE.

        If NAME is ommitted, it will be set to the name of EVT.  This
        name is used to insert an entry in the DictWrapper
        extension_event.
        If mode is X.ScreenSaverActive the screen saver is activated.
        If it is X.ScreenSaverReset, the screen saver is deactivated as
        if device input had been received.Return the current keyboard mapping as a list of tuples,
        starting at first_keycount and no more than count.Check if both the server and the client library support the X
        extension named extension.Return a bit vector for the logical state of the keyboard,
        where each bit set to 1 indicates that the corresponding key is
        currently pressed down. The vector is represented as a list of 32
        integers. List item N contains the bits for keys 8N to 8N + 7
        with the least significant bit in the byte representing key 8N.Set the default error handler which will be called for all
        unhandled errors. handler should take two arguments as a normal
        request error handler, but the second argument (the request) will
        be None.  See section Error Handling.Ask the server if it supports the extension name. If it is
        supported an object with the following attributes is returned:

        major_opcode
            The major opcode that the requests of this extension uses.
        first_event
            The base event code if the extension have additional events, or 0.
        first_error
            The base error code if the extension have additional errors, or 0.

        If the extension is not supported, None is returned.mode is either X.HostInsert or X.HostDelete. host_family is
        one of X.FamilyInternet, X.FamilyDECnet or X.FamilyChaos.

        host is a list of bytes. For the Internet family, it should be the
        four bytes of an IPv4 address.Ring the bell at the volume percent which is relative the base
        volume. See XBell(3X11).Set the font path to path, which should be a list of strings.
        If path is empty, the default font path of the server will be
        restored.extension_add_method(object, name, function)

        Add an X extension module method.  OBJECT is the type of
        object to add the function to, a string from this list:

            display
            resource
            drawable
            window
            pixmap
            fontable
            font
            gc
            colormap
            cursor

        NAME is the name of the method, a string.  FUNCTION is a
        normal function whose first argument is a 'self'.
        Look up the name of atom, returning it as a string. Will raise
        BadAtom if atom does not exist.Return the next event. If there are no events queued, it will
        block until the next event is fetched from the server.Release the server if it was previously grabbed by this client.Enable use of access control lists at connection setup if mode
        is X.EnableAccess, disable if it is X.DisableAccess.Return the number of the default screen, extracted from the
        display name.expected a MappingNotify eventReturn an object with the following attributes:

        focus
            The window which currently holds the input
            focus, X.NONE or X.PointerRoot.
        revert_to
            Where the focus will revert, one of X.RevertToParent,
            RevertToPointerRoot, or RevertToNone. Flush the queue and wait until the server has processed all
        the queued requests. Use this e.g. when it is important that
        errors caused by a certain request is trapped.Return a list of font names matching pattern. No more than
        max_names will be returned.Change the translation of KEYSYM to NEWSTRING.
        If NEWSTRING is None, remove old translation if any.
        Set the keycodes for the eight modifiers X.Shift, X.Lock,
        X.Control, X.Mod1, X.Mod2, X.Mod3, X.Mod4 and X.Mod5. keycodes
        should be a eight-element list where each entry is a list of the
        keycodes that should be bound to that modifier.

        If any changed
        key is logically in the down state, X.MappingBusy is returned and
        the mapping is not changed. If the mapping violates some server
        restriction, X.MappingFailed is returned. Otherwise the mapping
        is changed and X.MappingSuccess is returned.Intern the string name, returning its atom number. If
        only_if_exists is true and the atom does not already exist, it
        will not be created and X.NONE is returned.To change the pointer acceleration, set accel to a tuple (num,
        denum). The pointer will then move num/denum times the normal
        speed if it moves beyond the threshold number of pixels at once.
        To change the threshold, set it to the number of pixels. -1
        restores the default.This method should be called once when a MappingNotify event
        is received, to update the keymap cache. evt should be the event
        object.Open the font identifed by the pattern name and return its
        font object. If name does not match any font, None is returned.Release some queued events. mode should be one of
        X.AsyncPointer, X.SyncPointer, X.AsyncKeyboard, X.SyncKeyboard,
        X.ReplayPointer, X.ReplayKeyboard, X.AsyncBoth, or X.SyncBoth.
        time should be a timestamp or X.CurrentTime.Return an object with the following attributes:

        accel_num

        accel_denom
            The acceleration as numerator/denumerator.

        threshold
            The number of pixels the pointer must move before the
            acceleration kicks in.Close the display, freeing the resources that it holds.XauthErrorerror_typesget_requestresource_idXNoAuthErrorminor_opcodeDisplayNameError/usr/lib/python2.7/dist-packages/Xlib/error.pyBad display name "%s"Xlib.errorDisplay error "%s"Can't connect to display "%s": %sDisplay connection closed by %sRANDRSHAPErandrXINERAMAxineramaComposite/usr/lib/python2.7/dist-packages/Xlib/ext/__init__.pyid_baseClientDiedFromClientFromServerclient_infomajor_rangeminor_rangeserver_timeClientStartedFutureClientsCurrentClientsFromClientTimeFromServerTimeclient_swappedclient_resourceFromClientSequencerecord_get_contextrecord_get_versionrecord_register_clientsrecorded_sequence_numberrecord_unregister_clientsA field with raw data, stored as a stringXlib.ext.record/usr/lib/python2.7/dist-packages/Xlib/ext/record.pyxtest_fake_inputxtest_get_versionxtest_grab_controlxtest_compare_cursor/usr/lib/python2.7/dist-packages/Xlib/ext/xtest.py/usr/lib/python2.7/dist-packages/Xlib/protocol/__init__.pyqlenEINTRvendorvisualsdata_recvdata_sendvisual_idbig_endianroot_depthblack_pixelevent_queuelast_serialrecv_activeroot_visualsave_underssend_activewhite_pixeldisplay_nameresource_idsscanline_padsocket_errorvisual_classwidth_in_mmserror_classesevent_waitingheight_in_mmsreason_lengthrequest_queue_success_replyallowed_depthsauth_prot_dataauth_prot_namebits_per_pixelclose_internalparse_responsepixmap_formatsprotocol_majorprotocol_minorrelease_numberrequest_lengthrequest_serialcheck_for_errordata_sent_bytesevent_wait_lockrequest_waitingwidth_in_pixelscolormap_entriesheight_in_pixelslast_resource_idresource_id_baseresource_id_lockresource_id_maskadditional_lengthrequest_wait_locksocket_error_lockbits_per_rgb_valuecurrent_input_maskmax_installed_mapsmin_installed_mapsmotion_buffer_sizerequest_queue_lockget_waiting_requestparse_error_responseparse_event_responsedefault_error_handlerevent_queue_read_lockevent_queue_write_lockparse_connection_setupparse_request_responseextension_major_opcodesget_waiting_replyrequestsend_and_recv(flush = None, event = None, request = None, recv = None)

        Perform I/O, or wait for some other thread to do it for us.

        send_recv_lock MUST be LOCKED when send_and_recv is called.
        It will be UNLOCKED at return.

        Exactly or one of the parameters flush, event, request and recv must
        be set to control the return condition.

        To attempt to send all requests in the queue, flush should
        be true.  Will return immediately if another thread is
        already doing send_and_recv.

        To wait for an event to be recieved, event should be true.

        To wait for a response to a certain request (either an error
        or a response), request should be set the that request's
        serial number.

        To just read any pending data from the server, recv should be true.

        It is not guaranteed that the return condition has been
        fulfilled when the function returns, so the caller has to loop
        until it is finished.
        =Hserver: %sInternal method.

        Parse data recieved from server.  If REQUEST is not None
        true is returned if the request with that serial number
        was recieved, otherwise false is returned.

        If REQUEST is -1, we're parsing the server connection setup
        response.
        Internal function used to parse connection setup response.
        class = d.get_resource_class(class_name, default = None)

        Return the class to be used for X resource objects of type
        CLASS_NAME, or DEFAULT if no such class is set.
        out of resource idsX protocol error:
%s
Request reply to unknown request.  Can't happen!d.free_resource_id(rid)

        Free resource id RID.  Attempts to free a resource id which
        isn't allocated by us are ignored.
        Xlib.protocol.displayExpected reply for request %s, but got %s.  Can't happen!id = d.allocate_resource_id()

        Allocate a new X resource id number ID.

        Raises ResourceIDError if there are no free resource ids.
        =L/usr/lib/python2.7/dist-packages/Xlib/protocol/display.py(   t   selft   flusht   eventt   requestt   recvt	   wait_lockt	   recievingt   flush_bytest   sendingt   reqt   waitt   writesett   timeoutt   rst   wst   est   errt   it   gotreqt
   bytes_recvevent_xevent_yvalue_maskclient_typemajor_eventminor_eventabove_siblingfrom_configureXlib.protocol.event/usr/lib/python2.7/dist-packages/Xlib/protocol/event.pywin_xwin_ychildrenexact_redmap_statewin_classchar_infosexact_bluescreen_redexact_greenmajor_codesscreen_blueoverall_leftscreen_greenoverall_rightoverall_widthoverall_ascentall_event_masksoverall_descentyour_event_maskmap_is_installedbacking_bit_planes/usr/lib/python2.7/dist-packages/Xlib/protocol/request.pyXlib.protocol.requestbhilvlenvrangemaskcodeCard16Objvar_fieldscalc_lengthcheck_valuemaskcodelenusekeywordskeyword_argsstatic_codesstructvalues_errorhandlercast_functionstatic_fieldsstatic_valuesstring_textitemself.static_fields[%d].calc_length(%s)Wrong data length for FixedPropertyData: %sException raised by error handler.
self.static_fields[%d].calc_length(_%s_length)Neither structcode or parse_binary_value provided for %sdef parse_value(self, val, display, rawdict = 0):
  ret = {}
  return %s
struct.pack(%s)A FormatField encodes the format of some other field, in a manner
    similar to LengthFields.

    The ff.get_binary_value() method is not used, replaced by
    ff.get_binary_format().
     This function allows Struct objects to be used in List and
        Object fields.  Each item represents the arguments to pass to
        to_binary, either a tuple, a dictionary or a DictWrapper.

          %s = self.static_fields[%d].check_value(%s)
def parse_binary(self, data, display, rawdict = 0):
  ret = {}
  val = struct.unpack("%s", data[:%d])
value, remaindata = f.parse_binary_value(data, display, length, format)

        Decode a value for this field from the binary string DATA.
        If there are a LengthField and/or a FormatField connected to this
        field, their values will be LENGTH and FORMAT, respectively.  If
        there are no such fields the parameters will be None.

        DISPLAY is the display involved, which is really only used by
        the Resource fields.

        The decoded value is returned as VALUE, and the remaining part
        of DATA shold be returned as REMAINDATA.
        self.static_fields[%d].parse_value(val[%d], display)Field objects represent the data fields of a Struct.

    Field objects must have the following attributes:

       name         -- the field name, or None
       structcode   -- the struct codes representing this field
       structvalues -- the number of values encodes by structcode

    Additionally, these attributes should either be None or real methods:

       check_value  -- check a value before it is converted to binary
       parse_value  -- parse a value after it has been converted from binary

    If one of these attributes are None, no check or additional
    parsings will be done one values when converting to or from binary
    form.  Otherwise, the methods should have the following behaviour:

       newval = check_value(val)
         Check that VAL is legal when converting to binary form.  The
         value can also be converted to another Python value.  In any
         case, return the possibly new value.  NEWVAL should be a
         single Python value if structvalues is 1, a tuple of
         structvalues elements otherwise.

       newval = parse_value(val, display)
         VAL is an unpacked Python value, which now can be further
         refined.  DISPLAY is the current Display object.  Return the
         new value.  VAL will be a single value if structvalues is 1,
         a tuple of structvalues elements otherwise.

    If `structcode' is None the Field must have the method
    f.parse_binary_value() instead.  See its documentation string for
    details.

    values, remdata = s.parse_binary(data, display, rawdict = 0)

        Convert a binary representation of the structure into Python values.

        DATA is a string or a buffer containing the binary data.
        DISPLAY should be a Xlib.protocol.display.Display object if
        there are any Resource fields or Lists with ResourceObjs.

        The Python values are returned as VALUES.  If RAWDICT is true,
        a Python dictionary is returned, where the keys are field
        names and the values are the corresponding Python value.  If
        RAWDICT is false, a DictWrapper will be returned where all
        fields are available as attributes.

        REMDATA are the remaining binary data, unused by the Struct object.

          %s = %s
%dsThis function is used by List and Object fields to convert
        Struct objects with no var_fields into Python values.

        _%s_%ddef to_binary(self, %s):
  ret["%s"] = val[%s]
Xlib.protocol.rq%d:%d  ret["%s"], data = self.var_fields[%d].parse_binary_value(data, display, %s, %s)
  return %s + %s
  data = data[%d:]
A LengthField stores the length of some other Field whose size
    may vary, e.g. List and String8.

    Its name should be the same as the name of the field whose size
    it stores.

    The lf.get_binary_value() method of LengthFields is not used, instead
    a lf.get_binary_length() should be provided.

    Unless LengthField.get_binary_length() is overridden in child classes,
    there should also be a lf.calc_length().
    data = s.to_binary(...)

        Convert Python values into the binary representation.  The
        arguments will be all value fields with names, in the order
        given when the Struct object was instantiated.  With one
        exception: fields with default arguments will be last.

        Returns the binary representation as the string DATA.

        Struct objects represents a binary data structure.  It can
    contain both fields with static and dynamic sizes.  However, all
    static fields must appear before all dynamic fields.

    Fields are represented by various subclasses of the abstract base
    class Field.  The fields of a structure are given as arguments
    when instantiating a Struct object.

    Struct objects have two public methods:

      to_binary()    -- build a binary representation of the structure
                        with the values given as arguments
      parse_binary() -- convert a binary (string) representation into
                        a Python dictionary or object.

    These functions will be generated dynamically for each Struct
    object to make conversion as fast as possible.  They are
    generated the first time the methods are called.

    Invalid property data format %d  ret["%s"] = self.static_fields[%d].parse_value(val[%s], display)
field %s: argument %s not in %s, _keyword_args%s is not an Event for field %s + len(_%s)**_keyword_args  return ret
newlen = lf.calc_length(length)

        Return a new length NEWLEN based on the provided LENGTH.
        /usr/lib/python2.7/dist-packages/Xlib/protocol/rq.py=%s%dxObject value must be tuple, dictionary or DictWrapper: %s<%s serial = %s, data = %s, error = %s>  if not rawdict: return DictWrapper(ret)
length mismatch for FixedList %sThe List, FixedList and Object fields store compound data objects.
    The type of data objects must be provided as an object with the
    following attributes and methods:

    ...

    %s is not a tuple or a list>BL  if not rawdict: ret = DictWrapper(ret)
  _%(name)s, _%(name)s_length, _%(name)s_format = self.var_fields[%(fno)d].pack_value(%(name)s%(kw)s)
  return ret, data
_%s_formatModifierMapping list should have eight elements>Lstipplearc_modecap_styleclip_maskfill_rulefill_styleforegroundjoin_styleline_styleborder_pixelborder_pixmapclip_x_originclip_y_originbacking_planessubwindow_modecharacter_widthbackground_pixelbackground_pixmapleft_side_bearinggraphics_exposuresright_side_bearingtile_stipple_x_origintile_stipple_y_origin/usr/lib/python2.7/dist-packages/Xlib/protocol/structs.pyXlib.protocol.structs/usr/lib/python2.7/dist-packages/Xlib/support/__init__.pyOpenVMSvms_connectunix_connectXlib.support.connectsocket = get_socket(dname, host, dno)

    Connect to the display specified by DNAME, HOST and DNO, which
    are the corresponding values from a previous call to get_display().

    Return SOCKET, a new socket object connected to the X server.
    auth_name, auth_data = get_auth(sock, dname, host, dno)

    Return authentication data for the display on the other side of
    SOCK, which was opened with DNAME, HOST and DNO.

    Return AUTH_NAME and AUTH_DATA, two strings to be used in the
    connection setup request.
    dname, host, dno, screen = get_display(display)

    Parse DISPLAY into its components.  If DISPLAY is None, use
    the default display.  The return values are:

      DNAME  -- the full display name (string)
      HOST   -- the host name (string, possibly empty)
      DNO    -- display number (integer)
      SCREEN -- default screen number (integer)
    /usr/lib/python2.7/dist-packages/Xlib/support/connect.py__noop_DummyLock__noop/usr/lib/python2.7/dist-packages/Xlib/support/lock.pyXlib.support.lock/usr/lib/python2.7/dist-packages/Xlib/xobject/__init__.pyatoiscr_cmapalloc_colorfree_colorslookup_colorquery_colorsstore_colorsinstall_colormapalloc_color_cellsalloc_named_colorstore_named_coloralloc_color_planesuninstall_colormapcopy_colormap_and_free\A#([0-9a-fA-F])([0-9a-fA-F])([0-9a-fA-F])\Z\Argb:([0-9a-fA-F]{1,4})/([0-9a-fA-F]{1,4})/([0-9a-fA-F]{1,4})\Z\A#([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])\Z\A#([0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F])\Z/usr/lib/python2.7/dist-packages/Xlib/xobject/colormap.py\A#([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])\Zrecolor/usr/lib/python2.7/dist-packages/Xlib/xobject/cursor.pyunmapWM_STATEfill_arcgrab_keypoly_arcreparentcirculatecopy_areacreate_gcdraw_textfill_polyget_imagepoly_linepoly_textput_imageclear_areacopy_planeimage_textpoly_pointquery_treeungrab_keyget_wm_namegrab_buttonset_wm_nameWM_PROTOCOLSget_geometryget_wm_classget_wm_hintsget_wm_statepoly_segmentpoly_text_16raise_windowset_wm_classset_wm_hintsset_wm_statecreate_cursorcreate_pixmapcreate_windowimage_text_16poly_fill_arcput_pil_imagequery_pointerungrab_buttonfill_rectangleget_attributespoly_rectanglechange_propertychange_save_setcreate_colormapdelete_propertylist_propertiesmap_sub_windowsquery_best_size_get_struct_prop_set_struct_propget_wm_icon_nameget_wm_icon_sizeget_wm_protocolsset_wm_icon_nameset_wm_icon_sizeset_wm_protocolstranslate_coordschange_attributesconvert_selectionget_full_propertyget_motion_eventsrotate_propertiesunmap_sub_windowsWM_COLORMAP_WINDOWSdestroy_sub_windowsget_wm_normal_hintspoly_fill_rectangleset_selection_ownerset_wm_normal_hintsget_wm_transient_forset_wm_transient_forget_wm_client_machineset_wm_client_machineget_wm_colormap_windowsset_wm_colormap_windowslist_installed_colormaps%s %s /usr/lib/python2.7/dist-packages/Xlib/xobject/drawable.pyalias for raising the window to the top - as in XRaiseWindowUnknown data format(   t   selft   gct   xt   yt   imaget   onerrort   widtht   heightt   formatt   deptht   rawmodet   padt   stridet   unitt   maxlent   splitt   x1t   x2t   y1t   ht   subimaget   wt   dataset_dashesquery_text_extentscreate_glyph_cursorset_clip_rectangles/usr/lib/python2.7/dist-packages/Xlib/xobject/fontable.pyicon_xicon_yicon_maskmax_widthmin_widthwidth_incbase_widthheight_incmax_aspectmax_heightmin_aspectmin_heightbase_heighticon_pixmapicon_windowwindow_groupinitial_stateXlib.xobject.icccm/usr/lib/python2.7/dist-packages/Xlib/xobject/icccm.pykill_client<%s 0x%08x>%s(0x%08x)/usr/lib/python2.7/dist-packages/Xlib/xobject/resource.py<module>arduinoport.pyarduino port found:arduino port not found/usr/bin/python/usr/lib/python2.7/dist-packages/_markerlib/__init__.pyGtLtGtELtEIsNotNotEqNotInBoolOpJythonnew_nodenew_treedont_inheritcopy_locationgeneric_visitNodeTransformervisit_AttributeWeakValueDictionaryplatform.machineInterpret PEP 345 environment markers.

EXPR [in|==|!=|not in] EXPR [or|and] ...

where EXPR belongs to any of those:

    python_version = '%s.%s' % (sys.version_info[0], sys.version_info[1])
    python_full_version = sys.version.split()[0]
    os.name = os.name
    sys.platform = sys.platform
    platform.version = platform.version()
    platform.machine = platform.machine()
    platform.python_implementation = platform.python_implementation()
    a free string, like '2.6', or 'win32'
Return compiled marker as a function accepting an environment dict.Flatten one level of attribute access.Not allowed in environment markers.
%s
%sEnsure statement only contains allowed nodes.override updates environmentReturn copy of default PEP 385 globals dictionary./usr/lib/python2.7/dist-packages/_markerlib/markers.py<environment marker>ibody_self__lambda___source__kwonlyargsannotationsundecoratedcallermodule__kwdefaults__contextmanagerkwonlydefaultsshortsignature__annotations___FunctionMaker__iterator3.4.0Make a new function from a given template and update the signature\s*def\s*([_\w][_\w\d]*)\s*\(with _self_: return _func_(%(shortsignature)s)not a valid function template
%s%s=None
    An object with the ability to create functions with a given signature.
    It has attributes name, doc, module, signature, defaults, dict and
    methods update and make.
    Context manager decoratorYou are decorating a non function: %s/usr/lib/python2.7/dist-packages/decorator.pydecorator(%s) converts functions/generators into factories of %s objects
        Create a function from the strings name, signature and body.
        evaldict is the evaluation dictionary. If addsource is true an attribute
        __source__ is added to the result. The attributes attrs are added,
        if any.
        %s is overridden in
%sreturn _call_(_func_, %(shortsignature)s)
    decorator(caller) converts a caller function into a decorator;
    decorator(caller, func) decorates a function using a caller.
    def %(name)s(%(signature)s):
Error in generated code:
Decorator module, see http://pypi.python.org/pypi/decorator
for the documentation.
%s=%sUpdate the signature of func with the data in selfarg%dA quick and dirty replacement for getfullargspec for Python 2.Xreturn decorator(_call_, %s)/usr/lib/python2.7/dist-packages/easy_install.pyRun the EasyInstall command__git_revision__/usr/lib/python2.7/dist-packages/numpy
NumPy
=====

Provides
  1. An array object of arbitrary homogeneous items
  2. Fast mathematical operations over arrays
  3. Linear Algebra, Fourier Transforms, Random Number Generation

How to use the documentation
----------------------------
Documentation is available in two forms: docstrings provided
with the code, and a loose standing reference guide, available from
`the NumPy homepage <http://www.scipy.org>`_.

We recommend exploring the docstrings using
`IPython <http://ipython.scipy.org>`_, an advanced Python shell with
TAB-completion and introspection capabilities.  See below for further
instructions.

The docstring examples assume that `numpy` has been imported as `np`::

  >>> import numpy as np

Code snippets are indicated by three greater-than signs::

  >>> x = 42
  >>> x = x + 1

Use the built-in ``help`` function to view a function's docstring::

  >>> help(np.sort)
  ... # doctest: +SKIP

For some objects, ``np.info(obj)`` may provide additional help.  This is
particularly true if you see the line "Help on ufunc object:" at the top
of the help() page.  Ufuncs are implemented in C, not Python, for speed.
The native Python help() does not know how to view their help, but our
np.info() function does.

To search for documents containing a keyword, do::

  >>> np.lookfor('keyword')
  ... # doctest: +SKIP

General-purpose documents like a glossary and help on the basic concepts
of numpy are available under the ``doc`` sub-module::

  >>> from numpy import doc
  >>> help(doc)
  ... # doctest: +SKIP

Available subpackages
---------------------
doc
    Topical documentation on broadcasting, indexing, etc.
lib
    Basic functions used by several sub-packages.
random
    Core Random Tools
linalg
    Core Linear Algebra Tools
fft
    Core FFT routines
polynomial
    Polynomial tools
testing
    Numpy testing tools
f2py
    Fortran to Python Interface Generator.
distutils
    Enhancements to distutils with support for
    Fortran compilers support and more.

Utilities
---------
test
    Run numpy unittests
show_config
    Show numpy build configuration
dual
    Overwrite certain functions with high-performance Scipy tools
matlib
    Make everything matrices.
__version__
    Numpy version string

Viewing documentation using IPython
-----------------------------------
Start IPython with the NumPy profile (``ipython -p numpy``), which will
import `numpy` under the alias `np`.  Then, use the ``cpaste`` command to
paste examples into the shell.  To see which functions are available in
`numpy`, type ``np.<TAB>`` (where ``<TAB>`` refers to the TAB key), or use
``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER key) to narrow
down the list.  To view the docstring for a function, use
``np.cos?<ENTER>`` (to view the docstring) and ``np.cos??<ENTER>`` (to view
the source code).

Copies vs. in-place operation
-----------------------------
Most of the functions in `numpy` return a copy of the array argument
(e.g., `np.sort`).  In-place versions of these functions are often
available as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.
Exceptions to this rule are documented.

Error importing numpy: you should not try to import numpy from
        its source directory; please exit the numpy source tree, and relaunch
        your python intepreter from there.Module deprecation warning.

    The nose tester turns ordinary Deprecation warnings into test failures.
    That makes it hard to deprecate whole modules, because they get
    imported by default. So this is a special Deprecation warning that the
    nose tester will let pass without making tests fail.

    Running from numpy source directory.
/usr/lib/python2.7/dist-packages/numpy/__init__.py/usr/lib/python2.7/dist-packages/numpy/__config__.py_execcmdExecuting_obj2reprget_pkgdocsnames_filesparent_frame__doc_title___format_titles_get_doc_titlefiledescriptor_get_info_files_get_sorted_namesimported_packagesNUMPY_IMPORT_DEBUG_init_info_modulesparent_export_names
  [*] - using a package requires explicit import (see pkgload) Return documentation summary of subpackages.
        %s%s %s Manages loading packages.
         Return repr(obj) withImports to %r namespace
---------------------------- Return package names sorted in the order as they should be
        imported due to dependence relations between packages.
        Load one or more packages into parent package top-level namespace.

       This function is intended to shorten the need to import many
       subpackages, say of scipy, constantly with statements such as

         import scipy.linalg, scipy.fftpack, scipy.etc...

       Instead, you can say:

         import scipy
         scipy.pkgload('linalg','fftpack',...)

       or

         scipy.pkgload()

       to load all of them in one call.

       If a name which doesn't exist in scipy's namespace is
       given, a warning is shown.

       Parameters
       ----------
        *packages : arg-tuple
             the names (one or more strings) of all the modules one
             wishes to load into the top-level namespace.
        verbose= : integer
             verbosity level [default: -1].
             verbose=-1 will suspend also warnings.
        force= : bool
             when True, force reloading loaded packages [default: False].
        postpone= : bool
             when True, don't load packages [default: False]

      Return list of (package name,info.py file) from parent_path subdirectories.
        

Global symbols from subpackages
-------------------------------
%s -> successnumpy._import_toolsInitialize info_modules = {<package_name>: <package info.py module>}.
        import %s.info as infoOverwriting %s=%s (was %s)dir(%s)/usr/lib/python2.7/dist-packages/numpy/_import_tools.py%s -> failed: %sNo scipy-style subpackage %r found in %s. Ignoring: %sinfo.pyc__all__ = []--> Get the title from a package info.py file.
        * Not Available *getattr(%s,"__all__",None) Execute command in parent_frame.itersfloat96itemsetnumiterholidaysisnativeiternextsetflagsweekmasksetasflatcomplex256remove_axisisalignedstruct__array_struct__remove_multi_indexenable_external_loop_get_ndarray_c_version
    a.round(decimals=0, out=None)

    Return `a` with each element rounded to the given number of decimals.

    Refer to `numpy.around` for full documentation.

    See Also
    --------
    numpy.around : equivalent function

    
    `nd_grid` instance which returns an open multi-dimensional "meshgrid".

    An instance of `numpy.lib.index_tricks.nd_grid` which returns an open
    (i.e. not fleshed out) mesh-grid when indexed, so that only one dimension
    of each returned array is greater than 1.  The dimension and number of the
    output arrays are equal to the number of indexing dimensions.  If the step
    length is not a complex number, then the stop is not inclusive.

    However, if the step length is a **complex number** (e.g. 5j), then
    the integer part of its magnitude is interpreted as specifying the
    number of points to create between the start and stop values, where
    the stop value **is inclusive**.

    Returns
    ----------
    mesh-grid `ndarrays` with only one dimension :math:`\neq 1`

    See Also
    --------
    np.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects
    mgrid : like `ogrid` but returns dense (or fleshed out) mesh grids
    r_ : array concatenator

    Examples
    --------
    >>> from numpy import ogrid
    >>> ogrid[-1:1:5j]
    array([-1. , -0.5,  0. ,  0.5,  1. ])
    >>> ogrid[0:5,0:5]
    [array([[0],
            [1],
            [2],
            [3],
            [4]]), array([[0, 1, 2, 3, 4]])]

    
    a.tofile(fid, sep="", format="%s")

    Write array to a file as text or binary (default).

    Data is always written in 'C' order, independent of the order of `a`.
    The data produced by this method can be recovered using the function
    fromfile().

    Parameters
    ----------
    fid : file or str
        An open file object, or a string containing a filename.
    sep : str
        Separator between array items for text output.
        If "" (empty), a binary file is written, equivalent to
        ``file.write(a.tostring())``.
    format : str
        Format string for text file output.
        Each entry in the array is formatted to text by first converting
        it to the closest Python type, and then using "format" % item.

    Notes
    -----
    This is a convenience function for quick storage of array data.
    Information on endianness and precision is lost, so this method is not a
    good choice for files intended to archive data or transport data between
    machines with different endianness. Some of these problems can be overcome
    by outputting the data as text files, at the expense of speed and file
    size.

    a.__copy__([order])

    Return a copy of the array.

    Parameters
    ----------
    order : {'C', 'F', 'A'}, optional
        If order is 'C' (False) then the result is contiguous (default).
        If order is 'Fortran' (True) then the result has fortran order.
        If order is 'Any' (None) then the result has fortran order
        only if the array already is in fortran order.

    
    Data-type of the array's elements.

    Parameters
    ----------
    None

    Returns
    -------
    d : numpy dtype object

    See Also
    --------
    numpy.dtype

    Examples
    --------
    >>> x
    array([[0, 1],
           [2, 3]])
    >>> x.dtype
    dtype('int32')
    >>> type(x.dtype)
    <type 'numpy.dtype'>

     a.__array__(|dtype) -> reference if type unchanged, copy otherwise.

    Returns either a new reference to self if dtype is not given or a new array
    of provided data type if dtype is different from the current dtype of the
    array.

    
    newbyteorder(new_order='S')

    Return a new `dtype` with a different byte order.

    Changes are also made in all fields and sub-arrays of the data type.

    The `new_order` code can be any from the following:

    * {'<', 'L'} - little endian
    * {'>', 'B'} - big endian
    * {'=', 'N'} - native order
    * 'S' - swap dtype from current to opposite endian
    * {'|', 'I'} - ignore (no change to byte order)

    Parameters
    ----------
    new_order : str, optional
        Byte order to force; a value from the byte order specifications
        above.  The default value ('S') results in swapping the current
        byte order. The code does a case-insensitive check on the first
        letter of `new_order` for the alternatives above.  For example,
        any of 'B' or 'b' or 'biggish' are valid to specify big-endian.


    Returns
    -------
    new_dtype : dtype
        New `dtype` object with the given change to the byte order.

    _fastCopyAndTranspose(a)
    Base object if memory is from some other object.

    Examples
    --------
    The base of an array that owns its memory is None:

    >>> x = np.array([1,2,3,4])
    >>> x.base is None
    True

    Slicing creates a view, whose memory is shared with x:

    >>> y = x[2:]
    >>> y.base is x
    True

    
    zeros(shape, dtype=float, order='C')

    Return a new array of given shape and type, filled with zeros.

    Parameters
    ----------
    shape : int or sequence of ints
        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
    dtype : data-type, optional
        The desired data-type for the array, e.g., `numpy.int8`.  Default is
        `numpy.float64`.
    order : {'C', 'F'}, optional
        Whether to store multidimensional data in C- or Fortran-contiguous
        (row- or column-wise) order in memory.

    Returns
    -------
    out : ndarray
        Array of zeros with the given shape, dtype, and order.

    See Also
    --------
    zeros_like : Return an array of zeros with shape and type of input.
    ones_like : Return an array of ones with shape and type of input.
    empty_like : Return an empty array with shape and type of input.
    ones : Return a new array setting values to one.
    empty : Return a new uninitialized array.

    Examples
    --------
    >>> np.zeros(5)
    array([ 0.,  0.,  0.,  0.,  0.])

    >>> np.zeros((5,), dtype=numpy.int)
    array([0, 0, 0, 0, 0])

    >>> np.zeros((2, 1))
    array([[ 0.],
           [ 0.]])

    >>> s = (2,2)
    >>> np.zeros(s)
    array([[ 0.,  0.],
           [ 0.,  0.]])

    >>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype
    array([(0, 0), (0, 0)],
          dtype=[('x', '<i4'), ('y', '<i4')])

    
    a.sort(axis=-1, kind='quicksort', order=None)

    Sort an array, in-place.

    Parameters
    ----------
    axis : int, optional
        Axis along which to sort. Default is -1, which means sort along the
        last axis.
    kind : {'quicksort', 'mergesort', 'heapsort'}, optional
        Sorting algorithm. Default is 'quicksort'.
    order : list, optional
        When `a` is an array with fields defined, this argument specifies
        which fields to compare first, second, etc.  Not all fields need be
        specified.

    See Also
    --------
    numpy.sort : Return a sorted copy of an array.
    argsort : Indirect sort.
    lexsort : Indirect stable sort on multiple keys.
    searchsorted : Find elements in sorted array.
    partition: Partial sort.

    Notes
    -----
    See ``sort`` for notes on the different sorting algorithms.

    Examples
    --------
    >>> a = np.array([[1,4], [3,1]])
    >>> a.sort(axis=1)
    >>> a
    array([[1, 4],
           [1, 3]])
    >>> a.sort(axis=0)
    >>> a
    array([[1, 3],
           [1, 4]])

    Use the `order` keyword to specify a field to use when sorting a
    structured array:

    >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])
    >>> a.sort(order='y')
    >>> a
    array([('c', 1), ('a', 2)],
          dtype=[('x', '|S1'), ('y', '<i4')])

    
    Returns a list with types grouped input->output.

    Data attribute listing the data-type "Domain-Range" groupings the ufunc can
    deliver. The data-types are given using the character codes.

    See Also
    --------
    numpy.ufunc.ntypes

    Examples
    --------
    >>> np.add.types
    ['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l',
    'LL->L', 'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D',
    'GG->G', 'OO->O']

    >>> np.multiply.types
    ['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l',
    'LL->L', 'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D',
    'GG->G', 'OO->O']

    >>> np.power.types
    ['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', 'LL->L',
    'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D', 'GG->G',
    'OO->O']

    >>> np.exp.types
    ['f->f', 'd->d', 'g->g', 'F->F', 'D->D', 'G->G', 'O->O']

    >>> np.remainder.types
    ['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', 'LL->L',
    'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'OO->O']

    
    A character code (one of 'biufcSUV') identifying the general kind of data.

    
    a.conj()

    Complex-conjugate all elements.

    Refer to `numpy.conjugate` for full documentation.

    See Also
    --------
    numpy.conjugate : equivalent function

    
    a.dumps()

    Returns the pickle of the array as a string.
    pickle.loads or numpy.loads will convert the string back to an array.

    Parameters
    ----------
    None

    Tuple of bytes steps in each dimension.The length of the scalar in bytes.
    ravel_multi_index(multi_index, dims, mode='raise', order='C')

    Converts a tuple of index arrays into an array of flat
    indices, applying boundary modes to the multi-index.

    Parameters
    ----------
    multi_index : tuple of array_like
        A tuple of integer arrays, one array for each dimension.
    dims : tuple of ints
        The shape of array into which the indices from ``multi_index`` apply.
    mode : {'raise', 'wrap', 'clip'}, optional
        Specifies how out-of-bounds indices are handled.  Can specify
        either one mode or a tuple of modes, one mode per index.

        * 'raise' -- raise an error (default)
        * 'wrap' -- wrap around
        * 'clip' -- clip to the range

        In 'clip' mode, a negative index which would normally
        wrap will clip to 0 instead.
    order : {'C', 'F'}, optional
        Determines whether the multi-index should be viewed as indexing in
        C (row-major) order or FORTRAN (column-major) order.

    Returns
    -------
    raveled_indices : ndarray
        An array of indices into the flattened version of an array
        of dimensions ``dims``.

    See Also
    --------
    unravel_index

    Notes
    -----
    .. versionadded:: 1.6.0

    Examples
    --------
    >>> arr = np.array([[3,6,6],[4,5,1]])
    >>> np.ravel_multi_index(arr, (7,6))
    array([22, 41, 37])
    >>> np.ravel_multi_index(arr, (7,6), order='F')
    array([31, 41, 13])
    >>> np.ravel_multi_index(arr, (4,6), mode='clip')
    array([22, 23, 19])
    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))
    array([12, 13, 13])

    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))
    1621
    
    reduceat(a, indices, axis=0, dtype=None, out=None)

    Performs a (local) reduce with specified slices over a single axis.

    For i in ``range(len(indices))``, `reduceat` computes
    ``ufunc.reduce(a[indices[i]:indices[i+1]])``, which becomes the i-th
    generalized "row" parallel to `axis` in the final result (i.e., in a
    2-D array, for example, if `axis = 0`, it becomes the i-th row, but if
    `axis = 1`, it becomes the i-th column).  There are two exceptions to this:

      * when ``i = len(indices) - 1`` (so for the last index),
        ``indices[i+1] = a.shape[axis]``.
      * if ``indices[i] >= indices[i + 1]``, the i-th generalized "row" is
        simply ``a[indices[i]]``.

    The shape of the output depends on the size of `indices`, and may be
    larger than `a` (this happens if ``len(indices) > a.shape[axis]``).

    Parameters
    ----------
    a : array_like
        The array to act on.
    indices : array_like
        Paired indices, comma separated (not colon), specifying slices to
        reduce.
    axis : int, optional
        The axis along which to apply the reduceat.
    dtype : data-type code, optional
        The type used to represent the intermediate results. Defaults
        to the data type of the output array if this is provided, or
        the data type of the input array if no output array is provided.
    out : ndarray, optional
        A location into which the result is stored. If not provided a
        freshly-allocated array is returned.

    Returns
    -------
    r : ndarray
        The reduced values. If `out` was supplied, `r` is a reference to
        `out`.

    Notes
    -----
    A descriptive example:

    If `a` is 1-D, the function `ufunc.accumulate(a)` is the same as
    ``ufunc.reduceat(a, indices)[::2]`` where `indices` is
    ``range(len(array) - 1)`` with a zero placed
    in every other element:
    ``indices = zeros(2 * len(a) - 1)``, ``indices[1::2] = range(1, len(a))``.

    Don't be fooled by this attribute's name: `reduceat(a)` is not
    necessarily smaller than `a`.

    Examples
    --------
    To take the running sum of four successive values:

    >>> np.add.reduceat(np.arange(8),[0,4, 1,5, 2,6, 3,7])[::2]
    array([ 6, 10, 14, 18])

    A 2-D example:

    >>> x = np.linspace(0, 15, 16).reshape(4,4)
    >>> x
    array([[  0.,   1.,   2.,   3.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.],
           [ 12.,  13.,  14.,  15.]])

    ::

     # reduce such that the result has the following five rows:
     # [row1 + row2 + row3]
     # [row4]
     # [row2]
     # [row3]
     # [row1 + row2 + row3 + row4]

    >>> np.add.reduceat(x, [0, 3, 1, 2, 0])
    array([[ 12.,  15.,  18.,  21.],
           [ 12.,  13.,  14.,  15.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.],
           [ 24.,  28.,  32.,  36.]])

    ::

     # reduce such that result has the following two columns:
     # [col1 * col2 * col3, col4]

    >>> np.multiply.reduceat(x, [0, 3], 1)
    array([[    0.,     3.],
           [  120.,     7.],
           [  720.,    11.],
           [ 2184.,    15.]])

    The length of one element in bytes.
    Current flat index into the array.

    Examples
    --------
    >>> x = np.arange(6).reshape(2, 3)
    >>> fl = x.flat
    >>> fl.index
    0
    >>> fl.next()
    0
    >>> fl.index
    1

    
    An object to simplify the interaction of the array with the ctypes
    module.

    This attribute creates an object that makes it easier to use arrays
    when calling shared libraries with the ctypes module. The returned
    object has, among others, data, shape, and strides attributes (see
    Notes below) which themselves return ctypes objects that can be used
    as arguments to a shared library.

    Parameters
    ----------
    None

    Returns
    -------
    c : Python object
        Possessing attributes data, shape, strides, etc.

    See Also
    --------
    numpy.ctypeslib

    Notes
    -----
    Below are the public attributes of this object which were documented
    in "Guide to NumPy" (we have omitted undocumented public attributes,
    as well as documented private attributes):

    * data: A pointer to the memory area of the array as a Python integer.
      This memory area may contain data that is not aligned, or not in correct
      byte-order. The memory area may not even be writeable. The array
      flags and data-type of this array should be respected when passing this
      attribute to arbitrary C-code to avoid trouble that can include Python
      crashing. User Beware! The value of this attribute is exactly the same
      as self._array_interface_['data'][0].

    * shape (c_intp*self.ndim): A ctypes array of length self.ndim where
      the basetype is the C-integer corresponding to dtype('p') on this
      platform. This base-type could be c_int, c_long, or c_longlong
      depending on the platform. The c_intp type is defined accordingly in
      numpy.ctypeslib. The ctypes array contains the shape of the underlying
      array.

    * strides (c_intp*self.ndim): A ctypes array of length self.ndim where
      the basetype is the same as for the shape attribute. This ctypes array
      contains the strides information from the underlying array. This strides
      information is important for showing how many bytes must be jumped to
      get to the next element in the array.

    * data_as(obj): Return the data pointer cast to a particular c-types object.
      For example, calling self._as_parameter_ is equivalent to
      self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a
      pointer to a ctypes array of floating-point data:
      self.data_as(ctypes.POINTER(ctypes.c_double)).

    * shape_as(obj): Return the shape tuple as an array of some other c-types
      type. For example: self.shape_as(ctypes.c_short).

    * strides_as(obj): Return the strides tuple as an array of some other
      c-types type. For example: self.strides_as(ctypes.c_longlong).

    Be careful using the ctypes attribute - especially on temporary
    arrays or arrays constructed on the fly. For example, calling
    ``(a+b).ctypes.data_as(ctypes.c_void_p)`` returns a pointer to memory
    that is invalid because the array created as (a+b) is deallocated
    before the next Python statement. You can avoid this problem using
    either ``c=a+b`` or ``ct=(a+b).ctypes``. In the latter case, ct will
    hold a reference to the array until ct is deleted or re-assigned.

    If the ctypes module is not available, then the ctypes attribute
    of array objects still returns something useful, but ctypes objects
    are not returned and errors may be raised instead. In particular,
    the object will still have the as parameter attribute which will
    return an integer equal to the data attribute.

    Examples
    --------
    >>> import ctypes
    >>> x
    array([[0, 1],
           [2, 3]])
    >>> x.ctypes.data
    30439712
    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long))
    <ctypes.LP_c_long object at 0x01F01300>
    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_long)).contents
    c_long(0)
    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_longlong)).contents
    c_longlong(4294967296L)
    >>> x.ctypes.shape
    <numpy.core._internal.c_long_Array_2 object at 0x01FFD580>
    >>> x.ctypes.shape_as(ctypes.c_long)
    <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>
    >>> x.ctypes.strides
    <numpy.core._internal.c_long_Array_2 object at 0x01FCE620>
    >>> x.ctypes.strides_as(ctypes.c_longlong)
    <numpy.core._internal.c_longlong_Array_2 object at 0x01F01300>

    
    newbuffer(size)

    Return a new uninitialized buffer object.

    Parameters
    ----------
    size : int
        Size in bytes of returned buffer object.

    Returns
    -------
    newbuffer : buffer object
        Returned, uninitialized buffer object of `size` bytes.

    
    Boolean indicating whether the byte order of this dtype is native
    to the platform.

    8-bit integer. Character code ``b``. C char compatible.
    A 1-D iterator over the array.

    This is a `numpy.flatiter` instance, which acts similarly to, but is not
    a subclass of, Python's built-in iterator object.

    See Also
    --------
    flatten : Return a copy of the array collapsed into one dimension.

    flatiter

    Examples
    --------
    >>> x = np.arange(1, 7).reshape(2, 3)
    >>> x
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> x.flat[3]
    4
    >>> x.T
    array([[1, 4],
           [2, 5],
           [3, 6]])
    >>> x.T.flat[3]
    5
    >>> type(x.flat)
    <type 'numpy.flatiter'>

    An assignment example:

    >>> x.flat = 3; x
    array([[3, 3, 3],
           [3, 3, 3]])
    >>> x.flat[[1,4]] = 1; x
    array([[3, 1, 3],
           [3, 1, 3]])

    
    An N-dimensional tuple of current coordinates.

    Examples
    --------
    >>> x = np.arange(6).reshape(2, 3)
    >>> fl = x.flat
    >>> fl.coords
    (0, 0)
    >>> fl.next()
    0
    >>> fl.coords
    (0, 1)

    
    Integer indicating how this dtype relates to the built-in dtypes.

    Read-only.

    =  ========================================================================
    0  if this is a structured array type, with fields
    1  if this is a dtype compiled into numpy (such as ints, floats etc)
    2  if the dtype is for a user-defined numpy type
       A user-defined type uses the numpy C-API machinery to extend
       numpy to handle a new array type. See
       :ref:`user.user-defined-data-types` in the Numpy manual.
    =  ========================================================================

    Examples
    --------
    >>> dt = np.dtype('i2')
    >>> dt.isbuiltin
    1
    >>> dt = np.dtype('f8')
    >>> dt.isbuiltin
    1
    >>> dt = np.dtype([('field1', 'f8')])
    >>> dt.isbuiltin
    0

    
    A character indicating the byte-order of this data-type object.

    One of:

    ===  ==============
    '='  native
    '<'  little-endian
    '>'  big-endian
    '|'  not applicable
    ===  ==============

    All built-in data-type objects have byteorder either '=' or '|'.

    Examples
    --------

    >>> dt = np.dtype('i2')
    >>> dt.byteorder
    '='
    >>> # endian is not relevant for 8 bit numbers
    >>> np.dtype('i1').byteorder
    '|'
    >>> # or ASCII strings
    >>> np.dtype('S2').byteorder
    '|'
    >>> # Even if specific code is given, and it is native
    >>> # '=' is the byteorder
    >>> import sys
    >>> sys_is_le = sys.byteorder == 'little'
    >>> native_code = sys_is_le and '<' or '>'
    >>> swapped_code = sys_is_le and '>' or '<'
    >>> dt = np.dtype(native_code + 'i2')
    >>> dt.byteorder
    '='
    >>> # Swapped code shows up as itself
    >>> dt = np.dtype(swapped_code + 'i2')
    >>> dt.byteorder == swapped_code
    True

    
    a.max(axis=None, out=None)

    Return the maximum along a given axis.

    Refer to `numpy.amax` for full documentation.

    See Also
    --------
    numpy.amax : equivalent function

    
    busdaycalendar(weekmask='1111100', holidays=None)

    A business day calendar object that efficiently stores information
    defining valid days for the busday family of functions.

    The default valid days are Monday through Friday ("business days").
    A busdaycalendar object can be specified with any set of weekly
    valid days, plus an optional "holiday" dates that always will be invalid.

    Once a busdaycalendar object is created, the weekmask and holidays
    cannot be modified.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    weekmask : str or array_like of bool, optional
        A seven-element array indicating which of Monday through Sunday are
        valid days. May be specified as a length-seven list or array, like
        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
        weekdays, optionally separated by white space. Valid abbreviations
        are: Mon Tue Wed Thu Fri Sat Sun
    holidays : array_like of datetime64[D], optional
        An array of dates to consider as invalid dates, no matter which
        weekday they fall upon.  Holiday dates may be specified in any
        order, and NaT (not-a-time) dates are ignored.  This list is
        saved in a normalized form that is suited for fast calculations
        of valid days.

    Returns
    -------
    out : busdaycalendar
        A business day calendar object containing the specified
        weekmask and holidays values.

    See Also
    --------
    is_busday : Returns a boolean array indicating valid days.
    busday_offset : Applies an offset counted in valid days.
    busday_count : Counts how many valid days are in a half-open date range.

    Attributes
    ----------
    Note: once a busdaycalendar object is created, you cannot modify the
    weekmask or holidays.  The attributes return copies of internal data.
    weekmask : (copy) seven-element array of bool
    holidays : (copy) sorted array of datetime64[D]

    Examples
    --------
    >>> # Some important days in July
    ... bdd = np.busdaycalendar(
    ...             holidays=['2011-07-01', '2011-07-04', '2011-07-17'])
    >>> # Default is Monday to Friday weekdays
    ... bdd.weekmask
    array([ True,  True,  True,  True,  True, False, False], dtype='bool')
    >>> # Any holidays already on the weekend are removed
    ... bdd.holidays
    array(['2011-07-01', '2011-07-04'], dtype='datetime64[D]')
    
    a.clip(a_min, a_max, out=None)

    Return an array whose values are limited to ``[a_min, a_max]``.

    Refer to `numpy.clip` for full documentation.

    See Also
    --------
    numpy.clip : equivalent function

    a.__deepcopy__() -> Deep copy of array.

    Used if copy.deepcopy is called on an array.

    
    a.put(indices, values, mode='raise')

    Set ``a.flat[n] = values[n]`` for all `n` in indices.

    Refer to `numpy.put` for full documentation.

    See Also
    --------
    numpy.put : equivalent function

    
    Information about the memory layout of the array.

    Attributes
    ----------
    C_CONTIGUOUS (C)
        The data is in a single, C-style contiguous segment.
    F_CONTIGUOUS (F)
        The data is in a single, Fortran-style contiguous segment.
    OWNDATA (O)
        The array owns the memory it uses or borrows it from another object.
    WRITEABLE (W)
        The data area can be written to.  Setting this to False locks
        the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE
        from its base array at creation time, but a view of a writeable
        array may be subsequently locked while the base array remains writeable.
        (The opposite is not true, in that a view of a locked array may not
        be made writeable.  However, currently, locking a base object does not
        lock any views that already reference it, so under that circumstance it
        is possible to alter the contents of a locked array via a previously
        created writeable view onto it.)  Attempting to change a non-writeable
        array raises a RuntimeError exception.
    ALIGNED (A)
        The data and all elements are aligned appropriately for the hardware.
    UPDATEIFCOPY (U)
        This array is a copy of some other array. When this array is
        deallocated, the base array will be updated with the contents of
        this array.
    FNC
        F_CONTIGUOUS and not C_CONTIGUOUS.
    FORC
        F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).
    BEHAVED (B)
        ALIGNED and WRITEABLE.
    CARRAY (CA)
        BEHAVED and C_CONTIGUOUS.
    FARRAY (FA)
        BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.

    Notes
    -----
    The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),
    or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag
    names are only supported in dictionary access.

    Only the UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by
    the user, via direct assignment to the attribute or dictionary entry,
    or by calling `ndarray.setflags`.

    The array flags cannot be set arbitrarily:

    - UPDATEIFCOPY can only be set ``False``.
    - ALIGNED can only be set ``True`` if the data is truly aligned.
    - WRITEABLE can only be set ``True`` if the array owns its own memory
      or the ultimate owner of the memory exposes a writeable buffer
      interface or is a string.

    Arrays can be both C-style and Fortran-style contiguous simultaneously.
    This is clear for 1-dimensional arrays, but can also be true for higher
    dimensional arrays.

    Even for contiguous arrays a stride for a given dimension
    ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``
    or the array has no elements.
    It does *not* generally hold that ``self.strides[-1] == self.itemsize``
    for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for
    Fortran-style contiguous arrays is true.
    
This is only meant to add docs to objects defined in C-extension modules.
The purpose is to allow easier editing of the docstrings without
requiring a re-compile.

NOTE: Many of the methods of ndarray have corresponding functions.
      If you update these docstrings, please keep also the ones in
      core/fromnumeric.py, core/defmatrix.py up-to-date.


    copy()

    Get a copy of the iterator as a 1-D array.

    Examples
    --------
    >>> x = np.arange(6).reshape(2, 3)
    >>> x
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> fl = x.flat
    >>> fl.copy()
    array([0, 1, 2, 3, 4, 5])

    
    a.argmax(axis=None, out=None)

    Return indices of the maximum values along the given axis.

    Refer to `numpy.argmax` for full documentation.

    See Also
    --------
    numpy.argmax : equivalent function

    
    The real part of the array.

    Examples
    --------
    >>> x = np.sqrt([1+0j, 0+1j])
    >>> x.real
    array([ 1.        ,  0.70710678])
    >>> x.real.dtype
    dtype('float64')

    See Also
    --------
    numpy.real : equivalent function

    
    fromfile(file, dtype=float, count=-1, sep='')

    Construct an array from data in a text or binary file.

    A highly efficient way of reading binary data with a known data-type,
    as well as parsing simply formatted text files.  Data written using the
    `tofile` method can be read using this function.

    Parameters
    ----------
    file : file or str
        Open file object or filename.
    dtype : data-type
        Data type of the returned array.
        For binary files, it is used to determine the size and byte-order
        of the items in the file.
    count : int
        Number of items to read. ``-1`` means all items (i.e., the complete
        file).
    sep : str
        Separator between items if file is a text file.
        Empty ("") separator means the file should be treated as binary.
        Spaces (" ") in the separator match zero or more whitespace characters.
        A separator consisting only of spaces must match at least one
        whitespace.

    See also
    --------
    load, save
    ndarray.tofile
    loadtxt : More flexible way of loading data from a text file.

    Notes
    -----
    Do not rely on the combination of `tofile` and `fromfile` for
    data storage, as the binary files generated are are not platform
    independent.  In particular, no byte-order or data-type information is
    saved.  Data can be stored in the platform independent ``.npy`` format
    using `save` and `load` instead.

    Examples
    --------
    Construct an ndarray:

    >>> dt = np.dtype([('time', [('min', int), ('sec', int)]),
    ...                ('temp', float)])
    >>> x = np.zeros((1,), dtype=dt)
    >>> x['time']['min'] = 10; x['temp'] = 98.25
    >>> x
    array([((10, 0), 98.25)],
          dtype=[('time', [('min', '<i4'), ('sec', '<i4')]), ('temp', '<f8')])

    Save the raw data to disk:

    >>> import os
    >>> fname = os.tmpnam()
    >>> x.tofile(fname)

    Read the raw data from disk:

    >>> np.fromfile(fname, dtype=dt)
    array([((10, 0), 98.25)],
          dtype=[('time', [('min', '<i4'), ('sec', '<i4')]), ('temp', '<f8')])

    The recommended way to store and load data:

    >>> np.save(fname, x)
    >>> np.load(fname + '.npy')
    array([((10, 0), 98.25)],
          dtype=[('time', [('min', '<i4'), ('sec', '<i4')]), ('temp', '<f8')])

    
    dtype(obj, align=False, copy=False)

    Create a data type object.

    A numpy array is homogeneous, and contains elements described by a
    dtype object. A dtype object can be constructed from different
    combinations of fundamental numeric types.

    Parameters
    ----------
    obj
        Object to be converted to a data type object.
    align : bool, optional
        Add padding to the fields to match what a C compiler would output
        for a similar C-struct. Can be ``True`` only if `obj` is a dictionary
        or a comma-separated string. If a struct dtype is being created,
        this also sets a sticky alignment flag ``isalignedstruct``.
    copy : bool, optional
        Make a new copy of the data-type object. If ``False``, the result
        may just be a reference to a built-in data-type object.

    See also
    --------
    result_type

    Examples
    --------
    Using array-scalar type:

    >>> np.dtype(np.int16)
    dtype('int16')

    Record, one field name 'f1', containing int16:

    >>> np.dtype([('f1', np.int16)])
    dtype([('f1', '<i2')])

    Record, one field named 'f1', in itself containing a record with one field:

    >>> np.dtype([('f1', [('f1', np.int16)])])
    dtype([('f1', [('f1', '<i2')])])

    Record, two fields: the first field contains an unsigned int, the
    second an int32:

    >>> np.dtype([('f1', np.uint), ('f2', np.int32)])
    dtype([('f1', '<u4'), ('f2', '<i4')])

    Using array-protocol type strings:

    >>> np.dtype([('a','f8'),('b','S10')])
    dtype([('a', '<f8'), ('b', '|S10')])

    Using comma-separated field formats.  The shape is (2,3):

    >>> np.dtype("i4, (2,3)f8")
    dtype([('f0', '<i4'), ('f1', '<f8', (2, 3))])

    Using tuples.  ``int`` is a fixed type, 3 the field's shape.  ``void``
    is a flexible type, here of size 10:

    >>> np.dtype([('hello',(np.int,3)),('world',np.void,10)])
    dtype([('hello', '<i4', 3), ('world', '|V10')])

    Subdivide ``int16`` into 2 ``int8``'s, called x and y.  0 and 1 are
    the offsets in bytes:

    >>> np.dtype((np.int16, {'x':(np.int8,0), 'y':(np.int8,1)}))
    dtype(('<i2', [('x', '|i1'), ('y', '|i1')]))

    Using dictionaries.  Two fields named 'gender' and 'age':

    >>> np.dtype({'names':['gender','age'], 'formats':['S1',np.uint8]})
    dtype([('gender', '|S1'), ('age', '|u1')])

    Offsets in bytes, here 0 and 25:

    >>> np.dtype({'surname':('S25',0),'age':(np.uint8,25)})
    dtype([('surname', '|S25'), ('age', '|u1')])

    
    a.prod(axis=None, dtype=None, out=None)

    Return the product of the array elements over the given axis

    Refer to `numpy.prod` for full documentation.

    See Also
    --------
    numpy.prod : equivalent function

    
    Change `dot`, `vdot`, and `inner` to use accelerated BLAS functions.

    Typically, as a user of Numpy, you do not explicitly call this function. If
    Numpy is built with an accelerated BLAS, this function is automatically
    called when Numpy is imported.

    When Numpy is built with an accelerated BLAS like ATLAS, these functions
    are replaced to make use of the faster implementations.  The faster
    implementations only affect float32, float64, complex64, and complex128
    arrays. Furthermore, the BLAS API only includes matrix-matrix,
    matrix-vector, and vector-vector products. Products of arrays with larger
    dimensionalities use the built in functions and are not accelerated.

    See Also
    --------
    restoredot : `restoredot` undoes the effects of `alterdot`.

    set_typeDict(dict)

    Set the internal dictionary that can look up an array type using a
    registered code.

    
    result_type(*arrays_and_dtypes)

    Returns the type that results from applying the NumPy
    type promotion rules to the arguments.

    Type promotion in NumPy works similarly to the rules in languages
    like C++, with some slight differences.  When both scalars and
    arrays are used, the array's type takes precedence and the actual value
    of the scalar is taken into account.

    For example, calculating 3*a, where a is an array of 32-bit floats,
    intuitively should result in a 32-bit float output.  If the 3 is a
    32-bit integer, the NumPy rules indicate it can't convert losslessly
    into a 32-bit float, so a 64-bit float should be the result type.
    By examining the value of the constant, '3', we see that it fits in
    an 8-bit integer, which can be cast losslessly into the 32-bit float.

    Parameters
    ----------
    arrays_and_dtypes : list of arrays and dtypes
        The operands of some operation whose result type is needed.

    Returns
    -------
    out : dtype
        The result type.

    See also
    --------
    dtype, promote_types, min_scalar_type, can_cast

    Notes
    -----
    .. versionadded:: 1.6.0

    The specific algorithm used is as follows.

    Categories are determined by first checking which of boolean,
    integer (int/uint), or floating point (float/complex) the maximum
    kind of all the arrays and the scalars are.

    If there are only scalars or the maximum category of the scalars
    is higher than the maximum category of the arrays,
    the data types are combined with :func:`promote_types`
    to produce the return value.

    Otherwise, `min_scalar_type` is called on each array, and
    the resulting data types are all combined with :func:`promote_types`
    to produce the return value.

    The set of int values is not a subset of the uint values for types
    with the same number of bits, something not reflected in
    :func:`min_scalar_type`, but handled as a special case in `result_type`.

    Examples
    --------
    >>> np.result_type(3, np.arange(7, dtype='i1'))
    dtype('int8')

    >>> np.result_type('i4', 'c8')
    dtype('complex128')

    >>> np.result_type(3.0, -2)
    dtype('float64')

    
    concatenate((a1, a2, ...), axis=0)

    Join a sequence of arrays together.

    Parameters
    ----------
    a1, a2, ... : sequence of array_like
        The arrays must have the same shape, except in the dimension
        corresponding to `axis` (the first, by default).
    axis : int, optional
        The axis along which the arrays will be joined.  Default is 0.

    Returns
    -------
    res : ndarray
        The concatenated array.

    See Also
    --------
    ma.concatenate : Concatenate function that preserves input masks.
    array_split : Split an array into multiple sub-arrays of equal or
                  near-equal size.
    split : Split array into a list of multiple sub-arrays of equal size.
    hsplit : Split array into multiple sub-arrays horizontally (column wise)
    vsplit : Split array into multiple sub-arrays vertically (row wise)
    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).
    hstack : Stack arrays in sequence horizontally (column wise)
    vstack : Stack arrays in sequence vertically (row wise)
    dstack : Stack arrays in sequence depth wise (along third dimension)

    Notes
    -----
    When one or more of the arrays to be concatenated is a MaskedArray,
    this function will return a MaskedArray object instead of an ndarray,
    but the input masks are *not* preserved. In cases where a MaskedArray
    is expected as input, use the ma.concatenate function from the masked
    array module instead.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4]])
    >>> b = np.array([[5, 6]])
    >>> np.concatenate((a, b), axis=0)
    array([[1, 2],
           [3, 4],
           [5, 6]])
    >>> np.concatenate((a, b.T), axis=1)
    array([[1, 2, 5],
           [3, 4, 6]])

    This function will not preserve masking of MaskedArray inputs.

    >>> a = np.ma.arange(3)
    >>> a[1] = np.ma.masked
    >>> b = np.arange(2, 5)
    >>> a
    masked_array(data = [0 -- 2],
                 mask = [False  True False],
           fill_value = 999999)
    >>> b
    array([2, 3, 4])
    >>> np.concatenate([a, b])
    masked_array(data = [0 1 2 2 3 4],
                 mask = False,
           fill_value = 999999)
    >>> np.ma.concatenate([a, b])
    masked_array(data = [0 -- 2 2 3 4],
                 mask = [False  True False False False False],
           fill_value = 999999)

    
    bincount(x, weights=None, minlength=None)

    Count number of occurrences of each value in array of non-negative ints.

    The number of bins (of size 1) is one larger than the largest value in
    `x`. If `minlength` is specified, there will be at least this number
    of bins in the output array (though it will be longer if necessary,
    depending on the contents of `x`).
    Each bin gives the number of occurrences of its index value in `x`.
    If `weights` is specified the input array is weighted by it, i.e. if a
    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead
    of ``out[n] += 1``.

    Parameters
    ----------
    x : array_like, 1 dimension, nonnegative ints
        Input array.
    weights : array_like, optional
        Weights, array of the same shape as `x`.
    minlength : int, optional
        .. versionadded:: 1.6.0

        A minimum number of bins for the output array.

    Returns
    -------
    out : ndarray of ints
        The result of binning the input array.
        The length of `out` is equal to ``np.amax(x)+1``.

    Raises
    ------
    ValueError
        If the input is not 1-dimensional, or contains elements with negative
        values, or if `minlength` is non-positive.
    TypeError
        If the type of the input is float or complex.

    See Also
    --------
    histogram, digitize, unique

    Examples
    --------
    >>> np.bincount(np.arange(5))
    array([1, 1, 1, 1, 1])
    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))
    array([1, 3, 1, 1, 0, 0, 0, 1])

    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])
    >>> np.bincount(x).size == np.amax(x)+1
    True

    The input array needs to be of integer dtype, otherwise a
    TypeError is raised:

    >>> np.bincount(np.arange(5, dtype=np.float))
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    TypeError: array cannot be safely cast to required type

    A possible use of ``bincount`` is to perform sums over
    variable-size chunks of an array, using the ``weights`` keyword.

    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights
    >>> x = np.array([0, 1, 1, 2, 2, 2])
    >>> np.bincount(x,  weights=w)
    array([ 0.3,  0.7,  1.1])

    _get_ndarray_c_version()

    Return the compile time NDARRAY_VERSION number.

    Array protocol: Python side.The real part of the scalar.The number of elements in the gentype.
    Base class for numpy scalar types.

    Class from which most (all?) numpy scalar types are derived.  For
    consistency, exposes the same API as `ndarray`, despite many
    consequent attributes being either "get-only," or completely irrelevant.
    This is the class from which it is strongly suggested users should derive
    custom scalar types.

    
    ndarray(shape, dtype=float, buffer=None, offset=0,
            strides=None, order=None)

    An array object represents a multidimensional, homogeneous array
    of fixed-size items.  An associated data-type object describes the
    format of each element in the array (its byte-order, how many bytes it
    occupies in memory, whether it is an integer, a floating point number,
    or something else, etc.)

    Arrays should be constructed using `array`, `zeros` or `empty` (refer
    to the See Also section below).  The parameters given here refer to
    a low-level method (`ndarray(...)`) for instantiating an array.

    For more information, refer to the `numpy` module and examine the
    the methods and attributes of an array.

    Parameters
    ----------
    (for the __new__ method; see Notes below)

    shape : tuple of ints
        Shape of created array.
    dtype : data-type, optional
        Any object that can be interpreted as a numpy data type.
    buffer : object exposing buffer interface, optional
        Used to fill the array with data.
    offset : int, optional
        Offset of array data in buffer.
    strides : tuple of ints, optional
        Strides of data in memory.
    order : {'C', 'F'}, optional
        Row-major or column-major order.

    Attributes
    ----------
    T : ndarray
        Transpose of the array.
    data : buffer
        The array's elements, in memory.
    dtype : dtype object
        Describes the format of the elements in the array.
    flags : dict
        Dictionary containing information related to memory use, e.g.,
        'C_CONTIGUOUS', 'OWNDATA', 'WRITEABLE', etc.
    flat : numpy.flatiter object
        Flattened version of the array as an iterator.  The iterator
        allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for
        assignment examples; TODO).
    imag : ndarray
        Imaginary part of the array.
    real : ndarray
        Real part of the array.
    size : int
        Number of elements in the array.
    itemsize : int
        The memory use of each array element in bytes.
    nbytes : int
        The total number of bytes required to store the array data,
        i.e., ``itemsize * size``.
    ndim : int
        The array's number of dimensions.
    shape : tuple of ints
        Shape of the array.
    strides : tuple of ints
        The step-size required to move from one element to the next in
        memory. For example, a contiguous ``(3, 4)`` array of type
        ``int16`` in C-order has strides ``(8, 2)``.  This implies that
        to move from element to element in memory requires jumps of 2 bytes.
        To move from row-to-row, one needs to jump 8 bytes at a time
        (``2 * 4``).
    ctypes : ctypes object
        Class containing properties of the array needed for interaction
        with ctypes.
    base : ndarray
        If the array is a view into another array, that array is its `base`
        (unless that array is also a view).  The `base` array is where the
        array data is actually stored.

    See Also
    --------
    array : Construct an array.
    zeros : Create an array, each element of which is zero.
    empty : Create an array, but leave its allocated memory unchanged (i.e.,
            it contains "garbage").
    dtype : Create a data-type.

    Notes
    -----
    There are two modes of creating an array using ``__new__``:

    1. If `buffer` is None, then only `shape`, `dtype`, and `order`
       are used.
    2. If `buffer` is an object exposing the buffer interface, then
       all keywords are interpreted.

    No ``__init__`` method is needed because the array is fully initialized
    after the ``__new__`` method.

    Examples
    --------
    These examples illustrate the low-level `ndarray` constructor.  Refer
    to the `See Also` section above for easier ways of constructing an
    ndarray.

    First mode, `buffer` is None:

    >>> np.ndarray(shape=(2,2), dtype=float, order='F')
    array([[ -1.13698227e+002,   4.25087011e-303],
           [  2.88528414e-306,   3.27025015e-309]])         #random

    Second mode:

    >>> np.ndarray((2,), buffer=np.array([1,2,3]),
    ...            offset=np.int_().itemsize,
    ...            dtype=int) # offset = 1*itemsize, i.e. skip first element
    array([2, 3])

    
    a.reshape(shape, order='C')

    Returns an array containing the same data with a new shape.

    Refer to `numpy.reshape` for full documentation.

    See Also
    --------
    numpy.reshape : equivalent function

    
    can_cast(from, totype, casting = 'safe')

    Returns True if cast between data types can occur according to the
    casting rule.  If from is a scalar or array scalar, also returns
    True if the scalar value can be cast without overflow or truncation
    to an integer.

    Parameters
    ----------
    from : dtype, dtype specifier, scalar, or array
        Data type, scalar, or array to cast from.
    totype : dtype or dtype specifier
        Data type to cast to.
    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
        Controls what kind of data casting may occur.

          * 'no' means the data types should not be cast at all.
          * 'equiv' means only byte-order changes are allowed.
          * 'safe' means only casts which can preserve values are allowed.
          * 'same_kind' means only safe casts or casts within a kind,
            like float64 to float32, are allowed.
          * 'unsafe' means any data conversions may be done.

    Returns
    -------
    out : bool
        True if cast can occur according to the casting rule.

    See also
    --------
    dtype, result_type

    Examples
    --------
    Basic examples

    >>> np.can_cast(np.int32, np.int64)
    True
    >>> np.can_cast(np.float64, np.complex)
    True
    >>> np.can_cast(np.complex, np.float)
    False

    >>> np.can_cast('i8', 'f8')
    True
    >>> np.can_cast('i8', 'f4')
    False
    >>> np.can_cast('i4', 'S4')
    True

    Casting scalars

    >>> np.can_cast(100, 'i1')
    True
    >>> np.can_cast(150, 'i1')
    False
    >>> np.can_cast(150, 'u1')
    True

    >>> np.can_cast(3.5e100, np.float32)
    False
    >>> np.can_cast(1000.0, np.float32)
    True

    Array scalar checks the value, array does not

    >>> np.can_cast(np.array(1000.0), np.float32)
    True
    >>> np.can_cast(np.array([1000.0]), np.float32)
    False

    Using the casting rules

    >>> np.can_cast('i8', 'i8', 'no')
    True
    >>> np.can_cast('<i8', '>i8', 'no')
    False

    >>> np.can_cast('<i8', '>i8', 'equiv')
    True
    >>> np.can_cast('<i4', '>i8', 'equiv')
    False

    >>> np.can_cast('<i4', '>i8', 'safe')
    True
    >>> np.can_cast('<i8', '>i4', 'safe')
    False

    >>> np.can_cast('<i8', '>i4', 'same_kind')
    True
    >>> np.can_cast('<i8', '>u4', 'same_kind')
    False

    >>> np.can_cast('<i8', '>u4', 'unsafe')
    True

    
    The imaginary part of the array.

    Examples
    --------
    >>> x = np.sqrt([1+0j, 0+1j])
    >>> x.imag
    array([ 0.        ,  0.70710678])
    >>> x.imag.dtype
    dtype('float64')

    
    add_ufunc_docstring(ufunc, new_docstring)

    Replace the docstring for a ufunc with new_docstring.
    This method will only work if the current docstring for
    the ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)

    Parameters
    ----------
    ufunc : numpy.ufunc
        A ufunc whose current doc is NULL.
    new_docstring : string
        The new docstring for the ufunc.

    Notes
    -----
    This method allocates memory for new_docstring on
    the heap. Technically this creates a mempory leak, since this
    memory will not be reclaimed until the end of the program
    even if the ufunc itself is removed. However this will only
    be a problem if the user is repeatedly creating ufuncs with
    no documentation, adding documentation via add_newdoc_ufunc,
    and then throwing away the ufunc.
    
    Ordered list of field names, or ``None`` if there are no fields.

    The names are ordered according to increasing byte offset. This can be
    used, for example, to walk through all of the named fields in offset order.

    Examples
    --------
    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])
    >>> dt.names
    ('name', 'grades')

    
    Complex number type composed of two 128-bit floats. Character code: 'G'.

    
    einsum(subscripts, *operands, out=None, dtype=None, order='K', casting='safe')

    Evaluates the Einstein summation convention on the operands.

    Using the Einstein summation convention, many common multi-dimensional
    array operations can be represented in a simple fashion.  This function
    provides a way compute such summations. The best way to understand this
    function is to try the examples below, which show how many common NumPy
    functions can be implemented as calls to `einsum`.

    Parameters
    ----------
    subscripts : str
        Specifies the subscripts for summation.
    operands : list of array_like
        These are the arrays for the operation.
    out : ndarray, optional
        If provided, the calculation is done into this array.
    dtype : data-type, optional
        If provided, forces the calculation to use the data type specified.
        Note that you may have to also give a more liberal `casting`
        parameter to allow the conversions.
    order : {'C', 'F', 'A', 'K'}, optional
        Controls the memory layout of the output. 'C' means it should
        be C contiguous. 'F' means it should be Fortran contiguous,
        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.
        'K' means it should be as close to the layout as the inputs as
        is possible, including arbitrarily permuted axes.
        Default is 'K'.
    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
        Controls what kind of data casting may occur.  Setting this to
        'unsafe' is not recommended, as it can adversely affect accumulations.

          * 'no' means the data types should not be cast at all.
          * 'equiv' means only byte-order changes are allowed.
          * 'safe' means only casts which can preserve values are allowed.
          * 'same_kind' means only safe casts or casts within a kind,
            like float64 to float32, are allowed.
          * 'unsafe' means any data conversions may be done.

    Returns
    -------
    output : ndarray
        The calculation based on the Einstein summation convention.

    See Also
    --------
    dot, inner, outer, tensordot

    Notes
    -----
    .. versionadded:: 1.6.0

    The subscripts string is a comma-separated list of subscript labels,
    where each label refers to a dimension of the corresponding operand.
    Repeated subscripts labels in one operand take the diagonal.  For example,
    ``np.einsum('ii', a)`` is equivalent to ``np.trace(a)``.

    Whenever a label is repeated, it is summed, so ``np.einsum('i,i', a, b)``
    is equivalent to ``np.inner(a,b)``.  If a label appears only once,
    it is not summed, so ``np.einsum('i', a)`` produces a view of ``a``
    with no changes.

    The order of labels in the output is by default alphabetical.  This
    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while
    ``np.einsum('ji', a)`` takes its transpose.

    The output can be controlled by specifying output subscript labels
    as well.  This specifies the label order, and allows summing to
    be disallowed or forced when desired.  The call ``np.einsum('i->', a)``
    is like ``np.sum(a, axis=-1)``, and ``np.einsum('ii->i', a)``
    is like ``np.diag(a)``.  The difference is that `einsum` does not
    allow broadcasting by default.

    To enable and control broadcasting, use an ellipsis.  Default
    NumPy-style broadcasting is done by adding an ellipsis
    to the left of each term, like ``np.einsum('...ii->...i', a)``.
    To take the trace along the first and last axes,
    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix
    product with the left-most indices instead of rightmost, you can do
    ``np.einsum('ij...,jk...->ik...', a, b)``.

    When there is only one operand, no axes are summed, and no output
    parameter is provided, a view into the operand is returned instead
    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``
    produces a view.

    An alternative way to provide the subscripts and operands is as
    ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``. The examples
    below have corresponding `einsum` calls with the two parameter methods.

    Examples
    --------
    >>> a = np.arange(25).reshape(5,5)
    >>> b = np.arange(5)
    >>> c = np.arange(6).reshape(2,3)

    >>> np.einsum('ii', a)
    60
    >>> np.einsum(a, [0,0])
    60
    >>> np.trace(a)
    60

    >>> np.einsum('ii->i', a)
    array([ 0,  6, 12, 18, 24])
    >>> np.einsum(a, [0,0], [0])
    array([ 0,  6, 12, 18, 24])
    >>> np.diag(a)
    array([ 0,  6, 12, 18, 24])

    >>> np.einsum('ij,j', a, b)
    array([ 30,  80, 130, 180, 230])
    >>> np.einsum(a, [0,1], b, [1])
    array([ 30,  80, 130, 180, 230])
    >>> np.dot(a, b)
    array([ 30,  80, 130, 180, 230])

    >>> np.einsum('ji', c)
    array([[0, 3],
           [1, 4],
           [2, 5]])
    >>> np.einsum(c, [1,0])
    array([[0, 3],
           [1, 4],
           [2, 5]])
    >>> c.T
    array([[0, 3],
           [1, 4],
           [2, 5]])

    >>> np.einsum('..., ...', 3, c)
    array([[ 0,  3,  6],
           [ 9, 12, 15]])
    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])
    array([[ 0,  3,  6],
           [ 9, 12, 15]])
    >>> np.multiply(3, c)
    array([[ 0,  3,  6],
           [ 9, 12, 15]])

    >>> np.einsum('i,i', b, b)
    30
    >>> np.einsum(b, [0], b, [0])
    30
    >>> np.inner(b,b)
    30

    >>> np.einsum('i,j', np.arange(2)+1, b)
    array([[0, 1, 2, 3, 4],
           [0, 2, 4, 6, 8]])
    >>> np.einsum(np.arange(2)+1, [0], b, [1])
    array([[0, 1, 2, 3, 4],
           [0, 2, 4, 6, 8]])
    >>> np.outer(np.arange(2)+1, b)
    array([[0, 1, 2, 3, 4],
           [0, 2, 4, 6, 8]])

    >>> np.einsum('i...->...', a)
    array([50, 55, 60, 65, 70])
    >>> np.einsum(a, [0,Ellipsis], [Ellipsis])
    array([50, 55, 60, 65, 70])
    >>> np.sum(a, axis=0)
    array([50, 55, 60, 65, 70])

    >>> a = np.arange(60.).reshape(3,4,5)
    >>> b = np.arange(24.).reshape(4,3,2)
    >>> np.einsum('ijk,jil->kl', a, b)
    array([[ 4400.,  4730.],
           [ 4532.,  4874.],
           [ 4664.,  5018.],
           [ 4796.,  5162.],
           [ 4928.,  5306.]])
    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])
    array([[ 4400.,  4730.],
           [ 4532.,  4874.],
           [ 4664.,  5018.],
           [ 4796.,  5162.],
           [ 4928.,  5306.]])
    >>> np.tensordot(a,b, axes=([1,0],[0,1]))
    array([[ 4400.,  4730.],
           [ 4532.,  4874.],
           [ 4664.,  5018.],
           [ 4796.,  5162.],
           [ 4928.,  5306.]])

    
    Functions that operate element by element on whole arrays.

    To see the documentation for a specific ufunc, use np.info().  For
    example, np.info(np.sin).  Because ufuncs are written in C
    (for speed) and linked into Python with NumPy's ufunc facility,
    Python's help() function finds this page whenever help() is called
    on a ufunc.

    A detailed explanation of ufuncs can be found in the "ufuncs.rst"
    file in the NumPy reference guide.

    Unary ufuncs:
    =============

    op(X, out=None)
    Apply op to X elementwise

    Parameters
    ----------
    X : array_like
        Input array.
    out : array_like
        An array to store the output. Must be the same shape as `X`.

    Returns
    -------
    r : array_like
        `r` will have the same shape as `X`; if out is provided, `r`
        will be equal to out.

    Binary ufuncs:
    ==============

    op(X, Y, out=None)
    Apply `op` to `X` and `Y` elementwise. May "broadcast" to make
    the shapes of `X` and `Y` congruent.

    The broadcasting rules are:

    * Dimensions of length 1 may be prepended to either array.
    * Arrays may be repeated along dimensions of length 1.

    Parameters
    ----------
    X : array_like
        First input array.
    Y : array_like
        Second input array.
    out : array_like
        An array to store the output. Must be the same shape as the
        output would have.

    Returns
    -------
    r : array_like
        The return value; if out is provided, `r` will be equal to out.

    
    geterrobj()

    Return the current object that defines floating-point error handling.

    The error object contains all information that defines the error handling
    behavior in Numpy. `geterrobj` is used internally by the other
    functions that get and set error handling behavior (`geterr`, `seterr`,
    `geterrcall`, `seterrcall`).

    Returns
    -------
    errobj : list
        The error object, a list containing three elements:
        [internal numpy buffer size, error mask, error callback function].

        The error mask is a single integer that holds the treatment information
        on all four floating point errors. The information for each error type
        is contained in three bits of the integer. If we print it in base 8, we
        can see what treatment is set for "invalid", "under", "over", and
        "divide" (in that order). The printed string can be interpreted with

        * 0 : 'ignore'
        * 1 : 'warn'
        * 2 : 'raise'
        * 3 : 'call'
        * 4 : 'print'
        * 5 : 'log'

    See Also
    --------
    seterrobj, seterr, geterr, seterrcall, geterrcall
    getbufsize, setbufsize

    Notes
    -----
    For complete documentation of the types of floating-point exceptions and
    treatment options, see `seterr`.

    Examples
    --------
    >>> np.geterrobj()  # first get the defaults
    [10000, 0, None]

    >>> def err_handler(type, flag):
    ...     print "Floating point error (%s), with flag %s" % (type, flag)
    ...
    >>> old_bufsize = np.setbufsize(20000)
    >>> old_err = np.seterr(divide='raise')
    >>> old_handler = np.seterrcall(err_handler)
    >>> np.geterrobj()
    [20000, 2, <function err_handler at 0x91dcaac>]

    >>> old_err = np.seterr(all='ignore')
    >>> np.base_repr(np.geterrobj()[1], 8)
    '0'
    >>> old_err = np.seterr(divide='warn', over='log', under='call',
                            invalid='print')
    >>> np.base_repr(np.geterrobj()[1], 8)
    '4351'

    
    Boolean indicating whether this dtype contains any reference-counted
    objects in any fields or sub-dtypes.

    Recall that what is actually in the ndarray memory representing
    the Python object is the memory address of that object (a pointer).
    Special handling may be required, and this attribute is useful for
    distinguishing data types that may contain arbitrary Python objects
    and data-types that won't.

    
    Same as self.transpose(), except that self is returned if
    self.ndim < 2.

    Examples
    --------
    >>> x = np.array([[1.,2.],[3.,4.]])
    >>> x
    array([[ 1.,  2.],
           [ 3.,  4.]])
    >>> x.T
    array([[ 1.,  3.],
           [ 2.,  4.]])
    >>> x = np.array([1.,2.,3.,4.])
    >>> x
    array([ 1.,  2.,  3.,  4.])
    >>> x.T
    array([ 1.,  2.,  3.,  4.])

    Allow the array to be interpreted as a ctypes object by returning the
    data-memory location as an integer

    
    iternext()

    Check whether iterations are left, and perform a single internal iteration
    without returning the result.  Used in the C-style pattern do-while
    pattern.  For an example, see `nditer`.

    Returns
    -------
    iternext : bool
        Whether or not there are iterations left.

    
    64-bit floating-point number. Character code 'd'. Python float compatible.

    
    Complex number type composed of two 64 bit floats. Character code: 'D'.
    Python complex compatible.

    
    a.view(dtype=None, type=None)

    New view of array with the same data.

    Parameters
    ----------
    dtype : data-type or ndarray sub-class, optional
        Data-type descriptor of the returned view, e.g., float32 or int16. The
        default, None, results in the view having the same data-type as `a`.
        This argument can also be specified as an ndarray sub-class, which
        then specifies the type of the returned object (this is equivalent to
        setting the ``type`` parameter).
    type : Python type, optional
        Type of the returned view, e.g., ndarray or matrix.  Again, the
        default None results in type preservation.

    Notes
    -----
    ``a.view()`` is used two different ways:

    ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view
    of the array's memory with a different data-type.  This can cause a
    reinterpretation of the bytes of memory.

    ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just
    returns an instance of `ndarray_subclass` that looks at the same array
    (same shape, dtype, etc.)  This does not cause a reinterpretation of the
    memory.

    For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of
    bytes per entry than the previous dtype (for example, converting a
    regular array to a structured array), then the behavior of the view
    cannot be predicted just from the superficial appearance of ``a`` (shown
    by ``print(a)``). It also depends on exactly how ``a`` is stored in
    memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus
    defined as a slice or transpose, etc., the view may give different
    results.


    Examples
    --------
    >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])

    Viewing array data using a different type and dtype:

    >>> y = x.view(dtype=np.int16, type=np.matrix)
    >>> y
    matrix([[513]], dtype=int16)
    >>> print type(y)
    <class 'numpy.matrixlib.defmatrix.matrix'>

    Creating a view on a structured array so it can be used in calculations

    >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])
    >>> xv = x.view(dtype=np.int8).reshape(-1,2)
    >>> xv
    array([[1, 2],
           [3, 4]], dtype=int8)
    >>> xv.mean(0)
    array([ 2.,  3.])

    Making changes to the view changes the underlying array

    >>> xv[0,1] = 20
    >>> print x
    [(1, 20) (3, 4)]

    Using a view to convert an array to a record array:

    >>> z = x.view(np.recarray)
    >>> z.a
    array([1], dtype=int8)

    Views share data:

    >>> x[0] = (9, 10)
    >>> z[0]
    (9, 10)

    Views that change the dtype size (bytes per entry) should normally be
    avoided on arrays defined by slices, transposes, fortran-ordering, etc.:

    >>> x = np.array([[1,2,3],[4,5,6]], dtype=np.int16)
    >>> y = x[:, 0:2]
    >>> y
    array([[1, 2],
           [4, 5]], dtype=int16)
    >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ValueError: new type not compatible with array.
    >>> z = y.copy()
    >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])
    array([[(1, 2)],
           [(4, 5)]], dtype=[('width', '<i2'), ('length', '<i2')])
    
    a.item(*args)

    Copy an element of an array to a standard Python scalar and return it.

    Parameters
    ----------
    \*args : Arguments (variable number and type)

        * none: in this case, the method only works for arrays
          with one element (`a.size == 1`), which element is
          copied into a standard Python scalar object and returned.

        * int_type: this argument is interpreted as a flat index into
          the array, specifying which element to copy and return.

        * tuple of int_types: functions as does a single int_type argument,
          except that the argument is interpreted as an nd-index into the
          array.

    Returns
    -------
    z : Standard Python scalar object
        A copy of the specified element of the array as a suitable
        Python scalar

    Notes
    -----
    When the data type of `a` is longdouble or clongdouble, item() returns
    a scalar array object because there is no available Python scalar that
    would not lose information. Void arrays return a buffer object for item(),
    unless fields are defined, in which case a tuple is returned.

    `item` is very similar to a[args], except, instead of an array scalar,
    a standard Python scalar is returned. This can be useful for speeding up
    access to elements of the array and doing arithmetic on elements of the
    array using Python's optimized math.

    Examples
    --------
    >>> x = np.random.randint(9, size=(3, 3))
    >>> x
    array([[3, 1, 7],
           [2, 8, 3],
           [8, 5, 3]])
    >>> x.item(3)
    2
    >>> x.item(7)
    5
    >>> x.item((0, 1))
    1
    >>> x.item((2, 2))
    3

    
    reduce(a, axis=0, dtype=None, out=None, keepdims=False)

    Reduces `a`'s dimension by one, by applying ufunc along one axis.

    Let :math:`a.shape = (N_0, ..., N_i, ..., N_{M-1})`.  Then
    :math:`ufunc.reduce(a, axis=i)[k_0, ..,k_{i-1}, k_{i+1}, .., k_{M-1}]` =
    the result of iterating `j` over :math:`range(N_i)`, cumulatively applying
    ufunc to each :math:`a[k_0, ..,k_{i-1}, j, k_{i+1}, .., k_{M-1}]`.
    For a one-dimensional array, reduce produces results equivalent to:
    ::

     r = op.identity # op = ufunc
     for i in range(len(A)):
       r = op(r, A[i])
     return r

    For example, add.reduce() is equivalent to sum().

    Parameters
    ----------
    a : array_like
        The array to act on.
    axis : None or int or tuple of ints, optional
        Axis or axes along which a reduction is performed.
        The default (`axis` = 0) is perform a reduction over the first
        dimension of the input array. `axis` may be negative, in
        which case it counts from the last to the first axis.

        .. versionadded:: 1.7.0

        If this is `None`, a reduction is performed over all the axes.
        If this is a tuple of ints, a reduction is performed on multiple
        axes, instead of a single axis or all the axes as before.

        For operations which are either not commutative or not associative,
        doing a reduction over multiple axes is not well-defined. The
        ufuncs do not currently raise an exception in this case, but will
        likely do so in the future.
    dtype : data-type code, optional
        The type used to represent the intermediate results. Defaults
        to the data-type of the output array if this is provided, or
        the data-type of the input array if no output array is provided.
    out : ndarray, optional
        A location into which the result is stored. If not provided, a
        freshly-allocated array is returned.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    r : ndarray
        The reduced array. If `out` was supplied, `r` is a reference to it.

    Examples
    --------
    >>> np.multiply.reduce([2,3,5])
    30

    A multi-dimensional array example:

    >>> X = np.arange(8).reshape((2,2,2))
    >>> X
    array([[[0, 1],
            [2, 3]],
           [[4, 5],
            [6, 7]]])
    >>> np.add.reduce(X, 0)
    array([[ 4,  6],
           [ 8, 10]])
    >>> np.add.reduce(X) # confirm: default axis value is 0
    array([[ 4,  6],
           [ 8, 10]])
    >>> np.add.reduce(X, 1)
    array([[ 2,  4],
           [10, 12]])
    >>> np.add.reduce(X, 2)
    array([[ 1,  5],
           [ 9, 13]])

    
    Determine if two arrays can share memory

    The memory-bounds of a and b are computed.  If they overlap then
    this function returns True.  Otherwise, it returns False.

    A return of True does not necessarily mean that the two arrays
    share any element.  It just means that they *might*.

    Parameters
    ----------
    a, b : ndarray

    Returns
    -------
    out : bool

    Examples
    --------
    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))
    False

    
    copyto(dst, src, casting='same_kind', where=None, preservena=False)

    Copies values from one array to another, broadcasting as necessary.

    Raises a TypeError if the `casting` rule is violated, and if
    `where` is provided, it selects which elements to copy.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    dst : ndarray
        The array into which values are copied.
    src : array_like
        The array from which values are copied.
    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
        Controls what kind of data casting may occur when copying.

          * 'no' means the data types should not be cast at all.
          * 'equiv' means only byte-order changes are allowed.
          * 'safe' means only casts which can preserve values are allowed.
          * 'same_kind' means only safe casts or casts within a kind,
            like float64 to float32, are allowed.
          * 'unsafe' means any data conversions may be done.
    where : array_like of bool, optional
        A boolean array which is broadcasted to match the dimensions
        of `dst`, and selects elements to copy from `src` to `dst`
        wherever it contains the value True.
    preservena : bool, optional
        If set to True, leaves any NA values in `dst` untouched. This
        is similar to the "hard mask" feature in numpy.ma.

    
    tuple of iterators along ``self``'s "components."

    Returns a tuple of `numpy.flatiter` objects, one for each "component"
    of ``self``.

    See Also
    --------
    numpy.flatiter

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]])
    >>> b = np.broadcast(x, y)
    >>> row, col = b.iters
    >>> row.next(), col.next()
    (1, 4)

    a.dump(file)

    Dump a pickle of the array to the specified file.
    The array can be read back with pickle.load or numpy.load.

    Parameters
    ----------
    file : str
        A string naming the dump file.

    The integer value of flags.
    a.itemset(*args)

    Insert scalar into an array (scalar is cast to array's dtype, if possible)

    There must be at least 1 argument, and define the last argument
    as *item*.  Then, ``a.itemset(*args)`` is equivalent to but faster
    than ``a[args] = item``.  The item should be a scalar value and `args`
    must select a single item in the array `a`.

    Parameters
    ----------
    \*args : Arguments
        If one argument: a scalar, only used in case `a` is of size 1.
        If two arguments: the last argument is the value to be set
        and must be a scalar, the first argument specifies a single array
        element location. It is either an int or a tuple.

    Notes
    -----
    Compared to indexing syntax, `itemset` provides some speed increase
    for placing a scalar into a particular location in an `ndarray`,
    if you must do this.  However, generally this is discouraged:
    among other problems, it complicates the appearance of the code.
    Also, when using `itemset` (and `item`) inside a loop, be sure
    to assign the methods to a local variable to avoid the attribute
    look-up at each loop iteration.

    Examples
    --------
    >>> x = np.random.randint(9, size=(3, 3))
    >>> x
    array([[3, 1, 7],
           [2, 8, 3],
           [8, 5, 3]])
    >>> x.itemset(4, 0)
    >>> x.itemset((2, 2), 9)
    >>> x
    array([[3, 1, 7],
           [2, 0, 3],
           [8, 5, 9]])

    A copy of the holiday array indicating additional invalid days.
    a.setfield(val, dtype, offset=0)

    Put a value into a specified place in a field defined by a data-type.

    Place `val` into `a`'s field defined by `dtype` and beginning `offset`
    bytes into the field.

    Parameters
    ----------
    val : object
        Value to be placed in field.
    dtype : dtype object
        Data-type of the field in which to place `val`.
    offset : int, optional
        The number of bytes into the field at which to place `val`.

    Returns
    -------
    None

    See Also
    --------
    getfield

    Examples
    --------
    >>> x = np.eye(3)
    >>> x.getfield(np.float64)
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])
    >>> x.setfield(3, np.int32)
    >>> x.getfield(np.int32)
    array([[3, 3, 3],
           [3, 3, 3],
           [3, 3, 3]])
    >>> x
    array([[  1.00000000e+000,   1.48219694e-323,   1.48219694e-323],
           [  1.48219694e-323,   1.00000000e+000,   1.48219694e-323],
           [  1.48219694e-323,   1.48219694e-323,   1.00000000e+000]])
    >>> x.setfield(np.eye(3), np.int32)
    >>> x
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])

    
    a.argpartition(kth, axis=-1, kind='introselect', order=None)

    Returns the indices that would partition this array.

    Refer to `numpy.argpartition` for full documentation.

    .. versionadded:: 1.8.0

    See Also
    --------
    numpy.argpartition : equivalent function

    
    a.ptp(axis=None, out=None)

    Peak to peak (maximum - minimum) value along a given axis.

    Refer to `numpy.ptp` for full documentation.

    See Also
    --------
    numpy.ptp : equivalent function

    
    a.nonzero()

    Return the indices of the elements that are non-zero.

    Refer to `numpy.nonzero` for full documentation.

    See Also
    --------
    numpy.nonzero : equivalent function

    
    The number of inputs.

    Data attribute containing the number of arguments the ufunc treats as input.

    Examples
    --------
    >>> np.add.nin
    2
    >>> np.multiply.nin
    2
    >>> np.power.nin
    2
    >>> np.exp.nin
    1
    
    A reference to the array that is iterated over.

    Examples
    --------
    >>> x = np.arange(5)
    >>> fl = x.flat
    >>> fl.base is x
    True

    A 1-D view of the scalar.Numpy's Boolean type.  Character code: ``?``.  Alias: bool8
    The element size of this data-type object.

    For 18 of the 21 types this number is fixed by the data-type.
    For the flexible data-types, this number can be anything.

    
    a.compress(condition, axis=None, out=None)

    Return selected slices of this array along given axis.

    Refer to `numpy.compress` for full documentation.

    See Also
    --------
    numpy.compress : equivalent function

    
    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)

    Calculates which of the given dates are valid days, and which are not.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    dates : array_like of datetime64[D]
        The array of dates to process.
    weekmask : str or array_like of bool, optional
        A seven-element array indicating which of Monday through Sunday are
        valid days. May be specified as a length-seven list or array, like
        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
        weekdays, optionally separated by white space. Valid abbreviations
        are: Mon Tue Wed Thu Fri Sat Sun
    holidays : array_like of datetime64[D], optional
        An array of dates to consider as invalid dates.  They may be
        specified in any order, and NaT (not-a-time) dates are ignored.
        This list is saved in a normalized form that is suited for
        fast calculations of valid days.
    busdaycal : busdaycalendar, optional
        A `busdaycalendar` object which specifies the valid days. If this
        parameter is provided, neither weekmask nor holidays may be
        provided.
    out : array of bool, optional
        If provided, this array is filled with the result.

    Returns
    -------
    out : array of bool
        An array with the same shape as ``dates``, containing True for
        each valid day, and False for each invalid day.

    See Also
    --------
    busdaycalendar: An object that specifies a custom set of valid days.
    busday_offset : Applies an offset counted in valid days.
    busday_count : Counts how many valid days are in a half-open date range.

    Examples
    --------
    >>> # The weekdays are Friday, Saturday, and Monday
    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],
    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])
    array([False, False,  True], dtype='bool')
    
    Not implemented (virtual attribute)

    Class generic exists solely to derive numpy scalars from, and possesses,
    albeit unimplemented, all the attributes of the ndarray class so as to
    provide a uniform API.

    See Also
    --------
    The corresponding attribute of the derived class of interest.

    
    a.searchsorted(v, side='left', sorter=None)

    Find indices where elements of v should be inserted in a to maintain order.

    For full documentation, see `numpy.searchsorted`

    See Also
    --------
    numpy.searchsorted : equivalent function

    
    a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)

    Copy of the array, cast to a specified type.

    Parameters
    ----------
    dtype : str or dtype
        Typecode or data-type to which the array is cast.
    order : {'C', 'F', 'A', 'K'}, optional
        Controls the memory layout order of the result.
        'C' means C order, 'F' means Fortran order, 'A'
        means 'F' order if all the arrays are Fortran contiguous,
        'C' order otherwise, and 'K' means as close to the
        order the array elements appear in memory as possible.
        Default is 'K'.
    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
        Controls what kind of data casting may occur. Defaults to 'unsafe'
        for backwards compatibility.

          * 'no' means the data types should not be cast at all.
          * 'equiv' means only byte-order changes are allowed.
          * 'safe' means only casts which can preserve values are allowed.
          * 'same_kind' means only safe casts or casts within a kind,
            like float64 to float32, are allowed.
          * 'unsafe' means any data conversions may be done.
    subok : bool, optional
        If True, then sub-classes will be passed-through (default), otherwise
        the returned array will be forced to be a base-class array.
    copy : bool, optional
        By default, astype always returns a newly allocated array. If this
        is set to false, and the `dtype`, `order`, and `subok`
        requirements are satisfied, the input array is returned instead
        of a copy.

    Returns
    -------
    arr_t : ndarray
        Unless `copy` is False and the other conditions for returning the input
        array are satisfied (see description for `copy` input paramter), `arr_t`
        is a new array of the same shape as the input array, with dtype, order
        given by `dtype`, `order`.

    Raises
    ------
    ComplexWarning
        When casting from complex to float or int. To avoid this,
        one should use ``a.real.astype(t)``.

    Examples
    --------
    >>> x = np.array([1, 2, 2.5])
    >>> x
    array([ 1. ,  2. ,  2.5])

    >>> x.astype(int)
    array([1, 2, 2])

    
    reset()

    Reset the iterator to its initial state.

    
    128-bit floating-point number. Character code: 'g'. C long float
    compatible.

    
    a.tolist()

    Return the array as a (possibly nested) list.

    Return a copy of the array data as a (nested) Python list.
    Data items are converted to the nearest compatible Python type.

    Parameters
    ----------
    none

    Returns
    -------
    y : list
        The possibly nested list of array elements.

    Notes
    -----
    The array may be recreated, ``a = np.array(a.tolist())``.

    Examples
    --------
    >>> a = np.array([1, 2])
    >>> a.tolist()
    [1, 2]
    >>> a = np.array([[1, 2], [3, 4]])
    >>> list(a)
    [array([1, 2]), array([3, 4])]
    >>> a.tolist()
    [[1, 2], [3, 4]]

    Any Python object.  Character code: 'O'.
    Array-interface compliant full description of the data-type.

    The format is that required by the 'descr' key in the
    `__array_interface__` attribute.

    
    a.setflags(write=None, align=None, uic=None)

    Set array flags WRITEABLE, ALIGNED, and UPDATEIFCOPY, respectively.

    These Boolean-valued flags affect how numpy interprets the memory
    area used by `a` (see Notes below). The ALIGNED flag can only
    be set to True if the data is actually aligned according to the type.
    The UPDATEIFCOPY flag can never be set to True. The flag WRITEABLE
    can only be set to True if the array owns its own memory, or the
    ultimate owner of the memory exposes a writeable buffer interface,
    or is a string. (The exception for string is made so that unpickling
    can be done without copying memory.)

    Parameters
    ----------
    write : bool, optional
        Describes whether or not `a` can be written to.
    align : bool, optional
        Describes whether or not `a` is aligned properly for its type.
    uic : bool, optional
        Describes whether or not `a` is a copy of another "base" array.

    Notes
    -----
    Array flags provide information about how the memory area used
    for the array is to be interpreted. There are 6 Boolean flags
    in use, only three of which can be changed by the user:
    UPDATEIFCOPY, WRITEABLE, and ALIGNED.

    WRITEABLE (W) the data area can be written to;

    ALIGNED (A) the data and strides are aligned appropriately for the hardware
    (as determined by the compiler);

    UPDATEIFCOPY (U) this array is a copy of some other array (referenced
    by .base). When this array is deallocated, the base array will be
    updated with the contents of this array.

    All flags can be accessed using their first (upper case) letter as well
    as the full name.

    Examples
    --------
    >>> y
    array([[3, 1, 7],
           [2, 0, 0],
           [8, 5, 9]])
    >>> y.flags
      C_CONTIGUOUS : True
      F_CONTIGUOUS : False
      OWNDATA : True
      WRITEABLE : True
      ALIGNED : True
      UPDATEIFCOPY : False
    >>> y.setflags(write=0, align=0)
    >>> y.flags
      C_CONTIGUOUS : True
      F_CONTIGUOUS : False
      OWNDATA : True
      WRITEABLE : False
      ALIGNED : False
      UPDATEIFCOPY : False
    >>> y.setflags(uic=1)
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ValueError: cannot set UPDATEIFCOPY flag to True

    
    array(object, dtype=None, copy=True, order=None, subok=False, ndmin=0)

    Create an array.

    Parameters
    ----------
    object : array_like
        An array, any object exposing the array interface, an
        object whose __array__ method returns an array, or any
        (nested) sequence.
    dtype : data-type, optional
        The desired data-type for the array.  If not given, then
        the type will be determined as the minimum type required
        to hold the objects in the sequence.  This argument can only
        be used to 'upcast' the array.  For downcasting, use the
        .astype(t) method.
    copy : bool, optional
        If true (default), then the object is copied.  Otherwise, a copy
        will only be made if __array__ returns a copy, if obj is a
        nested sequence, or if a copy is needed to satisfy any of the other
        requirements (`dtype`, `order`, etc.).
    order : {'C', 'F', 'A'}, optional
        Specify the order of the array.  If order is 'C' (default), then the
        array will be in C-contiguous order (last-index varies the
        fastest).  If order is 'F', then the returned array
        will be in Fortran-contiguous order (first-index varies the
        fastest).  If order is 'A', then the returned array may
        be in any order (either C-, Fortran-contiguous, or even
        discontiguous).
    subok : bool, optional
        If True, then sub-classes will be passed-through, otherwise
        the returned array will be forced to be a base-class array (default).
    ndmin : int, optional
        Specifies the minimum number of dimensions that the resulting
        array should have.  Ones will be pre-pended to the shape as
        needed to meet this requirement.

    Returns
    -------
    out : ndarray
        An array object satisfying the specified requirements.

    See Also
    --------
    empty, empty_like, zeros, zeros_like, ones, ones_like, fill

    Examples
    --------
    >>> np.array([1, 2, 3])
    array([1, 2, 3])

    Upcasting:

    >>> np.array([1, 2, 3.0])
    array([ 1.,  2.,  3.])

    More than one dimension:

    >>> np.array([[1, 2], [3, 4]])
    array([[1, 2],
           [3, 4]])

    Minimum dimensions 2:

    >>> np.array([1, 2, 3], ndmin=2)
    array([[1, 2, 3]])

    Type provided:

    >>> np.array([1, 2, 3], dtype=complex)
    array([ 1.+0.j,  2.+0.j,  3.+0.j])

    Data-type consisting of more than one element:

    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])
    >>> x['a']
    array([1, 3])

    Creating an array from sub-classes:

    >>> np.array(np.mat('1 2; 3 4'))
    array([[1, 2],
           [3, 4]])

    >>> np.array(np.mat('1 2; 3 4'), subok=True)
    matrix([[1, 2],
            [3, 4]])

    
    copy()

    Get a copy of the iterator in its current state.

    Examples
    --------
    >>> x = np.arange(10)
    >>> y = x + 1
    >>> it = np.nditer([x, y])
    >>> it.next()
    (array(0), array(1))
    >>> it2 = it.copy()
    >>> it2.next()
    (array(1), array(2))

    
    seterrobj(errobj)

    Set the object that defines floating-point error handling.

    The error object contains all information that defines the error handling
    behavior in Numpy. `seterrobj` is used internally by the other
    functions that set error handling behavior (`seterr`, `seterrcall`).

    Parameters
    ----------
    errobj : list
        The error object, a list containing three elements:
        [internal numpy buffer size, error mask, error callback function].

        The error mask is a single integer that holds the treatment information
        on all four floating point errors. The information for each error type
        is contained in three bits of the integer. If we print it in base 8, we
        can see what treatment is set for "invalid", "under", "over", and
        "divide" (in that order). The printed string can be interpreted with

        * 0 : 'ignore'
        * 1 : 'warn'
        * 2 : 'raise'
        * 3 : 'call'
        * 4 : 'print'
        * 5 : 'log'

    See Also
    --------
    geterrobj, seterr, geterr, seterrcall, geterrcall
    getbufsize, setbufsize

    Notes
    -----
    For complete documentation of the types of floating-point exceptions and
    treatment options, see `seterr`.

    Examples
    --------
    >>> old_errobj = np.geterrobj()  # first get the defaults
    >>> old_errobj
    [10000, 0, None]

    >>> def err_handler(type, flag):
    ...     print "Floating point error (%s), with flag %s" % (type, flag)
    ...
    >>> new_errobj = [20000, 12, err_handler]
    >>> np.seterrobj(new_errobj)
    >>> np.base_repr(12, 8)  # int for divide=4 ('print') and over=1 ('warn')
    '14'
    >>> np.geterr()
    {'over': 'warn', 'divide': 'print', 'invalid': 'ignore', 'under': 'ignore'}
    >>> np.geterrcall() is err_handler
    True

    
    A bit-width name for this data-type.

    Un-sized flexible data-type objects do not have this attribute.

    
    frompyfunc(func, nin, nout)

    Takes an arbitrary Python function and returns a Numpy ufunc.

    Can be used, for example, to add broadcasting to a built-in Python
    function (see Examples section).

    Parameters
    ----------
    func : Python function object
        An arbitrary Python function.
    nin : int
        The number of input arguments.
    nout : int
        The number of objects returned by `func`.

    Returns
    -------
    out : ufunc
        Returns a Numpy universal function (``ufunc``) object.

    Notes
    -----
    The returned ufunc always returns PyObject arrays.

    Examples
    --------
    Use frompyfunc to add broadcasting to the Python function ``oct``:

    >>> oct_array = np.frompyfunc(oct, 1, 1)
    >>> oct_array(np.array((10, 30, 100)))
    array([012, 036, 0144], dtype=object)
    >>> np.array((oct(10), oct(30), oct(100))) # for comparison
    array(['012', '036', '0144'],
          dtype='|S4')

    
    A unique number for each of the 21 different built-in types.

    These are roughly ordered from least-to-most precision.

    
    a.conjugate()

    Return the complex conjugate, element-wise.

    Refer to `numpy.conjugate` for full documentation.

    See Also
    --------
    numpy.conjugate : equivalent function

    
    set_numeric_ops(op1=func1, op2=func2, ...)

    Set numerical operators for array objects.

    Parameters
    ----------
    op1, op2, ... : callable
        Each ``op = func`` pair describes an operator to be replaced.
        For example, ``add = lambda x, y: np.add(x, y) % 5`` would replace
        addition by modulus 5 addition.

    Returns
    -------
    saved_ops : list of callables
        A list of all operators, stored before making replacements.

    Notes
    -----
    .. WARNING::
       Use with care!  Incorrect usage may lead to memory errors.

    A function replacing an operator cannot make use of that operator.
    For example, when replacing add, you may not use ``+``.  Instead,
    directly call ufuncs.

    Examples
    --------
    >>> def add_mod5(x, y):
    ...     return np.add(x, y) % 5
    ...
    >>> old_funcs = np.set_numeric_ops(add=add_mod5)

    >>> x = np.arange(12).reshape((3, 4))
    >>> x + x
    array([[0, 2, 4, 1],
           [3, 0, 2, 4],
           [1, 3, 0, 2]])

    >>> ignore = np.set_numeric_ops(**old_funcs) # restore operators

    
    a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)

    Return the sum along diagonals of the array.

    Refer to `numpy.trace` for full documentation.

    See Also
    --------
    numpy.trace : equivalent function

    Get array data-descriptor.
    Not implemented (virtual attribute)

    Class generic exists solely to derive numpy scalars from, and possesses,
    albeit unimplemented, all the attributes of the ndarray class
    so as to provide a uniform API.

    See Also
    --------
    The corresponding attribute of the derived class of interest.

    _reconstruct(subtype, shape, dtype)

    Construct an empty array. Used by Pickles.

    
    a.mean(axis=None, dtype=None, out=None)

    Returns the average of the array elements along given axis.

    Refer to `numpy.mean` for full documentation.

    See Also
    --------
    numpy.mean : equivalent function

    
    Flat iterator object to iterate over arrays.

    A `flatiter` iterator is returned by ``x.flat`` for any array `x`.
    It allows iterating over the array as if it were a 1-D array,
    either in a for-loop or by calling its `next` method.

    Iteration is done in C-contiguous style, with the last index varying the
    fastest. The iterator can also be indexed using basic slicing or
    advanced indexing.

    See Also
    --------
    ndarray.flat : Return a flat iterator over an array.
    ndarray.flatten : Returns a flattened copy of an array.

    Notes
    -----
    A `flatiter` iterator can not be constructed directly from Python code
    by calling the `flatiter` constructor.

    Examples
    --------
    >>> x = np.arange(6).reshape(2, 3)
    >>> fl = x.flat
    >>> type(fl)
    <type 'numpy.flatiter'>
    >>> for item in fl:
    ...     print item
    ...
    0
    1
    2
    3
    4
    5

    >>> fl[2:4]
    array([2, 3])

    Tuple of array dimensions.
    a.resize(new_shape, refcheck=True)

    Change shape and size of array in-place.

    Parameters
    ----------
    new_shape : tuple of ints, or `n` ints
        Shape of resized array.
    refcheck : bool, optional
        If False, reference count will not be checked. Default is True.

    Returns
    -------
    None

    Raises
    ------
    ValueError
        If `a` does not own its own data or references or views to it exist,
        and the data memory must be changed.

    SystemError
        If the `order` keyword argument is specified. This behaviour is a
        bug in NumPy.

    See Also
    --------
    resize : Return a new array with the specified shape.

    Notes
    -----
    This reallocates space for the data area if necessary.

    Only contiguous arrays (data elements consecutive in memory) can be
    resized.

    The purpose of the reference count check is to make sure you
    do not use this array as a buffer for another Python object and then
    reallocate the memory. However, reference counts can increase in
    other ways so if you are sure that you have not shared the memory
    for this array with another Python object, then you may safely set
    `refcheck` to False.

    Examples
    --------
    Shrinking an array: array is flattened (in the order that the data are
    stored in memory), resized, and reshaped:

    >>> a = np.array([[0, 1], [2, 3]], order='C')
    >>> a.resize((2, 1))
    >>> a
    array([[0],
           [1]])

    >>> a = np.array([[0, 1], [2, 3]], order='F')
    >>> a.resize((2, 1))
    >>> a
    array([[0],
           [2]])

    Enlarging an array: as above, but missing entries are filled with zeros:

    >>> b = np.array([[0, 1], [2, 3]])
    >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple
    >>> b
    array([[0, 1, 2],
           [3, 0, 0]])

    Referencing an array prevents resizing...

    >>> c = a
    >>> a.resize((1, 1))
    Traceback (most recent call last):
    ...
    ValueError: cannot resize an array that has been referenced ...

    Unless `refcheck` is False:

    >>> a.resize((1, 1), refcheck=False)
    >>> a
    array([[0]])
    >>> c
    array([[0]])

    
    a.swapaxes(axis1, axis2)

    Return a view of the array with `axis1` and `axis2` interchanged.

    Refer to `numpy.swapaxes` for full documentation.

    See Also
    --------
    numpy.swapaxes : equivalent function

    A copy of the seven-element boolean mask indicating valid days.Pointer to start of data.
    a.dot(b, out=None)

    Dot product of two arrays.

    Refer to `numpy.dot` for full documentation.

    See Also
    --------
    numpy.dot : equivalent function

    Examples
    --------
    >>> a = np.eye(2)
    >>> b = np.ones((2, 2)) * 2
    >>> a.dot(b)
    array([[ 2.,  2.],
           [ 2.,  2.]])

    This array method can be conveniently chained:

    >>> a.dot(b).dot(b)
    array([[ 8.,  8.],
           [ 8.,  8.]])

    
    count_nonzero(a)

    Counts the number of non-zero values in the array ``a``.

    Parameters
    ----------
    a : array_like
        The array for which to count non-zeros.

    Returns
    -------
    count : int or array of int
        Number of non-zero values in the array.

    See Also
    --------
    nonzero : Return the coordinates of all the non-zero values.

    Examples
    --------
    >>> np.count_nonzero(np.eye(4))
    4
    >>> np.count_nonzero([[0,1,7,0,0],[3,0,0,2,19]])
    5
    
    Number of iterators possessed by the broadcasted result.

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]])
    >>> b = np.broadcast(x, y)
    >>> b.numiter
    2

    
    vdot(a, b)

    Return the dot product of two vectors.

    The vdot(`a`, `b`) function handles complex numbers differently than
    dot(`a`, `b`).  If the first argument is complex the complex conjugate
    of the first argument is used for the calculation of the dot product.

    Note that `vdot` handles multidimensional arrays differently than `dot`:
    it does *not* perform a matrix product, but flattens input arguments
    to 1-D vectors first. Consequently, it should only be used for vectors.

    Parameters
    ----------
    a : array_like
        If `a` is complex the complex conjugate is taken before calculation
        of the dot product.
    b : array_like
        Second argument to the dot product.

    Returns
    -------
    output : ndarray
        Dot product of `a` and `b`.  Can be an int, float, or
        complex depending on the types of `a` and `b`.

    See Also
    --------
    dot : Return the dot product without using the complex conjugate of the
          first argument.

    Examples
    --------
    >>> a = np.array([1+2j,3+4j])
    >>> b = np.array([5+6j,7+8j])
    >>> np.vdot(a, b)
    (70-8j)
    >>> np.vdot(b, a)
    (70+8j)

    Note that higher-dimensional arrays are flattened!

    >>> a = np.array([[1, 4], [5, 6]])
    >>> b = np.array([[4, 1], [2, 2]])
    >>> np.vdot(a, b)
    30
    >>> np.vdot(b, a)
    30
    >>> 1*4 + 4*1 + 5*2 + 6*2
    30

    
    unpackbits(myarray, axis=None)

    Unpacks elements of a uint8 array into a binary-valued output array.

    Each element of `myarray` represents a bit-field that should be unpacked
    into a binary-valued output array. The shape of the output array is either
    1-D (if `axis` is None) or the same shape as the input array with unpacking
    done along the axis specified.

    Parameters
    ----------
    myarray : ndarray, uint8 type
       Input array.
    axis : int, optional
       Unpacks along this axis.

    Returns
    -------
    unpacked : ndarray, uint8 type
       The elements are binary-valued (0 or 1).

    See Also
    --------
    packbits : Packs the elements of a binary-valued array into bits in a uint8
               array.

    Examples
    --------
    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)
    >>> a
    array([[ 2],
           [ 7],
           [23]], dtype=uint8)
    >>> b = np.unpackbits(a, axis=1)
    >>> b
    array([[0, 0, 0, 0, 0, 0, 1, 0],
           [0, 0, 0, 0, 0, 1, 1, 1],
           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)

    
    lexsort(keys, axis=-1)

    Perform an indirect sort using a sequence of keys.

    Given multiple sorting keys, which can be interpreted as columns in a
    spreadsheet, lexsort returns an array of integer indices that describes
    the sort order by multiple columns. The last key in the sequence is used
    for the primary sort order, the second-to-last key for the secondary sort
    order, and so on. The keys argument must be a sequence of objects that
    can be converted to arrays of the same shape. If a 2D array is provided
    for the keys argument, it's rows are interpreted as the sorting keys and
    sorting is according to the last row, second last row etc.

    Parameters
    ----------
    keys : (k, N) array or tuple containing k (N,)-shaped sequences
        The `k` different "columns" to be sorted.  The last column (or row if
        `keys` is a 2D array) is the primary sort key.
    axis : int, optional
        Axis to be indirectly sorted.  By default, sort over the last axis.

    Returns
    -------
    indices : (N,) ndarray of ints
        Array of indices that sort the keys along the specified axis.

    See Also
    --------
    argsort : Indirect sort.
    ndarray.sort : In-place sort.
    sort : Return a sorted copy of an array.

    Examples
    --------
    Sort names: first by surname, then by name.

    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')
    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')
    >>> ind = np.lexsort((first_names, surnames))
    >>> ind
    array([1, 2, 0])

    >>> [surnames[i] + ", " + first_names[i] for i in ind]
    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']

    Sort two columns of numbers:

    >>> a = [1,5,1,4,3,4,4] # First column
    >>> b = [9,4,0,4,0,2,1] # Second column
    >>> ind = np.lexsort((b,a)) # Sort by a, then by b
    >>> print ind
    [2 0 4 6 5 3 1]

    >>> [(a[i],b[i]) for i in ind]
    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]

    Note that sorting is first according to the elements of ``a``.
    Secondary sorting is according to the elements of ``b``.

    A normal ``argsort`` would have yielded:

    >>> [(a[i],b[i]) for i in np.argsort(a)]
    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]

    Structured arrays are sorted lexically by ``argsort``:

    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],
    ...              dtype=np.dtype([('x', int), ('y', int)]))

    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))
    array([2, 0, 4, 6, 5, 3, 1])

    
    a.fill(value)

    Fill the array with a scalar value.

    Parameters
    ----------
    value : scalar
        All elements of `a` will be assigned this value.

    Examples
    --------
    >>> a = np.array([1, 2])
    >>> a.fill(0)
    >>> a
    array([0, 0])
    >>> a = np.empty(2)
    >>> a.fill(1)
    >>> a
    array([ 1.,  1.])

    
    min_scalar_type(a)

    For scalar ``a``, returns the data type with the smallest size
    and smallest scalar kind which can hold its value.  For non-scalar
    array ``a``, returns the vector's dtype unmodified.

    Floating point values are not demoted to integers,
    and complex values are not demoted to floats.

    Parameters
    ----------
    a : scalar or array_like
        The value whose minimal data type is to be found.

    Returns
    -------
    out : dtype
        The minimal data type.

    Notes
    -----
    .. versionadded:: 1.6.0

    See Also
    --------
    result_type, promote_types, dtype, can_cast

    Examples
    --------
    >>> np.min_scalar_type(10)
    dtype('uint8')

    >>> np.min_scalar_type(-260)
    dtype('int16')

    >>> np.min_scalar_type(3.1)
    dtype('float16')

    >>> np.min_scalar_type(1e50)
    dtype('float64')

    >>> np.min_scalar_type(np.arange(4,dtype='f8'))
    dtype('float64')

    
    a.transpose(*axes)

    Returns a view of the array with axes transposed.

    For a 1-D array, this has no effect. (To change between column and
    row vectors, first cast the 1-D array into a matrix object.)
    For a 2-D array, this is the usual matrix transpose.
    For an n-D array, if axes are given, their order indicates how the
    axes are permuted (see Examples). If axes are not provided and
    ``a.shape = (i[0], i[1], ... i[n-2], i[n-1])``, then
    ``a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])``.

    Parameters
    ----------
    axes : None, tuple of ints, or `n` ints

     * None or no argument: reverses the order of the axes.

     * tuple of ints: `i` in the `j`-th place in the tuple means `a`'s
       `i`-th axis becomes `a.transpose()`'s `j`-th axis.

     * `n` ints: same as an n-tuple of the same ints (this form is
       intended simply as a "convenience" alternative to the tuple form)

    Returns
    -------
    out : ndarray
        View of `a`, with axes suitably permuted.

    See Also
    --------
    ndarray.T : Array property returning the array transposed.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4]])
    >>> a
    array([[1, 2],
           [3, 4]])
    >>> a.transpose()
    array([[1, 3],
           [2, 4]])
    >>> a.transpose((1, 0))
    array([[1, 3],
           [2, 4]])
    >>> a.transpose(1, 0)
    array([[1, 3],
           [2, 4]])

    The type object used to instantiate a scalar of this data-type.Array protocol: C-struct side.
    The identity value.

    Data attribute containing the identity element for the ufunc, if it has one.
    If it does not, the attribute value is None.

    Examples
    --------
    >>> np.add.identity
    0
    >>> np.multiply.identity
    1
    >>> np.power.identity
    1
    >>> print np.exp.identity
    None
    
    reset()

    Reset the broadcasted result's iterator(s).

    Parameters
    ----------
    None

    Returns
    -------
    None

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]]
    >>> b = np.broadcast(x, y)
    >>> b.index
    0
    >>> b.next(), b.next(), b.next()
    ((1, 4), (2, 4), (3, 4))
    >>> b.index
    3
    >>> b.reset()
    >>> b.index
    0

    
    a.diagonal(offset=0, axis1=0, axis2=1)

    Return specified diagonals.

    Refer to :func:`numpy.diagonal` for full documentation.

    See Also
    --------
    numpy.diagonal : equivalent function

    Python buffer object pointing to the start of the array's data.
    newbyteorder(new_order='S')

    Return a new dtype with a different byte order.

    Changes are also made in all fields and sub-arrays of the data type.

    Parameters
    ----------
    new_order : string, optional
        Byte order to force; a value from the byte order
        specifications below.  The default value ('S') results in
        swapping the current byte order.
        `new_order` codes can be any of::

         * 'S' - swap dtype from current to opposite endian
         * {'<', 'L'} - little endian
         * {'>', 'B'} - big endian
         * {'=', 'N'} - native order
         * {'|', 'I'} - ignore (no change to byte order)

        The code does a case-insensitive check on the first letter of
        `new_order` for these alternatives.  For example, any of '>'
        or 'B' or 'b' or 'brian' are valid to specify big-endian.

    Returns
    -------
    new_dtype : dtype
        New dtype object with the given change to the byte order.

    Notes
    -----
    Changes are also made in all fields and sub-arrays of the data type.

    Examples
    --------
    >>> import sys
    >>> sys_is_le = sys.byteorder == 'little'
    >>> native_code = sys_is_le and '<' or '>'
    >>> swapped_code = sys_is_le and '>' or '<'
    >>> native_dt = np.dtype(native_code+'i2')
    >>> swapped_dt = np.dtype(swapped_code+'i2')
    >>> native_dt.newbyteorder('S') == swapped_dt
    True
    >>> native_dt.newbyteorder() == swapped_dt
    True
    >>> native_dt == swapped_dt.newbyteorder('S')
    True
    >>> native_dt == swapped_dt.newbyteorder('=')
    True
    >>> native_dt == swapped_dt.newbyteorder('N')
    True
    >>> native_dt == native_dt.newbyteorder('|')
    True
    >>> np.dtype('<i2') == native_dt.newbyteorder('<')
    True
    >>> np.dtype('<i2') == native_dt.newbyteorder('L')
    True
    >>> np.dtype('>i2') == native_dt.newbyteorder('>')
    True
    >>> np.dtype('>i2') == native_dt.newbyteorder('B')
    True

    
    Bit-flags describing how this data type is to be interpreted.

    Bit-masks are in `numpy.core.multiarray` as the constants
    `ITEM_HASOBJECT`, `LIST_PICKLE`, `ITEM_IS_POINTER`, `NEEDS_INIT`,
    `NEEDS_PYAPI`, `USE_GETITEM`, `USE_SETITEM`. A full explanation
    of these flags is in C-API documentation; they are largely useful
    for user-defined data-types.

    
    a.std(axis=None, dtype=None, out=None, ddof=0)

    Returns the standard deviation of the array elements along given axis.

    Refer to `numpy.std` for full documentation.

    See Also
    --------
    numpy.std : equivalent function

    The array-protocol typestring of this data-type object.
    a.var(axis=None, dtype=None, out=None, ddof=0)

    Returns the variance of the array elements, along given axis.

    Refer to `numpy.var` for full documentation.

    See Also
    --------
    numpy.var : equivalent function

    
    Dictionary of named fields defined for this data type, or ``None``.

    The dictionary is indexed by keys that are the names of the fields.
    Each entry in the dictionary is a tuple fully describing the field::

      (dtype, offset[, title])

    If present, the optional title can be any object (if it is a string
    or unicode then it will also be a key in the fields dictionary,
    otherwise it's meta-data). Notice also that the first two elements
    of the tuple can be passed directly as arguments to the ``ndarray.getfield``
    and ``ndarray.setfield`` methods.

    See Also
    --------
    ndarray.getfield, ndarray.setfield

    Examples
    --------
    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])
    >>> print dt.fields
    {'grades': (dtype(('float64',(2,))), 16), 'name': (dtype('|S16'), 0)}

    The number of array dimensions.
    Efficient multi-dimensional iterator object to iterate over arrays.
    To get started using this object, see the
    :ref:`introductory guide to array iteration <arrays.nditer>`.

    Parameters
    ----------
    op : ndarray or sequence of array_like
        The array(s) to iterate over.
    flags : sequence of str, optional
        Flags to control the behavior of the iterator.

          * "buffered" enables buffering when required.
          * "c_index" causes a C-order index to be tracked.
          * "f_index" causes a Fortran-order index to be tracked.
          * "multi_index" causes a multi-index, or a tuple of indices
            with one per iteration dimension, to be tracked.
          * "common_dtype" causes all the operands to be converted to
            a common data type, with copying or buffering as necessary.
          * "delay_bufalloc" delays allocation of the buffers until
            a reset() call is made. Allows "allocate" operands to
            be initialized before their values are copied into the buffers.
          * "external_loop" causes the `values` given to be
            one-dimensional arrays with multiple values instead of
            zero-dimensional arrays.
          * "grow_inner" allows the `value` array sizes to be made
            larger than the buffer size when both "buffered" and
            "external_loop" is used.
          * "ranged" allows the iterator to be restricted to a sub-range
            of the iterindex values.
          * "refs_ok" enables iteration of reference types, such as
            object arrays.
          * "reduce_ok" enables iteration of "readwrite" operands
            which are broadcasted, also known as reduction operands.
          * "zerosize_ok" allows `itersize` to be zero.
    op_flags : list of list of str, optional
        This is a list of flags for each operand. At minimum, one of
        "readonly", "readwrite", or "writeonly" must be specified.

          * "readonly" indicates the operand will only be read from.
          * "readwrite" indicates the operand will be read from and written to.
          * "writeonly" indicates the operand will only be written to.
          * "no_broadcast" prevents the operand from being broadcasted.
          * "contig" forces the operand data to be contiguous.
          * "aligned" forces the operand data to be aligned.
          * "nbo" forces the operand data to be in native byte order.
          * "copy" allows a temporary read-only copy if required.
          * "updateifcopy" allows a temporary read-write copy if required.
          * "allocate" causes the array to be allocated if it is None
            in the `op` parameter.
          * "no_subtype" prevents an "allocate" operand from using a subtype.
          * "arraymask" indicates that this operand is the mask to use
            for selecting elements when writing to operands with the
            'writemasked' flag set. The iterator does not enforce this,
            but when writing from a buffer back to the array, it only
            copies those elements indicated by this mask.
          * 'writemasked' indicates that only elements where the chosen
            'arraymask' operand is True will be written to.
    op_dtypes : dtype or tuple of dtype(s), optional
        The required data type(s) of the operands. If copying or buffering
        is enabled, the data will be converted to/from their original types.
    order : {'C', 'F', 'A', 'K'}, optional
        Controls the iteration order. 'C' means C order, 'F' means
        Fortran order, 'A' means 'F' order if all the arrays are Fortran
        contiguous, 'C' order otherwise, and 'K' means as close to the
        order the array elements appear in memory as possible. This also
        affects the element memory order of "allocate" operands, as they
        are allocated to be compatible with iteration order.
        Default is 'K'.
    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
        Controls what kind of data casting may occur when making a copy
        or buffering.  Setting this to 'unsafe' is not recommended,
        as it can adversely affect accumulations.

          * 'no' means the data types should not be cast at all.
          * 'equiv' means only byte-order changes are allowed.
          * 'safe' means only casts which can preserve values are allowed.
          * 'same_kind' means only safe casts or casts within a kind,
            like float64 to float32, are allowed.
          * 'unsafe' means any data conversions may be done.
    op_axes : list of list of ints, optional
        If provided, is a list of ints or None for each operands.
        The list of axes for an operand is a mapping from the dimensions
        of the iterator to the dimensions of the operand. A value of
        -1 can be placed for entries, causing that dimension to be
        treated as "newaxis".
    itershape : tuple of ints, optional
        The desired shape of the iterator. This allows "allocate" operands
        with a dimension mapped by op_axes not corresponding to a dimension
        of a different operand to get a value not equal to 1 for that
        dimension.
    buffersize : int, optional
        When buffering is enabled, controls the size of the temporary
        buffers. Set to 0 for the default value.

    Attributes
    ----------
    dtypes : tuple of dtype(s)
        The data types of the values provided in `value`. This may be
        different from the operand data types if buffering is enabled.
    finished : bool
        Whether the iteration over the operands is finished or not.
    has_delayed_bufalloc : bool
        If True, the iterator was created with the "delay_bufalloc" flag,
        and no reset() function was called on it yet.
    has_index : bool
        If True, the iterator was created with either the "c_index" or
        the "f_index" flag, and the property `index` can be used to
        retrieve it.
    has_multi_index : bool
        If True, the iterator was created with the "multi_index" flag,
        and the property `multi_index` can be used to retrieve it.
    index :
        When the "c_index" or "f_index" flag was used, this property
        provides access to the index. Raises a ValueError if accessed
        and `has_index` is False.
    iterationneedsapi : bool
        Whether iteration requires access to the Python API, for example
        if one of the operands is an object array.
    iterindex : int
        An index which matches the order of iteration.
    itersize : int
        Size of the iterator.
    itviews :
        Structured view(s) of `operands` in memory, matching the reordered
        and optimized iterator access pattern.
    multi_index :
        When the "multi_index" flag was used, this property
        provides access to the index. Raises a ValueError if accessed
        accessed and `has_multi_index` is False.
    ndim : int
        The iterator's dimension.
    nop : int
        The number of iterator operands.
    operands : tuple of operand(s)
        The array(s) to be iterated over.
    shape : tuple of ints
        Shape tuple, the shape of the iterator.
    value :
        Value of `operands` at current iteration. Normally, this is a
        tuple of array scalars, but if the flag "external_loop" is used,
        it is a tuple of one dimensional arrays.

    Notes
    -----
    `nditer` supersedes `flatiter`.  The iterator implementation behind
    `nditer` is also exposed by the Numpy C API.

    The Python exposure supplies two iteration interfaces, one which follows
    the Python iterator protocol, and another which mirrors the C-style
    do-while pattern.  The native Python approach is better in most cases, but
    if you need the iterator's coordinates or index, use the C-style pattern.

    Examples
    --------
    Here is how we might write an ``iter_add`` function, using the
    Python iterator protocol::

        def iter_add_py(x, y, out=None):
            addop = np.add
            it = np.nditer([x, y, out], [],
                        [['readonly'], ['readonly'], ['writeonly','allocate']])
            for (a, b, c) in it:
                addop(a, b, out=c)
            return it.operands[2]

    Here is the same function, but following the C-style pattern::

        def iter_add(x, y, out=None):
            addop = np.add

            it = np.nditer([x, y, out], [],
                        [['readonly'], ['readonly'], ['writeonly','allocate']])

            while not it.finished:
                addop(it[0], it[1], out=it[2])
                it.iternext()

            return it.operands[2]

    Here is an example outer product function::

        def outer_it(x, y, out=None):
            mulop = np.multiply

            it = np.nditer([x, y, out], ['external_loop'],
                    [['readonly'], ['readonly'], ['writeonly', 'allocate']],
                    op_axes=[range(x.ndim)+[-1]*y.ndim,
                             [-1]*x.ndim+range(y.ndim),
                             None])

            for (a, b, c) in it:
                mulop(a, b, out=c)

            return it.operands[2]

        >>> a = np.arange(2)+1
        >>> b = np.arange(3)+1
        >>> outer_it(a,b)
        array([[1, 2, 3],
               [2, 4, 6]])

    Here is an example function which operates like a "lambda" ufunc::

        def luf(lamdaexpr, *args, **kwargs):
            "luf(lambdaexpr, op1, ..., opn, out=None, order='K', casting='safe', buffersize=0)"
            nargs = len(args)
            op = (kwargs.get('out',None),) + args
            it = np.nditer(op, ['buffered','external_loop'],
                    [['writeonly','allocate','no_broadcast']] +
                                    [['readonly','nbo','aligned']]*nargs,
                    order=kwargs.get('order','K'),
                    casting=kwargs.get('casting','safe'),
                    buffersize=kwargs.get('buffersize',0))
            while not it.finished:
                it[0] = lamdaexpr(*it[1:])
                it.iternext()
            return it.operands[0]

        >>> a = np.arange(5)
        >>> b = np.ones(5)
        >>> luf(lambda i,j:i*i + j/2, a, b)
        array([  0.5,   1.5,   4.5,   9.5,  16.5])

    Array priority.
    getbuffer(obj [,offset[, size]])

    Create a buffer object from the given object referencing a slice of
    length size starting at offset.

    Default is the entire buffer. A read-write buffer is attempted followed
    by a read-only buffer.

    Parameters
    ----------
    obj : object

    offset : int, optional

    size : int, optional

    Returns
    -------
    buffer_obj : buffer

    Examples
    --------
    >>> buf = np.getbuffer(np.ones(5), 1, 3)
    >>> len(buf)
    3
    >>> buf[0]
    '\x00'
    >>> buf
    <read-write buffer for 0x8af1e70, size 3, offset 1 at 0x8ba4ec0>

    
    Number of dimensions of broadcasted result.

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]])
    >>> b = np.broadcast(x, y)
    >>> b.nd
    2

    
    a.squeeze(axis=None)

    Remove single-dimensional entries from the shape of `a`.

    Refer to `numpy.squeeze` for full documentation.

    See Also
    --------
    numpy.squeeze : equivalent function

    
    a.flatten(order='C')

    Return a copy of the array collapsed into one dimension.

    Parameters
    ----------
    order : {'C', 'F', 'A'}, optional
        Whether to flatten in C (row-major), Fortran (column-major) order,
        or preserve the C/Fortran ordering from `a`.
        The default is 'C'.

    Returns
    -------
    y : ndarray
        A copy of the input array, flattened to one dimension.

    See Also
    --------
    ravel : Return a flattened array.
    flat : A 1-D flat iterator over the array.

    Examples
    --------
    >>> a = np.array([[1,2], [3,4]])
    >>> a.flatten()
    array([1, 2, 3, 4])
    >>> a.flatten('F')
    array([1, 3, 2, 4])

    
    32-bit floating-point number. Character code 'f'. C float compatible.

    
    Complex number type composed of two 32 bit floats. Character code: 'F'.

    
    Tuple ``(item_dtype, shape)`` if this `dtype` describes a sub-array, and
    None otherwise.

    The *shape* is the fixed shape of the sub-array described by this
    data type, and *item_dtype* the data type of the array.

    If a field whose dtype object has this attribute is retrieved,
    then the extra dimensions implied by *shape* are tacked on to
    the end of the retrieved array.

    
    fromiter(iterable, dtype, count=-1)

    Create a new 1-dimensional array from an iterable object.

    Parameters
    ----------
    iterable : iterable object
        An iterable object providing data for the array.
    dtype : data-type
        The data-type of the returned array.
    count : int, optional
        The number of items to read from *iterable*.  The default is -1,
        which means all data is read.

    Returns
    -------
    out : ndarray
        The output array.

    Notes
    -----
    Specify `count` to improve performance.  It allows ``fromiter`` to
    pre-allocate the output array, instead of resizing it on demand.

    Examples
    --------
    >>> iterable = (x*x for x in range(5))
    >>> np.fromiter(iterable, np.float)
    array([  0.,   1.,   4.,   9.,  16.])

    
    arange([start,] stop[, step,], dtype=None)

    Return evenly spaced values within a given interval.

    Values are generated within the half-open interval ``[start, stop)``
    (in other words, the interval including `start` but excluding `stop`).
    For integer arguments the function is equivalent to the Python built-in
    `range <http://docs.python.org/lib/built-in-funcs.html>`_ function,
    but returns an ndarray rather than a list.

    When using a non-integer step, such as 0.1, the results will often not
    be consistent.  It is better to use ``linspace`` for these cases.

    Parameters
    ----------
    start : number, optional
        Start of interval.  The interval includes this value.  The default
        start value is 0.
    stop : number
        End of interval.  The interval does not include this value, except
        in some cases where `step` is not an integer and floating point
        round-off affects the length of `out`.
    step : number, optional
        Spacing between values.  For any output `out`, this is the distance
        between two adjacent values, ``out[i+1] - out[i]``.  The default
        step size is 1.  If `step` is specified, `start` must also be given.
    dtype : dtype
        The type of the output array.  If `dtype` is not given, infer the data
        type from the other input arguments.

    Returns
    -------
    arange : ndarray
        Array of evenly spaced values.

        For floating point arguments, the length of the result is
        ``ceil((stop - start)/step)``.  Because of floating point overflow,
        this rule may result in the last element of `out` being greater
        than `stop`.

    See Also
    --------
    linspace : Evenly spaced numbers with careful handling of endpoints.
    ogrid: Arrays of evenly spaced numbers in N-dimensions.
    mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.

    Examples
    --------
    >>> np.arange(3)
    array([0, 1, 2])
    >>> np.arange(3.0)
    array([ 0.,  1.,  2.])
    >>> np.arange(3,7)
    array([3, 4, 5, 6])
    >>> np.arange(3,7,2)
    array([3, 5])

    a.__reduce__()

    For pickling.

    32-bit integer. Character code 'i'. C int compatible.cross_correlate(a,v, mode=0)
    dot(a, b, out=None)

    Dot product of two arrays.

    For 2-D arrays it is equivalent to matrix multiplication, and for 1-D
    arrays to inner product of vectors (without complex conjugation). For
    N dimensions it is a sum product over the last axis of `a` and
    the second-to-last of `b`::

        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])

    Parameters
    ----------
    a : array_like
        First argument.
    b : array_like
        Second argument.
    out : ndarray, optional
        Output argument. This must have the exact kind that would be returned
        if it was not used. In particular, it must have the right type, must be
        C-contiguous, and its dtype must be the dtype that would be returned
        for `dot(a,b)`. This is a performance feature. Therefore, if these
        conditions are not met, an exception is raised, instead of attempting
        to be flexible.

    Returns
    -------
    output : ndarray
        Returns the dot product of `a` and `b`.  If `a` and `b` are both
        scalars or both 1-D arrays then a scalar is returned; otherwise
        an array is returned.
        If `out` is given, then it is returned.

    Raises
    ------
    ValueError
        If the last dimension of `a` is not the same size as
        the second-to-last dimension of `b`.

    See Also
    --------
    vdot : Complex-conjugating dot product.
    tensordot : Sum products over arbitrary axes.
    einsum : Einstein summation convention.

    Examples
    --------
    >>> np.dot(3, 4)
    12

    Neither argument is complex-conjugated:

    >>> np.dot([2j, 3j], [2j, 3j])
    (-13+0j)

    For 2-D arrays it's the matrix product:

    >>> a = [[1, 0], [0, 1]]
    >>> b = [[4, 1], [2, 2]]
    >>> np.dot(a, b)
    array([[4, 1],
           [2, 2]])

    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))
    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))
    >>> np.dot(a, b)[2,3,2,1,2,2]
    499128
    >>> sum(a[2,3,2,:] * b[1,2,:,2])
    499128

    
    frombuffer(buffer, dtype=float, count=-1, offset=0)

    Interpret a buffer as a 1-dimensional array.

    Parameters
    ----------
    buffer : buffer_like
        An object that exposes the buffer interface.
    dtype : data-type, optional
        Data-type of the returned array; default: float.
    count : int, optional
        Number of items to read. ``-1`` means all data in the buffer.
    offset : int, optional
        Start reading the buffer from this offset; default: 0.

    Notes
    -----
    If the buffer has data that is not in machine byte-order, this should
    be specified as part of the data-type, e.g.::

      >>> dt = np.dtype(int)
      >>> dt = dt.newbyteorder('>')
      >>> np.frombuffer(buf, dtype=dt)

    The data of the resulting array will not be byteswapped, but will be
    interpreted correctly.

    Examples
    --------
    >>> s = 'hello world'
    >>> np.frombuffer(s, dtype='S1', count=5, offset=6)
    array(['w', 'o', 'r', 'l', 'd'],
          dtype='|S1')

    numpy.add_newdocs
    arr.newbyteorder(new_order='S')

    Return the array with the same data viewed with a different byte order.

    Equivalent to::

        arr.view(arr.dtype.newbytorder(new_order))

    Changes are also made in all fields and sub-arrays of the array data
    type.



    Parameters
    ----------
    new_order : string, optional
        Byte order to force; a value from the byte order specifications
        above. `new_order` codes can be any of::

         * 'S' - swap dtype from current to opposite endian
         * {'<', 'L'} - little endian
         * {'>', 'B'} - big endian
         * {'=', 'N'} - native order
         * {'|', 'I'} - ignore (no change to byte order)

        The default value ('S') results in swapping the current
        byte order. The code does a case-insensitive check on the first
        letter of `new_order` for the alternatives above.  For example,
        any of 'B' or 'b' or 'biggish' are valid to specify big-endian.


    Returns
    -------
    new_arr : array
        New array object with the dtype reflecting given change to the
        byte order.

    
    current index in broadcasted result

    Examples
    --------
    >>> x = np.array([[1], [2], [3]])
    >>> y = np.array([4, 5, 6])
    >>> b = np.broadcast(x, y)
    >>> b.index
    0
    >>> b.next(), b.next(), b.next()
    ((1, 4), (1, 5), (1, 6))
    >>> b.index
    3

    
    digitize(x, bins, right=False)

    Return the indices of the bins to which each value in input array belongs.

    Each index ``i`` returned is such that ``bins[i-1] <= x < bins[i]`` if
    `bins` is monotonically increasing, or ``bins[i-1] > x >= bins[i]`` if
    `bins` is monotonically decreasing. If values in `x` are beyond the
    bounds of `bins`, 0 or ``len(bins)`` is returned as appropriate. If right
    is True, then the right bin is closed so that the index ``i`` is such
    that ``bins[i-1] < x <= bins[i]`` or bins[i-1] >= x > bins[i]`` if `bins`
    is monotonically increasing or decreasing, respectively.

    Parameters
    ----------
    x : array_like
        Input array to be binned. It has to be 1-dimensional.
    bins : array_like
        Array of bins. It has to be 1-dimensional and monotonic.
    right : bool, optional
        Indicating whether the intervals include the right or the left bin
        edge. Default behavior is (right==False) indicating that the interval
        does not include the right edge. The left bin and is open in this
        case. Ie., bins[i-1] <= x < bins[i] is the default behavior for
        monotonically increasing bins.

    Returns
    -------
    out : ndarray of ints
        Output array of indices, of same shape as `x`.

    Raises
    ------
    ValueError
        If the input is not 1-dimensional, or if `bins` is not monotonic.
    TypeError
        If the type of the input is complex.

    See Also
    --------
    bincount, histogram, unique

    Notes
    -----
    If values in `x` are such that they fall outside the bin range,
    attempting to index `bins` with the indices that `digitize` returns
    will result in an IndexError.

    Examples
    --------
    >>> x = np.array([0.2, 6.4, 3.0, 1.6])
    >>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])
    >>> inds = np.digitize(x, bins)
    >>> inds
    array([1, 4, 3, 2])
    >>> for n in range(x.size):
    ...   print bins[inds[n]-1], "<=", x[n], "<", bins[inds[n]]
    ...
    0.0 <= 0.2 < 1.0
    4.0 <= 6.4 < 10.0
    2.5 <= 3.0 < 4.0
    1.0 <= 1.6 < 2.5

    >>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])
    >>> bins = np.array([0,5,10,15,20])
    >>> np.digitize(x,bins,right=True)
    array([1, 2, 3, 4, 4])
    >>> np.digitize(x,bins,right=False)
    array([1, 3, 3, 4, 5])
    64-bit integer. Character code 'l'. Python int compatible.
    unravel_index(indices, dims, order='C')

    Converts a flat index or array of flat indices into a tuple
    of coordinate arrays.

    Parameters
    ----------
    indices : array_like
        An integer array whose elements are indices into the flattened
        version of an array of dimensions ``dims``. Before version 1.6.0,
        this function accepted just one index value.
    dims : tuple of ints
        The shape of the array to use for unraveling ``indices``.
    order : {'C', 'F'}, optional
        .. versionadded:: 1.6.0

        Determines whether the indices should be viewed as indexing in
        C (row-major) order or FORTRAN (column-major) order.

    Returns
    -------
    unraveled_coords : tuple of ndarray
        Each array in the tuple has the same shape as the ``indices``
        array.

    See Also
    --------
    ravel_multi_index

    Examples
    --------
    >>> np.unravel_index([22, 41, 37], (7,6))
    (array([3, 6, 6]), array([4, 5, 1]))
    >>> np.unravel_index([31, 41, 13], (7,6), order='F')
    (array([3, 6, 6]), array([4, 5, 1]))

    >>> np.unravel_index(1621, (6,7,8,9))
    (3, 1, 4, 1)

    
    a.any(axis=None, out=None)

    Returns True if any of the elements of `a` evaluate to True.

    Refer to `numpy.any` for full documentation.

    See Also
    --------
    numpy.any : equivalent function

    
    The number of outputs.

    Data attribute containing the number of arguments the ufunc treats as output.

    Notes
    -----
    Since all ufuncs can take output arguments, this will always be (at least) 1.

    Examples
    --------
    >>> np.add.nout
    1
    >>> np.multiply.nout
    1
    >>> np.power.nout
    1
    >>> np.exp.nout
    1

    
    a.getfield(dtype, offset=0)

    Returns a field of the given array as a certain type.

    A field is a view of the array data with a given data-type. The values in
    the view are determined by the given type and the offset into the current
    array in bytes. The offset needs to be such that the view dtype fits in the
    array dtype; for example an array of dtype complex128 has 16-byte elements.
    If taking a view with a 32-bit integer (4 bytes), the offset needs to be
    between 0 and 12 bytes.

    Parameters
    ----------
    dtype : str or dtype
        The data type of the view. The dtype size of the view can not be larger
        than that of the array itself.
    offset : int
        Number of bytes to skip before beginning the element view.

    Examples
    --------
    >>> x = np.diag([1.+1.j]*2)
    >>> x[1, 1] = 2 + 4.j
    >>> x
    array([[ 1.+1.j,  0.+0.j],
           [ 0.+0.j,  2.+4.j]])
    >>> x.getfield(np.float64)
    array([[ 1.,  0.],
           [ 0.,  2.]])

    By choosing an offset of 8 bytes we can select the complex part of the
    array for our view:

    >>> x.getfield(np.float64, offset=8)
    array([[ 1.,  0.],
       [ 0.,  4.]])

    
    inner(a, b)

    Inner product of two arrays.

    Ordinary inner product of vectors for 1-D arrays (without complex
    conjugation), in higher dimensions a sum product over the last axes.

    Parameters
    ----------
    a, b : array_like
        If `a` and `b` are nonscalar, their last dimensions of must match.

    Returns
    -------
    out : ndarray
        `out.shape = a.shape[:-1] + b.shape[:-1]`

    Raises
    ------
    ValueError
        If the last dimension of `a` and `b` has different size.

    See Also
    --------
    tensordot : Sum products over arbitrary axes.
    dot : Generalised matrix product, using second last dimension of `b`.
    einsum : Einstein summation convention.

    Notes
    -----
    For vectors (1-D arrays) it computes the ordinary inner-product::

        np.inner(a, b) = sum(a[:]*b[:])

    More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::

        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))

    or explicitly::

        np.inner(a, b)[i0,...,ir-1,j0,...,js-1]
             = sum(a[i0,...,ir-1,:]*b[j0,...,js-1,:])

    In addition `a` or `b` may be scalars, in which case::

       np.inner(a,b) = a*b

    Examples
    --------
    Ordinary inner product for vectors:

    >>> a = np.array([1,2,3])
    >>> b = np.array([0,1,0])
    >>> np.inner(a, b)
    2

    A multidimensional example:

    >>> a = np.arange(24).reshape((2,3,4))
    >>> b = np.arange(4)
    >>> np.inner(a, b)
    array([[ 14,  38,  62],
           [ 86, 110, 134]])

    An example where `b` is a scalar:

    >>> np.inner(np.eye(2), 7)
    array([[ 7.,  0.],
           [ 0.,  7.]])

    
    scalar(dtype, obj)

    Return a new scalar array of the given type initialized with obj.

    This function is meant mainly for pickle support. `dtype` must be a
    valid data-type descriptor. If `dtype` corresponds to an object
    descriptor, then `obj` can be any object, otherwise `obj` must be a
    string. If `obj` is not given, it will be interpreted as None for object
    type and as zeros for all other types.

    
    Total bytes consumed by the elements of the array.

    Notes
    -----
    Does not include memory consumed by non-element attributes of the
    array object.

    Examples
    --------
    >>> x = np.zeros((3,5,2), dtype=np.complex128)
    >>> x.nbytes
    480
    >>> np.prod(x.shape) * x.itemsize
    480

    
    a.byteswap(inplace)

    Swap the bytes of the array elements

    Toggle between low-endian and big-endian data representation by
    returning a byteswapped array, optionally swapped in-place.

    Parameters
    ----------
    inplace : bool, optional
        If ``True``, swap bytes in-place, default is ``False``.

    Returns
    -------
    out : ndarray
        The byteswapped array. If `inplace` is ``True``, this is
        a view to self.

    Examples
    --------
    >>> A = np.array([1, 256, 8755], dtype=np.int16)
    >>> map(hex, A)
    ['0x1', '0x100', '0x2233']
    >>> A.byteswap(True)
    array([  256,     1, 13090], dtype=int16)
    >>> map(hex, A)
    ['0x100', '0x1', '0x3322']

    Arrays of strings are not swapped

    >>> A = np.array(['ceg', 'fac'])
    >>> A.byteswap()
    array(['ceg', 'fac'],
          dtype='|S3')

    
    at(a, indices, b=None)

    Performs unbuffered in place operation on operand 'a' for elements
    specified by 'indices'. For addition ufunc, this method is equivalent to
    `a[indices] += b`, except that results are accumulated for elements that
    are indexed more than once. For example, `a[[0,0]] += 1` will only
    increment the first element once because of buffering, whereas
    `add.at(a, [0,0], 1)` will increment the first element twice.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        The array to perform in place operation on.
    indices : array_like or tuple
        Array like index object or slice object for indexing into first
        operand. If first operand has multiple dimensions, indices can be a
        tuple of array like index objects or slice objects.
    b : array_like
        Second operand for ufuncs requiring two operands. Operand must be
        broadcastable over first operand after indexing or slicing.

    Examples
    --------
    Set items 0 and 1 to their negative values:

    >>> a = np.array([1, 2, 3, 4])
    >>> np.negative.at(a, [0, 1])
    >>> print(a)
    array([-1, -2, 3, 4])

    ::

    Increment items 0 and 1, and increment item 2 twice:

    >>> a = np.array([1, 2, 3, 4])
    >>> np.add.at(a, [0, 1, 2, 2], 1)
    >>> print(a)
    array([2, 3, 5, 4])

    ::

    Add items 0 and 1 in first array to second array,
    and store results in first array:

    >>> a = np.array([1, 2, 3, 4])
    >>> b = np.array([1, 2])
    >>> np.add.at(a, [0, 1], b)
    >>> print(a)
    array([2, 4, 3, 4])

    
    set_string_function(f, repr=1)

    Internal method to set a function to be used when pretty printing arrays.

    
    empty(shape, dtype=float, order='C')

    Return a new array of given shape and type, without initializing entries.

    Parameters
    ----------
    shape : int or tuple of int
        Shape of the empty array
    dtype : data-type, optional
        Desired output data-type.
    order : {'C', 'F'}, optional
        Whether to store multi-dimensional data in C (row-major) or
        Fortran (column-major) order in memory.

    See Also
    --------
    empty_like, zeros, ones

    Notes
    -----
    `empty`, unlike `zeros`, does not set the array values to zero,
    and may therefore be marginally faster.  On the other hand, it requires
    the user to manually set all the values in the array, and should be
    used with caution.

    Examples
    --------
    >>> np.empty([2, 2])
    array([[ -9.74499359e+001,   6.69583040e-309],
           [  2.13182611e-314,   3.06959433e-309]])         #random

    >>> np.empty([2, 2], dtype=int)
    array([[-1073741821, -1067949133],
           [  496041986,    19249760]])                     #random

    
    accumulate(array, axis=0, dtype=None, out=None)

    Accumulate the result of applying the operator to all elements.

    For a one-dimensional array, accumulate produces results equivalent to::

      r = np.empty(len(A))
      t = op.identity        # op = the ufunc being applied to A's  elements
      for i in range(len(A)):
          t = op(t, A[i])
          r[i] = t
      return r

    For example, add.accumulate() is equivalent to np.cumsum().

    For a multi-dimensional array, accumulate is applied along only one
    axis (axis zero by default; see Examples below) so repeated use is
    necessary if one wants to accumulate over multiple axes.

    Parameters
    ----------
    array : array_like
        The array to act on.
    axis : int, optional
        The axis along which to apply the accumulation; default is zero.
    dtype : data-type code, optional
        The data-type used to represent the intermediate results. Defaults
        to the data-type of the output array if such is provided, or the
        the data-type of the input array if no output array is provided.
    out : ndarray, optional
        A location into which the result is stored. If not provided a
        freshly-allocated array is returned.

    Returns
    -------
    r : ndarray
        The accumulated values. If `out` was supplied, `r` is a reference to
        `out`.

    Examples
    --------
    1-D array examples:

    >>> np.add.accumulate([2, 3, 5])
    array([ 2,  5, 10])
    >>> np.multiply.accumulate([2, 3, 5])
    array([ 2,  6, 30])

    2-D array examples:

    >>> I = np.eye(2)
    >>> I
    array([[ 1.,  0.],
           [ 0.,  1.]])

    Accumulate along axis 0 (rows), down columns:

    >>> np.add.accumulate(I, 0)
    array([[ 1.,  0.],
           [ 1.,  1.]])
    >>> np.add.accumulate(I) # no axis specified = axis zero
    array([[ 1.,  0.],
           [ 1.,  1.]])

    Accumulate along axis 1 (columns), through rows:

    >>> np.add.accumulate(I, 1)
    array([[ 1.,  1.],
           [ 0.,  1.]])

    
    Total size of broadcasted result.

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]])
    >>> b = np.broadcast(x, y)
    >>> b.size
    9

    
    packbits(myarray, axis=None)

    Packs the elements of a binary-valued array into bits in a uint8 array.

    The result is padded to full bytes by inserting zero bits at the end.

    Parameters
    ----------
    myarray : array_like
        An integer type array whose elements should be packed to bits.
    axis : int, optional
        The dimension over which bit-packing is done.
        ``None`` implies packing the flattened array.

    Returns
    -------
    packed : ndarray
        Array of type uint8 whose elements represent bits corresponding to the
        logical (0 or nonzero) value of the input elements. The shape of
        `packed` has the same number of dimensions as the input (unless `axis`
        is None, in which case the output is 1-D).

    See Also
    --------
    unpackbits: Unpacks elements of a uint8 array into a binary-valued output
                array.

    Examples
    --------
    >>> a = np.array([[[1,0,1],
    ...                [0,1,0]],
    ...               [[1,1,0],
    ...                [0,0,1]]])
    >>> b = np.packbits(a, axis=-1)
    >>> b
    array([[[160],[64]],[[192],[32]]], dtype=uint8)

    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,
    and 32 = 0010 0000.

    
    a.copy(order='C')

    Return a copy of the array.

    Parameters
    ----------
    order : {'C', 'F', 'A', 'K'}, optional
        Controls the memory layout of the copy. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of `a` as closely
        as possible. (Note that this function and :func:numpy.copy are very
        similar, but have different default values for their order=
        arguments.)

    See also
    --------
    numpy.copy
    numpy.copyto

    Examples
    --------
    >>> x = np.array([[1,2,3],[4,5,6]], order='F')

    >>> y = x.copy()

    >>> x.fill(0)

    >>> x
    array([[0, 0, 0],
           [0, 0, 0]])

    >>> y
    array([[1, 2, 3],
           [4, 5, 6]])

    >>> y.flags['C_CONTIGUOUS']
    True

    
    Number of elements in the array.

    Equivalent to ``np.prod(a.shape)``, i.e., the product of the array's
    dimensions.

    Examples
    --------
    >>> x = np.zeros((3, 5, 2), dtype=np.complex128)
    >>> x.size
    30
    >>> np.prod(x.shape)
    30

    
    a.all(axis=None, out=None)

    Returns True if all elements evaluate to True.

    Refer to `numpy.all` for full documentation.

    See Also
    --------
    numpy.all : equivalent function

    
    Produce an object that mimics broadcasting.

    Parameters
    ----------
    in1, in2, ... : array_like
        Input parameters.

    Returns
    -------
    b : broadcast object
        Broadcast the input parameters against one another, and
        return an object that encapsulates the result.
        Amongst others, it has ``shape`` and ``nd`` properties, and
        may be used as an iterator.

    Examples
    --------
    Manually adding two vectors, using broadcasting:

    >>> x = np.array([[1], [2], [3]])
    >>> y = np.array([4, 5, 6])
    >>> b = np.broadcast(x, y)

    >>> out = np.empty(b.shape)
    >>> out.flat = [u+v for (u,v) in b]
    >>> out
    array([[ 5.,  6.,  7.],
           [ 6.,  7.,  8.],
           [ 7.,  8.,  9.]])

    Compare against built-in broadcasting:

    >>> x + y
    array([[5, 6, 7],
           [6, 7, 8],
           [7, 8, 9]])

    
    `nd_grid` instance which returns a dense multi-dimensional "meshgrid".

    An instance of `numpy.lib.index_tricks.nd_grid` which returns an dense
    (or fleshed out) mesh-grid when indexed, so that each returned argument
    has the same shape.  The dimensions and number of the output arrays are
    equal to the number of indexing dimensions.  If the step length is not a
    complex number, then the stop is not inclusive.

    However, if the step length is a **complex number** (e.g. 5j), then
    the integer part of its magnitude is interpreted as specifying the
    number of points to create between the start and stop values, where
    the stop value **is inclusive**.

    Returns
    ----------
    mesh-grid `ndarrays` all of the same dimensions

    See Also
    --------
    numpy.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects
    ogrid : like mgrid but returns open (not fleshed out) mesh grids
    r_ : array concatenator

    Examples
    --------
    >>> np.mgrid[0:5,0:5]
    array([[[0, 0, 0, 0, 0],
            [1, 1, 1, 1, 1],
            [2, 2, 2, 2, 2],
            [3, 3, 3, 3, 3],
            [4, 4, 4, 4, 4]],
           [[0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4]]])
    >>> np.mgrid[-1:1:5j]
    array([-1. , -0.5,  0. ,  0.5,  1. ])

    
    Number of array dimensions.

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> x.ndim
    1
    >>> y = np.zeros((2, 3, 4))
    >>> y.ndim
    3

    
    where(condition, [x, y])

    Return elements, either from `x` or `y`, depending on `condition`.

    If only `condition` is given, return ``condition.nonzero()``.

    Parameters
    ----------
    condition : array_like, bool
        When True, yield `x`, otherwise yield `y`.
    x, y : array_like, optional
        Values from which to choose. `x` and `y` need to have the same
        shape as `condition`.

    Returns
    -------
    out : ndarray or tuple of ndarrays
        If both `x` and `y` are specified, the output array contains
        elements of `x` where `condition` is True, and elements from
        `y` elsewhere.

        If only `condition` is given, return the tuple
        ``condition.nonzero()``, the indices where `condition` is True.

    See Also
    --------
    nonzero, choose

    Notes
    -----
    If `x` and `y` are given and input arrays are 1-D, `where` is
    equivalent to::

        [xv if c else yv for (c,xv,yv) in zip(condition,x,y)]

    Examples
    --------
    >>> np.where([[True, False], [True, True]],
    ...          [[1, 2], [3, 4]],
    ...          [[9, 8], [7, 6]])
    array([[1, 8],
           [3, 4]])

    >>> np.where([[0, 1], [1, 0]])
    (array([0, 1]), array([1, 0]))

    >>> x = np.arange(9.).reshape(3, 3)
    >>> np.where( x > 5 )
    (array([2, 2, 2]), array([0, 1, 2]))
    >>> x[np.where( x > 3.0 )]               # Note: result is 1D.
    array([ 4.,  5.,  6.,  7.,  8.])
    >>> np.where(x < 5, x, -1)               # Note: broadcasting.
    array([[ 0.,  1.,  2.],
           [ 3.,  4., -1.],
           [-1., -1., -1.]])

    Find the indices of elements of `x` that are in `goodvalues`.

    >>> goodvalues = [3, 4, 7]
    >>> ix = np.in1d(x.ravel(), goodvalues).reshape(x.shape)
    >>> ix
    array([[False, False, False],
           [ True,  True, False],
           [False,  True, False]], dtype=bool)
    >>> np.where(ix)
    (array([1, 1, 2]), array([0, 1, 1]))

    
    a.min(axis=None, out=None)

    Return the minimum along a given axis.

    Refer to `numpy.amin` for full documentation.

    See Also
    --------
    numpy.amin : equivalent function

    
    debug_print()

    Print the current state of the `nditer` instance and debug info to stdout.

    
    The number of arguments.

    Data attribute containing the number of arguments the ufunc takes, including
    optional ones.

    Notes
    -----
    Typically this value will be one more than what you might expect because all
    ufuncs take  the optional "out" argument.

    Examples
    --------
    >>> np.add.nargs
    3
    >>> np.multiply.nargs
    3
    >>> np.power.nargs
    3
    >>> np.exp.nargs
    2
    a.__array_wrap__(obj) -> Object of same type as ndarray object a.

    
    a.tostring(order='C')

    Construct a Python string containing the raw data bytes in the array.

    Constructs a Python string showing a copy of the raw contents of
    data memory. The string can be produced in either 'C' or 'Fortran',
    or 'Any' order (the default is 'C'-order). 'Any' order means C-order
    unless the F_CONTIGUOUS flag in the array is set, in which case it
    means 'Fortran' order.

    Parameters
    ----------
    order : {'C', 'F', None}, optional
        Order of the data for multidimensional arrays:
        C, Fortran, or the same as for the original array.

    Returns
    -------
    s : str
        A Python string exhibiting a copy of `a`'s raw data.

    Examples
    --------
    >>> x = np.array([[0, 1], [2, 3]])
    >>> x.tostring()
    '\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00'
    >>> x.tostring('C') == x.tostring()
    True
    >>> x.tostring('F')
    '\x00\x00\x00\x00\x02\x00\x00\x00\x01\x00\x00\x00\x03\x00\x00\x00'

    
    enable_external_loop()

    When the "external_loop" was not used during construction, but
    is desired, this modifies the iterator to behave as if the flag
    was specified.

    
    a.take(indices, axis=None, out=None, mode='raise')

    Return an array formed from the elements of `a` at the given indices.

    Refer to `numpy.take` for full documentation.

    See Also
    --------
    numpy.take : equivalent function

    
    Shape tuple of the sub-array if this data type describes a sub-array,
    and ``()`` otherwise.

    16-bit integer. Character code ``h``. C short compatible./usr/lib/python2.7/dist-packages/numpy/add_newdocs.py
    putmask(a, mask, values)

    Changes elements of an array based on conditional and input values.

    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.

    If `values` is not the same size as `a` and `mask` then it will repeat.
    This gives behavior different from ``a[mask] = values``.

    .. note:: The `putmask` functionality is also provided by `copyto`, which
              can be significantly faster and in addition is NA-aware
              (`preservena` keyword).  Replacing `putmask` with
              ``np.copyto(a, values, where=mask)`` is recommended.

    Parameters
    ----------
    a : array_like
        Target array.
    mask : array_like
        Boolean mask array. It has to be the same shape as `a`.
    values : array_like
        Values to put into `a` where `mask` is True. If `values` is smaller
        than `a` it will be repeated.

    See Also
    --------
    place, put, take, copyto

    Examples
    --------
    >>> x = np.arange(6).reshape(2, 3)
    >>> np.putmask(x, x>2, x**2)
    >>> x
    array([[ 0,  1,  2],
           [ 9, 16, 25]])

    If `values` is smaller than `a` it is repeated:

    >>> x = np.arange(5)
    >>> np.putmask(x, x>1, [-33, -44])
    >>> x
    array([  0,   1, -33, -44, -33])

    
    remove_multi_index()

    When the "multi_index" flag was specified, this removes it, allowing
    the internal iteration structure to be optimized further.

    
    Shape of broadcasted result.

    Examples
    --------
    >>> x = np.array([1, 2, 3])
    >>> y = np.array([[4], [5], [6]])
    >>> b = np.broadcast(x, y)
    >>> b.shape
    (3, 3)

    
    a.repeat(repeats, axis=None)

    Repeat elements of an array.

    Refer to `numpy.repeat` for full documentation.

    See Also
    --------
    numpy.repeat : equivalent function

    
    remove_axis(i)

    Removes axis `i` from the iterator. Requires that the flag "multi_index"
    be enabled.

    __array__(type=None) Get array from iterator

    
    a.ravel([order])

    Return a flattened array.

    Refer to `numpy.ravel` for full documentation.

    See Also
    --------
    numpy.ravel : equivalent function

    ndarray.flat : a flat iterator on the array.

    
    a.cumsum(axis=None, dtype=None, out=None)

    Return the cumulative sum of the elements along the given axis.

    Refer to `numpy.cumsum` for full documentation.

    See Also
    --------
    numpy.cumsum : equivalent function

    
    promote_types(type1, type2)

    Returns the data type with the smallest size and smallest scalar
    kind to which both ``type1`` and ``type2`` may be safely cast.
    The returned data type is always in native byte order.

    This function is symmetric and associative.

    Parameters
    ----------
    type1 : dtype or dtype specifier
        First data type.
    type2 : dtype or dtype specifier
        Second data type.

    Returns
    -------
    out : dtype
        The promoted data type.

    Notes
    -----
    .. versionadded:: 1.6.0

    See Also
    --------
    result_type, dtype, can_cast

    Examples
    --------
    >>> np.promote_types('f4', 'f8')
    dtype('float64')

    >>> np.promote_types('i8', 'f4')
    dtype('float64')

    >>> np.promote_types('>i8', '<c8')
    dtype('complex128')

    >>> np.promote_types('i1', 'S8')
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    TypeError: invalid type promotion

    
    empty_like(a, dtype=None, order='K', subok=True)

    Return a new array with the same shape and type as a given array.

    Parameters
    ----------
    a : array_like
        The shape and data-type of `a` define these same attributes of the
        returned array.
    dtype : data-type, optional
        .. versionadded:: 1.6.0
        Overrides the data type of the result.
    order : {'C', 'F', 'A', or 'K'}, optional
        .. versionadded:: 1.6.0
        Overrides the memory layout of the result. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if ``a`` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of ``a`` as closely
        as possible.
    subok : bool, optional.
        If True, then the newly created array will use the sub-class
        type of 'a', otherwise it will be a base-class array. Defaults
        to True.

    Returns
    -------
    out : ndarray
        Array of uninitialized (arbitrary) data with the same
        shape and type as `a`.

    See Also
    --------
    ones_like : Return an array of ones with shape and type of input.
    zeros_like : Return an array of zeros with shape and type of input.
    empty : Return a new uninitialized array.
    ones : Return a new array setting values to one.
    zeros : Return a new array setting values to zero.

    Notes
    -----
    This function does *not* initialize the returned array; to do that use
    `zeros_like` or `ones_like` instead.  It may be marginally faster than
    the functions that do set the array values.

    Examples
    --------
    >>> a = ([1,2,3], [4,5,6])                         # a is array-like
    >>> np.empty_like(a)
    array([[-1073741821, -1073741821,           3],    #random
           [          0,           0, -1073741821]])
    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])
    >>> np.empty_like(a)
    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000],#random
           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])

    
    a.partition(kth, axis=-1, kind='introselect', order=None)

    Rearranges the elements in the array in such a way that value of the
    element in kth position is in the position it would be in a sorted array.
    All elements smaller than the kth element are moved before this element and
    all equal or greater are moved behind it. The ordering of the elements in
    the two partitions is undefined.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    kth : int or sequence of ints
        Element index to partition by. The kth element value will be in its
        final sorted position and all smaller elements will be moved before it
        and all equal or greater elements behind it.
        The order all elements in the partitions is undefined.
        If provided with a sequence of kth it will partition all elements
        indexed by kth of them into their sorted position at once.
    axis : int, optional
        Axis along which to sort. Default is -1, which means sort along the
        last axis.
    kind : {'introselect'}, optional
        Selection algorithm. Default is 'introselect'.
    order : list, optional
        When `a` is an array with fields defined, this argument specifies
        which fields to compare first, second, etc.  Not all fields need be
        specified.

    See Also
    --------
    numpy.partition : Return a parititioned copy of an array.
    argpartition : Indirect partition.
    sort : Full sort.

    Notes
    -----
    See ``np.partition`` for notes on the different algorithms.

    Examples
    --------
    >>> a = np.array([3, 4, 2, 1])
    >>> a.partition(a, 3)
    >>> a
    array([2, 1, 3, 4])

    >>> a.partition((1, 3))
    array([1, 2, 3, 4])
    
    add_docstring(obj, docstring)

    Add a docstring to a built-in obj if possible.
    If the obj already has a docstring raise a RuntimeError
    If this routine does not know how to add a docstring to the object
    raise a TypeError
    
    The required alignment (bytes) of this data-type according to the compiler.

    More information is available in the C-API section of the manual.

    
    Boolean indicating whether the dtype is a struct which maintains
    field alignment. This flag is sticky, so when combining multiple
    structs together, it is preserved and produces new dtypes which
    are also aligned.
    
    Length of one array element in bytes.

    Examples
    --------
    >>> x = np.array([1,2,3], dtype=np.float64)
    >>> x.itemsize
    8
    >>> x = np.array([1,2,3], dtype=np.complex128)
    >>> x.itemsize
    16

    
    a.argsort(axis=-1, kind='quicksort', order=None)

    Returns the indices that would sort this array.

    Refer to `numpy.argsort` for full documentation.

    See Also
    --------
    numpy.argsort : equivalent function

    
    Not implemented (virtual attribute)

    Class generic exists solely to derive numpy scalars from, and possesses,
    albeit unimplemented, all the attributes of the ndarray class so as to
    a uniform API.

    See Also
    --------
    The corresponding attribute of the derived class of interest.

    The imaginary part of the scalar.a.__setstate__(version, shape, dtype, isfortran, rawdata)

    For unpickling.

    Parameters
    ----------
    version : int
        optional pickle version. If omitted defaults to 0.
    shape : tuple
    dtype : data-type
    isFortran : bool
    rawdata : string or list
        a binary string with the data (or a list if 'a' is an object array)

    
    outer(A, B)

    Apply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.

    Let ``M = A.ndim``, ``N = B.ndim``. Then the result, `C`, of
    ``op.outer(A, B)`` is an array of dimension M + N such that:

    .. math:: C[i_0, ..., i_{M-1}, j_0, ..., j_{N-1}] =
       op(A[i_0, ..., i_{M-1}], B[j_0, ..., j_{N-1}])

    For `A` and `B` one-dimensional, this is equivalent to::

      r = empty(len(A),len(B))
      for i in range(len(A)):
          for j in range(len(B)):
              r[i,j] = op(A[i], B[j]) # op = ufunc in question

    Parameters
    ----------
    A : array_like
        First array
    B : array_like
        Second array

    Returns
    -------
    r : ndarray
        Output array

    See Also
    --------
    numpy.outer

    Examples
    --------
    >>> np.multiply.outer([1, 2, 3], [4, 5, 6])
    array([[ 4,  5,  6],
           [ 8, 10, 12],
           [12, 15, 18]])

    A multi-dimensional example:

    >>> A = np.array([[1, 2, 3], [4, 5, 6]])
    >>> A.shape
    (2, 3)
    >>> B = np.array([[1, 2, 3, 4]])
    >>> B.shape
    (1, 4)
    >>> C = np.multiply.outer(A, B)
    >>> C.shape; C
    (2, 3, 1, 4)
    array([[[[ 1,  2,  3,  4]],
            [[ 2,  4,  6,  8]],
            [[ 3,  6,  9, 12]]],
           [[[ 4,  8, 12, 16]],
            [[ 5, 10, 15, 20]],
            [[ 6, 12, 18, 24]]]])

    
    Tuple of array dimensions.

    Notes
    -----
    May be used to "reshape" the array, as long as this would not
    require a change in the total number of elements

    Examples
    --------
    >>> x = np.array([1, 2, 3, 4])
    >>> x.shape
    (4,)
    >>> y = np.zeros((2, 3, 4))
    >>> y.shape
    (2, 3, 4)
    >>> y.shape = (3, 8)
    >>> y
    array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])
    >>> y.shape = (3, 6)
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ValueError: total size of new array must be unchanged

    
    Tuple of bytes to step in each dimension when traversing an array.

    The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`
    is::

        offset = sum(np.array(i) * a.strides)

    A more detailed explanation of strides can be found in the
    "ndarray.rst" file in the NumPy reference guide.

    Notes
    -----
    Imagine an array of 32-bit integers (each 4 bytes)::

      x = np.array([[0, 1, 2, 3, 4],
                    [5, 6, 7, 8, 9]], dtype=np.int32)

    This array is stored in memory as 40 bytes, one after the other
    (known as a contiguous block of memory).  The strides of an array tell
    us how many bytes we have to skip in memory to move to the next position
    along a certain axis.  For example, we have to skip 4 bytes (1 value) to
    move to the next column, but 20 bytes (5 values) to get to the same
    position in the next row.  As such, the strides for the array `x` will be
    ``(20, 4)``.

    See Also
    --------
    numpy.lib.stride_tricks.as_strided

    Examples
    --------
    >>> y = np.reshape(np.arange(2*3*4), (2,3,4))
    >>> y
    array([[[ 0,  1,  2,  3],
            [ 4,  5,  6,  7],
            [ 8,  9, 10, 11]],
           [[12, 13, 14, 15],
            [16, 17, 18, 19],
            [20, 21, 22, 23]]])
    >>> y.strides
    (48, 16, 4)
    >>> y[1,1,1]
    17
    >>> offset=sum(y.strides * np.array((1,1,1)))
    >>> offset/y.itemsize
    17

    >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)
    >>> x.strides
    (32, 4, 224, 1344)
    >>> i = np.array([3,5,2,2])
    >>> offset = sum(i * x.strides)
    >>> x[3,5,2,2]
    813
    >>> offset / x.itemsize
    813

    
    a.cumprod(axis=None, dtype=None, out=None)

    Return the cumulative product of the elements along the given axis.

    Refer to `numpy.cumprod` for full documentation.

    See Also
    --------
    numpy.cumprod : equivalent function

    
    a.argmin(axis=None, out=None)

    Return indices of the minimum values along the given axis of `a`.

    Refer to `numpy.argmin` for detailed documentation.

    See Also
    --------
    numpy.argmin : equivalent function

    
    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)

    First adjusts the date to fall on a valid day according to
    the ``roll`` rule, then applies offsets to the given dates
    counted in valid days.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    dates : array_like of datetime64[D]
        The array of dates to process.
    offsets : array_like of int
        The array of offsets, which is broadcast with ``dates``.
    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional
        How to treat dates that do not fall on a valid day. The default
        is 'raise'.

          * 'raise' means to raise an exception for an invalid day.
          * 'nat' means to return a NaT (not-a-time) for an invalid day.
          * 'forward' and 'following' mean to take the first valid day
            later in time.
          * 'backward' and 'preceding' mean to take the first valid day
            earlier in time.
          * 'modifiedfollowing' means to take the first valid day
            later in time unless it is across a Month boundary, in which
            case to take the first valid day earlier in time.
          * 'modifiedpreceding' means to take the first valid day
            earlier in time unless it is across a Month boundary, in which
            case to take the first valid day later in time.
    weekmask : str or array_like of bool, optional
        A seven-element array indicating which of Monday through Sunday are
        valid days. May be specified as a length-seven list or array, like
        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
        weekdays, optionally separated by white space. Valid abbreviations
        are: Mon Tue Wed Thu Fri Sat Sun
    holidays : array_like of datetime64[D], optional
        An array of dates to consider as invalid dates.  They may be
        specified in any order, and NaT (not-a-time) dates are ignored.
        This list is saved in a normalized form that is suited for
        fast calculations of valid days.
    busdaycal : busdaycalendar, optional
        A `busdaycalendar` object which specifies the valid days. If this
        parameter is provided, neither weekmask nor holidays may be
        provided.
    out : array of datetime64[D], optional
        If provided, this array is filled with the result.

    Returns
    -------
    out : array of datetime64[D]
        An array with a shape from broadcasting ``dates`` and ``offsets``
        together, containing the dates with offsets applied.

    See Also
    --------
    busdaycalendar: An object that specifies a custom set of valid days.
    is_busday : Returns a boolean array indicating valid days.
    busday_count : Counts how many valid days are in a half-open date range.

    Examples
    --------
    >>> # First business day in October 2011 (not accounting for holidays)
    ... np.busday_offset('2011-10', 0, roll='forward')
    numpy.datetime64('2011-10-03','D')
    >>> # Last business day in February 2012 (not accounting for holidays)
    ... np.busday_offset('2012-03', -1, roll='forward')
    numpy.datetime64('2012-02-29','D')
    >>> # Third Wednesday in January 2011
    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')
    numpy.datetime64('2011-01-19','D')
    >>> # 2012 Mother's Day in Canada and the U.S.
    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')
    numpy.datetime64('2012-05-13','D')

    >>> # First business day on or after a date
    ... np.busday_offset('2011-03-20', 0, roll='forward')
    numpy.datetime64('2011-03-21','D')
    >>> np.busday_offset('2011-03-22', 0, roll='forward')
    numpy.datetime64('2011-03-22','D')
    >>> # First business day after a date
    ... np.busday_offset('2011-03-20', 1, roll='backward')
    numpy.datetime64('2011-03-21','D')
    >>> np.busday_offset('2011-03-22', 1, roll='backward')
    numpy.datetime64('2011-03-23','D')
    
    a.setasflat(arr)

    Equivalent to a.flat = arr.flat, but is generally more efficient.
    This function does not check for overlap, so if ``arr`` and ``a``
    are viewing the same data with different strides, the results will
    be unpredictable.

    Parameters
    ----------
    arr : array_like
        The array to copy into a.

    Examples
    --------
    >>> a = np.arange(2*4).reshape(2,4)[:,:-1]; a
    array([[0, 1, 2],
           [4, 5, 6]])
    >>> b = np.arange(3*3, dtype='f4').reshape(3,3).T[::-1,:-1]; b
    array([[ 2.,  5.],
           [ 1.,  4.],
           [ 0.,  3.]], dtype=float32)
    >>> a.setasflat(b)
    >>> a
    array([[2, 5, 1],
           [4, 0, 3]])

    
    The number of types.

    The number of numerical NumPy types - of which there are 18 total - on which
    the ufunc can operate.

    See Also
    --------
    numpy.ufunc.types

    Examples
    --------
    >>> np.add.ntypes
    18
    >>> np.multiply.ntypes
    18
    >>> np.power.ntypes
    17
    >>> np.exp.ntypes
    7
    >>> np.remainder.ntypes
    14

    
    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)

    Counts the number of valid days between `begindates` and
    `enddates`, not including the day of `enddates`.

    If ``enddates`` specifies a date value that is earlier than the
    corresponding ``begindates`` date value, the count will be negative.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    begindates : array_like of datetime64[D]
        The array of the first dates for counting.
    enddates : array_like of datetime64[D]
        The array of the end dates for counting, which are excluded
        from the count themselves.
    weekmask : str or array_like of bool, optional
        A seven-element array indicating which of Monday through Sunday are
        valid days. May be specified as a length-seven list or array, like
        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
        weekdays, optionally separated by white space. Valid abbreviations
        are: Mon Tue Wed Thu Fri Sat Sun
    holidays : array_like of datetime64[D], optional
        An array of dates to consider as invalid dates.  They may be
        specified in any order, and NaT (not-a-time) dates are ignored.
        This list is saved in a normalized form that is suited for
        fast calculations of valid days.
    busdaycal : busdaycalendar, optional
        A `busdaycalendar` object which specifies the valid days. If this
        parameter is provided, neither weekmask nor holidays may be
        provided.
    out : array of int, optional
        If provided, this array is filled with the result.

    Returns
    -------
    out : array of int
        An array with a shape from broadcasting ``begindates`` and ``enddates``
        together, containing the number of valid days between
        the begin and end dates.

    See Also
    --------
    busdaycalendar: An object that specifies a custom set of valid days.
    is_busday : Returns a boolean array indicating valid days.
    busday_offset : Applies an offset counted in valid days.

    Examples
    --------
    >>> # Number of weekdays in January 2011
    ... np.busday_count('2011-01', '2011-02')
    21
    >>> # Number of weekdays in 2011
    ...  np.busday_count('2011', '2012')
    260
    >>> # Number of Saturdays in 2011
    ... np.busday_count('2011', '2012', weekmask='Sat')
    53
    
    Restore `dot`, `vdot`, and `innerproduct` to the default non-BLAS
    implementations.

    Typically, the user will only need to call this when troubleshooting and
    installation problem, reproducing the conditions of a build without an
    accelerated BLAS, or when being very careful about benchmarking linear
    algebra operations.

    See Also
    --------
    alterdot : `restoredot` undoes the effects of `alterdot`.

    
    a.choose(choices, out=None, mode='raise')

    Use an index array to construct a new array from a set of choices.

    Refer to `numpy.choose` for full documentation.

    See Also
    --------
    numpy.choose : equivalent function

    
    a.sum(axis=None, dtype=None, out=None)

    Return the sum of the array elements over the given axis.

    Refer to `numpy.sum` for full documentation.

    See Also
    --------
    numpy.sum : equivalent function

    a.__array_prepare__(obj) -> Object of same type as ndarray object obj.

    A unique character code for each of the 21 different built-in types.
    fromstring(string, dtype=float, count=-1, sep='')

    A new 1-D array initialized from raw binary or text data in a string.

    Parameters
    ----------
    string : str
        A string containing the data.
    dtype : data-type, optional
        The data type of the array; default: float.  For binary input data,
        the data must be in exactly this format.
    count : int, optional
        Read this number of `dtype` elements from the data.  If this is
        negative (the default), the count will be determined from the
        length of the data.
    sep : str, optional
        If not provided or, equivalently, the empty string, the data will
        be interpreted as binary data; otherwise, as ASCII text with
        decimal numbers.  Also in this latter case, this argument is
        interpreted as the string separating numbers in the data; extra
        whitespace between elements is also ignored.

    Returns
    -------
    arr : ndarray
        The constructed array.

    Raises
    ------
    ValueError
        If the string is not the correct size to satisfy the requested
        `dtype` and `count`.

    See Also
    --------
    frombuffer, fromfile, fromiter

    Examples
    --------
    >>> np.fromstring('\x01\x02', dtype=np.uint8)
    array([1, 2], dtype=uint8)
    >>> np.fromstring('1 2', dtype=int, sep=' ')
    array([1, 2])
    >>> np.fromstring('1, 2', dtype=int, sep=',')
    array([1, 2])
    >>> np.fromstring('\x01\x02\x03\x04\x05', dtype=np.uint8, count=3)
    array([1, 2, 3], dtype=uint8)

    /usr/lib/python2.7/dist-packages/numpy/compat
Compatibility module.

This module contains duplicated code from Python itself or 3rd party
extensions, which may be included for the following reasons:

  * compatibility
  * we may only need a small subset of the copied library/module

/usr/lib/python2.7/dist-packages/numpy/compat/__init__.pyopnameco_flagsSTORE_FASTco_varnamesCO_NEWLOCALSCO_OPTIMIZEDUNPACK_TUPLEgetargvaluesUNPACK_SEQUENCEformatargvaluesRecursively walk a sequence, stringifying each element.Get the names and default values of a function's arguments.

    A tuple of four things is returned: (args, varargs, varkw, defaults).
    'args' is a list of the argument names (it may contain nested lists).
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'defaults' is an n-tuple of the default values of the last n arguments.
    /usr/lib/python2.7/dist-packages/numpy/compat/_inspect.pyGet information about the arguments accepted by a code object.

    Three things are returned: (args, varargs, varkw), where 'args' is
    a list of argument names (possibly containing nested lists), and
    'varargs' and 'varkw' are the names of the * and ** arguments or None.Return true if the object is a code object.

    Code objects provide these attributes:
        co_argcount     number of arguments (not including * or ** args)
        co_code         string of raw compiled bytecode
        co_consts       tuple of constants used in the bytecode
        co_filename     name of file in which this code object was created
        co_firstlineno  number of first line in Python source code
        co_flags        bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
        co_lnotab       encoded mapping of line numbers to bytecode indices
        co_name         name with which this code object was defined
        co_names        tuple of names of local variables
        co_nlocals      number of local variables
        co_stacksize    virtual machine stack space required
        co_varnames     tuple of names of arguments and local variablesFormat an argument spec from the 4 values returned by getargspec.

    The first four arguments are (args, varargs, varkw, defaults).  The
    other four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.Subset of inspect module from upstream python

We use this instead of upstream because upstream inspect is slow to import, and
significanly contributes to numpy import times. Importing this copy has almost
no overhead.

Return true if the object is a user-defined function.

    Function objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this function was defined
        func_code       code object containing compiled function bytecode
        func_defaults   tuple of any default values for arguments
        func_doc        (same as __doc__)
        func_globals    global namespace in which this function was defined
        func_name       (same as __name__)Return true if the object is an instance method.

    Instance method objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this method was defined
        im_class        class object in which this method belongs
        im_func         function object containing implementation of method
        im_self         instance to which this method is bound, or Nonearg is not a code objectFormat an argument spec from the 4 values returned by getargvalues.

    The first four arguments are (args, varargs, varkw, locals).  The
    next four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.arg is not a Python functionnumpy.compat._inspectGet information about arguments passed into a particular frame.

    A tuple of four things is returned: (args, varargs, varkw, locals).
    'args' is a list of the argument names (it may contain nested lists).
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'locals' is the locals dictionary of the given frame.sixuFileIOstrchargetexceptionBufferedReadernumpy.compat.py3k/usr/lib/python2.7/dist-packages/numpy/compat/py3k.py
Python 3 compatibility tools.

scalarmathwhichmodule/usr/lib/python2.7/dist-packages/numpy/core/usr/lib/python2.7/dist-packages/numpy/core/__init__.pyUSV_zerodfnamesnewitemoldnames_newnames_usefieldscopy_dtypeview_dtypeget_strideslast_offset_commastring_index_fieldsstart_paddingnumpy_byteorderget_as_parameterc-types data{t   ?R    t   BR   t   IR   t   HR   t   LR   t   OR   t   QR   t   bR   t   eR   t   dR	   t   gR
   t   fR   s   Zdt   Dt   hR   s   Zft   Fs   Zgt   Gt   lR   t   qR   t   iR   t   st   St   wt   Ut   xt   V0c-types shape_as parameter_c-types strides{t   qs   i8t   BR   t   es   f2t   dR   t   fR   s   Zdt   Dt   is   i4s   Zft   Ft   Ls   u4t   OR	   t   ls   i4t   Qs   u8t   Is   u4t   st   St   bR   t   wt   Ut   Hs   u2t   xt   Vt   hs   i2t   ?R   0Inject the specified number of padding bytes at the end of a dtypeT{unsupported order value: %s\s+$
A place for code to be called from core C-code.

Some things are more easily handled Python.

|V%dentry not a 2- or 3- tupleall itemsizes must be fixed./usr/lib/python2.7/dist-packages/numpy/core/_internal.pyunknown field name: %sDuplicate field name '%s' in PEP3118 formatinvalid offset.Unknown PEP 3118 data type specifier %r(?P<order1>[<>|=]?)(?P<repeats> *[(]?[ ,0-9L]*[)]? *)(?P<order2>[<>|=]?)(?P<dtype>[A-Za-z0-9.]*(?:\[[a-zA-Z0-9,.]+\])?)format number %d of "%s" is not recognizedinconsistent byte-order specification %s and %spad%dCalculate the greatest common divisor of a and b(    t   spect	   byteordert   is_subdtypet   dtypet   fieldst   offsett   explicit_namet   this_explicit_namet   common_alignmentt
   is_paddingt   last_offsett   dummy_name_indext   next_dummy_namet   get_dummy_namet   valuet   shapet   jt   type_mapt   type_map_charst   itemsizet   alignt   next_byteordert   typechart	   dtypechart   numpy_byteordert   extra_offsett   start_paddingt   intra_paddingt   it   namet   rett   padding_anyarrmeannumpy.core._methodsDegrees of freedom <= 0 for slice/usr/lib/python2.7/dist-packages/numpy/core/_methods.pyMean of empty slice.
Array methods which are called by the both the C-code for the method
and the Python code for the NumPy-namespace function

-C6?UTC>N}a+expsigndtypeobjnumpystrstr_kindexp_formatfillFormatfloat_kindimag_formatmax_str_lenreal_formatspecial_fmtcomplex_kindlarge_exponentlongcomplexfloatrestructuredtext%d.%de
    Return the current print options.

    Returns
    -------
    print_opts : dict
        Dictionary of current print options with keys

          - precision : int
          - threshold : int
          - edgeitems : int
          - linewidth : int
          - suppress : bool
          - nanstr : str
          - infstr : str
          - formatter : dict of callables

        For a full description of these options, see `set_printoptions`.

    See Also
    --------
    set_printoptions, set_string_function

    %+%%%ds%d.%df%#+The `_format` attribute is deprecated in Numpy 2.0 and will be removed in 2.1. Use the `formatter` kw instead.Array printing function

$Id: arrayprint.py,v 1.9 2005/09/13 13:58:44 teoliphant Exp $

formatArray is designed for two modes of operation:

    1. Full output

    2. Summarized output

    
    Set printing options.

    These options determine the way floating point numbers, arrays and
    other NumPy objects are displayed.

    Parameters
    ----------
    precision : int, optional
        Number of digits of precision for floating point output (default 8).
    threshold : int, optional
        Total number of array elements which trigger summarization
        rather than full repr (default 1000).
    edgeitems : int, optional
        Number of array items in summary at beginning and end of
        each dimension (default 3).
    linewidth : int, optional
        The number of characters per line for the purpose of inserting
        line breaks (default 75).
    suppress : bool, optional
        Whether or not suppress printing of small floating point values
        using scientific notation (default False).
    nanstr : str, optional
        String representation of floating point not-a-number (default nan).
    infstr : str, optional
        String representation of floating point infinity (default inf).
    formatter : dict of callables, optional
        If not None, the keys should indicate the type(s) that the respective
        formatting function applies to.  Callables should return a string.
        Types that are not specified (by their corresponding keys) are handled
        by the default formatters.  Individual types for which a formatter
        can be set are::

            - 'bool'
            - 'int'
            - 'timedelta' : a `numpy.timedelta64`
            - 'datetime' : a `numpy.datetime64`
            - 'float'
            - 'longfloat' : 128-bit floats
            - 'complexfloat'
            - 'longcomplexfloat' : composed of two 128-bit floats
            - 'numpy_str' : types `numpy.string_` and `numpy.unicode_`
            - 'str' : all other strings

        Other keys that can be used to set a group of types at once are::

            - 'all' : sets all types
            - 'int_kind' : sets 'int'
            - 'float_kind' : sets 'float' and 'longfloat'
            - 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'
            - 'str_kind' : sets 'str' and 'numpystr'

    See Also
    --------
    get_printoptions, set_string_function, array2string

    Notes
    -----
    `formatter` is always reset with a call to `set_printoptions`.

    Examples
    --------
    Floating point precision can be set:

    >>> np.set_printoptions(precision=4)
    >>> print np.array([1.123456789])
    [ 1.1235]

    Long arrays can be summarised:

    >>> np.set_printoptions(threshold=5)
    >>> print np.arange(10)
    [0 1 2 ..., 7 8 9]

    Small results can be suppressed:

    >>> eps = np.finfo(float).eps
    >>> x = np.arange(4.)
    >>> x**2 - (x + eps)**2
    array([ -4.9304e-32,  -4.4409e-16,   0.0000e+00,   0.0000e+00])
    >>> np.set_printoptions(suppress=True)
    >>> x**2 - (x + eps)**2
    array([-0., -0.,  0.,  0.])

    A custom formatter can be used to display array elements as desired:

    >>> np.set_printoptions(formatter={'all':lambda x: 'int: '+str(-x)})
    >>> x = np.arange(3)
    >>> x
    array([int: 0, int: -1, int: -2])
    >>> np.set_printoptions()  # formatter gets reset
    >>> x
    array([0, 1, 2])

    To put back the default options, you can use:

    >>> np.set_printoptions(edgeitems=3,infstr='inf',
    ... linewidth=75, nanstr='nan', precision=8,
    ... suppress=False, threshold=1000, formatter=None)
    
    Return a string representation of an array.

    Parameters
    ----------
    a : ndarray
        Input array.
    max_line_width : int, optional
        The maximum number of columns the string should span. Newline
        characters splits the string appropriately after array elements.
    precision : int, optional
        Floating point precision. Default is the current printing
        precision (usually 8), which can be altered using `set_printoptions`.
    suppress_small : bool, optional
        Represent very small numbers as zero. A number is "very small" if it
        is smaller than the current printing precision.
    separator : str, optional
        Inserted between elements.
    prefix : str, optional
        An array is typically printed as::

          'prefix(' + array2string(a) + ')'

        The length of the prefix string is used to align the
        output correctly.
    style : function, optional
        A function that accepts an ndarray and returns a string.  Used only
        when the shape of `a` is equal to ``()``, i.e. for 0-D arrays.
    formatter : dict of callables, optional
        If not None, the keys should indicate the type(s) that the respective
        formatting function applies to.  Callables should return a string.
        Types that are not specified (by their corresponding keys) are handled
        by the default formatters.  Individual types for which a formatter
        can be set are::

            - 'bool'
            - 'int'
            - 'timedelta' : a `numpy.timedelta64`
            - 'datetime' : a `numpy.datetime64`
            - 'float'
            - 'longfloat' : 128-bit floats
            - 'complexfloat'
            - 'longcomplexfloat' : composed of two 128-bit floats
            - 'numpy_str' : types `numpy.string_` and `numpy.unicode_`
            - 'str' : all other strings

        Other keys that can be used to set a group of types at once are::

            - 'all' : sets all types
            - 'int_kind' : sets 'int'
            - 'float_kind' : sets 'float' and 'longfloat'
            - 'complex_kind' : sets 'complexfloat' and 'longcomplexfloat'
            - 'str_kind' : sets 'str' and 'numpystr'

    Returns
    -------
    array_str : str
        String representation of the array.

    Raises
    ------
    TypeError
        if a callable in `formatter` does not return a string.

    See Also
    --------
    array_str, array_repr, set_printoptions, get_printoptions

    Notes
    -----
    If a formatter is specified for a certain type, the `precision` keyword is
    ignored for that type.

    Examples
    --------
    >>> x = np.array([1e-16,1,2,3])
    >>> print np.array2string(x, precision=2, separator=',',
    ...                       suppress_small=True)
    [ 0., 1., 2., 3.]

    >>> x  = np.arange(3.)
    >>> np.array2string(x, formatter={'float_kind':lambda x: "%.2f" % x})
    '[0.00 1.00 2.00]'

    >>> x  = np.arange(3)
    >>> np.array2string(x, formatter={'int':lambda x: hex(x)})
    '[0x0L 0x1L 0x2L]'

    /usr/lib/python2.7/dist-packages/numpy/core/arrayprint.py%%.%dfnumpy.core.arrayprintSUbcarr1arr2ucs2ucs4i_arrutf_32__mod____rmod__out_sizewidth_arrmaxunicode[5   s	   chararrays   equals	   not_equals   greater_equals
   less_equals   greaters   lesss   str_lens   adds   multiplys   mods
   capitalizes   centers   counts   decodes   encodes   endswiths
   expandtabss   finds   formats   indexs   isalnums   isalphas   isdigits   islowers   isspaces   istitles   isuppers   joins   ljusts   lowers   lstrips	   partitions   replaces   rfinds   rindexs   rjusts
   rpartitions   rsplits   rstrips   splits
   splitliness
   startswiths   strips   swapcases   titles	   translates   uppers   zfills	   isnumerics	   isdecimals   arrays   asarray
    Return len(a) element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of integers

    See also
    --------
    __builtin__.len
    
        Return (self <= other) element-wise.

        See also
        --------
        less_equal
        
        Return a copy of `self` with only the first character of each element
        capitalized.

        See also
        --------
        char.capitalize

        
    Return element-wise a copy of the string with
    uppercase characters converted to lowercase and vice versa.

    Calls `str.swapcase` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type

    See also
    --------
    str.swapcase

    Examples
    --------
    >>> c=np.array(['a1B c','1b Ca','b Ca1','cA1b'],'S5'); c
    array(['a1B c', '1b Ca', 'b Ca1', 'cA1b'],
        dtype='|S5')
    >>> np.char.swapcase(c)
    array(['A1b C', '1B cA', 'B cA1', 'Ca1B'],
        dtype='|S5')

    
        Returns a boolean array which is `True` where the string element
        in `self` ends with `suffix`, otherwise `False`.

        See also
        --------
        char.endswith

        
    Return an array with the elements of `a` right-justified in a
    string of length `width`.

    Calls `str.rjust` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    width : int
        The length of the resulting strings
    fillchar : str or unicode, optional
        The character to use for padding

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.rjust

    
    Return element-wise title cased version of string or unicode.

    Title case words start with uppercase characters, all remaining cased
    characters are lowercase.

    Calls `str.title` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.title

    Examples
    --------
    >>> c=np.array(['a1b c','1b ca','b ca1','ca1b'],'S5'); c
    array(['a1b c', '1b ca', 'b ca1', 'ca1b'],
        dtype='|S5')
    >>> np.char.title(c)
    array(['A1B C', '1B Ca', 'B Ca1', 'Ca1B'],
        dtype='|S5')

    
    For each element in `a`, return a copy of the string with all
    occurrences of substring `old` replaced by `new`.

    Calls `str.replace` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    old, new : str or unicode

    count : int, optional
        If the optional argument `count` is given, only the first
        `count` occurrences are replaced.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.replace

    
    For each element, return the lowest index in the string where
    substring `sub` is found.

    Calls `str.find` element-wise.

    For each element, return the lowest index in the string where
    substring `sub` is found, such that `sub` is contained in the
    range [`start`, `end`].

    Parameters
    ----------
    a : array_like of str or unicode

    sub : str or unicode

    start, end : int, optional
        Optional arguments `start` and `end` are interpreted as in
        slice notation.

    Returns
    -------
    out : ndarray or int
        Output array of ints.  Returns -1 if `sub` is not found.

    See also
    --------
    str.find

    
    For each element, return True if there are only decimal
    characters in the element.

    Calls `unicode.isdecimal` element-wise.

    Decimal characters include digit characters, and all characters
    that that can be used to form decimal-radix numbers,
    e.g. ``U+0660, ARABIC-INDIC DIGIT ZERO``.

    Parameters
    ----------
    a : array_like, unicode
        Input array.

    Returns
    -------
    out : ndarray, bool
        Array of booleans identical in shape to `a`.

    See also
    --------
    unicode.isdecimal

    
    Return (x1 != x2) element-wise.

    Unlike `numpy.not_equal`, this comparison is performed by first
    stripping whitespace characters from the end of the string.  This
    behavior is provided for backward-compatibility with numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    equal, greater_equal, less_equal, greater, less
    
        Returns true for each element if all characters in the string are
        digits and there is at least one character, false otherwise.

        See also
        --------
        char.isdigit

        
        For each element, return the lowest index in the string where
        substring `sub` is found.

        See also
        --------
        char.find

        
        For each element in `self`, return True if there are only
        numeric characters in the element.

        See also
        --------
        char.isnumeric

        
        Calls `str.encode` element-wise.

        See also
        --------
        char.encode

        
        Return (self != other) element-wise.

        See also
        --------
        not_equal
        
    For each element in `a`, return a list of the lines in the
    element, breaking at line boundaries.

    Calls `str.splitlines` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    keepends : bool, optional
        Line breaks are not included in the resulting list unless
        keepends is given and true.

    Returns
    -------
    out : ndarray
        Array of list objects

    See also
    --------
    str.splitlines

    Can only multiply by integers
        Return (self == other) element-wise.

        See also
        --------
        equal
        
    For each element in `a`, return a copy with the leading and
    trailing characters removed.

    Calls `str.rstrip` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    chars : str or unicode, optional
       The `chars` argument is a string specifying the set of
       characters to be removed. If omitted or None, the `chars`
       argument defaults to removing whitespace. The `chars` argument
       is not a prefix or suffix; rather, all combinations of its
       values are stripped.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.strip

    Examples
    --------
    >>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])
    >>> c
    array(['aAaAaA', '  aA  ', 'abBABba'],
        dtype='|S7')
    >>> np.char.strip(c)
    array(['aAaAaA', 'aA', 'abBABba'],
        dtype='|S7')
    >>> np.char.strip(c, 'a') # 'a' unstripped from c[1] because whitespace leads
    array(['AaAaA', '  aA  ', 'bBABb'],
        dtype='|S7')
    >>> np.char.strip(c, 'A') # 'A' unstripped from c[1] because (unprinted) ws trails
    array(['aAaAa', '  aA  ', 'abBABba'],
        dtype='|S7')

    
    Returns an array with the number of non-overlapping occurrences of
    substring `sub` in the range [`start`, `end`].

    Calls `str.count` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    sub : str or unicode
       The substring to search for.

    start, end : int, optional
       Optional arguments `start` and `end` are interpreted as slice
       notation to specify the range in which to count.

    Returns
    -------
    out : ndarray
        Output array of ints.

    See also
    --------
    str.count

    Examples
    --------
    >>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])
    >>> c
    array(['aAaAaA', '  aA  ', 'abBABba'],
        dtype='|S7')
    >>> np.char.count(c, 'A')
    array([3, 1, 1])
    >>> np.char.count(c, 'aA')
    array([3, 1, 0])
    >>> np.char.count(c, 'A', start=1, end=4)
    array([2, 1, 1])
    >>> np.char.count(c, 'A', start=1, end=3)
    array([1, 0, 0])

    
        Returns true for each element if all cased characters in the
        string are lowercase and there is at least one cased character,
        false otherwise.

        See also
        --------
        char.islower

        
        Returns true for each element if all characters in the string
        are alphabetic and there is at least one character, false
        otherwise.

        See also
        --------
        char.isalpha

        
        Return (self >= other) element-wise.

        See also
        --------
        greater_equal
        
    Return an array with the elements converted to uppercase.

    Calls `str.upper` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type

    See also
    --------
    str.upper

    Examples
    --------
    >>> c = np.array(['a1b c', '1bca', 'bca1']); c
    array(['a1b c', '1bca', 'bca1'],
        dtype='|S5')
    >>> np.char.upper(c)
    array(['A1B C', '1BCA', 'BCA1'],
        dtype='|S5')

    
        Returns true for each element if all characters in the string
        are alphanumeric and there is at least one character, false
        otherwise.

        See also
        --------
        char.isalnum

        
    Create a `chararray`.

    .. note::
       This class is provided for numarray backward-compatibility.
       New code (not concerned with numarray compatibility) should use
       arrays of type `string_` or `unicode_` and use the free functions
       in :mod:`numpy.char <numpy.core.defchararray>` for fast
       vectorized string operations instead.

    Versus a regular Numpy array of type `str` or `unicode`, this
    class adds the following functionality:

      1) values automatically have whitespace removed from the end
         when indexed

      2) comparison operators automatically remove whitespace from the
         end when comparing values

      3) vectorized string operations are provided as methods
         (e.g. `str.endswith`) and infix operators (e.g. ``+, *, %``)

    Parameters
    ----------
    obj : array of str or unicode-like

    itemsize : int, optional
        `itemsize` is the number of characters per scalar in the
        resulting array.  If `itemsize` is None, and `obj` is an
        object array or a Python list, the `itemsize` will be
        automatically determined.  If `itemsize` is provided and `obj`
        is of type str or unicode, then the `obj` string will be
        chunked into `itemsize` pieces.

    copy : bool, optional
        If true (default), then the object is copied.  Otherwise, a copy
        will only be made if __array__ returns a copy, if obj is a
        nested sequence, or if a copy is needed to satisfy any of the other
        requirements (`itemsize`, unicode, `order`, etc.).

    unicode : bool, optional
        When true, the resulting `chararray` can contain Unicode
        characters, when false only 8-bit characters.  If unicode is
        `None` and `obj` is one of the following:

          - a `chararray`,
          - an ndarray of type `str` or `unicode`
          - a Python str or unicode object,

        then the unicode setting of the output array will be
        automatically determined.

    order : {'C', 'F', 'A'}, optional
        Specify the order of the array.  If order is 'C' (default), then the
        array will be in C-contiguous order (last-index varies the
        fastest).  If order is 'F', then the returned array
        will be in Fortran-contiguous order (first-index varies the
        fastest).  If order is 'A', then the returned array may
        be in any order (either C-, Fortran-contiguous, or even
        discontiguous).
    
        For each element in `self`, return a copy with the leading and
        trailing characters removed.

        See also
        --------
        char.strip

        
    Convert the input to a `chararray`, copying the data only if
    necessary.

    Versus a regular Numpy array of type `str` or `unicode`, this
    class adds the following functionality:

      1) values automatically have whitespace removed from the end
         when indexed

      2) comparison operators automatically remove whitespace from the
         end when comparing values

      3) vectorized string operations are provided as methods
         (e.g. `str.endswith`) and infix operators (e.g. +, *, %)

    Parameters
    ----------
    obj : array of str or unicode-like

    itemsize : int, optional
        `itemsize` is the number of characters per scalar in the
        resulting array.  If `itemsize` is None, and `obj` is an
        object array or a Python list, the `itemsize` will be
        automatically determined.  If `itemsize` is provided and `obj`
        is of type str or unicode, then the `obj` string will be
        chunked into `itemsize` pieces.

    unicode : bool, optional
        When true, the resulting `chararray` can contain Unicode
        characters, when false only 8-bit characters.  If unicode is
        `None` and `obj` is one of the following:

          - a `chararray`,
          - an ndarray of type `str` or 'unicode`
          - a Python str or unicode object,

        then the unicode setting of the output array will be
        automatically determined.

    order : {'C', 'F'}, optional
        Specify the order of the array.  If order is 'C' (default), then the
        array will be in C-contiguous order (last-index varies the
        fastest).  If order is 'F', then the returned array
        will be in Fortran-contiguous order (first-index varies the
        fastest).
    
    Partition each element in `a` around `sep`.

    Calls `str.partition` element-wise.

    For each element in `a`, split the element as the first
    occurrence of `sep`, and return 3 strings containing the part
    before the separator, the separator itself, and the part after
    the separator. If the separator is not found, return 3 strings
    containing the string itself, followed by two empty strings.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array
    sep : {str, unicode}
        Separator to split each string element in `a`.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type.
        The output array will have an extra dimension with 3
        elements per input element.

    See also
    --------
    str.partition

    
        Return (other + self), that is string concatenation,
        element-wise for a pair of array_likes of `string_` or `unicode_`.

        See also
        --------
        add
        
        For each element in `self`, return a copy of the string with all
        occurrences of substring `old` replaced by `new`.

        See also
        --------
        char.replace

        
        Return a string which is the concatenation of the strings in the
        sequence `seq`.

        See also
        --------
        char.join

        
        For each element in `self`, return a titlecased version of the
        string: words start with uppercase characters, all remaining cased
        characters are lowercase.

        See also
        --------
        char.title

        
    Returns true for each element if all cased characters in the
    string are lowercase and there is at least one cased character,
    false otherwise.

    Calls `str.islower` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.islower
    
    chararray(shape, itemsize=1, unicode=False, buffer=None, offset=0,
              strides=None, order=None)

    Provides a convenient view on arrays of string and unicode values.

    .. note::
       The `chararray` class exists for backwards compatibility with
       Numarray, it is not recommended for new development. Starting from numpy
       1.4, if one needs arrays of strings, it is recommended to use arrays of
       `dtype` `object_`, `string_` or `unicode_`, and use the free functions
       in the `numpy.char` module for fast vectorized string operations.

    Versus a regular Numpy array of type `str` or `unicode`, this
    class adds the following functionality:

      1) values automatically have whitespace removed from the end
         when indexed

      2) comparison operators automatically remove whitespace from the
         end when comparing values

      3) vectorized string operations are provided as methods
         (e.g. `.endswith`) and infix operators (e.g. ``"+", "*", "%"``)

    chararrays should be created using `numpy.char.array` or
    `numpy.char.asarray`, rather than this constructor directly.

    This constructor creates the array, using `buffer` (with `offset`
    and `strides`) if it is not ``None``. If `buffer` is ``None``, then
    constructs a new array with `strides` in "C order", unless both
    ``len(shape) >= 2`` and ``order='Fortran'``, in which case `strides`
    is in "Fortran order".

    Methods
    -------
    astype
    argsort
    copy
    count
    decode
    dump
    dumps
    encode
    endswith
    expandtabs
    fill
    find
    flatten
    getfield
    index
    isalnum
    isalpha
    isdecimal
    isdigit
    islower
    isnumeric
    isspace
    istitle
    isupper
    item
    join
    ljust
    lower
    lstrip
    nonzero
    put
    ravel
    repeat
    replace
    reshape
    resize
    rfind
    rindex
    rjust
    rsplit
    rstrip
    searchsorted
    setfield
    setflags
    sort
    split
    splitlines
    squeeze
    startswith
    strip
    swapaxes
    swapcase
    take
    title
    tofile
    tolist
    tostring
    translate
    transpose
    upper
    view
    zfill

    Parameters
    ----------
    shape : tuple
        Shape of the array.
    itemsize : int, optional
        Length of each array element, in number of characters. Default is 1.
    unicode : bool, optional
        Are the array elements of type unicode (True) or string (False).
        Default is False.
    buffer : int, optional
        Memory address of the start of the array data.  Default is None,
        in which case a new array is created.
    offset : int, optional
        Fixed stride displacement from the beginning of an axis?
        Default is 0. Needs to be >=0.
    strides : array_like of ints, optional
        Strides for the array (see `ndarray.strides` for full description).
        Default is None.
    order : {'C', 'F'}, optional
        The order in which the array data is stored in memory: 'C' ->
        "row major" order (the default), 'F' -> "column major"
        (Fortran) order.

    Examples
    --------
    >>> charar = np.chararray((3, 3))
    >>> charar[:] = 'a'
    >>> charar
    chararray([['a', 'a', 'a'],
           ['a', 'a', 'a'],
           ['a', 'a', 'a']],
          dtype='|S1')

    >>> charar = np.chararray(charar.shape, itemsize=5)
    >>> charar[:] = 'abc'
    >>> charar
    chararray([['abc', 'abc', 'abc'],
           ['abc', 'abc', 'abc'],
           ['abc', 'abc', 'abc']],
          dtype='|S5')

    
        Return an array with the elements of `self` left-justified in a
        string of length `width`.

        See also
        --------
        char.ljust

        
    For each element in `a`, return the highest index in the string
    where substring `sub` is found, such that `sub` is contained
    within [`start`, `end`].

    Calls `str.rfind` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    sub : str or unicode

    start, end : int, optional
        Optional arguments `start` and `end` are interpreted as in
        slice notation.

    Returns
    -------
    out : ndarray
       Output array of ints.  Return -1 on failure.

    See also
    --------
    str.rfind

    /usr/lib/python2.7/dist-packages/numpy/core/defchararray.py
        Returns true for each element if there are only whitespace
        characters in the string and there is at least one character,
        false otherwise.

        See also
        --------
        char.isspace

        isnumeric is only available for Unicode strings and arrays
        Return (self % i), that is pre-Python 2.6 string formatting
        (iterpolation), element-wise for a pair of array_likes of `string_`
        or `unicode_`.

        See also
        --------
        mod
        
    Return element-wise string concatenation for two arrays of str or unicode.

    Arrays `x1` and `x2` must have the same shape.

    Parameters
    ----------
    x1 : array_like of str or unicode
        Input array.
    x2 : array_like of str or unicode
        Input array.

    Returns
    -------
    add : ndarray
        Output array of `string_` or `unicode_`, depending on input types
        of the same shape as `x1` and `x2`.

    
    Returns true for each element if the element is a titlecased
    string and there is at least one character, false otherwise.

    Call `str.istitle` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.istitle
    
    Helper function that returns the number of characters per field in
    a string or unicode array.  This is to abstract out the fact that
    for a unicode array this is itemsize / 4.
    
    For each element in `a`, return a copy with the trailing
    characters removed.

    Calls `str.rstrip` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    chars : str or unicode, optional
       The `chars` argument is a string specifying the set of
       characters to be removed. If omitted or None, the `chars`
       argument defaults to removing whitespace. The `chars` argument
       is not a suffix; rather, all combinations of its values are
       stripped.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.rstrip

    Examples
    --------
    >>> c = np.array(['aAaAaA', 'abBABba'], dtype='S7'); c
    array(['aAaAaA', 'abBABba'],
        dtype='|S7')
    >>> np.char.rstrip(c, 'a')
    array(['aAaAaA', 'abBABb'],
        dtype='|S7')
    >>> np.char.rstrip(c, 'A')
    array(['aAaAa', 'abBABba'],
        dtype='|S7')

    
    Returns a boolean array which is `True` where the string element
    in `a` ends with `suffix`, otherwise `False`.

    Calls `str.endswith` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    suffix : str

    start, end : int, optional
        With optional `start`, test beginning at that position. With
        optional `end`, stop comparing at that position.

    Returns
    -------
    out : ndarray
        Outputs an array of bools.

    See also
    --------
    str.endswith

    Examples
    --------
    >>> s = np.array(['foo', 'bar'])
    >>> s[0] = 'foo'
    >>> s[1] = 'bar'
    >>> s
    array(['foo', 'bar'],
        dtype='|S3')
    >>> np.char.endswith(s, 'ar')
    array([False,  True], dtype=bool)
    >>> np.char.endswith(s, 'a', start=1, end=2)
    array([False,  True], dtype=bool)

    
    Return (x1 <= x2) element-wise.

    Unlike `numpy.less_equal`, this comparison is performed by first
    stripping whitespace characters from the end of the string.  This
    behavior is provided for backward-compatibility with numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    equal, not_equal, greater_equal, greater, less
    
    Helper function for determining the output type of some string
    operations.

    For an operation on two ndarrays, if at least one is unicode, the
    result should be unicode.
    
        For each element in `self`, return a list of the words in
        the string, using `sep` as the delimiter string.

        See also
        --------
        char.rsplit

        
        Like `find`, but raises `ValueError` when the substring is not found.

        See also
        --------
        char.index

        
        Returns an array with the number of non-overlapping occurrences of
        substring `sub` in the range [`start`, `end`].

        See also
        --------
        char.count

        
        Calls `str.decode` element-wise.

        See also
        --------
        char.decode

        
    Returns true for each element if all characters in the string are
    alphabetic and there is at least one character, false otherwise.

    Calls `str.isalpha` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.isalpha
    
    Returns true for each element if there are only whitespace
    characters in the string and there is at least one character,
    false otherwise.

    Calls `str.isspace` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.isspace
    
    Return (x1 > x2) element-wise.

    Unlike `numpy.greater`, this comparison is performed by first
    stripping whitespace characters from the end of the string.  This
    behavior is provided for backward-compatibility with numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    equal, not_equal, greater_equal, less_equal, less
    
    Returns true for each element if all characters in the string are
    digits and there is at least one character, false otherwise.

    Calls `str.isdigit` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.isdigit
    
    Returns a boolean array which is `True` where the string element
    in `a` starts with `prefix`, otherwise `False`.

    Calls `str.startswith` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    prefix : str

    start, end : int, optional
        With optional `start`, test beginning at that position. With
        optional `end`, stop comparing at that position.

    Returns
    -------
    out : ndarray
        Array of booleans

    See also
    --------
    str.startswith

    
    For each element in `a`, return a copy of the string where all
    characters occurring in the optional argument `deletechars` are
    removed, and the remaining characters have been mapped through the
    given translation table.

    Calls `str.translate` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    table : str of length 256

    deletechars : str

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.translate

    
        Return an array with the elements of `self` converted to
        uppercase.

        See also
        --------
        char.upper

        
        For each element in `self`, return a copy with the trailing
        characters removed.

        See also
        --------
        char.rstrip

        
        Return a copy of each string element where all tab characters are
        replaced by one or more spaces.

        See also
        --------
        char.expandtabs

        
    Like `find`, but raises `ValueError` when the substring is not found.

    Calls `str.index` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    sub : str or unicode

    start, end : int, optional

    Returns
    -------
    out : ndarray
        Output array of ints.  Returns -1 if `sub` is not found.

    See also
    --------
    find, str.find

    
        For each element in `self`, return a list of the lines in the
        element, breaking at line boundaries.

        See also
        --------
        char.splitlines

        
        Return the numeric string left-filled with zeros in a string of
        length `width`.

        See also
        --------
        char.zfill

        
    Calls `str.encode` element-wise.

    The set of available codecs comes from the Python standard library,
    and may be extended at runtime. For more information, see the codecs
    module.

    Parameters
    ----------
    a : array_like of str or unicode

    encoding : str, optional
       The name of an encoding

    errors : str, optional
       Specifies how to handle encoding errors

    Returns
    -------
    out : ndarray

    See also
    --------
    str.encode

    Notes
    -----
    The type of the result will depend on the encoding specified.

    
    Return (a * i), that is string multiple concatenation,
    element-wise.

    Values in `i` of less than 0 are treated as 0 (which yields an
    empty string).

    Parameters
    ----------
    a : array_like of str or unicode

    i : array_like of ints

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input types

    
    For each element in `a`, return a list of the words in the
    string, using `sep` as the delimiter string.

    Calls `str.rsplit` element-wise.

    Except for splitting from the right, `rsplit`
    behaves like `split`.

    Parameters
    ----------
    a : array_like of str or unicode

    sep : str or unicode, optional
        If `sep` is not specified or `None`, any whitespace string
        is a separator.
    maxsplit : int, optional
        If `maxsplit` is given, at most `maxsplit` splits are done,
        the rightmost ones.

    Returns
    -------
    out : ndarray
       Array of list objects

    See also
    --------
    str.rsplit, split

    
    Return (x1 < x2) element-wise.

    Unlike `numpy.greater`, this comparison is performed by first
    stripping whitespace characters from the end of the string.  This
    behavior is provided for backward-compatibility with numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    equal, not_equal, greater_equal, less_equal, greater
    
    Return (x1 == x2) element-wise.

    Unlike `numpy.equal`, this comparison is performed by first
    stripping whitespace characters from the end of the string.  This
    behavior is provided for backward-compatibility with numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    not_equal, greater_equal, less_equal, greater, less
    
    Partition (split) each element around the right-most separator.

    Calls `str.rpartition` element-wise.

    For each element in `a`, split the element as the last
    occurrence of `sep`, and return 3 strings containing the part
    before the separator, the separator itself, and the part after
    the separator. If the separator is not found, return 3 strings
    containing the string itself, followed by two empty strings.

    Parameters
    ----------
    a : array_like of str or unicode
        Input array
    sep : str or unicode
        Right-most separator to split each element in array.

    Returns
    -------
    out : ndarray
        Output array of string or unicode, depending on input
        type.  The output array will have an extra dimension with
        3 elements per input element.

    See also
    --------
    str.rpartition

    
        Return (self * i), that is string multiple concatenation,
        element-wise.

        See also
        --------
        multiply
        
    Return a copy of `a` with its elements centered in a string of
    length `width`.

    Calls `str.center` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    width : int
        The length of the resulting strings
    fillchar : str or unicode, optional
        The padding character to use (default is space).

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input
        types

    See also
    --------
    str.center

    
    Return the numeric string left-filled with zeros

    Calls `str.zfill` element-wise.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array.
    width : int
        Width of string to left-fill elements in `a`.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type

    See also
    --------
    str.zfill

    
        Partition each element in `self` around `sep`.

        See also
        --------
        partition
        
    Returns true for each element if all characters in the string are
    alphanumeric and there is at least one character, false otherwise.

    Calls `str.isalnum` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.isalnum
    
This module contains a set of functions for vectorized string
operations and methods.

.. note::
   The `chararray` class exists for backwards compatibility with
   Numarray, it is not recommended for new development. Starting from numpy
   1.4, if one needs arrays of strings, it is recommended to use arrays of
   `dtype` `object_`, `string_` or `unicode_`, and use the free functions
   in the `numpy.char` module for fast vectorized string operations.

Some methods will only be available if the corresponding string method is
available in your version of Python.

The preferred alias for `defchararray` is `numpy.char`.


    Return (a % i), that is pre-Python 2.6 string formatting
    (iterpolation), element-wise for a pair of array_likes of str
    or unicode.

    Parameters
    ----------
    a : array_like of str or unicode

    values : array_like of values
       These values will be element-wise interpolated into the string.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input types

    See also
    --------
    str.__mod__

    
        Return the indices that sort the array lexicographically.

        For full documentation see `numpy.argsort`, for which this method is
        in fact merely a "thin wrapper."

        Examples
        --------
        >>> c = np.array(['a1b c', '1b ca', 'b ca1', 'Ca1b'], 'S5')
        >>> c = c.view(np.chararray); c
        chararray(['a1b c', '1b ca', 'b ca1', 'Ca1b'],
              dtype='|S5')
        >>> c[c.argsort()]
        chararray(['1b ca', 'Ca1b', 'a1b c', 'b ca1'],
              dtype='|S5')

        
        For each element in `self`, return the highest index in the string
        where substring `sub` is found, such that `sub` is contained
        within [`start`, `end`].

        See also
        --------
        char.rfind

        
        For each element in `self`, return a copy of the string with
        uppercase characters converted to lowercase and vice versa.

        See also
        --------
        char.swapcase

        
        Returns a boolean array which is `True` where the string element
        in `self` starts with `prefix`, otherwise `False`.

        See also
        --------
        char.startswith

        
        For each element in `self`, return a copy of the string where
        all characters occurring in the optional argument
        `deletechars` are removed, and the remaining characters have
        been mapped through the given translation table.

        See also
        --------
        char.translate

        
    Returns true for each element if all cased characters in the
    string are uppercase and there is at least one character, false
    otherwise.

    Call `str.isupper` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of bools

    See also
    --------
    str.isupper
    
        For each element in `self`, return a list of the words in the
        string, using `sep` as the delimiter string.

        See also
        --------
        char.split

        
        For each element in `self`, return True if there are only
        decimal characters in the element.

        See also
        --------
        char.isdecimal

        
    Like `rfind`, but raises `ValueError` when the substring `sub` is
    not found.

    Calls `str.rindex` element-wise.

    Parameters
    ----------
    a : array-like of str or unicode

    sub : str or unicode

    start, end : int, optional

    Returns
    -------
    out : ndarray
       Output array of ints.

    See also
    --------
    rfind, str.rindex

    
        For each element in `self`, return a copy with the leading characters
        removed.

        See also
        --------
        char.lstrip

        
        Return (self < other) element-wise.

        See also
        --------
        less
        
    Calls `str.decode` element-wise.

    The set of available codecs comes from the Python standard library,
    and may be extended at runtime.  For more information, see the
    :mod:`codecs` module.

    Parameters
    ----------
    a : array_like of str or unicode

    encoding : str, optional
       The name of an encoding

    errors : str, optional
       Specifies how to handle encoding errors

    Returns
    -------
    out : ndarray

    See also
    --------
    str.decode

    Notes
    -----
    The type of the result will depend on the encoding specified.

    Examples
    --------
    >>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])
    >>> c
    array(['aAaAaA', '  aA  ', 'abBABba'],
        dtype='|S7')
    >>> np.char.encode(c, encoding='cp037')
    array(['\x81\xc1\x81\xc1\x81\xc1', '@@\x81\xc1@@',
        '\x81\x82\xc2\xc1\xc2\x82\x81'],
        dtype='|S7')

    
        Return (self + other), that is string concatenation,
        element-wise for a pair of array_likes of str or unicode.

        See also
        --------
        add
        
        Return (self > other) element-wise.

        See also
        --------
        greater
        Can only create a chararray from string data.
        Return an array with the elements of `self`
        right-justified in a string of length `width`.

        See also
        --------
        char.rjust

        
    Helper function to cast a result back into a string or unicode array
    if an object array must be used as an intermediary.
    
    Return an array with the elements converted to lowercase.

    Call `str.lower` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like, {str, unicode}
        Input array.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type

    See also
    --------
    str.lower

    Examples
    --------
    >>> c = np.array(['A1B C', '1BCA', 'BCA1']); c
    array(['A1B C', '1BCA', 'BCA1'],
          dtype='|S5')
    >>> np.char.lower(c)
    array(['a1b c', '1bca', 'bca1'],
          dtype='|S5')

    
    Return a string which is the concatenation of the strings in the
    sequence `seq`.

    Calls `str.join` element-wise.

    Parameters
    ----------
    sep : array_like of str or unicode
    seq : array_like of str or unicode

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input types

    See also
    --------
    str.join
    
        Returns true for each element if all cased characters in the
        string are uppercase and there is at least one character, false
        otherwise.

        See also
        --------
        char.isupper

        
        Return an array with the elements of `self` converted to
        lowercase.

        See also
        --------
        char.lower

        
    Return an array with the elements of `a` left-justified in a
    string of length `width`.

    Calls `str.ljust` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    width : int
        The length of the resulting strings
    fillchar : str or unicode, optional
        The character to use for padding

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.ljust

    
    Return (x1 >= x2) element-wise.

    Unlike `numpy.greater_equal`, this comparison is performed by
    first stripping whitespace characters from the end of the string.
    This behavior is provided for backward-compatibility with
    numarray.

    Parameters
    ----------
    x1, x2 : array_like of str or unicode
        Input arrays of the same shape.

    Returns
    -------
    out : {ndarray, bool}
        Output array of bools, or a single bool if x1 and x2 are scalars.

    See Also
    --------
    equal, not_equal, less_equal, greater, less
    
    For each element in `a`, return a copy with the leading characters
    removed.

    Calls `str.lstrip` element-wise.

    Parameters
    ----------
    a : array-like, {str, unicode}
        Input array.

    chars : {str, unicode}, optional
        The `chars` argument is a string specifying the set of
        characters to be removed. If omitted or None, the `chars`
        argument defaults to removing whitespace. The `chars` argument
        is not a prefix; rather, all combinations of its values are
        stripped.

    Returns
    -------
    out : ndarray, {str, unicode}
        Output array of str or unicode, depending on input type

    See also
    --------
    str.lstrip

    Examples
    --------
    >>> c = np.array(['aAaAaA', '  aA  ', 'abBABba'])
    >>> c
    array(['aAaAaA', '  aA  ', 'abBABba'],
        dtype='|S7')

    The 'a' variable is unstripped from c[1] because whitespace leading.

    >>> np.char.lstrip(c, 'a')
    array(['AaAaA', '  aA  ', 'bBABba'],
        dtype='|S7')


    >>> np.char.lstrip(c, 'A') # leaves c unchanged
    array(['aAaAaA', '  aA  ', 'abBABba'],
        dtype='|S7')
    >>> (np.char.lstrip(c, ' ') == np.char.lstrip(c, '')).all()
    ... # XXX: is this a regression? this line now returns False
    ... # np.char.lstrip(c,'') does not modify c at all.
    True
    >>> (np.char.lstrip(c, ' ') == np.char.lstrip(c, None)).all()
    True

    
    Helper function for delegating arguments to Python string
    functions.

    Many of the Python string operations that have optional arguments
    do not use 'None' to indicate a default value.  In these cases,
    we need to remove all `None` arguments, and those following them.
    
    Return a copy of `a` with only the first character of each element
    capitalized.

    Calls `str.capitalize` element-wise.

    For 8-bit strings, this method is locale-dependent.

    Parameters
    ----------
    a : array_like of str or unicode
        Input array of strings to capitalize.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input
        types

    See also
    --------
    str.capitalize

    Examples
    --------
    >>> c = np.array(['a1b2','1b2a','b2a1','2a1b'],'S4'); c
    array(['a1b2', '1b2a', 'b2a1', '2a1b'],
        dtype='|S4')
    >>> np.char.capitalize(c)
    array(['A1b2', '1b2a', 'B2a1', '2a1b'],
        dtype='|S4')

    
        Like `rfind`, but raises `ValueError` when the substring `sub` is
        not found.

        See also
        --------
        char.rindex

        
    For each element in `a`, return a list of the words in the
    string, using `sep` as the delimiter string.

    Calls `str.rsplit` element-wise.

    Parameters
    ----------
    a : array_like of str or unicode

    sep : str or unicode, optional
       If `sep` is not specified or `None`, any whitespace string is a
       separator.

    maxsplit : int, optional
        If `maxsplit` is given, at most `maxsplit` splits are done.

    Returns
    -------
    out : ndarray
        Array of list objects

    See also
    --------
    str.split, rsplit

    
        Returns true for each element if the element is a titlecased
        string and there is at least one character, false otherwise.

        See also
        --------
        char.istitle

        
        Partition each element in `self` around `sep`.

        See also
        --------
        rpartition
        
        Return a copy of `self` with its elements centered in a
        string of length `width`.

        See also
        --------
        center
        
    For each element, return True if there are only numeric
    characters in the element.

    Calls `unicode.isnumeric` element-wise.

    Numeric characters include digit characters, and all characters
    that have the Unicode numeric value property, e.g. ``U+2155,
    VULGAR FRACTION ONE FIFTH``.

    Parameters
    ----------
    a : array_like, unicode
        Input array.

    Returns
    -------
    out : ndarray, bool
        Array of booleans of same shape as `a`.

    See also
    --------
    unicode.isnumeric

    
    Return a copy of each string element where all tab characters are
    replaced by one or more spaces.

    Calls `str.expandtabs` element-wise.

    Return a copy of each string element where all tab characters are
    replaced by one or more spaces, depending on the current column
    and the given `tabsize`. The column number is reset to zero after
    each newline occurring in the string. This doesn't understand other
    non-printing characters or escape sequences.

    Parameters
    ----------
    a : array_like of str or unicode
        Input array
    tabsize : int, optional
        Replace tabs with `tabsize` number of spaces.  If not given defaults
        to 8 spaces.

    Returns
    -------
    out : ndarray
        Output array of str or unicode, depending on input type

    See also
    --------
    str.expandtabs

    _dt_n_copiestotal_sizeGeneratorType[-   s   alens   alls   alltrues   amaxs   amins   anys   argmaxs   argmins   argpartitions   argsorts   arounds   chooses   clips   compresss   cumprods
   cumproducts   cumsums   diagonals   means   ndims   nonzeros	   partitions   prods   products   ptps   puts   ranks   ravels   repeats   reshapes   resizes   round_s   searchsorteds   shapes   sizes   sometrues   sorts   squeezes   stds   sums   swapaxess   takes   traces	   transposes   var
    Return a new array with the specified shape.

    If the new array is larger than the original array, then the new
    array is filled with repeated copies of `a`.  Note that this behavior
    is different from a.resize(new_shape) which fills with zeros instead
    of repeated copies of `a`.

    Parameters
    ----------
    a : array_like
        Array to be resized.

    new_shape : int or tuple of int
        Shape of resized array.

    Returns
    -------
    reshaped_array : ndarray
        The new array is formed from the data in the old array, repeated
        if necessary to fill out the required number of elements.  The
        data are repeated in the order that they are stored in memory.

    See Also
    --------
    ndarray.resize : resize an array in-place.

    Examples
    --------
    >>> a=np.array([[0,1],[2,3]])
    >>> np.resize(a,(1,4))
    array([[0, 1, 2, 3]])
    >>> np.resize(a,(2,4))
    array([[0, 1, 2, 3],
           [0, 1, 2, 3]])

    /usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py
    Interchange two axes of an array.

    Parameters
    ----------
    a : array_like
        Input array.
    axis1 : int
        First axis.
    axis2 : int
        Second axis.

    Returns
    -------
    a_swapped : ndarray
        If `a` is an ndarray, then a view of `a` is returned; otherwise
        a new array is created.

    Examples
    --------
    >>> x = np.array([[1,2,3]])
    >>> np.swapaxes(x,0,1)
    array([[1],
           [2],
           [3]])

    >>> x = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])
    >>> x
    array([[[0, 1],
            [2, 3]],
           [[4, 5],
            [6, 7]]])

    >>> np.swapaxes(x,0,2)
    array([[[0, 4],
            [2, 6]],
           [[1, 5],
            [3, 7]]])

    
    Take elements from an array along an axis.

    This function does the same thing as "fancy" indexing (indexing arrays
    using arrays); however, it can be easier to use if you need elements
    along a given axis.

    Parameters
    ----------
    a : array_like
        The source array.
    indices : array_like
        The indices of the values to extract.

        .. versionadded:: 1.8.0

        Also allow scalars for indices.
    axis : int, optional
        The axis over which to select values. By default, the flattened
        input array is used.
    out : ndarray, optional
        If provided, the result will be placed in this array. It should
        be of the appropriate shape and dtype.
    mode : {'raise', 'wrap', 'clip'}, optional
        Specifies how out-of-bounds indices will behave.

        * 'raise' -- raise an error (default)
        * 'wrap' -- wrap around
        * 'clip' -- clip to the range

        'clip' mode means that all indices that are too large are replaced
        by the index that addresses the last element along that axis. Note
        that this disables indexing with negative numbers.

    Returns
    -------
    subarray : ndarray
        The returned array has the same type as `a`.

    See Also
    --------
    ndarray.take : equivalent method

    Examples
    --------
    >>> a = [4, 3, 5, 7, 6, 8]
    >>> indices = [0, 1, 4]
    >>> np.take(a, indices)
    array([4, 3, 6])

    In this example if `a` is an ndarray, "fancy" indexing can be used.

    >>> a = np.array(a)
    >>> a[indices]
    array([4, 3, 6])

    If `indices` is not one dimensional, the output also has these dimensions.

    >>> np.take(a, [[0, 1], [2, 3]])
    array([[4, 3],
           [5, 7]])
    
    Return the indices of the elements that are non-zero.

    Returns a tuple of arrays, one for each dimension of `a`, containing
    the indices of the non-zero elements in that dimension. The
    corresponding non-zero values can be obtained with::

        a[nonzero(a)]

    To group the indices by element, rather than dimension, use::

        transpose(nonzero(a))

    The result of this is always a 2-D array, with a row for
    each non-zero element.

    Parameters
    ----------
    a : array_like
        Input array.

    Returns
    -------
    tuple_of_arrays : tuple
        Indices of elements that are non-zero.

    See Also
    --------
    flatnonzero :
        Return indices that are non-zero in the flattened version of the input
        array.
    ndarray.nonzero :
        Equivalent ndarray method.
    count_nonzero :
        Counts the number of non-zero elements in the input array.

    Examples
    --------
    >>> x = np.eye(3)
    >>> x
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])
    >>> np.nonzero(x)
    (array([0, 1, 2]), array([0, 1, 2]))

    >>> x[np.nonzero(x)]
    array([ 1.,  1.,  1.])
    >>> np.transpose(np.nonzero(x))
    array([[0, 0],
           [1, 1],
           [2, 2]])

    A common use for ``nonzero`` is to find the indices of an array, where
    a condition is True.  Given an array `a`, the condition `a` > 3 is a
    boolean array and since False is interpreted as 0, np.nonzero(a > 3)
    yields the indices of the `a` where the condition is true.

    >>> a = np.array([[1,2,3],[4,5,6],[7,8,9]])
    >>> a > 3
    array([[False, False, False],
           [ True,  True,  True],
           [ True,  True,  True]], dtype=bool)
    >>> np.nonzero(a > 3)
    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))

    The ``nonzero`` method of the boolean array can also be called.

    >>> (a > 3).nonzero()
    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))

    
    Return the number of dimensions of an array.

    Parameters
    ----------
    a : array_like
        Input array.  If it is not already an ndarray, a conversion is
        attempted.

    Returns
    -------
    number_of_dimensions : int
        The number of dimensions in `a`.  Scalars are zero-dimensional.

    See Also
    --------
    ndarray.ndim : equivalent method
    shape : dimensions of array
    ndarray.shape : dimensions of array

    Examples
    --------
    >>> np.ndim([[1,2,3],[4,5,6]])
    2
    >>> np.ndim(np.array([[1,2,3],[4,5,6]]))
    2
    >>> np.ndim(1)
    0

    
    Clip (limit) the values in an array.

    Given an interval, values outside the interval are clipped to
    the interval edges.  For example, if an interval of ``[0, 1]``
    is specified, values smaller than 0 become 0, and values larger
    than 1 become 1.

    Parameters
    ----------
    a : array_like
        Array containing elements to clip.
    a_min : scalar or array_like
        Minimum value.
    a_max : scalar or array_like
        Maximum value.  If `a_min` or `a_max` are array_like, then they will
        be broadcasted to the shape of `a`.
    out : ndarray, optional
        The results will be placed in this array. It may be the input
        array for in-place clipping.  `out` must be of the right shape
        to hold the output.  Its type is preserved.

    Returns
    -------
    clipped_array : ndarray
        An array with the elements of `a`, but where values
        < `a_min` are replaced with `a_min`, and those > `a_max`
        with `a_max`.

    See Also
    --------
    numpy.doc.ufuncs : Section "Output arguments"

    Examples
    --------
    >>> a = np.arange(10)
    >>> np.clip(a, 1, 8)
    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])
    >>> a
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
    >>> np.clip(a, 3, 6, out=a)
    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
    >>> a = np.arange(10)
    >>> a
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
    >>> np.clip(a, [3,4,1,1,1,4,4,4,4,4], 8)
    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])

    
    Round an array to the given number of decimals.

    Refer to `around` for full documentation.

    See Also
    --------
    around : equivalent function

    
    Return the cumulative product over the given axis.


    See Also
    --------
    cumprod : equivalent function; see for details.

    
    Return the number of elements along a given axis.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : int, optional
        Axis along which the elements are counted.  By default, give
        the total number of elements.

    Returns
    -------
    element_count : int
        Number of elements along the specified axis.

    See Also
    --------
    shape : dimensions of array
    ndarray.shape : dimensions of array
    ndarray.size : number of elements in array

    Examples
    --------
    >>> a = np.array([[1,2,3],[4,5,6]])
    >>> np.size(a)
    6
    >>> np.size(a,1)
    3
    >>> np.size(a,0)
    2

    
    Check whether some values are true.

    Refer to `any` for full documentation.

    See Also
    --------
    any : equivalent function

    
    Replaces specified elements of an array with given values.

    The indexing works on the flattened target array. `put` is roughly
    equivalent to:

    ::

        a.flat[ind] = v

    Parameters
    ----------
    a : ndarray
        Target array.
    ind : array_like
        Target indices, interpreted as integers.
    v : array_like
        Values to place in `a` at target indices. If `v` is shorter than
        `ind` it will be repeated as necessary.
    mode : {'raise', 'wrap', 'clip'}, optional
        Specifies how out-of-bounds indices will behave.

        * 'raise' -- raise an error (default)
        * 'wrap' -- wrap around
        * 'clip' -- clip to the range

        'clip' mode means that all indices that are too large are replaced
        by the index that addresses the last element along that axis. Note
        that this disables indexing with negative numbers.

    See Also
    --------
    putmask, place

    Examples
    --------
    >>> a = np.arange(5)
    >>> np.put(a, [0, 2], [-44, -55])
    >>> a
    array([-44,   1, -55,   3,   4])

    >>> a = np.arange(5)
    >>> np.put(a, 22, -5, mode='clip')
    >>> a
    array([ 0,  1,  2,  3, -5])

    
    Indices of the maximum values along an axis.

    Parameters
    ----------
    a : array_like
        Input array.
    axis : int, optional
        By default, the index is into the flattened array, otherwise
        along the specified axis.

    Returns
    -------
    index_array : ndarray of ints
        Array of indices into the array. It has the same shape as `a.shape`
        with the dimension along `axis` removed.

    See Also
    --------
    ndarray.argmax, argmin
    amax : The maximum value along a given axis.
    unravel_index : Convert a flat index into an index tuple.

    Notes
    -----
    In case of multiple occurrences of the maximum values, the indices
    corresponding to the first occurrence are returned.

    Examples
    --------
    >>> a = np.arange(6).reshape(2,3)
    >>> a
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.argmax(a)
    5
    >>> np.argmax(a, axis=0)
    array([1, 1, 1])
    >>> np.argmax(a, axis=1)
    array([2, 2])

    >>> b = np.arange(6)
    >>> b[1] = 5
    >>> b
    array([0, 5, 2, 3, 4, 5])
    >>> np.argmax(b) # Only the first occurrence is returned.
    1

    
    Test whether all array elements along a given axis evaluate to True.

    Parameters
    ----------
    a : array_like
        Input array or object that can be converted to an array.
    axis : None or int or tuple of ints, optional
        Axis or axes along which a logical AND reduction is performed.
        The default (`axis` = `None`) is perform a logical OR over all
        the dimensions of the input array. `axis` may be negative, in
        which case it counts from the last to the first axis.

        .. versionadded:: 1.7.0

        If this is a tuple of ints, a reduction is performed on multiple
        axes, instead of a single axis or all the axes as before.
    out : ndarray, optional
        Alternate output array in which to place the result.
        It must have the same shape as the expected output and its
        type is preserved (e.g., if ``dtype(out)`` is float, the result
        will consist of 0.0's and 1.0's).  See `doc.ufuncs` (Section
        "Output arguments") for more details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    all : ndarray, bool
        A new boolean or array is returned unless `out` is specified,
        in which case a reference to `out` is returned.

    See Also
    --------
    ndarray.all : equivalent method

    any : Test whether any element along a given axis evaluates to True.

    Notes
    -----
    Not a Number (NaN), positive infinity and negative infinity
    evaluate to `True` because these are not equal to zero.

    Examples
    --------
    >>> np.all([[True,False],[True,True]])
    False

    >>> np.all([[True,False],[True,True]], axis=0)
    array([ True, False], dtype=bool)

    >>> np.all([-1, 4, 5])
    True

    >>> np.all([1.0, np.nan])
    True

    >>> o=np.array([False])
    >>> z=np.all([-1, 4, 5], out=o)
    >>> id(z), id(o), z                             # doctest: +SKIP
    (28293632, 28293632, array([ True], dtype=bool))

    
    Return the shape of an array.

    Parameters
    ----------
    a : array_like
        Input array.

    Returns
    -------
    shape : tuple of ints
        The elements of the shape tuple give the lengths of the
        corresponding array dimensions.

    See Also
    --------
    alen
    ndarray.shape : Equivalent array method.

    Examples
    --------
    >>> np.shape(np.eye(3))
    (3, 3)
    >>> np.shape([[1, 2]])
    (1, 2)
    >>> np.shape([0])
    (1,)
    >>> np.shape(0)
    ()

    >>> a = np.array([(1, 2), (3, 4)], dtype=[('x', 'i4'), ('y', 'i4')])
    >>> np.shape(a)
    (2,)
    >>> a.shape
    (2,)

    
    Gives a new shape to an array without changing its data.

    Parameters
    ----------
    a : array_like
        Array to be reshaped.
    newshape : int or tuple of ints
        The new shape should be compatible with the original shape. If
        an integer, then the result will be a 1-D array of that length.
        One shape dimension can be -1. In this case, the value is inferred
        from the length of the array and remaining dimensions.
    order : {'C', 'F', 'A'}, optional
        Read the elements of `a` using this index order, and place the elements
        into the reshaped array using this index order.  'C' means to
        read / write the elements using C-like index order, with the last axis index
        changing fastest, back to the first axis index changing slowest.  'F'
        means to read / write the elements using Fortran-like index order, with
        the first index changing fastest, and the last index changing slowest.
        Note that the 'C' and 'F' options take no account of the memory layout
        of the underlying array, and only refer to the order of indexing.  'A'
        means to read / write the elements in Fortran-like index order if `a` is
        Fortran *contiguous* in memory, C-like order otherwise.

    Returns
    -------
    reshaped_array : ndarray
        This will be a new view object if possible; otherwise, it will
        be a copy.  Note there is no guarantee of the *memory layout* (C- or
        Fortran- contiguous) of the returned array.

    See Also
    --------
    ndarray.reshape : Equivalent method.

    Notes
    -----
    It is not always possible to change the shape of an array without
    copying the data. If you want an error to be raise if the data is copied,
    you should assign the new shape to the shape attribute of the array::

     >>> a = np.zeros((10, 2))
     # A transpose make the array non-contiguous
     >>> b = a.T
     # Taking a view makes it possible to modify the shape without modifying the
     # initial object.
     >>> c = b.view()
     >>> c.shape = (20)
     AttributeError: incompatible shape for a non-contiguous array

    The `order` keyword gives the index ordering both for *fetching* the values
    from `a`, and then *placing* the values into the output array.  For example,
    let's say you have an array:

    >>> a = np.arange(6).reshape((3, 2))
    >>> a
    array([[0, 1],
           [2, 3],
           [4, 5]])

    You can think of reshaping as first raveling the array (using the given
    index order), then inserting the elements from the raveled array into the
    new array using the same kind of index ordering as was used for the
    raveling.

    >>> np.reshape(a, (2, 3)) # C-like index ordering
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering
    array([[0, 4, 3],
           [2, 1, 5]])
    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')
    array([[0, 4, 3],
           [2, 1, 5]])

    Examples
    --------
    >>> a = np.array([[1,2,3], [4,5,6]])
    >>> np.reshape(a, 6)
    array([1, 2, 3, 4, 5, 6])
    >>> np.reshape(a, 6, order='F')
    array([1, 4, 2, 5, 3, 6])

    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2
    array([[1, 2],
           [3, 4],
           [5, 6]])
    
    Range of values (maximum - minimum) along an axis.

    The name of the function comes from the acronym for 'peak to peak'.

    Parameters
    ----------
    a : array_like
        Input values.
    axis : int, optional
        Axis along which to find the peaks.  By default, flatten the
        array.
    out : array_like
        Alternative output array in which to place the result. It must
        have the same shape and buffer length as the expected output,
        but the type of the output values will be cast if necessary.

    Returns
    -------
    ptp : ndarray
        A new array holding the result, unless `out` was
        specified, in which case a reference to `out` is returned.

    Examples
    --------
    >>> x = np.arange(4).reshape((2,2))
    >>> x
    array([[0, 1],
           [2, 3]])

    >>> np.ptp(x, axis=0)
    array([2, 2])

    >>> np.ptp(x, axis=1)
    array([1, 1])

    
    Construct an array from an index array and a set of arrays to choose from.

    First of all, if confused or uncertain, definitely look at the Examples -
    in its full generality, this function is less simple than it might
    seem from the following code description (below ndi =
    `numpy.lib.index_tricks`):

    ``np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])``.

    But this omits some subtleties.  Here is a fully general summary:

    Given an "index" array (`a`) of integers and a sequence of `n` arrays
    (`choices`), `a` and each choice array are first broadcast, as necessary,
    to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =
    0,...,n-1* we have that, necessarily, ``Ba.shape == Bchoices[i].shape``
    for each `i`.  Then, a new array with shape ``Ba.shape`` is created as
    follows:

    * if ``mode=raise`` (the default), then, first of all, each element of
      `a` (and thus `Ba`) must be in the range `[0, n-1]`; now, suppose that
      `i` (in that range) is the value at the `(j0, j1, ..., jm)` position
      in `Ba` - then the value at the same position in the new array is the
      value in `Bchoices[i]` at that same position;

    * if ``mode=wrap``, values in `a` (and thus `Ba`) may be any (signed)
      integer; modular arithmetic is used to map integers outside the range
      `[0, n-1]` back into that range; and then the new array is constructed
      as above;

    * if ``mode=clip``, values in `a` (and thus `Ba`) may be any (signed)
      integer; negative integers are mapped to 0; values greater than `n-1`
      are mapped to `n-1`; and then the new array is constructed as above.

    Parameters
    ----------
    a : int array
        This array must contain integers in `[0, n-1]`, where `n` is the number
        of choices, unless ``mode=wrap`` or ``mode=clip``, in which cases any
        integers are permissible.
    choices : sequence of arrays
        Choice arrays. `a` and all of the choices must be broadcastable to the
        same shape.  If `choices` is itself an array (not recommended), then
        its outermost dimension (i.e., the one corresponding to
        ``choices.shape[0]``) is taken as defining the "sequence".
    out : array, optional
        If provided, the result will be inserted into this array. It should
        be of the appropriate shape and dtype.
    mode : {'raise' (default), 'wrap', 'clip'}, optional
        Specifies how indices outside `[0, n-1]` will be treated:

          * 'raise' : an exception is raised
          * 'wrap' : value becomes value mod `n`
          * 'clip' : values < 0 are mapped to 0, values > n-1 are mapped to n-1

    Returns
    -------
    merged_array : array
        The merged result.

    Raises
    ------
    ValueError: shape mismatch
        If `a` and each choice array are not all broadcastable to the same
        shape.

    See Also
    --------
    ndarray.choose : equivalent method

    Notes
    -----
    To reduce the chance of misinterpretation, even though the following
    "abuse" is nominally supported, `choices` should neither be, nor be
    thought of as, a single array, i.e., the outermost sequence-like container
    should be either a list or a tuple.

    Examples
    --------

    >>> choices = [[0, 1, 2, 3], [10, 11, 12, 13],
    ...   [20, 21, 22, 23], [30, 31, 32, 33]]
    >>> np.choose([2, 3, 1, 0], choices
    ... # the first element of the result will be the first element of the
    ... # third (2+1) "array" in choices, namely, 20; the second element
    ... # will be the second element of the fourth (3+1) choice array, i.e.,
    ... # 31, etc.
    ... )
    array([20, 31, 12,  3])
    >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1)
    array([20, 31, 12,  3])
    >>> # because there are 4 choice arrays
    >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4)
    array([20,  1, 12,  3])
    >>> # i.e., 0

    A couple examples illustrating how choose broadcasts:

    >>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]
    >>> choices = [-10, 10]
    >>> np.choose(a, choices)
    array([[ 10, -10,  10],
           [-10,  10, -10],
           [ 10, -10,  10]])

    >>> # With thanks to Anne Archibald
    >>> a = np.array([0, 1]).reshape((2,1,1))
    >>> c1 = np.array([1, 2, 3]).reshape((1,3,1))
    >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5))
    >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2
    array([[[ 1,  1,  1,  1,  1],
            [ 2,  2,  2,  2,  2],
            [ 3,  3,  3,  3,  3]],
           [[-1, -2, -3, -4, -5],
            [-1, -2, -3, -4, -5],
            [-1, -2, -3, -4, -5]]])

    
    Return specified diagonals.

    If `a` is 2-D, returns the diagonal of `a` with the given offset,
    i.e., the collection of elements of the form ``a[i, i+offset]``.  If
    `a` has more than two dimensions, then the axes specified by `axis1`
    and `axis2` are used to determine the 2-D sub-array whose diagonal is
    returned.  The shape of the resulting array can be determined by
    removing `axis1` and `axis2` and appending an index to the right equal
    to the size of the resulting diagonals.

    In versions of NumPy prior to 1.7, this function always returned a new,
    independent array containing a copy of the values in the diagonal.

    In NumPy 1.7, it continues to return a copy of the diagonal, but depending
    on this fact is deprecated. Writing to the resulting array continues to
    work as it used to, but a FutureWarning will be issued.

    In NumPy 1.9, it will switch to returning a read-only view on the original
    array. Attempting to write to the resulting array will produce an error.

    In NumPy 1.10, it will still return a view, but this view will no longer be
    marked read-only. Writing to the returned array will alter your original
    array as well.

    If you don't write to the array returned by this function, then you can
    just ignore all of the above.

    If you depend on the current behavior, then we suggest copying the
    returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead of
    just ``np.diagonal(a)``. This will work with both past and future versions
    of NumPy.

    Parameters
    ----------
    a : array_like
        Array from which the diagonals are taken.
    offset : int, optional
        Offset of the diagonal from the main diagonal.  Can be positive or
        negative.  Defaults to main diagonal (0).
    axis1 : int, optional
        Axis to be used as the first axis of the 2-D sub-arrays from which
        the diagonals should be taken.  Defaults to first axis (0).
    axis2 : int, optional
        Axis to be used as the second axis of the 2-D sub-arrays from
        which the diagonals should be taken. Defaults to second axis (1).

    Returns
    -------
    array_of_diagonals : ndarray
        If `a` is 2-D, a 1-D array containing the diagonal is returned.
        If the dimension of `a` is larger, then an array of diagonals is
        returned, "packed" from left-most dimension to right-most (e.g.,
        if `a` is 3-D, then the diagonals are "packed" along rows).

    Raises
    ------
    ValueError
        If the dimension of `a` is less than 2.

    See Also
    --------
    diag : MATLAB work-a-like for 1-D and 2-D arrays.
    diagflat : Create diagonal arrays.
    trace : Sum along diagonals.

    Examples
    --------
    >>> a = np.arange(4).reshape(2,2)
    >>> a
    array([[0, 1],
           [2, 3]])
    >>> a.diagonal()
    array([0, 3])
    >>> a.diagonal(1)
    array([1])

    A 3-D example:

    >>> a = np.arange(8).reshape(2,2,2); a
    array([[[0, 1],
            [2, 3]],
           [[4, 5],
            [6, 7]]])
    >>> a.diagonal(0, # Main diagonals of two arrays created by skipping
    ...            0, # across the outer(left)-most axis last and
    ...            1) # the "middle" (row) axis first.
    array([[0, 6],
           [1, 7]])

    The sub-arrays whose main diagonals we just obtained; note that each
    corresponds to fixing the right-most (column) axis, and that the
    diagonals are "packed" in rows.

    >>> a[:,:,0] # main diagonal is [0 6]
    array([[0, 2],
           [4, 6]])
    >>> a[:,:,1] # main diagonal is [1 7]
    array([[1, 3],
           [5, 7]])

    
    Return the length of the first dimension of the input array.

    Parameters
    ----------
    a : array_like
       Input array.

    Returns
    -------
    alen : int
       Length of the first dimension of `a`.

    See Also
    --------
    shape, size

    Examples
    --------
    >>> a = np.zeros((7,4,5))
    >>> a.shape[0]
    7
    >>> np.alen(a)
    7

    
    Return selected slices of an array along given axis.

    When working along a given axis, a slice along that axis is returned in
    `output` for each index where `condition` evaluates to True. When
    working on a 1-D array, `compress` is equivalent to `extract`.

    Parameters
    ----------
    condition : 1-D array of bools
        Array that selects which entries to return. If len(condition)
        is less than the size of `a` along the given axis, then output is
        truncated to the length of the condition array.
    a : array_like
        Array from which to extract a part.
    axis : int, optional
        Axis along which to take slices. If None (default), work on the
        flattened array.
    out : ndarray, optional
        Output array.  Its type is preserved and it must be of the right
        shape to hold the output.

    Returns
    -------
    compressed_array : ndarray
        A copy of `a` without the slices along axis for which `condition`
        is false.

    See Also
    --------
    take, choose, diag, diagonal, select
    ndarray.compress : Equivalent method in ndarray
    np.extract: Equivalent method when working on 1-D arrays
    numpy.doc.ufuncs : Section "Output arguments"

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4], [5, 6]])
    >>> a
    array([[1, 2],
           [3, 4],
           [5, 6]])
    >>> np.compress([0, 1], a, axis=0)
    array([[3, 4]])
    >>> np.compress([False, True, True], a, axis=0)
    array([[3, 4],
           [5, 6]])
    >>> np.compress([False, True], a, axis=1)
    array([[2],
           [4],
           [6]])

    Working on the flattened array does not return slices along an axis but
    selects elements.

    >>> np.compress([False, True], a)
    array([2])

    
    Evenly round to the given number of decimals.

    Parameters
    ----------
    a : array_like
        Input data.
    decimals : int, optional
        Number of decimal places to round to (default: 0).  If
        decimals is negative, it specifies the number of positions to
        the left of the decimal point.
    out : ndarray, optional
        Alternative output array in which to place the result. It must have
        the same shape as the expected output, but the type of the output
        values will be cast if necessary. See `doc.ufuncs` (Section
        "Output arguments") for details.

    Returns
    -------
    rounded_array : ndarray
        An array of the same type as `a`, containing the rounded values.
        Unless `out` was specified, a new array is created.  A reference to
        the result is returned.

        The real and imaginary parts of complex numbers are rounded
        separately.  The result of rounding a float is a float.

    See Also
    --------
    ndarray.round : equivalent method

    ceil, fix, floor, rint, trunc


    Notes
    -----
    For values exactly halfway between rounded decimal values, Numpy
    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,
    -0.5 and 0.5 round to 0.0, etc. Results may also be surprising due
    to the inexact representation of decimal fractions in the IEEE
    floating point standard [1]_ and errors introduced when scaling
    by powers of ten.

    References
    ----------
    .. [1] "Lecture Notes on the Status of  IEEE 754", William Kahan,
           http://www.cs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
    .. [2] "How Futile are Mindless Assessments of
           Roundoff in Floating-Point Computation?", William Kahan,
           http://www.cs.berkeley.edu/~wkahan/Mindless.pdf

    Examples
    --------
    >>> np.around([0.37, 1.64])
    array([ 0.,  2.])
    >>> np.around([0.37, 1.64], decimals=1)
    array([ 0.4,  1.6])
    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value
    array([ 0.,  2.,  2.,  4.,  4.])
    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned
    array([ 1,  2,  3, 11])
    >>> np.around([1,2,3,11], decimals=-1)
    array([ 0,  0,  0, 10])

    
    Test whether any array element along a given axis evaluates to True.

    Returns single boolean unless `axis` is not ``None``

    Parameters
    ----------
    a : array_like
        Input array or object that can be converted to an array.
    axis : None or int or tuple of ints, optional
        Axis or axes along which a logical OR reduction is performed.
        The default (`axis` = `None`) is perform a logical OR over all
        the dimensions of the input array. `axis` may be negative, in
        which case it counts from the last to the first axis.

        .. versionadded:: 1.7.0

        If this is a tuple of ints, a reduction is performed on multiple
        axes, instead of a single axis or all the axes as before.
    out : ndarray, optional
        Alternate output array in which to place the result.  It must have
        the same shape as the expected output and its type is preserved
        (e.g., if it is of type float, then it will remain so, returning
        1.0 for True and 0.0 for False, regardless of the type of `a`).
        See `doc.ufuncs` (Section "Output arguments") for details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    any : bool or ndarray
        A new boolean or `ndarray` is returned unless `out` is specified,
        in which case a reference to `out` is returned.

    See Also
    --------
    ndarray.any : equivalent method

    all : Test whether all elements along a given axis evaluate to True.

    Notes
    -----
    Not a Number (NaN), positive infinity and negative infinity evaluate
    to `True` because these are not equal to zero.

    Examples
    --------
    >>> np.any([[True, False], [True, True]])
    True

    >>> np.any([[True, False], [False, False]], axis=0)
    array([ True, False], dtype=bool)

    >>> np.any([-1, 0, 5])
    True

    >>> np.any(np.nan)
    True

    >>> o=np.array([False])
    >>> z=np.any([-1, 4, 5], out=o)
    >>> z, o
    (array([ True], dtype=bool), array([ True], dtype=bool))
    >>> # Check now that z is a reference to o
    >>> z is o
    True
    >>> id(z), id(o) # identity of z and o              # doctest: +SKIP
    (191614240, 191614240)

    Module containing non-deprecated functions borrowed from Numeric.


    Check if all elements of input array are true.

    See Also
    --------
    numpy.all : Equivalent function; see for details.

    
    Find indices where elements should be inserted to maintain order.

    Find the indices into a sorted array `a` such that, if the
    corresponding elements in `v` were inserted before the indices, the
    order of `a` would be preserved.

    Parameters
    ----------
    a : 1-D array_like
        Input array. If `sorter` is None, then it must be sorted in
        ascending order, otherwise `sorter` must be an array of indices
        that sort it.
    v : array_like
        Values to insert into `a`.
    side : {'left', 'right'}, optional
        If 'left', the index of the first suitable location found is given.
        If 'right', return the last such index.  If there is no suitable
        index, return either 0 or N (where N is the length of `a`).
    sorter : 1-D array_like, optional
        .. versionadded:: 1.7.0
        Optional array of integer indices that sort array a into ascending
        order. They are typically the result of argsort.

    Returns
    -------
    indices : array of ints
        Array of insertion points with the same shape as `v`.

    See Also
    --------
    sort : Return a sorted copy of an array.
    histogram : Produce histogram from 1-D data.

    Notes
    -----
    Binary search is used to find the required insertion points.

    As of Numpy 1.4.0 `searchsorted` works with real/complex arrays containing
    `nan` values. The enhanced sort order is documented in `sort`.

    Examples
    --------
    >>> np.searchsorted([1,2,3,4,5], 3)
    2
    >>> np.searchsorted([1,2,3,4,5], 3, side='right')
    3
    >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3])
    array([0, 5, 1, 2])

    
    Sum of array elements over a given axis.

    Parameters
    ----------
    a : array_like
        Elements to sum.
    axis : None or int or tuple of ints, optional
        Axis or axes along which a sum is performed.
        The default (`axis` = `None`) is perform a sum over all
        the dimensions of the input array. `axis` may be negative, in
        which case it counts from the last to the first axis.

        .. versionadded:: 1.7.0

        If this is a tuple of ints, a sum is performed on multiple
        axes, instead of a single axis or all the axes as before.
    dtype : dtype, optional
        The type of the returned array and of the accumulator in which
        the elements are summed.  By default, the dtype of `a` is used.
        An exception is when `a` has an integer type with less precision
        than the default platform integer.  In that case, the default
        platform integer is used instead.
    out : ndarray, optional
        Array into which the output is placed.  By default, a new array is
        created.  If `out` is given, it must be of the appropriate shape
        (the shape of `a` with `axis` removed, i.e.,
        ``numpy.delete(a.shape, axis)``).  Its type is preserved. See
        `doc.ufuncs` (Section "Output arguments") for more details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    sum_along_axis : ndarray
        An array with the same shape as `a`, with the specified
        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar
        is returned.  If an output array is specified, a reference to
        `out` is returned.

    See Also
    --------
    ndarray.sum : Equivalent method.

    cumsum : Cumulative sum of array elements.

    trapz : Integration of array values using the composite trapezoidal rule.

    mean, average

    Notes
    -----
    Arithmetic is modular when using integer types, and no error is
    raised on overflow.

    Examples
    --------
    >>> np.sum([0.5, 1.5])
    2.0
    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)
    1
    >>> np.sum([[0, 1], [0, 5]])
    6
    >>> np.sum([[0, 1], [0, 5]], axis=0)
    array([0, 6])
    >>> np.sum([[0, 1], [0, 5]], axis=1)
    array([1, 5])

    If the accumulator is too small, overflow occurs:

    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)
    -128

    
    Return a flattened array.

    A 1-D array, containing the elements of the input, is returned.  A copy is
    made only if needed.

    Parameters
    ----------
    a : array_like
        Input array.  The elements in `a` are read in the order specified by
        `order`, and packed as a 1-D array.
    order : {'C','F', 'A', 'K'}, optional
        The elements of `a` are read using this index order. 'C' means to
        index the elements in C-like order, with the last axis index changing
        fastest, back to the first axis index changing slowest.   'F' means to
        index the elements in Fortran-like index order, with the first index
        changing fastest, and the last index changing slowest. Note that the 'C'
        and 'F' options take no account of the memory layout of the underlying
        array, and only refer to the order of axis indexing.  'A' means to read
        the elements in Fortran-like index order if `a` is Fortran *contiguous*
        in memory, C-like order otherwise.  'K' means to read the elements in
        the order they occur in memory, except for reversing the data when
        strides are negative.  By default, 'C' index order is used.

    Returns
    -------
    1d_array : ndarray
        Output of the same dtype as `a`, and of shape ``(a.size,)``.

    See Also
    --------
    ndarray.flat : 1-D iterator over an array.
    ndarray.flatten : 1-D array copy of the elements of an array
                      in row-major order.

    Notes
    -----
    In C-like (row-major) order, in two dimensions, the row index varies the
    slowest, and the column index the quickest.  This can be generalized to
    multiple dimensions, where row-major order implies that the index along the
    first axis varies slowest, and the index along the last quickest.  The
    opposite holds for Fortran-like, or column-major, index ordering.

    Examples
    --------
    It is equivalent to ``reshape(-1, order=order)``.

    >>> x = np.array([[1, 2, 3], [4, 5, 6]])
    >>> print np.ravel(x)
    [1 2 3 4 5 6]

    >>> print x.reshape(-1)
    [1 2 3 4 5 6]

    >>> print np.ravel(x, order='F')
    [1 4 2 5 3 6]

    When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:

    >>> print np.ravel(x.T)
    [1 4 2 5 3 6]
    >>> print np.ravel(x.T, order='A')
    [1 2 3 4 5 6]

    When ``order`` is 'K', it will preserve orderings that are neither 'C'
    nor 'F', but won't reverse axes:

    >>> a = np.arange(3)[::-1]; a
    array([2, 1, 0])
    >>> a.ravel(order='C')
    array([2, 1, 0])
    >>> a.ravel(order='K')
    array([2, 1, 0])

    >>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a
    array([[[ 0,  2,  4],
            [ 1,  3,  5]],
           [[ 6,  8, 10],
            [ 7,  9, 11]]])
    >>> a.ravel(order='C')
    array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])
    >>> a.ravel(order='K')
    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

    
    Return the indices of the minimum values along an axis.

    See Also
    --------
    argmax : Similar function.  Please refer to `numpy.argmax` for detailed
        documentation.

    
    Perform an indirect partition along the given axis using the algorithm
    specified by the `kind` keyword. It returns an array of indices of the
    same shape as `a` that index data along the given axis in partitioned
    order.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        Array to sort.
    kth : int or sequence of ints
        Element index to partition by. The kth element will be in its final
        sorted position and all smaller elements will be moved before it and
        all larger elements behind it.
        The order all elements in the partitions is undefined.
        If provided with a sequence of kth it will partition all of them into
        their sorted position at once.
    axis : int or None, optional
        Axis along which to sort.  The default is -1 (the last axis). If None,
        the flattened array is used.
    kind : {'introselect'}, optional
        Selection algorithm. Default is 'introselect'
    order : list, optional
        When `a` is an array with fields defined, this argument specifies
        which fields to compare first, second, etc.  Not all fields need be
        specified.

    Returns
    -------
    index_array : ndarray, int
        Array of indices that partition `a` along the specified axis.
        In other words, ``a[index_array]`` yields a sorted `a`.

    See Also
    --------
    partition : Describes partition algorithms used.
    ndarray.partition : Inplace partition.
    argsort : Full indirect sort

    Notes
    -----
    See `partition` for notes on the different selection algorithms.

    Examples
    --------
    One dimensional array:

    >>> x = np.array([3, 4, 2, 1])
    >>> x[np.argpartition(x, 3)]
    array([2, 1, 3, 4])
    >>> x[np.argpartition(x, (1, 3))]
    array([1, 2, 3, 4])

    
    Return the number of dimensions of an array.

    If `a` is not already an array, a conversion is attempted.
    Scalars are zero dimensional.

    Parameters
    ----------
    a : array_like
        Array whose number of dimensions is desired. If `a` is not an array,
        a conversion is attempted.

    Returns
    -------
    number_of_dimensions : int
        The number of dimensions in the array.

    See Also
    --------
    ndim : equivalent function
    ndarray.ndim : equivalent property
    shape : dimensions of array
    ndarray.shape : dimensions of array

    Notes
    -----
    In the old Numeric package, `rank` was the term used for the number of
    dimensions, but in Numpy `ndim` is used instead.

    Examples
    --------
    >>> np.rank([1,2,3])
    1
    >>> np.rank(np.array([[1,2,3],[4,5,6]]))
    2
    >>> np.rank(1)
    0

    
    Return the sum along diagonals of the array.

    If `a` is 2-D, the sum along its diagonal with the given offset
    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.

    If `a` has more than two dimensions, then the axes specified by axis1 and
    axis2 are used to determine the 2-D sub-arrays whose traces are returned.
    The shape of the resulting array is the same as that of `a` with `axis1`
    and `axis2` removed.

    Parameters
    ----------
    a : array_like
        Input array, from which the diagonals are taken.
    offset : int, optional
        Offset of the diagonal from the main diagonal. Can be both positive
        and negative. Defaults to 0.
    axis1, axis2 : int, optional
        Axes to be used as the first and second axis of the 2-D sub-arrays
        from which the diagonals should be taken. Defaults are the first two
        axes of `a`.
    dtype : dtype, optional
        Determines the data-type of the returned array and of the accumulator
        where the elements are summed. If dtype has the value None and `a` is
        of integer type of precision less than the default integer
        precision, then the default integer precision is used. Otherwise,
        the precision is the same as that of `a`.
    out : ndarray, optional
        Array into which the output is placed. Its type is preserved and
        it must be of the right shape to hold the output.

    Returns
    -------
    sum_along_diagonals : ndarray
        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has
        larger dimensions, then an array of sums along diagonals is returned.

    See Also
    --------
    diag, diagonal, diagflat

    Examples
    --------
    >>> np.trace(np.eye(3))
    3.0
    >>> a = np.arange(8).reshape((2,2,2))
    >>> np.trace(a)
    array([6, 8])

    >>> a = np.arange(24).reshape((2,2,2,3))
    >>> np.trace(a).shape
    (2, 3)

    
    Remove single-dimensional entries from the shape of an array.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : None or int or tuple of ints, optional
        .. versionadded:: 1.7.0

        Selects a subset of the single-dimensional entries in the
        shape. If an axis is selected with shape entry greater than
        one, an error is raised.

    Returns
    -------
    squeezed : ndarray
        The input array, but with with all or a subset of the
        dimensions of length 1 removed. This is always `a` itself
        or a view into `a`.

    Examples
    --------
    >>> x = np.array([[[0], [1], [2]]])
    >>> x.shape
    (1, 3, 1)
    >>> np.squeeze(x).shape
    (3,)
    >>> np.squeeze(x, axis=(2,)).shape
    (1, 3)

    
    Return a partitioned copy of an array.

    Creates a copy of the array with its elements rearranged in such a way that
    the value of the element in kth position is in the position it would be in
    a sorted array. All elements smaller than the kth element are moved before
    this element and all equal or greater are moved behind it. The ordering of
    the elements in the two partitions is undefined.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        Array to be sorted.
    kth : int or sequence of ints
        Element index to partition by. The kth value of the element will be in
        its final sorted position and all smaller elements will be moved before
        it and all equal or greater elements behind it.
        The order all elements in the partitions is undefined.
        If provided with a sequence of kth it will partition all elements
        indexed by kth  of them into their sorted position at once.
    axis : int or None, optional
        Axis along which to sort. If None, the array is flattened before
        sorting. The default is -1, which sorts along the last axis.
    kind : {'introselect'}, optional
        Selection algorithm. Default is 'introselect'.
    order : list, optional
        When `a` is a structured array, this argument specifies which fields
        to compare first, second, and so on.  This list does not need to
        include all of the fields.

    Returns
    -------
    partitioned_array : ndarray
        Array of the same type and shape as `a`.

    See Also
    --------
    ndarray.partition : Method to sort an array in-place.
    argpartition : Indirect partition.
    sort : Full sorting

    Notes
    -----
    The various selection algorithms are characterized by their average speed,
    worst case performance, work space size, and whether they are stable. A
    stable sort keeps items with the same key in the same relative order. The
    three available algorithms have the following properties:

    ================= ======= ============= ============ =======
       kind            speed   worst case    work space  stable
    ================= ======= ============= ============ =======
    'introselect'        1        O(n)           0         no
    ================= ======= ============= ============ =======

    All the partition algorithms make temporary copies of the data when
    partitioning along any but the last axis.  Consequently, partitioning
    along the last axis is faster and uses less space than partitioning
    along any other axis.

    The sort order for complex numbers is lexicographic. If both the real
    and imaginary parts are non-nan then the order is determined by the
    real parts except when they are equal, in which case the order is
    determined by the imaginary parts.

    Examples
    --------
    >>> a = np.array([3, 4, 2, 1])
    >>> np.partition(a, 3)
    array([2, 1, 3, 4])

    >>> np.partition(a, (1, 3))
    array([1, 2, 3, 4])

    
    Compute the standard deviation along the specified axis.

    Returns the standard deviation, a measure of the spread of a distribution,
    of the array elements. The standard deviation is computed for the
    flattened array by default, otherwise over the specified axis.

    Parameters
    ----------
    a : array_like
        Calculate the standard deviation of these values.
    axis : int, optional
        Axis along which the standard deviation is computed. The default is
        to compute the standard deviation of the flattened array.
    dtype : dtype, optional
        Type to use in computing the standard deviation. For arrays of
        integer type the default is float64, for arrays of float types it is
        the same as the array type.
    out : ndarray, optional
        Alternative output array in which to place the result. It must have
        the same shape as the expected output but the type (of the calculated
        values) will be cast if necessary.
    ddof : int, optional
        Means Delta Degrees of Freedom.  The divisor used in calculations
        is ``N - ddof``, where ``N`` represents the number of elements.
        By default `ddof` is zero.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    standard_deviation : ndarray, see dtype parameter above.
        If `out` is None, return a new array containing the standard deviation,
        otherwise return a reference to the output array.

    See Also
    --------
    var, mean, nanmean, nanstd, nanvar
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    The standard deviation is the square root of the average of the squared
    deviations from the mean, i.e., ``std = sqrt(mean(abs(x - x.mean())**2))``.

    The average squared deviation is normally calculated as
    ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
    the divisor ``N - ddof`` is used instead. In standard statistical
    practice, ``ddof=1`` provides an unbiased estimator of the variance
    of the infinite population. ``ddof=0`` provides a maximum likelihood
    estimate of the variance for normally distributed variables. The
    standard deviation computed in this function is the square root of
    the estimated variance, so even with ``ddof=1``, it will not be an
    unbiased estimate of the standard deviation per se.

    Note that, for complex numbers, `std` takes the absolute
    value before squaring, so that the result is always real and nonnegative.

    For floating-point input, the *std* is computed using the same
    precision the input has. Depending on the input data, this can cause
    the results to be inaccurate, especially for float32 (see example below).
    Specifying a higher-accuracy accumulator using the `dtype` keyword can
    alleviate this issue.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4]])
    >>> np.std(a)
    1.1180339887498949
    >>> np.std(a, axis=0)
    array([ 1.,  1.])
    >>> np.std(a, axis=1)
    array([ 0.5,  0.5])

    In single precision, std() can be inaccurate:

    >>> a = np.zeros((2,512*512), dtype=np.float32)
    >>> a[0,:] = 1.0
    >>> a[1,:] = 0.1
    >>> np.std(a)
    0.45172946707416706

    Computing the standard deviation in float64 is more accurate:

    >>> np.std(a, dtype=np.float64)
    0.44999999925552653

    
    Return a sorted copy of an array.

    Parameters
    ----------
    a : array_like
        Array to be sorted.
    axis : int or None, optional
        Axis along which to sort. If None, the array is flattened before
        sorting. The default is -1, which sorts along the last axis.
    kind : {'quicksort', 'mergesort', 'heapsort'}, optional
        Sorting algorithm. Default is 'quicksort'.
    order : list, optional
        When `a` is a structured array, this argument specifies which fields
        to compare first, second, and so on.  This list does not need to
        include all of the fields.

    Returns
    -------
    sorted_array : ndarray
        Array of the same type and shape as `a`.

    See Also
    --------
    ndarray.sort : Method to sort an array in-place.
    argsort : Indirect sort.
    lexsort : Indirect stable sort on multiple keys.
    searchsorted : Find elements in a sorted array.
    partition : Partial sort.

    Notes
    -----
    The various sorting algorithms are characterized by their average speed,
    worst case performance, work space size, and whether they are stable. A
    stable sort keeps items with the same key in the same relative
    order. The three available algorithms have the following
    properties:

    =========== ======= ============= ============ =======
       kind      speed   worst case    work space  stable
    =========== ======= ============= ============ =======
    'quicksort'    1     O(n^2)            0          no
    'mergesort'    2     O(n*log(n))      ~n/2        yes
    'heapsort'     3     O(n*log(n))       0          no
    =========== ======= ============= ============ =======

    All the sort algorithms make temporary copies of the data when
    sorting along any but the last axis.  Consequently, sorting along
    the last axis is faster and uses less space than sorting along
    any other axis.

    The sort order for complex numbers is lexicographic. If both the real
    and imaginary parts are non-nan then the order is determined by the
    real parts except when they are equal, in which case the order is
    determined by the imaginary parts.

    Previous to numpy 1.4.0 sorting real and complex arrays containing nan
    values led to undefined behaviour. In numpy versions >= 1.4.0 nan
    values are sorted to the end. The extended sort order is:

      * Real: [R, nan]
      * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]

    where R is a non-nan real value. Complex values with the same nan
    placements are sorted according to the non-nan part if it exists.
    Non-nan values are sorted as before.

    Examples
    --------
    >>> a = np.array([[1,4],[3,1]])
    >>> np.sort(a)                # sort along the last axis
    array([[1, 4],
           [1, 3]])
    >>> np.sort(a, axis=None)     # sort the flattened array
    array([1, 1, 3, 4])
    >>> np.sort(a, axis=0)        # sort along the first axis
    array([[1, 1],
           [3, 4]])

    Use the `order` keyword to specify a field to use when sorting a
    structured array:

    >>> dtype = [('name', 'S10'), ('height', float), ('age', int)]
    >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),
    ...           ('Galahad', 1.7, 38)]
    >>> a = np.array(values, dtype=dtype)       # create a structured array
    >>> np.sort(a, order='height')                        # doctest: +SKIP
    array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),
           ('Lancelot', 1.8999999999999999, 38)],
          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])

    Sort by age, then height if ages are equal:

    >>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP
    array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),
           ('Arthur', 1.8, 41)],
          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])

    
    Return the product of array elements over a given axis.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : None or int or tuple of ints, optional
        Axis or axes along which a product is performed.
        The default (`axis` = `None`) is perform a product over all
        the dimensions of the input array. `axis` may be negative, in
        which case it counts from the last to the first axis.

        .. versionadded:: 1.7.0

        If this is a tuple of ints, a product is performed on multiple
        axes, instead of a single axis or all the axes as before.
    dtype : data-type, optional
        The data-type of the returned array, as well as of the accumulator
        in which the elements are multiplied.  By default, if `a` is of
        integer type, `dtype` is the default platform integer. (Note: if
        the type of `a` is unsigned, then so is `dtype`.)  Otherwise,
        the dtype is the same as that of `a`.
    out : ndarray, optional
        Alternative output array in which to place the result. It must have
        the same shape as the expected output, but the type of the
        output values will be cast if necessary.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    product_along_axis : ndarray, see `dtype` parameter above.
        An array shaped as `a` but with the specified axis removed.
        Returns a reference to `out` if specified.

    See Also
    --------
    ndarray.prod : equivalent method
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    Arithmetic is modular when using integer types, and no error is
    raised on overflow.  That means that, on a 32-bit platform:

    >>> x = np.array([536870910, 536870910, 536870910, 536870910])
    >>> np.prod(x) #random
    16

    Examples
    --------
    By default, calculate the product of all elements:

    >>> np.prod([1.,2.])
    2.0

    Even when the input array is two-dimensional:

    >>> np.prod([[1.,2.],[3.,4.]])
    24.0

    But we can also specify the axis over which to multiply:

    >>> np.prod([[1.,2.],[3.,4.]], axis=1)
    array([  2.,  12.])

    If the type of `x` is unsigned, then the output type is
    the unsigned platform integer:

    >>> x = np.array([1, 2, 3], dtype=np.uint8)
    >>> np.prod(x).dtype == np.uint
    True

    If `x` is of a signed integer type, then the output type
    is the default platform integer:

    >>> x = np.array([1, 2, 3], dtype=np.int8)
    >>> np.prod(x).dtype == np.int
    True

    
    Compute the variance along the specified axis.

    Returns the variance of the array elements, a measure of the spread of a
    distribution.  The variance is computed for the flattened array by
    default, otherwise over the specified axis.

    Parameters
    ----------
    a : array_like
        Array containing numbers whose variance is desired.  If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the variance is computed.  The default is to compute
        the variance of the flattened array.
    dtype : data-type, optional
        Type to use in computing the variance.  For arrays of integer type
        the default is `float32`; for arrays of float types it is the same as
        the array type.
    out : ndarray, optional
        Alternate output array in which to place the result.  It must have
        the same shape as the expected output, but the type is cast if
        necessary.
    ddof : int, optional
        "Delta Degrees of Freedom": the divisor used in the calculation is
        ``N - ddof``, where ``N`` represents the number of elements. By
        default `ddof` is zero.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    variance : ndarray, see dtype parameter above
        If ``out=None``, returns a new array containing the variance;
        otherwise, a reference to the output array is returned.

    See Also
    --------
    std , mean, nanmean, nanstd, nanvar
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    The variance is the average of the squared deviations from the mean,
    i.e.,  ``var = mean(abs(x - x.mean())**2)``.

    The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
    If, however, `ddof` is specified, the divisor ``N - ddof`` is used
    instead.  In standard statistical practice, ``ddof=1`` provides an
    unbiased estimator of the variance of a hypothetical infinite population.
    ``ddof=0`` provides a maximum likelihood estimate of the variance for
    normally distributed variables.

    Note that for complex numbers, the absolute value is taken before
    squaring, so that the result is always real and nonnegative.

    For floating-point input, the variance is computed using the same
    precision the input has.  Depending on the input data, this can cause
    the results to be inaccurate, especially for `float32` (see example
    below).  Specifying a higher-accuracy accumulator using the ``dtype``
    keyword can alleviate this issue.

    Examples
    --------
    >>> a = np.array([[1,2],[3,4]])
    >>> np.var(a)
    1.25
    >>> np.var(a, axis=0)
    array([ 1.,  1.])
    >>> np.var(a, axis=1)
    array([ 0.25,  0.25])

    In single precision, var() can be inaccurate:

    >>> a = np.zeros((2,512*512), dtype=np.float32)
    >>> a[0,:] = 1.0
    >>> a[1,:] = 0.1
    >>> np.var(a)
    0.20405951142311096

    Computing the variance in float64 is more accurate:

    >>> np.var(a, dtype=np.float64)
    0.20249999932997387
    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2
    0.20250000000000001

    
    Return the product of array elements over a given axis.

    See Also
    --------
    prod : equivalent function; see for details.

    
    Compute the arithmetic mean along the specified axis.

    Returns the average of the array elements.  The average is taken over
    the flattened array by default, otherwise over the specified axis.
    `float64` intermediate and return values are used for integer inputs.

    Parameters
    ----------
    a : array_like
        Array containing numbers whose mean is desired. If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the means are computed. The default is to compute
        the mean of the flattened array.
    dtype : data-type, optional
        Type to use in computing the mean.  For integer inputs, the default
        is `float64`; for floating point inputs, it is the same as the
        input dtype.
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``; if provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.
        See `doc.ufuncs` for details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    m : ndarray, see dtype parameter above
        If `out=None`, returns a new array containing the mean values,
        otherwise a reference to the output array is returned.

    See Also
    --------
    average : Weighted average
    std, var, nanmean, nanstd, nanvar

    Notes
    -----
    The arithmetic mean is the sum of the elements along the axis divided
    by the number of elements.

    Note that for floating-point input, the mean is computed using the
    same precision the input has.  Depending on the input data, this can
    cause the results to be inaccurate, especially for `float32` (see
    example below).  Specifying a higher-precision accumulator using the
    `dtype` keyword can alleviate this issue.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4]])
    >>> np.mean(a)
    2.5
    >>> np.mean(a, axis=0)
    array([ 2.,  3.])
    >>> np.mean(a, axis=1)
    array([ 1.5,  3.5])

    In single precision, `mean` can be inaccurate:

    >>> a = np.zeros((2, 512*512), dtype=np.float32)
    >>> a[0, :] = 1.0
    >>> a[1, :] = 0.1
    >>> np.mean(a)
    0.546875

    Computing the mean in float64 is more accurate:

    >>> np.mean(a, dtype=np.float64)
    0.55000000074505806

    
    Return the maximum of an array or maximum along an axis.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : int, optional
        Axis along which to operate.  By default, flattened input is used.
    out : ndarray, optional
        Alternative output array in which to place the result.  Must
        be of the same shape and buffer length as the expected output.
        See `doc.ufuncs` (Section "Output arguments") for more details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    amax : ndarray or scalar
        Maximum of `a`. If `axis` is None, the result is a scalar value.
        If `axis` is given, the result is an array of dimension
        ``a.ndim - 1``.

    See Also
    --------
    amin :
        The minimum value of an array along a given axis, propagating any NaNs.
    nanmax :
        The maximum value of an array along a given axis, ignoring any NaNs.
    maximum :
        Element-wise maximum of two arrays, propagating any NaNs.
    fmax :
        Element-wise maximum of two arrays, ignoring any NaNs.
    argmax :
        Return the indices of the maximum values.

    nanmin, minimum, fmin

    Notes
    -----
    NaN values are propagated, that is if at least one item is NaN, the
    corresponding max value will be NaN as well. To ignore NaN values
    (MATLAB behavior), please use nanmax.

    Don't use `amax` for element-wise comparison of 2 arrays; when
    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than
    ``amax(a, axis=0)``.

    Examples
    --------
    >>> a = np.arange(4).reshape((2,2))
    >>> a
    array([[0, 1],
           [2, 3]])
    >>> np.amax(a)           # Maximum of the flattened array
    3
    >>> np.amax(a, axis=0)   # Maxima along the first axis
    array([2, 3])
    >>> np.amax(a, axis=1)   # Maxima along the second axis
    array([1, 3])

    >>> b = np.arange(5, dtype=np.float)
    >>> b[2] = np.NaN
    >>> np.amax(b)
    nan
    >>> np.nanmax(b)
    4.0

    
    Return the cumulative sum of the elements along a given axis.

    Parameters
    ----------
    a : array_like
        Input array.
    axis : int, optional
        Axis along which the cumulative sum is computed. The default
        (None) is to compute the cumsum over the flattened array.
    dtype : dtype, optional
        Type of the returned array and of the accumulator in which the
        elements are summed.  If `dtype` is not specified, it defaults
        to the dtype of `a`, unless `a` has an integer dtype with a
        precision less than that of the default platform integer.  In
        that case, the default platform integer is used.
    out : ndarray, optional
        Alternative output array in which to place the result. It must
        have the same shape and buffer length as the expected output
        but the type will be cast if necessary. See `doc.ufuncs`
        (Section "Output arguments") for more details.

    Returns
    -------
    cumsum_along_axis : ndarray.
        A new array holding the result is returned unless `out` is
        specified, in which case a reference to `out` is returned. The
        result has the same size as `a`, and the same shape as `a` if
        `axis` is not None or `a` is a 1-d array.


    See Also
    --------
    sum : Sum array elements.

    trapz : Integration of array values using the composite trapezoidal rule.

    diff :  Calculate the n-th order discrete difference along given axis.

    Notes
    -----
    Arithmetic is modular when using integer types, and no error is
    raised on overflow.

    Examples
    --------
    >>> a = np.array([[1,2,3], [4,5,6]])
    >>> a
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> np.cumsum(a)
    array([ 1,  3,  6, 10, 15, 21])
    >>> np.cumsum(a, dtype=float)     # specifies type of output value(s)
    array([  1.,   3.,   6.,  10.,  15.,  21.])

    >>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns
    array([[1, 2, 3],
           [5, 7, 9]])
    >>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows
    array([[ 1,  3,  6],
           [ 4,  9, 15]])

    
    Return the cumulative product of elements along a given axis.

    Parameters
    ----------
    a : array_like
        Input array.
    axis : int, optional
        Axis along which the cumulative product is computed.  By default
        the input is flattened.
    dtype : dtype, optional
        Type of the returned array, as well as of the accumulator in which
        the elements are multiplied.  If *dtype* is not specified, it
        defaults to the dtype of `a`, unless `a` has an integer dtype with
        a precision less than that of the default platform integer.  In
        that case, the default platform integer is used instead.
    out : ndarray, optional
        Alternative output array in which to place the result. It must
        have the same shape and buffer length as the expected output
        but the type of the resulting values will be cast if necessary.

    Returns
    -------
    cumprod : ndarray
        A new array holding the result is returned unless `out` is
        specified, in which case a reference to out is returned.

    See Also
    --------
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    Arithmetic is modular when using integer types, and no error is
    raised on overflow.

    Examples
    --------
    >>> a = np.array([1,2,3])
    >>> np.cumprod(a) # intermediate results 1, 1*2
    ...               # total product 1*2*3 = 6
    array([1, 2, 6])
    >>> a = np.array([[1, 2, 3], [4, 5, 6]])
    >>> np.cumprod(a, dtype=float) # specify type of output
    array([   1.,    2.,    6.,   24.,  120.,  720.])

    The cumulative product for each column (i.e., over the rows) of `a`:

    >>> np.cumprod(a, axis=0)
    array([[ 1,  2,  3],
           [ 4, 10, 18]])

    The cumulative product for each row (i.e. over the columns) of `a`:

    >>> np.cumprod(a,axis=1)
    array([[  1,   2,   6],
           [  4,  20, 120]])

    
    Returns the indices that would sort an array.

    Perform an indirect sort along the given axis using the algorithm specified
    by the `kind` keyword. It returns an array of indices of the same shape as
    `a` that index data along the given axis in sorted order.

    Parameters
    ----------
    a : array_like
        Array to sort.
    axis : int or None, optional
        Axis along which to sort.  The default is -1 (the last axis). If None,
        the flattened array is used.
    kind : {'quicksort', 'mergesort', 'heapsort'}, optional
        Sorting algorithm.
    order : list, optional
        When `a` is an array with fields defined, this argument specifies
        which fields to compare first, second, etc.  Not all fields need be
        specified.

    Returns
    -------
    index_array : ndarray, int
        Array of indices that sort `a` along the specified axis.
        In other words, ``a[index_array]`` yields a sorted `a`.

    See Also
    --------
    sort : Describes sorting algorithms used.
    lexsort : Indirect stable sort with multiple keys.
    ndarray.sort : Inplace sort.
    argpartition : Indirect partial sort.

    Notes
    -----
    See `sort` for notes on the different sorting algorithms.

    As of NumPy 1.4.0 `argsort` works with real/complex arrays containing
    nan values. The enhanced sort order is documented in `sort`.

    Examples
    --------
    One dimensional array:

    >>> x = np.array([3, 1, 2])
    >>> np.argsort(x)
    array([1, 2, 0])

    Two-dimensional array:

    >>> x = np.array([[0, 3], [2, 2]])
    >>> x
    array([[0, 3],
           [2, 2]])

    >>> np.argsort(x, axis=0)
    array([[0, 1],
           [1, 0]])

    >>> np.argsort(x, axis=1)
    array([[0, 1],
           [0, 1]])

    Sorting with keys:

    >>> x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])
    >>> x
    array([(1, 0), (0, 1)],
          dtype=[('x', '<i4'), ('y', '<i4')])

    >>> np.argsort(x, order=('x','y'))
    array([1, 0])

    >>> np.argsort(x, order=('y','x'))
    array([0, 1])

    
    Permute the dimensions of an array.

    Parameters
    ----------
    a : array_like
        Input array.
    axes : list of ints, optional
        By default, reverse the dimensions, otherwise permute the axes
        according to the values given.

    Returns
    -------
    p : ndarray
        `a` with its axes permuted.  A view is returned whenever
        possible.

    See Also
    --------
    rollaxis

    Examples
    --------
    >>> x = np.arange(4).reshape((2,2))
    >>> x
    array([[0, 1],
           [2, 3]])

    >>> np.transpose(x)
    array([[0, 2],
           [1, 3]])

    >>> x = np.ones((1, 2, 3))
    >>> np.transpose(x, (1, 0, 2)).shape
    (2, 1, 3)

    
    Repeat elements of an array.

    Parameters
    ----------
    a : array_like
        Input array.
    repeats : {int, array of ints}
        The number of repetitions for each element.  `repeats` is broadcasted
        to fit the shape of the given axis.
    axis : int, optional
        The axis along which to repeat values.  By default, use the
        flattened input array, and return a flat output array.

    Returns
    -------
    repeated_array : ndarray
        Output array which has the same shape as `a`, except along
        the given axis.

    See Also
    --------
    tile : Tile an array.

    Examples
    --------
    >>> x = np.array([[1,2],[3,4]])
    >>> np.repeat(x, 2)
    array([1, 1, 2, 2, 3, 3, 4, 4])
    >>> np.repeat(x, 3, axis=1)
    array([[1, 1, 1, 2, 2, 2],
           [3, 3, 3, 4, 4, 4]])
    >>> np.repeat(x, [1, 2], axis=0)
    array([[1, 2],
           [3, 4],
           [3, 4]])

    
    Return the minimum of an array or minimum along an axis.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : int, optional
        Axis along which to operate.  By default, flattened input is used.
    out : ndarray, optional
        Alternative output array in which to place the result.  Must
        be of the same shape and buffer length as the expected output.
        See `doc.ufuncs` (Section "Output arguments") for more details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    amin : ndarray or scalar
        Minimum of `a`. If `axis` is None, the result is a scalar value.
        If `axis` is given, the result is an array of dimension
        ``a.ndim - 1``.

    See Also
    --------
    amax :
        The maximum value of an array along a given axis, propagating any NaNs.
    nanmin :
        The minimum value of an array along a given axis, ignoring any NaNs.
    minimum :
        Element-wise minimum of two arrays, propagating any NaNs.
    fmin :
        Element-wise minimum of two arrays, ignoring any NaNs.
    argmin :
        Return the indices of the minimum values.

    nanmax, maximum, fmax

    Notes
    -----
    NaN values are propagated, that is if at least one item is NaN, the
    corresponding min value will be NaN as well. To ignore NaN values
    (MATLAB behavior), please use nanmin.

    Don't use `amin` for element-wise comparison of 2 arrays; when
    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than
    ``amin(a, axis=0)``.

    Examples
    --------
    >>> a = np.arange(4).reshape((2,2))
    >>> a
    array([[0, 1],
           [2, 3]])
    >>> np.amin(a)           # Minimum of the flattened array
    0
    >>> np.amin(a, axis=0)   # Minima along the first axis
    array([0, 1])
    >>> np.amin(a, axis=1)   # Minima along the second axis
    array([0, 2])

    >>> b = np.arange(5, dtype=np.float)
    >>> b[2] = np.NaN
    >>> np.amin(b)
    nan
    >>> np.nanmin(b)
    0.0

    logspacenumpy.core.function_base
    Return evenly spaced numbers over a specified interval.

    Returns `num` evenly spaced samples, calculated over the
    interval [`start`, `stop` ].

    The endpoint of the interval can optionally be excluded.

    Parameters
    ----------
    start : scalar
        The starting value of the sequence.
    stop : scalar
        The end value of the sequence, unless `endpoint` is set to False.
        In that case, the sequence consists of all but the last of ``num + 1``
        evenly spaced samples, so that `stop` is excluded.  Note that the step
        size changes when `endpoint` is False.
    num : int, optional
        Number of samples to generate. Default is 50.
    endpoint : bool, optional
        If True, `stop` is the last sample. Otherwise, it is not included.
        Default is True.
    retstep : bool, optional
        If True, return (`samples`, `step`), where `step` is the spacing
        between samples.

    Returns
    -------
    samples : ndarray
        There are `num` equally spaced samples in the closed interval
        ``[start, stop]`` or the half-open interval ``[start, stop)``
        (depending on whether `endpoint` is True or False).
    step : float (only if `retstep` is True)
        Size of spacing between samples.


    See Also
    --------
    arange : Similar to `linspace`, but uses a step size (instead of the
             number of samples).
    logspace : Samples uniformly distributed in log space.

    Examples
    --------
    >>> np.linspace(2.0, 3.0, num=5)
        array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ])
    >>> np.linspace(2.0, 3.0, num=5, endpoint=False)
        array([ 2. ,  2.2,  2.4,  2.6,  2.8])
    >>> np.linspace(2.0, 3.0, num=5, retstep=True)
        (array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)

    Graphical illustration:

    >>> import matplotlib.pyplot as plt
    >>> N = 8
    >>> y = np.zeros(N)
    >>> x1 = np.linspace(0, 10, N, endpoint=True)
    >>> x2 = np.linspace(0, 10, N, endpoint=False)
    >>> plt.plot(x1, y, 'o')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.plot(x2, y + 0.5, 'o')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.ylim([-0.5, 1])
    (-0.5, 1)
    >>> plt.show()

    
    Return numbers spaced evenly on a log scale.

    In linear space, the sequence starts at ``base ** start``
    (`base` to the power of `start`) and ends with ``base ** stop``
    (see `endpoint` below).

    Parameters
    ----------
    start : float
        ``base ** start`` is the starting value of the sequence.
    stop : float
        ``base ** stop`` is the final value of the sequence, unless `endpoint`
        is False.  In that case, ``num + 1`` values are spaced over the
        interval in log-space, of which all but the last (a sequence of
        length ``num``) are returned.
    num : integer, optional
        Number of samples to generate.  Default is 50.
    endpoint : boolean, optional
        If true, `stop` is the last sample. Otherwise, it is not included.
        Default is True.
    base : float, optional
        The base of the log space. The step size between the elements in
        ``ln(samples) / ln(base)`` (or ``log_base(samples)``) is uniform.
        Default is 10.0.

    Returns
    -------
    samples : ndarray
        `num` samples, equally spaced on a log scale.

    See Also
    --------
    arange : Similar to linspace, with the step size specified instead of the
             number of samples. Note that, when used with a float endpoint, the
             endpoint may or may not be included.
    linspace : Similar to logspace, but with the samples uniformly distributed
               in linear space, instead of log space.

    Notes
    -----
    Logspace is equivalent to the code

    >>> y = np.linspace(start, stop, num=num, endpoint=endpoint)
    ... # doctest: +SKIP
    >>> power(base, y)
    ... # doctest: +SKIP

    Examples
    --------
    >>> np.logspace(2.0, 3.0, num=4)
        array([  100.        ,   215.443469  ,   464.15888336,  1000.        ])
    >>> np.logspace(2.0, 3.0, num=4, endpoint=False)
        array([ 100.        ,  177.827941  ,  316.22776602,  562.34132519])
    >>> np.logspace(2.0, 3.0, num=4, base=2.0)
        array([ 4.        ,  5.0396842 ,  6.34960421,  8.        ])

    Graphical illustration:

    >>> import matplotlib.pyplot as plt
    >>> N = 10
    >>> x1 = np.logspace(0.1, 1, N, endpoint=True)
    >>> x2 = np.logspace(0.1, 1, N, endpoint=False)
    >>> y = np.zeros(N)
    >>> plt.plot(x1, y, 'o')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.plot(x2, y + 0.5, 'o')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.ylim([-0.5, 1])
    (-0.5, 1)
    >>> plt.show()

    /usr/lib/python2.7/dist-packages/numpy/core/function_base.pynmant_str_max_max_vals_min_vals_str_tiny_finfo_cache%s(min=%s, max=%s, dtype=%s)Machine limits for Float32 and Float64 and (long double) if available...

Minimum value of given dtype.
    iinfo(type)

    Machine limits for integer types.

    Attributes
    ----------
    min : int
        The smallest integer expressible by the type.
    max : int
        The largest integer expressible by the type.

    Parameters
    ----------
    type : integer type, dtype, or instance
        The kind of integer data type to get information about.

    See Also
    --------
    finfo : The equivalent for floating point data types.

    Examples
    --------
    With types:

    >>> ii16 = np.iinfo(np.int16)
    >>> ii16.min
    -32768
    >>> ii16.max
    32767
    >>> ii32 = np.iinfo(np.int32)
    >>> ii32.min
    -2147483648
    >>> ii32.max
    2147483647

    With instances:

    >>> ii32 = np.iinfo(np.int32(10))
    >>> ii32.min
    -2147483648
    >>> ii32.max
    2147483647

    data type %r not inexact%12.5e
    finfo(dtype)

    Machine limits for floating point types.

    Attributes
    ----------
    eps : float
        The smallest representable positive number such that
        ``1.0 + eps != 1.0``.  Type of `eps` is an appropriate floating
        point type.
    epsneg : floating point number of the appropriate type
        The smallest representable positive number such that
        ``1.0 - epsneg != 1.0``.
    iexp : int
        The number of bits in the exponent portion of the floating point
        representation.
    machar : MachAr
        The object which calculated these parameters and holds more
        detailed information.
    machep : int
        The exponent that yields `eps`.
    max : floating point number of the appropriate type
        The largest representable number.
    maxexp : int
        The smallest positive power of the base (2) that causes overflow.
    min : floating point number of the appropriate type
        The smallest representable number, typically ``-max``.
    minexp : int
        The most negative power of the base (2) consistent with there
        being no leading 0's in the mantissa.
    negep : int
        The exponent that yields `epsneg`.
    nexp : int
        The number of bits in the exponent including its sign and bias.
    nmant : int
        The number of bits in the mantissa.
    precision : int
        The approximate number of decimal digits to which this kind of
        float is precise.
    resolution : floating point number of the appropriate type
        The approximate decimal resolution of this type, i.e.,
        ``10**-precision``.
    tiny : float
        The smallest positive usable number.  Type of `tiny` is an
        appropriate floating point type.

    Parameters
    ----------
    dtype : float, dtype, or instance
        Kind of floating point data-type about which to get information.

    See Also
    --------
    MachAr : The implementation of the tests that produce this information.
    iinfo : The equivalent for integer data types.

    Notes
    -----
    For developers of NumPy: do not instantiate this at the module level.
    The initial calculation of these parameters is expensive and negatively
    impacts import times.  These objects are cached, so calling ``finfo()``
    repeatedly inside your functions is not a problem.

    fix rank-0 --> rank-1numpy.core.getlimits/usr/lib/python2.7/dist-packages/numpy/core/getlimits.pynumpy %s precision floating point numberMachine parameters for %(dtype)s
---------------------------------------------------------------------
precision=%(precision)3s   resolution= %(_str_resolution)s
machep=%(machep)6s   eps=        %(_str_eps)s
negep =%(negep)6s   epsneg=     %(_str_epsneg)s
minexp=%(minexp)6s   tiny=       %(_str_tiny)s
maxexp=%(maxexp)6s   max=        %(_str_max)s
nexp  =%(nexp)6s   min=        -max
---------------------------------------------------------------------
Invalid integer data type.%(klass)s(resolution=%(resolution)s, min=-%(_str_max)s, max=%(_str_max)s, dtype=%(dtype)s)String representation.Maximum value of given dtype.%15.7eMachine parameters for %(dtype)s
---------------------------------------------------------------------
min = %(min)s
max = %(max)s
---------------------------------------------------------------------
numpy.core.info/usr/lib/python2.7/dist-packages/numpy/core/info.pyDefines a multi-dimensional array and useful procedures for Numerical computation.

Functions

-   array                      - NumPy Array construction
-   zeros                      - Return an array of all zeros
-   empty                      - Return an unitialized array
-   shape                      - Return shape of sequence or array
-   rank                       - Return number of dimensions
-   size                       - Return number of elements in entire array or a
                                 certain dimension
-   fromstring                 - Construct array from (byte) string
-   take                       - Select sub-arrays using sequence of indices
-   put                        - Set sub-arrays using sequence of 1-D indices
-   putmask                    - Set portion of arrays using a mask
-   reshape                    - Return array with new shape
-   repeat                     - Repeat elements of array
-   choose                     - Construct new array from indexed array tuple
-   correlate                  - Correlate two 1-d arrays
-   searchsorted               - Search for element in 1-d array
-   sum                        - Total sum over a specified dimension
-   average                    - Average, possibly weighted, over axis or array.
-   cumsum                     - Cumulative sum over a specified dimension
-   product                    - Total product over a specified dimension
-   cumproduct                 - Cumulative product over a specified dimension
-   alltrue                    - Logical and over an entire axis
-   sometrue                   - Logical or over an entire axis
-   allclose                   - Tests if sequences are essentially equal

More Functions:

-   arange                     - Return regularly spaced array
-   asarray                    - Guarantee NumPy array
-   convolve                   - Convolve two 1-d arrays
-   swapaxes                   - Exchange axes
-   concatenate                - Join arrays together
-   transpose                  - Permute axes
-   sort                       - Sort elements of array
-   argsort                    - Indices of sorted array
-   argmax                     - Index of largest value
-   argmin                     - Index of smallest value
-   inner                      - Innerproduct of two arrays
-   dot                        - Dot product (matrix multiplication)
-   outer                      - Outerproduct of two arrays
-   resize                     - Return array with arbitrary new shape
-   indices                    - Tuple of indices
-   fromfunction               - Construct array from universal function
-   diagonal                   - Return diagonal array
-   trace                      - Trace of array
-   dump                       - Dump array to file object (pickle)
-   dumps                      - Return pickled string representing data
-   load                       - Return array stored in file object
-   loads                      - Return array from pickled string
-   ravel                      - Return array as 1-D
-   nonzero                    - Indices of nonzero elements for 1-D array
-   shape                      - Shape of array
-   where                      - Construct array from binary result
-   compress                   - Elements of array where condition is true
-   clip                       - Clip array between two values
-   ones                       - Array of all ones
-   identity                   - 2-D identity array (matrix)

(Universal) Math Functions

       add                    logical_or             exp
       subtract               logical_xor            log
       multiply               logical_not            log10
       divide                 maximum                sin
       divide_safe            minimum                sinh
       conjugate              bitwise_and            sqrt
       power                  bitwise_or             tan
       absolute               bitwise_xor            tanh
       negative               invert                 ceil
       greater                left_shift             fabs
       greater_equal          right_shift            floor
       less                   arccos                 arctan2
       less_equal             arcsin                 fmod
       equal                  arctan                 hypot
       not_equal              cos                    around
       logical_and            cosh                   sign
       arccosh                arcsinh                arctanh

temp1tempaepsilon_do_init
    Diagnosing machine parameters.

    Attributes
    ----------
    ibeta : int
        Radix in which numbers are represented.
    it : int
        Number of base-`ibeta` digits in the floating point mantissa M.
    machep : int
        Exponent of the smallest (most negative) power of `ibeta` that,
        added to 1.0, gives something different from 1.0
    eps : float
        Floating-point number ``beta**machep`` (floating point precision)
    negep : int
        Exponent of the smallest power of `ibeta` that, substracted
        from 1.0, gives something different from 1.0.
    epsneg : float
        Floating-point number ``beta**negep``.
    iexp : int
        Number of bits in the exponent (including its sign and bias).
    minexp : int
        Smallest (most negative) power of `ibeta` consistent with there
        being no leading zeros in the mantissa.
    xmin : float
        Floating point number ``beta**minexp`` (the smallest [in
        magnitude] usable floating value).
    maxexp : int
        Smallest (positive) power of `ibeta` that causes overflow.
    xmax : float
        ``(1-epsneg) * beta**maxexp`` (the largest [in magnitude]
        usable floating value).
    irnd : int
        In ``range(6)``, information on what kind of rounding is done
        in addition, and on how underflow is handled.
    ngrd : int
        Number of 'guard digits' used when truncating the product
        of two mantissas to fit the representation.
    epsilon : float
        Same as `eps`.
    tiny : float
        Same as `xmin`.
    huge : float
        Same as `xmax`.
    precision : float
        ``- int(-log10(eps))``
    resolution : float
        ``- 10**(-precision)``

    Parameters
    ----------
    float_conv : function, optional
        Function that converts an integer or integer array to a float
        or float array. Default is `float`.
    int_conv : function, optional
        Function that converts a float or float array to an integer or
        integer array. Default is `int`.
    float_to_float : function, optional
        Function that converts a float array to float. Default is `float`.
        Note that this does not seem to do anything useful in the current
        implementation.
    float_to_str : function, optional
        Function that converts a single float to a string. Default is
        ``lambda v:'%24.16e' %v``.
    title : str, optional
        Title that is printed in the string representation of `MachAr`.

    See Also
    --------
    finfo : Machine limits for floating point types.
    iinfo : Machine limits for integer types.

    References
    ----------
    .. [1] Press, Teukolsky, Vetterling and Flannery,
           "Numerical Recipes in C++," 2nd ed,
           Cambridge University Press, 2002, p. 31.

    Did not converge after %d tries with %sMachine parameters for %(title)s
---------------------------------------------------------------------
ibeta=%(ibeta)s it=%(it)s iexp=%(iexp)s ngrd=%(ngrd)s irnd=%(irnd)s
machep=%(machep)s     eps=%(_str_eps)s (beta**machep == epsilon)
negep =%(negep)s  epsneg=%(_str_epsneg)s (beta**epsneg)
minexp=%(minexp)s   xmin=%(_str_xmin)s (beta**minexp == tiny)
maxexp=%(maxexp)s    xmax=%(_str_xmax)s ((1-epsneg)*beta**maxexp == huge)
---------------------------------------------------------------------
Python floating point number/usr/lib/python2.7/dist-packages/numpy/core/machar.py
Machine arithmetics - determine the parameters of the
floating-point arithmetic system

Author: Pearu Peterson, September 2003

numpy.core.macharcould not determine machine tolerance for 'negep', locals() -> %s
          float_conv - convert integer to float (array)
          int_conv   - convert float (array) to integer
          float_to_float - convert float array to float
          float_to_str - convert array float to str
          title        - description of used floating point numbers
        (.   t   selft
   float_convt   int_convt   float_to_floatt   float_to_strt   titlet	   max_iterNt   msgt   onet   twot   zerot   at   _t   tempt   temp1t   bt   itempt   ibetat   betat   itt   betaht   irndt   tempat   negept   betaint   it   epsnegt   machept   epst   ngrdt   kt   zt   tt   nxrest   yt   iexpt   mxt   izt   xmint   minexpt   maxexpt   xmaxt   jt   matht   tent
   resolution      YACCESS_COPYACCESS_READcopyonwriteACCESS_WRITEwriteable_filemodesALLOCATIONGRANULARITYshape must be givenmode must be one of %sSize of available data is not a multiple of the data-type size./usr/lib/python2.7/dist-packages/numpy/core/memmap.py
        Write any changes in the array to the file on disk.

        For further information, see `memmap`.

        Parameters
        ----------
        None

        See Also
        --------
        memmap

        numpy.core.memmap
    Create a memory-map to an array stored in a *binary* file on disk.

    Memory-mapped files are used for accessing small segments of large files
    on disk, without reading the entire file into memory.  Numpy's
    memmap's are array-like objects.  This differs from Python's ``mmap``
    module, which uses file-like objects.

    This subclass of ndarray has some unpleasant interactions with
    some operations, because it doesn't quite fit properly as a subclass.
    An alternative to using this subclass is to create the ``mmap``
    object yourself, then create an ndarray with ndarray.__new__ directly,
    passing the object created in its 'buffer=' parameter.

    This class may at some point be turned into a factory function
    which returns a view into an mmap buffer.

    Parameters
    ----------
    filename : str or file-like object
        The file name or file object to be used as the array data buffer.
    dtype : data-type, optional
        The data-type used to interpret the file contents.
        Default is `uint8`.
    mode : {'r+', 'r', 'w+', 'c'}, optional
        The file is opened in this mode:

        +------+-------------------------------------------------------------+
        | 'r'  | Open existing file for reading only.                        |
        +------+-------------------------------------------------------------+
        | 'r+' | Open existing file for reading and writing.                 |
        +------+-------------------------------------------------------------+
        | 'w+' | Create or overwrite existing file for reading and writing.  |
        +------+-------------------------------------------------------------+
        | 'c'  | Copy-on-write: assignments affect data in memory, but       |
        |      | changes are not saved to disk.  The file on disk is         |
        |      | read-only.                                                  |
        +------+-------------------------------------------------------------+

        Default is 'r+'.
    offset : int, optional
        In the file, array data starts at this offset. Since `offset` is
        measured in bytes, it should normally be a multiple of the byte-size
        of `dtype`. When ``mode != 'r'``, even positive offsets beyond end of
        file are valid; The file will be extended to accommodate the
        additional data. The default offset is 0.
    shape : tuple, optional
        The desired shape of the array. If ``mode == 'r'`` and the number
        of remaining bytes after `offset` is not a multiple of the byte-size
        of `dtype`, you must specify `shape`. By default, the returned array
        will be 1-D with the number of elements determined by file size
        and data-type.
    order : {'C', 'F'}, optional
        Specify the order of the ndarray memory layout: C (row-major) or
        Fortran (column-major).  This only has an effect if the shape is
        greater than 1-D.  The default order is 'C'.

    Attributes
    ----------
    filename : str
        Path to the mapped file.
    offset : int
        Offset position in the file.
    mode : str
        File mode.

    Methods
    -------
    close
        Close the memmap file.
    flush
        Flush any changes in memory to file on disk.
        When you delete a memmap object, flush is called first to write
        changes to disk before removing the object.


    Notes
    -----
    The memmap object can be used anywhere an ndarray is accepted.
    Given a memmap ``fp``, ``isinstance(fp, numpy.ndarray)`` returns
    ``True``.

    Memory-mapped arrays use the Python memory-map object which
    (prior to Python 2.5) does not allow files to be larger than a
    certain size depending on the platform. This size is always < 2GB
    even on 64-bit systems.

    Examples
    --------
    >>> data = np.arange(12, dtype='float32')
    >>> data.resize((3,4))

    This example uses a temporary file so that doctest doesn't write
    files to your directory. You would use a 'normal' filename.

    >>> from tempfile import mkdtemp
    >>> import os.path as path
    >>> filename = path.join(mkdtemp(), 'newfile.dat')

    Create a memmap with dtype and shape that matches our data:

    >>> fp = np.memmap(filename, dtype='float32', mode='w+', shape=(3,4))
    >>> fp
    memmap([[ 0.,  0.,  0.,  0.],
            [ 0.,  0.,  0.,  0.],
            [ 0.,  0.,  0.,  0.]], dtype=float32)

    Write data to memmap array:

    >>> fp[:] = data[:]
    >>> fp
    memmap([[  0.,   1.,   2.,   3.],
            [  4.,   5.,   6.,   7.],
            [  8.,   9.,  10.,  11.]], dtype=float32)

    >>> fp.filename == path.abspath(filename)
    True

    Deletion flushes memory changes to disk before removing the object:

    >>> del fp

    Load the memmap and verify data was stored:

    >>> newfp = np.memmap(filename, dtype='float32', mode='r', shape=(3,4))
    >>> newfp
    memmap([[  0.,   1.,   2.,   3.],
            [  4.,   5.,   6.,   7.],
            [  8.,   9.,  10.,  11.]], dtype=float32)

    Read-only memmap:

    >>> fpr = np.memmap(filename, dtype='float32', mode='r', shape=(3,4))
    >>> fpr.flags.writeable
    False

    Copy-on-write memmap:

    >>> fpc = np.memmap(filename, dtype='float32', mode='c', shape=(3,4))
    >>> fpc.flags.writeable
    True

    It's possible to assign to copy-on-write array, but values are only
    written into the memory copy of the array, and not written to disk:

    >>> fpc
    memmap([[  0.,   1.,   2.,   3.],
            [  4.,   5.,   6.,   7.],
            [  8.,   9.,  10.,  11.]], dtype=float32)
    >>> fpc[0,:] = 0
    >>> fpc
    memmap([[  0.,   0.,   0.,   0.],
            [  4.,   5.,   6.,   7.],
            [  8.,   9.,  10.,  11.]], dtype=float32)

    File on disk is unchanged:

    >>> fpr
    memmap([[  0.,   1.,   2.,   3.],
            [  4.,   5.,   6.,   7.],
            [  8.,   9.,  10.,  11.]], dtype=float32)

    Offset into a memmap:

    >>> fpo = np.memmap(filename, dtype='float32', mode='r', offset=16)
    >>> fpo
    memmap([  4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.], dtype=float32)

    (   t   subtypet   filenamet   dtypet   modet   offsett   shapet   ordert   mmaps   ost   fidt   own_filet   flent   descrt   _dbytest   bytest   sizet   kt   acct   startt   mmt   selfTrue_    cAFalse_newdimindexesiscloseoldcallInfinity_dotblasargwhereoldstatefull_likemaskvaluecorrelate2ENSUREARRAYint_asbuffernested_itersALLOW_THREADSlittle_endianasfortranarray_move_axis_to_0ascontiguousarray{t   1s   0001t   0s   0000t   3s   0011t   2s   0010t   5s   0101t   4s   0100t   7s   0111t   6s   0110t   9s   1001t   8s   1000t   As   1010t   Cs   1100t   Bs   1011t   Es   1110t   Ds   1101t   Fs   1111t   Lt    t   as   1010t   cs   1100t   bs   1011t   es   1110t   ds   1101t   fs   11110[d   s   newaxiss   ndarrays   flatiters   nditers   nested_iterss   ufuncs   aranges   arrays   zeross   count_nonzeros   emptys	   broadcasts   dtypes
   fromstrings   fromfiles
   frombuffers   int_asbuffers   wheres   argwheres   copytos   concatenates   fastCopyAndTransposes   lexsorts   set_numeric_opss   can_casts   promote_typess   min_scalar_types   result_types   asarrays
   asanyarrays   ascontiguousarrays   asfortranarrays	   isfortrans
   empty_likes
   zeros_likes	   ones_likes	   correlates   convolves   inners   dots   einsums   outers   vdots   alterdots
   restoredots   rolls   rollaxiss   crosss	   tensordots   array2strings   get_printoptionss   set_printoptionss
   array_reprs	   array_strs   set_string_functions   little_endians   requires   fromiters   array_equals   array_equivs   indicess   fromfunctions   iscloses   loads   loadss   isscalars   binary_reprs	   base_reprs   oness   identitys   allcloses   compare_chararrayss   putmasks   seterrs   geterrs
   setbufsizes
   getbufsizes
   seterrcalls
   geterrcalls   errstates   flatnonzeros   Infs   infs   inftys   Infinitys   nans   NaNs   False_s   True_s   bitwise_nots   CLIPs   RAISEs   WRAPs   MAXDIMSs   BUFSIZEs   ALLOW_THREADSs   ComplexWarnings   may_share_memorys   fulls	   full_likeincompatible dimensions for cross product
(dimension must be 2 or 3)
    Returns True if the type of `num` is a scalar type.

    Parameters
    ----------
    num : any
        Input argument, can be of any type and shape.

    Returns
    -------
    val : bool
        True if `num` is a scalar type, False if it is not.

    Examples
    --------
    >>> np.isscalar(3.1)
    True
    >>> np.isscalar([3.1])
    False
    >>> np.isscalar(False)
    True

    
    Return the size of the buffer used in ufuncs.

    Returns
    -------
    getbufsize : int
        Size of ufunc buffer in bytes.

    
    Return an array representing the indices of a grid.

    Compute an array where the subarrays contain index values 0,1,...
    varying only along the corresponding axis.

    Parameters
    ----------
    dimensions : sequence of ints
        The shape of the grid.
    dtype : dtype, optional
        Data type of the result.

    Returns
    -------
    grid : ndarray
        The array of grid indices,
        ``grid.shape = (len(dimensions),) + tuple(dimensions)``.

    See Also
    --------
    mgrid, meshgrid

    Notes
    -----
    The output shape is obtained by prepending the number of dimensions
    in front of the tuple of dimensions, i.e. if `dimensions` is a tuple
    ``(r0, ..., rN-1)`` of length ``N``, the output shape is
    ``(N,r0,...,rN-1)``.

    The subarrays ``grid[k]`` contains the N-D array of indices along the
    ``k-th`` axis. Explicitly::

        grid[k,i0,i1,...,iN-1] = ik

    Examples
    --------
    >>> grid = np.indices((2, 3))
    >>> grid.shape
    (2, 2, 3)
    >>> grid[0]        # row indices
    array([[0, 0, 0],
           [1, 1, 1]])
    >>> grid[1]        # column indices
    array([[0, 1, 2],
           [0, 1, 2]])

    The indices can be used as an index into an array.

    >>> x = np.arange(20).reshape(5, 4)
    >>> row, col = np.indices((2, 3))
    >>> x[row, col]
    array([[0, 1, 2],
           [4, 5, 6]])

    Note that it would be more straightforward in the above example to
    extract the required elements directly with ``x[:2, :3]``.

    
    Return a contiguous array in memory (C order).

    Parameters
    ----------
    a : array_like
        Input array.
    dtype : str or dtype object, optional
        Data-type of returned array.

    Returns
    -------
    out : ndarray
        Contiguous array of same shape and content as `a`, with type `dtype`
        if specified.

    See Also
    --------
    asfortranarray : Convert input to an ndarray with column-major
                     memory order.
    require : Return an ndarray that satisfies requirements.
    ndarray.flags : Information about the memory layout of the array.

    Examples
    --------
    >>> x = np.arange(6).reshape(2,3)
    >>> np.ascontiguousarray(x, dtype=np.float32)
    array([[ 0.,  1.,  2.],
           [ 3.,  4.,  5.]], dtype=float32)
    >>> x.flags['C_CONTIGUOUS']
    True

    
    Get the current way of handling floating-point errors.

    Returns
    -------
    res : dict
        A dictionary with keys "divide", "over", "under", and "invalid",
        whose values are from the strings "ignore", "print", "log", "warn",
        "raise", and "call". The keys represent possible floating-point
        exceptions, and the values define how these exceptions are handled.

    See Also
    --------
    geterrcall, seterr, seterrcall

    Notes
    -----
    For complete documentation of the types of floating-point exceptions and
    treatment options, see `seterr`.

    Examples
    --------
    >>> np.geterr()
    {'over': 'warn', 'divide': 'warn', 'invalid': 'warn',
    'under': 'ignore'}
    >>> np.arange(3.) / np.arange(3.)
    array([ NaN,   1.,   1.])

    >>> oldsettings = np.seterr(all='warn', over='raise')
    >>> np.geterr()
    {'over': 'raise', 'divide': 'warn', 'invalid': 'warn', 'under': 'warn'}
    >>> np.arange(3.) / np.arange(3.)
    __main__:1: RuntimeWarning: invalid value encountered in divide
    array([ NaN,   1.,   1.])

    
    Return a new array of given shape and type, filled with ones.

    Parameters
    ----------
    shape : int or sequence of ints
        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
    dtype : data-type, optional
        The desired data-type for the array, e.g., `numpy.int8`.  Default is
        `numpy.float64`.
    order : {'C', 'F'}, optional
        Whether to store multidimensional data in C- or Fortran-contiguous
        (row- or column-wise) order in memory.

    Returns
    -------
    out : ndarray
        Array of ones with the given shape, dtype, and order.

    See Also
    --------
    zeros, ones_like

    Examples
    --------
    >>> np.ones(5)
    array([ 1.,  1.,  1.,  1.,  1.])

    >>> np.ones((5,), dtype=np.int)
    array([1, 1, 1, 1, 1])

    >>> np.ones((2, 1))
    array([[ 1.],
           [ 1.]])

    >>> s = (2,2)
    >>> np.ones(s)
    array([[ 1.,  1.],
           [ 1.,  1.]])

    Buffer size, %s, is too small.
    Set the size of the buffer used in ufuncs.

    Parameters
    ----------
    size : int
        Size of buffer.

    
    Set how floating-point errors are handled.

    Note that operations on integer scalar types (such as `int16`) are
    handled like floating point, and are affected by these settings.

    Parameters
    ----------
    all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
        Set treatment for all types of floating-point errors at once:

        - ignore: Take no action when the exception occurs.
        - warn: Print a `RuntimeWarning` (via the Python `warnings` module).
        - raise: Raise a `FloatingPointError`.
        - call: Call a function specified using the `seterrcall` function.
        - print: Print a warning directly to ``stdout``.
        - log: Record error in a Log object specified by `seterrcall`.

        The default is not to change the current behavior.
    divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
        Treatment for division by zero.
    over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
        Treatment for floating-point overflow.
    under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
        Treatment for floating-point underflow.
    invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
        Treatment for invalid floating-point operation.

    Returns
    -------
    old_settings : dict
        Dictionary containing the old settings.

    See also
    --------
    seterrcall : Set a callback function for the 'call' mode.
    geterr, geterrcall, errstate

    Notes
    -----
    The floating-point exceptions are defined in the IEEE 754 standard [1]:

    - Division by zero: infinite result obtained from finite numbers.
    - Overflow: result too large to be expressed.
    - Underflow: result so close to zero that some precision
      was lost.
    - Invalid operation: result is not an expressible number, typically
      indicates that a NaN was produced.

    .. [1] http://en.wikipedia.org/wiki/IEEE_754

    Examples
    --------
    >>> old_settings = np.seterr(all='ignore')  #seterr to known value
    >>> np.seterr(over='raise')
    {'over': 'ignore', 'divide': 'ignore', 'invalid': 'ignore',
     'under': 'ignore'}
    >>> np.seterr(**old_settings)  # reset to default
    {'over': 'raise', 'divide': 'ignore', 'invalid': 'ignore', 'under': 'ignore'}

    >>> np.int16(32000) * np.int16(3)
    30464
    >>> old_settings = np.seterr(all='warn', over='raise')
    >>> np.int16(32000) * np.int16(3)
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    FloatingPointError: overflow encountered in short_scalars

    >>> old_settings = np.seterr(all='print')
    >>> np.geterr()
    {'over': 'print', 'divide': 'print', 'invalid': 'print', 'under': 'print'}
    >>> np.int16(32000) * np.int16(3)
    Warning: overflow encountered in short_scalars
    30464

    
    Wrapper around cPickle.load which accepts either a file-like object or
    a filename.

    Note that the NumPy binary format is not based on pickle/cPickle anymore.
    For details on the preferred way of loading and saving files, see `load`
    and `save`.

    See Also
    --------
    load, save

    
    Return a new array of given shape and type, filled with `fill_value`.

    Parameters
    ----------
    shape : int or sequence of ints
        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
    fill_value : scalar
        Fill value.
    dtype : data-type, optional
        The desired data-type for the array, e.g., `numpy.int8`.  Default is
        is chosen as `np.array(fill_value).dtype`.
    order : {'C', 'F'}, optional
        Whether to store multidimensional data in C- or Fortran-contiguous
        (row- or column-wise) order in memory.

    Returns
    -------
    out : ndarray
        Array of `fill_value` with the given shape, dtype, and order.

    See Also
    --------
    zeros_like : Return an array of zeros with shape and type of input.
    ones_like : Return an array of ones with shape and type of input.
    empty_like : Return an empty array with shape and type of input.
    full_like : Fill an array with shape and type of input.
    zeros : Return a new array setting values to zero.
    ones : Return a new array setting values to one.
    empty : Return a new uninitialized array.

    Examples
    --------
    >>> np.full((2, 2), np.inf)
    array([[ inf,  inf],
           [ inf,  inf]])
    >>> np.full((2, 2), 10, dtype=np.int)
    array([[10, 10],
           [10, 10]])

    
    Return a string representation of the data in an array.

    The data in the array is returned as a single string.  This function is
    similar to `array_repr`, the difference being that `array_repr` also
    returns information on the kind of array and its data type.

    Parameters
    ----------
    a : ndarray
        Input array.
    max_line_width : int, optional
        Inserts newlines if text is longer than `max_line_width`.  The
        default is, indirectly, 75.
    precision : int, optional
        Floating point precision.  Default is the current printing precision
        (usually 8), which can be altered using `set_printoptions`.
    suppress_small : bool, optional
        Represent numbers "very close" to zero as zero; default is False.
        Very close is defined by precision: if the precision is 8, e.g.,
        numbers smaller (in absolute value) than 5e-9 are represented as
        zero.

    See Also
    --------
    array2string, array_repr, set_printoptions

    Examples
    --------
    >>> np.array_str(np.arange(3))
    '[0 1 2]'

    
    Returns the discrete, linear convolution of two one-dimensional sequences.

    The convolution operator is often seen in signal processing, where it
    models the effect of a linear time-invariant system on a signal [1]_.  In
    probability theory, the sum of two independent random variables is
    distributed according to the convolution of their individual
    distributions.

    Parameters
    ----------
    a : (N,) array_like
        First one-dimensional input array.
    v : (M,) array_like
        Second one-dimensional input array.
    mode : {'full', 'valid', 'same'}, optional
        'full':
          By default, mode is 'full'.  This returns the convolution
          at each point of overlap, with an output shape of (N+M-1,). At
          the end-points of the convolution, the signals do not overlap
          completely, and boundary effects may be seen.

        'same':
          Mode `same` returns output of length ``max(M, N)``.  Boundary
          effects are still visible.

        'valid':
          Mode `valid` returns output of length
          ``max(M, N) - min(M, N) + 1``.  The convolution product is only given
          for points where the signals overlap completely.  Values outside
          the signal boundary have no effect.

    Returns
    -------
    out : ndarray
        Discrete, linear convolution of `a` and `v`.

    See Also
    --------
    scipy.signal.fftconvolve : Convolve two arrays using the Fast Fourier
                               Transform.
    scipy.linalg.toeplitz : Used to construct the convolution operator.

    Notes
    -----
    The discrete convolution operation is defined as

    .. math:: (f * g)[n] = \sum_{m = -\infty}^{\infty} f[m] g[n - m]

    It can be shown that a convolution :math:`x(t) * y(t)` in time/space
    is equivalent to the multiplication :math:`X(f) Y(f)` in the Fourier
    domain, after appropriate padding (padding is necessary to prevent
    circular convolution).  Since multiplication is more efficient (faster)
    than convolution, the function `scipy.signal.fftconvolve` exploits the
    FFT to calculate the convolution of large data-sets.

    References
    ----------
    .. [1] Wikipedia, "Convolution", http://en.wikipedia.org/wiki/Convolution.

    Examples
    --------
    Note how the convolution operator flips the second array
    before "sliding" the two across one another:

    >>> np.convolve([1, 2, 3], [0, 1, 0.5])
    array([ 0. ,  1. ,  2.5,  4. ,  1.5])

    Only return the middle values of the convolution.
    Contains boundary effects, where zeros are taken
    into account:

    >>> np.convolve([1,2,3],[0,1,0.5], 'same')
    array([ 1. ,  2.5,  4. ])

    The two arrays are of the same length, so there
    is only one position where they completely overlap:

    >>> np.convolve([1,2,3],[0,1,0.5], 'valid')
    array([ 2.5])

    
    Return the binary representation of the input number as a string.

    For negative numbers, if width is not given, a minus sign is added to the
    front. If width is given, the two's complement of the number is
    returned, with respect to that width.

    In a two's-complement system negative numbers are represented by the two's
    complement of the absolute value. This is the most common method of
    representing signed integers on computers [1]_. A N-bit two's-complement
    system can represent every integer in the range
    :math:`-2^{N-1}` to :math:`+2^{N-1}-1`.

    Parameters
    ----------
    num : int
        Only an integer decimal number can be used.
    width : int, optional
        The length of the returned string if `num` is positive, the length of
        the two's complement if `num` is negative.

    Returns
    -------
    bin : str
        Binary representation of `num` or two's complement of `num`.

    See Also
    --------
    base_repr: Return a string representation of a number in the given base
               system.

    Notes
    -----
    `binary_repr` is equivalent to using `base_repr` with base 2, but about 25x
    faster.

    References
    ----------
    .. [1] Wikipedia, "Two's complement",
        http://en.wikipedia.org/wiki/Two's_complement

    Examples
    --------
    >>> np.binary_repr(3)
    '11'
    >>> np.binary_repr(-3)
    '-11'
    >>> np.binary_repr(3, width=4)
    '0011'

    The two's complement is returned when the input number is negative and
    width is specified:

    >>> np.binary_repr(-3, width=4)
    '1101'

    
    Return an array of ones with the same shape and type as a given array.

    Parameters
    ----------
    a : array_like
        The shape and data-type of `a` define these same attributes of
        the returned array.
    dtype : data-type, optional
        .. versionadded:: 1.6.0
        Overrides the data type of the result.
    order : {'C', 'F', 'A', or 'K'}, optional
        .. versionadded:: 1.6.0
        Overrides the memory layout of the result. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of `a` as closely
        as possible.
    subok : bool, optional.
        If True, then the newly created array will use the sub-class
        type of 'a', otherwise it will be a base-class array. Defaults
        to True.

    Returns
    -------
    out : ndarray
        Array of ones with the same shape and type as `a`.

    See Also
    --------
    zeros_like : Return an array of zeros with shape and type of input.
    empty_like : Return an empty array with shape and type of input.
    zeros : Return a new array setting values to zero.
    ones : Return a new array setting values to one.
    empty : Return a new uninitialized array.

    Examples
    --------
    >>> x = np.arange(6)
    >>> x = x.reshape((2, 3))
    >>> x
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.ones_like(x)
    array([[1, 1, 1],
           [1, 1, 1]])

    >>> y = np.arange(3, dtype=np.float)
    >>> y
    array([ 0.,  1.,  2.])
    >>> np.ones_like(y)
    array([ 1.,  1.,  1.])

    a cannot be empty
    Return the cross product of two (arrays of) vectors.

    The cross product of `a` and `b` in :math:`R^3` is a vector perpendicular
    to both `a` and `b`.  If `a` and `b` are arrays of vectors, the vectors
    are defined by the last axis of `a` and `b` by default, and these axes
    can have dimensions 2 or 3.  Where the dimension of either `a` or `b` is
    2, the third component of the input vector is assumed to be zero and the
    cross product calculated accordingly.  In cases where both input vectors
    have dimension 2, the z-component of the cross product is returned.

    Parameters
    ----------
    a : array_like
        Components of the first vector(s).
    b : array_like
        Components of the second vector(s).
    axisa : int, optional
        Axis of `a` that defines the vector(s).  By default, the last axis.
    axisb : int, optional
        Axis of `b` that defines the vector(s).  By default, the last axis.
    axisc : int, optional
        Axis of `c` containing the cross product vector(s).  By default, the
        last axis.
    axis : int, optional
        If defined, the axis of `a`, `b` and `c` that defines the vector(s)
        and cross product(s).  Overrides `axisa`, `axisb` and `axisc`.

    Returns
    -------
    c : ndarray
        Vector cross product(s).

    Raises
    ------
    ValueError
        When the dimension of the vector(s) in `a` and/or `b` does not
        equal 2 or 3.

    See Also
    --------
    inner : Inner product
    outer : Outer product.
    ix_ : Construct index arrays.

    Examples
    --------
    Vector cross-product.

    >>> x = [1, 2, 3]
    >>> y = [4, 5, 6]
    >>> np.cross(x, y)
    array([-3,  6, -3])

    One vector with dimension 2.

    >>> x = [1, 2]
    >>> y = [4, 5, 6]
    >>> np.cross(x, y)
    array([12, -6, -3])

    Equivalently:

    >>> x = [1, 2, 0]
    >>> y = [4, 5, 6]
    >>> np.cross(x, y)
    array([12, -6, -3])

    Both vectors with dimension 2.

    >>> x = [1,2]
    >>> y = [4,5]
    >>> np.cross(x, y)
    -3

    Multiple vector cross-products. Note that the direction of the cross
    product vector is defined by the `right-hand rule`.

    >>> x = np.array([[1,2,3], [4,5,6]])
    >>> y = np.array([[4,5,6], [1,2,3]])
    >>> np.cross(x, y)
    array([[-3,  6, -3],
           [ 3, -6,  3]])

    The orientation of `c` can be changed using the `axisc` keyword.

    >>> np.cross(x, y, axisc=0)
    array([[-3,  3],
           [ 6, -6],
           [-3,  3]])

    Change the vector definition of `x` and `y` using `axisa` and `axisb`.

    >>> x = np.array([[1,2,3], [4,5,6], [7, 8, 9]])
    >>> y = np.array([[7, 8, 9], [4,5,6], [1,2,3]])
    >>> np.cross(x, y)
    array([[ -6,  12,  -6],
           [  0,   0,   0],
           [  6, -12,   6]])
    >>> np.cross(x, y, axisa=0, axisb=0)
    array([[-24,  48, -24],
           [-30,  60, -30],
           [-36,  72, -36]])

    
    Return the string representation of an array.

    Parameters
    ----------
    arr : ndarray
        Input array.
    max_line_width : int, optional
        The maximum number of columns the string should span. Newline
        characters split the string appropriately after array elements.
    precision : int, optional
        Floating point precision. Default is the current printing precision
        (usually 8), which can be altered using `set_printoptions`.
    suppress_small : bool, optional
        Represent very small numbers as zero, default is False. Very small
        is defined by `precision`, if the precision is 8 then
        numbers smaller than 5e-9 are represented as zero.

    Returns
    -------
    string : str
      The string representation of an array.

    See Also
    --------
    array_str, array2string, set_printoptions

    Examples
    --------
    >>> np.array_repr(np.array([1,2]))
    'array([1, 2])'
    >>> np.array_repr(np.ma.array([0.]))
    'MaskedArray([ 0.])'
    >>> np.array_repr(np.array([], np.int32))
    'array([], dtype=int32)'

    >>> x = np.array([1e-6, 4e-7, 2, 3])
    >>> np.array_repr(x, precision=6, suppress_small=True)
    'array([ 0.000001,  0.      ,  2.      ,  3.      ])'

    
    Return an array of zeros with the same shape and type as a given array.

    Parameters
    ----------
    a : array_like
        The shape and data-type of `a` define these same attributes of
        the returned array.
    dtype : data-type, optional
        .. versionadded:: 1.6.0
        Overrides the data type of the result.
    order : {'C', 'F', 'A', or 'K'}, optional
        .. versionadded:: 1.6.0
        Overrides the memory layout of the result. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of `a` as closely
        as possible.
    subok : bool, optional.
        If True, then the newly created array will use the sub-class
        type of 'a', otherwise it will be a base-class array. Defaults
        to True.

    Returns
    -------
    out : ndarray
        Array of zeros with the same shape and type as `a`.

    See Also
    --------
    ones_like : Return an array of ones with shape and type of input.
    empty_like : Return an empty array with shape and type of input.
    zeros : Return a new array setting values to zero.
    ones : Return a new array setting values to one.
    empty : Return a new uninitialized array.

    Examples
    --------
    >>> x = np.arange(6)
    >>> x = x.reshape((2, 3))
    >>> x
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.zeros_like(x)
    array([[0, 0, 0],
           [0, 0, 0]])

    >>> y = np.arange(3, dtype=np.float)
    >>> y
    array([ 0.,  1.,  2.])
    >>> np.zeros_like(y)
    array([ 0.,  0.,  0.])

    Bases greater than 36 not handled in base_repr.
The old behavior of correlate was deprecated for 1.4.0, and will be completely removed
for NumPy 2.0.

The new behavior fits the conventional definition of correlation: inputs are
never swapped, and the second argument is conjugated for complex arrays.
    Construct an array by executing a function over each coordinate.

    The resulting array therefore has a value ``fn(x, y, z)`` at
    coordinate ``(x, y, z)``.

    Parameters
    ----------
    function : callable
        The function is called with N parameters, where N is the rank of
        `shape`.  Each parameter represents the coordinates of the array
        varying along a specific axis.  For example, if `shape`
        were ``(2, 2)``, then the parameters in turn be (0, 0), (0, 1),
        (1, 0), (1, 1).
    shape : (N,) tuple of ints
        Shape of the output array, which also determines the shape of
        the coordinate arrays passed to `function`.
    dtype : data-type, optional
        Data-type of the coordinate arrays passed to `function`.
        By default, `dtype` is float.

    Returns
    -------
    fromfunction : any
        The result of the call to `function` is passed back directly.
        Therefore the shape of `fromfunction` is completely determined by
        `function`.  If `function` returns a scalar value, the shape of
        `fromfunction` would match the `shape` parameter.

    See Also
    --------
    indices, meshgrid

    Notes
    -----
    Keywords other than `dtype` are passed to `function`.

    Examples
    --------
    >>> np.fromfunction(lambda i, j: i == j, (3, 3), dtype=int)
    array([[ True, False, False],
           [False,  True, False],
           [False, False,  True]], dtype=bool)

    >>> np.fromfunction(lambda i, j: i + j, (3, 3), dtype=int)
    array([[0, 1, 2],
           [1, 2, 3],
           [2, 3, 4]])

    
    Convert the input to an ndarray, but pass ndarray subclasses through.

    Parameters
    ----------
    a : array_like
        Input data, in any form that can be converted to an array.  This
        includes scalars, lists, lists of tuples, tuples, tuples of tuples,
        tuples of lists, and ndarrays.
    dtype : data-type, optional
        By default, the data-type is inferred from the input data.
    order : {'C', 'F'}, optional
        Whether to use row-major ('C') or column-major ('F') memory
        representation.  Defaults to 'C'.

    Returns
    -------
    out : ndarray or an ndarray subclass
        Array interpretation of `a`.  If `a` is an ndarray or a subclass
        of ndarray, it is returned as-is and no copy is performed.

    See Also
    --------
    asarray : Similar function which always returns ndarrays.
    ascontiguousarray : Convert input to a contiguous array.
    asfarray : Convert input to a floating point ndarray.
    asfortranarray : Convert input to an ndarray with column-major
                     memory order.
    asarray_chkfinite : Similar function which checks input for NaNs and
                        Infs.
    fromiter : Create an array from an iterator.
    fromfunction : Construct an array by executing a function on grid
                   positions.

    Examples
    --------
    Convert a list into an array:

    >>> a = [1, 2]
    >>> np.asanyarray(a)
    array([1, 2])

    Instances of `ndarray` subclasses are passed through as-is:

    >>> a = np.matrix([1, 2])
    >>> np.asanyarray(a) is a
    True

    
    Convert the input to an array.

    Parameters
    ----------
    a : array_like
        Input data, in any form that can be converted to an array.  This
        includes lists, lists of tuples, tuples, tuples of tuples, tuples
        of lists and ndarrays.
    dtype : data-type, optional
        By default, the data-type is inferred from the input data.
    order : {'C', 'F'}, optional
        Whether to use row-major ('C') or column-major ('F' for FORTRAN)
        memory representation.  Defaults to 'C'.

    Returns
    -------
    out : ndarray
        Array interpretation of `a`.  No copy is performed if the input
        is already an ndarray.  If `a` is a subclass of ndarray, a base
        class ndarray is returned.

    See Also
    --------
    asanyarray : Similar function which passes through subclasses.
    ascontiguousarray : Convert input to a contiguous array.
    asfarray : Convert input to a floating point ndarray.
    asfortranarray : Convert input to an ndarray with column-major
                     memory order.
    asarray_chkfinite : Similar function which checks input for NaNs and Infs.
    fromiter : Create an array from an iterator.
    fromfunction : Construct an array by executing a function on grid
                   positions.

    Examples
    --------
    Convert a list into an array:

    >>> a = [1, 2]
    >>> np.asarray(a)
    array([1, 2])

    Existing arrays are not copied:

    >>> a = np.array([1, 2])
    >>> np.asarray(a) is a
    True

    If `dtype` is set, array is copied only if dtype does not match:

    >>> a = np.array([1, 2], dtype=np.float32)
    >>> np.asarray(a, dtype=np.float32) is a
    True
    >>> np.asarray(a, dtype=np.float64) is a
    False

    Contrary to `asanyarray`, ndarray subclasses are not passed through:

    >>> issubclass(np.matrix, np.ndarray)
    True
    >>> a = np.matrix([[1, 2]])
    >>> np.asarray(a) is a
    False
    >>> np.asanyarray(a) is a
    True

    
    True if two arrays have the same shape and elements, False otherwise.

    Parameters
    ----------
    a1, a2 : array_like
        Input arrays.

    Returns
    -------
    b : bool
        Returns True if the arrays are equal.

    See Also
    --------
    allclose: Returns True if two arrays are element-wise equal within a
              tolerance.
    array_equiv: Returns True if input arrays are shape consistent and all
                 elements equal.

    Examples
    --------
    >>> np.array_equal([1, 2], [1, 2])
    True
    >>> np.array_equal(np.array([1, 2]), np.array([1, 2]))
    True
    >>> np.array_equal([1, 2], [1, 2, 3])
    False
    >>> np.array_equal([1, 2], [1, 4])
    False

    
    Return an ndarray of the provided type that satisfies requirements.

    This function is useful to be sure that an array with the correct flags
    is returned for passing to compiled code (perhaps through ctypes).

    Parameters
    ----------
    a : array_like
       The object to be converted to a type-and-requirement-satisfying array.
    dtype : data-type
       The required data-type, the default data-type is float64).
    requirements : str or list of str
       The requirements list can be any of the following

       * 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array
       * 'C_CONTIGUOUS' ('C') - ensure a C-contiguous array
       * 'ALIGNED' ('A')      - ensure a data-type aligned array
       * 'WRITEABLE' ('W')    - ensure a writable array
       * 'OWNDATA' ('O')      - ensure an array that owns its own data

    See Also
    --------
    asarray : Convert input to an ndarray.
    asanyarray : Convert to an ndarray, but pass through ndarray subclasses.
    ascontiguousarray : Convert input to a contiguous array.
    asfortranarray : Convert input to an ndarray with column-major
                     memory order.
    ndarray.flags : Information about the memory layout of the array.

    Notes
    -----
    The returned array will be guaranteed to have the listed requirements
    by making a copy if needed.

    Examples
    --------
    >>> x = np.arange(6).reshape(2,3)
    >>> x.flags
      C_CONTIGUOUS : True
      F_CONTIGUOUS : False
      OWNDATA : False
      WRITEABLE : True
      ALIGNED : True
      UPDATEIFCOPY : False

    >>> y = np.require(x, dtype=np.float32, requirements=['A', 'O', 'W', 'F'])
    >>> y.flags
      C_CONTIGUOUS : False
      F_CONTIGUOUS : True
      OWNDATA : True
      WRITEABLE : True
      ALIGNED : True
      UPDATEIFCOPY : False

    axis must be >= 0 and < %d
    Returns True if two arrays are element-wise equal within a tolerance.

    The tolerance values are positive, typically very small numbers.  The
    relative difference (`rtol` * abs(`b`)) and the absolute difference
    `atol` are added together to compare against the absolute difference
    between `a` and `b`.

    If either array contains one or more NaNs, False is returned.
    Infs are treated as equal if they are in the same place and of the same
    sign in both arrays.

    Parameters
    ----------
    a, b : array_like
        Input arrays to compare.
    rtol : float
        The relative tolerance parameter (see Notes).
    atol : float
        The absolute tolerance parameter (see Notes).

    Returns
    -------
    allclose : bool
        Returns True if the two arrays are equal within the given
        tolerance; False otherwise.

    See Also
    --------
    isclose, all, any

    Notes
    -----
    If the following equation is element-wise True, then allclose returns
    True.

     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))

    The above equation is not symmetric in `a` and `b`, so that
    `allclose(a, b)` might be different from `allclose(b, a)` in
    some rare cases.

    Examples
    --------
    >>> np.allclose([1e10,1e-7], [1.00001e10,1e-8])
    False
    >>> np.allclose([1e10,1e-8], [1.00001e10,1e-9])
    True
    >>> np.allclose([1e10,1e-8], [1.0001e10,1e-9])
    False
    >>> np.allclose([1.0, np.nan], [1.0, np.nan])
    False

    
    Return the current callback function used on floating-point errors.

    When the error handling for a floating-point error (one of "divide",
    "over", "under", or "invalid") is set to 'call' or 'log', the function
    that is called or the log instance that is written to is returned by
    `geterrcall`. This function or log instance has been set with
    `seterrcall`.

    Returns
    -------
    errobj : callable, log instance or None
        The current error handler. If no handler was set through `seterrcall`,
        ``None`` is returned.

    See Also
    --------
    seterrcall, seterr, geterr

    Notes
    -----
    For complete documentation of the types of floating-point exceptions and
    treatment options, see `seterr`.

    Examples
    --------
    >>> np.geterrcall()  # we did not yet set a handler, returns None

    >>> oldsettings = np.seterr(all='call')
    >>> def err_handler(type, flag):
    ...     print "Floating point error (%s), with flag %s" % (type, flag)
    >>> oldhandler = np.seterrcall(err_handler)
    >>> np.array([1, 2, 3]) / 0.0
    Floating point error (divide by zero), with flag 1
    array([ Inf,  Inf,  Inf])

    >>> cur_handler = np.geterrcall()
    >>> cur_handler is err_handler
    True

    /usr/lib/python2.7/dist-packages/numpy/core/numeric.py
    Return an array laid out in Fortran order in memory.

    Parameters
    ----------
    a : array_like
        Input array.
    dtype : str or dtype object, optional
        By default, the data-type is inferred from the input data.

    Returns
    -------
    out : ndarray
        The input `a` in Fortran, or column-major, order.

    See Also
    --------
    ascontiguousarray : Convert input to a contiguous (C order) array.
    asanyarray : Convert input to an ndarray with either row or
        column-major memory order.
    require : Return an ndarray that satisfies requirements.
    ndarray.flags : Information about the memory layout of the array.

    Examples
    --------
    >>> x = np.arange(6).reshape(2,3)
    >>> y = np.asfortranarray(x)
    >>> x.flags['F_CONTIGUOUS']
    False
    >>> y.flags['F_CONTIGUOUS']
    True

    
    Return a string representation of a number in the given base system.

    Parameters
    ----------
    number : int
        The value to convert. Only positive values are handled.
    base : int, optional
        Convert `number` to the `base` number system. The valid range is 2-36,
        the default value is 2.
    padding : int, optional
        Number of zeros padded on the left. Default is 0 (no padding).

    Returns
    -------
    out : str
        String representation of `number` in `base` system.

    See Also
    --------
    binary_repr : Faster version of `base_repr` for base 2.

    Examples
    --------
    >>> np.base_repr(5)
    '101'
    >>> np.base_repr(6, 5)
    '11'
    >>> np.base_repr(7, base=5, padding=3)
    '00012'

    >>> np.base_repr(10, base=16)
    'A'
    >>> np.base_repr(32, base=16)
    '20'

    Only callable can be used as callback
    Compute the outer product of two vectors.

    Given two vectors, ``a = [a0, a1, ..., aM]`` and
    ``b = [b0, b1, ..., bN]``,
    the outer product [1]_ is::

      [[a0*b0  a0*b1 ... a0*bN ]
       [a1*b0    .
       [ ...          .
       [aM*b0            aM*bN ]]

    Parameters
    ----------
    a : (M,) array_like
        First input vector.  Input is flattened if
        not already 1-dimensional.
    b : (N,) array_like
        Second input vector.  Input is flattened if
        not already 1-dimensional.

    Returns
    -------
    out : (M, N) ndarray
        ``out[i, j] = a[i] * b[j]``

    See also
    --------
    inner, einsum

    References
    ----------
    .. [1] : G. H. Golub and C. F. van Loan, *Matrix Computations*, 3rd
             ed., Baltimore, MD, Johns Hopkins University Press, 1996,
             pg. 8.

    Examples
    --------
    Make a (*very* coarse) grid for computing a Mandelbrot set:

    >>> rl = np.outer(np.ones((5,)), np.linspace(-2, 2, 5))
    >>> rl
    array([[-2., -1.,  0.,  1.,  2.],
           [-2., -1.,  0.,  1.,  2.],
           [-2., -1.,  0.,  1.,  2.],
           [-2., -1.,  0.,  1.,  2.],
           [-2., -1.,  0.,  1.,  2.]])
    >>> im = np.outer(1j*np.linspace(2, -2, 5), np.ones((5,)))
    >>> im
    array([[ 0.+2.j,  0.+2.j,  0.+2.j,  0.+2.j,  0.+2.j],
           [ 0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j,  0.+1.j],
           [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
           [ 0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j,  0.-1.j],
           [ 0.-2.j,  0.-2.j,  0.-2.j,  0.-2.j,  0.-2.j]])
    >>> grid = rl + im
    >>> grid
    array([[-2.+2.j, -1.+2.j,  0.+2.j,  1.+2.j,  2.+2.j],
           [-2.+1.j, -1.+1.j,  0.+1.j,  1.+1.j,  2.+1.j],
           [-2.+0.j, -1.+0.j,  0.+0.j,  1.+0.j,  2.+0.j],
           [-2.-1.j, -1.-1.j,  0.-1.j,  1.-1.j,  2.-1.j],
           [-2.-2.j, -1.-2.j,  0.-2.j,  1.-2.j,  2.-2.j]])

    An example using a "vector" of letters:

    >>> x = np.array(['a', 'b', 'c'], dtype=object)
    >>> np.outer(x, [1, 2, 3])
    array([[a, aa, aaa],
           [b, bb, bbb],
           [c, cc, ccc]], dtype=object)

    
    Compute tensor dot product along specified axes for arrays >= 1-D.

    Given two tensors (arrays of dimension greater than or equal to one),
    `a` and `b`, and an array_like object containing two array_like
    objects, ``(a_axes, b_axes)``, sum the products of `a`'s and `b`'s
    elements (components) over the axes specified by ``a_axes`` and
    ``b_axes``. The third argument can be a single non-negative
    integer_like scalar, ``N``; if it is such, then the last ``N``
    dimensions of `a` and the first ``N`` dimensions of `b` are summed
    over.

    Parameters
    ----------
    a, b : array_like, len(shape) >= 1
        Tensors to "dot".
    axes : variable type
        * integer_like scalar
          Number of axes to sum over (applies to both arrays); or
        * (2,) array_like, both elements array_like of the same length
          List of axes to be summed over, first sequence applying to `a`,
          second to `b`.

    See Also
    --------
    dot, einsum

    Notes
    -----
    When there is more than one axis to sum over - and they are not the last
    (first) axes of `a` (`b`) - the argument `axes` should consist of
    two sequences of the same length, with the first axis to sum over given
    first in both sequences, the second axis second, and so forth.

    Examples
    --------
    A "traditional" example:

    >>> a = np.arange(60.).reshape(3,4,5)
    >>> b = np.arange(24.).reshape(4,3,2)
    >>> c = np.tensordot(a,b, axes=([1,0],[0,1]))
    >>> c.shape
    (5, 2)
    >>> c
    array([[ 4400.,  4730.],
           [ 4532.,  4874.],
           [ 4664.,  5018.],
           [ 4796.,  5162.],
           [ 4928.,  5306.]])
    >>> # A slower but equivalent way of computing the same...
    >>> d = np.zeros((5,2))
    >>> for i in range(5):
    ...   for j in range(2):
    ...     for k in range(3):
    ...       for n in range(4):
    ...         d[i,j] += a[k,n,i] * b[n,k,j]
    >>> c == d
    array([[ True,  True],
           [ True,  True],
           [ True,  True],
           [ True,  True],
           [ True,  True]], dtype=bool)

    An extended example taking advantage of the overloading of + and \*:

    >>> a = np.array(range(1, 9))
    >>> a.shape = (2, 2, 2)
    >>> A = np.array(('a', 'b', 'c', 'd'), dtype=object)
    >>> A.shape = (2, 2)
    >>> a; A
    array([[[1, 2],
            [3, 4]],
           [[5, 6],
            [7, 8]]])
    array([[a, b],
           [c, d]], dtype=object)

    >>> np.tensordot(a, A) # third argument default is 2
    array([abbcccdddd, aaaaabbbbbbcccccccdddddddd], dtype=object)

    >>> np.tensordot(a, A, 1)
    array([[[acc, bdd],
            [aaacccc, bbbdddd]],
           [[aaaaacccccc, bbbbbdddddd],
            [aaaaaaacccccccc, bbbbbbbdddddddd]]], dtype=object)

    >>> np.tensordot(a, A, 0) # "Left for reader" (result too long to incl.)
    array([[[[[a, b],
              [c, d]],
              ...

    >>> np.tensordot(a, A, (0, 1))
    array([[[abbbbb, cddddd],
            [aabbbbbb, ccdddddd]],
           [[aaabbbbbbb, cccddddddd],
            [aaaabbbbbbbb, ccccdddddddd]]], dtype=object)

    >>> np.tensordot(a, A, (2, 1))
    array([[[abb, cdd],
            [aaabbbb, cccdddd]],
           [[aaaaabbbbbb, cccccdddddd],
            [aaaaaaabbbbbbbb, cccccccdddddddd]]], dtype=object)

    >>> np.tensordot(a, A, ((0, 1), (0, 1)))
    array([abbbcccccddddddd, aabbbbccccccdddddddd], dtype=object)

    >>> np.tensordot(a, A, ((2, 1), (1, 0)))
    array([acccbbdddd, aaaaacccccccbbbbbbdddddddd], dtype=object)

    
    Returns a boolean array where two arrays are element-wise equal within a
    tolerance.

    The tolerance values are positive, typically very small numbers.  The
    relative difference (`rtol` * abs(`b`)) and the absolute difference
    `atol` are added together to compare against the absolute difference
    between `a` and `b`.

    Parameters
    ----------
    a, b : array_like
        Input arrays to compare.
    rtol : float
        The relative tolerance parameter (see Notes).
    atol : float
        The absolute tolerance parameter (see Notes).
    equal_nan : bool
        Whether to compare NaN's as equal.  If True, NaN's in `a` will be
        considered equal to NaN's in `b` in the output array.

    Returns
    -------
    y : array_like
        Returns a boolean array of where `a` and `b` are equal within the
        given tolerance. If both `a` and `b` are scalars, returns a single
        boolean value.

    See Also
    --------
    allclose

    Notes
    -----
    .. versionadded:: 1.7.0

    For finite values, isclose uses the following equation to test whether
    two floating point values are equivalent.

     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))

    The above equation is not symmetric in `a` and `b`, so that
    `isclose(a, b)` might be different from `isclose(b, a)` in
    some rare cases.

    Examples
    --------
    >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8])
    array([True, False])
    >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9])
    array([True, True])
    >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9])
    array([False, True])
    >>> np.isclose([1.0, np.nan], [1.0, np.nan])
    array([True, False])
    >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
    array([True, True])
    (%s, %sdtype=%s)
    Return indices that are non-zero in the flattened version of a.

    This is equivalent to a.ravel().nonzero()[0].

    Parameters
    ----------
    a : ndarray
        Input array.

    Returns
    -------
    res : ndarray
        Output array, containing the indices of the elements of `a.ravel()`
        that are non-zero.

    See Also
    --------
    nonzero : Return the indices of the non-zero elements of the input array.
    ravel : Return a 1-D array containing the elements of the input array.

    Examples
    --------
    >>> x = np.arange(-2, 3)
    >>> x
    array([-2, -1,  0,  1,  2])
    >>> np.flatnonzero(x)
    array([0, 1, 3, 4])

    Use the indices of the non-zero elements as an index array to extract
    these elements:

    >>> x.ravel()[np.flatnonzero(x)]
    array([-2, -1,  1,  2])

    
    Find the indices of array elements that are non-zero, grouped by element.

    Parameters
    ----------
    a : array_like
        Input data.

    Returns
    -------
    index_array : ndarray
        Indices of elements that are non-zero. Indices are grouped by element.

    See Also
    --------
    where, nonzero

    Notes
    -----
    ``np.argwhere(a)`` is the same as ``np.transpose(np.nonzero(a))``.

    The output of ``argwhere`` is not suitable for indexing arrays.
    For this purpose use ``where(a)`` instead.

    Examples
    --------
    >>> x = np.arange(6).reshape(2,3)
    >>> x
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.argwhere(x>1)
    array([[0, 2],
           [1, 0],
           [1, 1],
           [1, 2]])

    
    Return a full array with the same shape and type as a given array.

    Parameters
    ----------
    a : array_like
        The shape and data-type of `a` define these same attributes of
        the returned array.
    fill_value : scalar
        Fill value.
    dtype : data-type, optional
        Overrides the data type of the result.
    order : {'C', 'F', 'A', or 'K'}, optional
        Overrides the memory layout of the result. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of `a` as closely
        as possible.
    subok : bool, optional.
        If True, then the newly created array will use the sub-class
        type of 'a', otherwise it will be a base-class array. Defaults
        to True.

    Returns
    -------
    out : ndarray
        Array of `fill_value` with the same shape and type as `a`.

    See Also
    --------
    zeros_like : Return an array of zeros with shape and type of input.
    ones_like : Return an array of ones with shape and type of input.
    empty_like : Return an empty array with shape and type of input.
    zeros : Return a new array setting values to zero.
    ones : Return a new array setting values to one.
    empty : Return a new uninitialized array.
    full : Fill a new array.

    Examples
    --------
    >>> x = np.arange(6, dtype=np.int)
    >>> np.full_like(x, 1)
    array([1, 1, 1, 1, 1, 1])
    >>> np.full_like(x, 0.1)
    array([0, 0, 0, 0, 0, 0])
    >>> np.full_like(x, 0.1, dtype=np.double)
    array([ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1])
    >>> np.full_like(x, np.nan, dtype=np.double)
    array([ nan,  nan,  nan,  nan,  nan,  nan])

    >>> y = np.arange(6, dtype=np.double)
    >>> np.full_like(y, 0.1)
    array([ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1])

    
    The warning raised when casting a complex dtype to a real dtype.

    As implemented, casting a complex number to a real discards its imaginary
    part, but this behavior may not be what the user actually wants.

    
    Cross-correlation of two 1-dimensional sequences.

    This function computes the correlation as generally defined in signal
    processing texts::

        z[k] = sum_n a[n] * conj(v[n+k])

    with a and v sequences being zero-padded where necessary and conj being
    the conjugate.

    Parameters
    ----------
    a, v : array_like
        Input sequences.
    mode : {'valid', 'same', 'full'}, optional
        Refer to the `convolve` docstring.  Note that the default
        is `valid`, unlike `convolve`, which uses `full`.
    old_behavior : bool
        If True, uses the old behavior from Numeric,
        (correlate(a,v) == correlate(v,a), and the conjugate is not taken
        for complex arrays). If False, uses the conventional signal
        processing definition.

    See Also
    --------
    convolve : Discrete, linear convolution of two one-dimensional sequences.

    Examples
    --------
    >>> np.correlate([1, 2, 3], [0, 1, 0.5])
    array([ 3.5])
    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "same")
    array([ 2. ,  3.5,  3. ])
    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "full")
    array([ 0.5,  2. ,  3.5,  3. ,  0. ])

    
    Roll array elements along a given axis.

    Elements that roll beyond the last position are re-introduced at
    the first.

    Parameters
    ----------
    a : array_like
        Input array.
    shift : int
        The number of places by which elements are shifted.
    axis : int, optional
        The axis along which elements are shifted.  By default, the array
        is flattened before shifting, after which the original
        shape is restored.

    Returns
    -------
    res : ndarray
        Output array, with the same shape as `a`.

    See Also
    --------
    rollaxis : Roll the specified axis backwards, until it lies in a
               given position.

    Examples
    --------
    >>> x = np.arange(10)
    >>> np.roll(x, 2)
    array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])

    >>> x2 = np.reshape(x, (2,5))
    >>> x2
    array([[0, 1, 2, 3, 4],
           [5, 6, 7, 8, 9]])
    >>> np.roll(x2, 1)
    array([[9, 0, 1, 2, 3],
           [4, 5, 6, 7, 8]])
    >>> np.roll(x2, 1, axis=0)
    array([[5, 6, 7, 8, 9],
           [0, 1, 2, 3, 4]])
    >>> np.roll(x2, 1, axis=1)
    array([[4, 0, 1, 2, 3],
           [9, 5, 6, 7, 8]])

    
    Roll the specified axis backwards, until it lies in a given position.

    Parameters
    ----------
    a : ndarray
        Input array.
    axis : int
        The axis to roll backwards.  The positions of the other axes do not
        change relative to one another.
    start : int, optional
        The axis is rolled until it lies before this position.  The default,
        0, results in a "complete" roll.

    Returns
    -------
    res : ndarray
        Output array.

    See Also
    --------
    roll : Roll the elements of an array by a number of positions along a
        given axis.

    Examples
    --------
    >>> a = np.ones((3,4,5,6))
    >>> np.rollaxis(a, 3, 1).shape
    (3, 6, 4, 5)
    >>> np.rollaxis(a, 2).shape
    (5, 3, 4, 6)
    >>> np.rollaxis(a, 1, 4).shape
    (3, 5, 6, 4)

    
    errstate(**kwargs)

    Context manager for floating-point error handling.

    Using an instance of `errstate` as a context manager allows statements in
    that context to execute with a known error handling behavior. Upon entering
    the context the error handling is set with `seterr` and `seterrcall`, and
    upon exiting it is reset to what it was before.

    Parameters
    ----------
    kwargs : {divide, over, under, invalid}
        Keyword arguments. The valid keywords are the possible floating-point
        exceptions. Each keyword should have a string value that defines the
        treatment for the particular error. Possible values are
        {'ignore', 'warn', 'raise', 'call', 'print', 'log'}.

    See Also
    --------
    seterr, geterr, seterrcall, geterrcall

    Notes
    -----
    The ``with`` statement was introduced in Python 2.5, and can only be used
    there by importing it: ``from __future__ import with_statement``. In
    earlier Python versions the ``with`` statement is not available.

    For complete documentation of the types of floating-point exceptions and
    treatment options, see `seterr`.

    Examples
    --------
    >>> from __future__ import with_statement  # use 'with' in Python 2.5
    >>> olderr = np.seterr(all='ignore')  # Set error handling to known state.

    >>> np.arange(3) / 0.
    array([ NaN,  Inf,  Inf])
    >>> with np.errstate(divide='warn'):
    ...     np.arange(3) / 0.
    ...
    __main__:2: RuntimeWarning: divide by zero encountered in divide
    array([ NaN,  Inf,  Inf])

    >>> np.sqrt(-1)
    nan
    >>> with np.errstate(invalid='raise'):
    ...     np.sqrt(-1)
    Traceback (most recent call last):
      File "<stdin>", line 2, in <module>
    FloatingPointError: invalid value encountered in sqrt

    Outside the context the error handling behavior has not changed:

    >>> np.geterr()
    {'over': 'warn', 'divide': 'warn', 'invalid': 'warn',
    'under': 'ignore'}

    v cannot be empty
    Set a Python function to be used when pretty printing arrays.

    Parameters
    ----------
    f : function or None
        Function to be used to pretty print arrays. The function should expect
        a single array argument and return a string of the representation of
        the array. If None, the function is reset to the default NumPy function
        to print arrays.
    repr : bool, optional
        If True (default), the function for pretty printing (``__repr__``)
        is set, if False the function that returns the default string
        representation (``__str__``) is set.

    See Also
    --------
    set_printoptions, get_printoptions

    Examples
    --------
    >>> def pprint(arr):
    ...     return 'HA! - What are you going to do now?'
    ...
    >>> np.set_string_function(pprint)
    >>> a = np.arange(10)
    >>> a
    HA! - What are you going to do now?
    >>> print a
    [0 1 2 3 4 5 6 7 8 9]

    We can reset the function to the default:

    >>> np.set_string_function(None)
    >>> a
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

    `repr` affects either pretty printing or normal string representation.
    Note that ``__repr__`` is still affected by setting ``__str__``
    because the width of each array element in the returned string becomes
    equal to the length of the result of ``__str__()``.

    >>> x = np.arange(4)
    >>> np.set_string_function(lambda x:'random', repr=False)
    >>> x.__str__()
    'random'
    >>> x.__repr__()
    'array([     0,      1,      2,      3])'

    
    Return the identity array.

    The identity array is a square array with ones on
    the main diagonal.

    Parameters
    ----------
    n : int
        Number of rows (and columns) in `n` x `n` output.
    dtype : data-type, optional
        Data-type of the output.  Defaults to ``float``.

    Returns
    -------
    out : ndarray
        `n` x `n` array with its main diagonal set to one,
        and all other elements 0.

    Examples
    --------
    >>> np.identity(3)
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])

    Buffer size, %s, is too big.Buffer size, %s, is not a multiple of 16.[], shape=%s
    Set the floating-point error callback function or log object.

    There are two ways to capture floating-point error messages.  The first
    is to set the error-handler to 'call', using `seterr`.  Then, set
    the function to call using this function.

    The second is to set the error-handler to 'log', using `seterr`.
    Floating-point errors then trigger a call to the 'write' method of
    the provided object.

    Parameters
    ----------
    func : callable f(err, flag) or object with write method
        Function to call upon floating-point errors ('call'-mode) or
        object whose 'write' method is used to log such message ('log'-mode).

        The call function takes two arguments. The first is the
        type of error (one of "divide", "over", "under", or "invalid"),
        and the second is the status flag.  The flag is a byte, whose
        least-significant bits indicate the status::

          [0 0 0 0 invalid over under invalid]

        In other words, ``flags = divide + 2*over + 4*under + 8*invalid``.

        If an object is provided, its write method should take one argument,
        a string.

    Returns
    -------
    h : callable, log instance or None
        The old error handler.

    See Also
    --------
    seterr, geterr, geterrcall

    Examples
    --------
    Callback upon error:

    >>> def err_handler(type, flag):
    ...     print "Floating point error (%s), with flag %s" % (type, flag)
    ...

    >>> saved_handler = np.seterrcall(err_handler)
    >>> save_err = np.seterr(all='call')

    >>> np.array([1, 2, 3]) / 0.0
    Floating point error (divide by zero), with flag 1
    array([ Inf,  Inf,  Inf])

    >>> np.seterrcall(saved_handler)
    <function err_handler at 0x...>
    >>> np.seterr(**save_err)
    {'over': 'call', 'divide': 'call', 'invalid': 'call', 'under': 'call'}

    Log error message:

    >>> class Log(object):
    ...     def write(self, msg):
    ...         print "LOG: %s" % msg
    ...

    >>> log = Log()
    >>> saved_handler = np.seterrcall(log)
    >>> save_err = np.seterr(all='log')

    >>> np.array([1, 2, 3]) / 0.0
    LOG: Warning: divide by zero encountered in divide
    <BLANKLINE>
    array([ Inf,  Inf,  Inf])

    >>> np.seterrcall(saved_handler)
    <__main__.Log object at 0x...>
    >>> np.seterr(**save_err)
    {'over': 'log', 'divide': 'log', 'invalid': 'log', 'under': 'log'}

    rollaxis: %s (%d) must be >=0 and < %d
    Returns True if input arrays are shape consistent and all elements equal.

    Shape consistent means they are either the same shape, or one input array
    can be broadcasted to create the same shape as the other one.

    Parameters
    ----------
    a1, a2 : array_like
        Input arrays.

    Returns
    -------
    out : bool
        True if equivalent, False otherwise.

    Examples
    --------
    >>> np.array_equiv([1, 2], [1, 2])
    True
    >>> np.array_equiv([1, 2], [1, 3])
    False

    Showing the shape equivalence:

    >>> np.array_equiv([1, 2], [[1, 2], [1, 2]])
    True
    >>> np.array_equiv([1, 2], [[1, 2, 1, 2], [1, 2, 1, 2]])
    False

    >>> np.array_equiv([1, 2], [[1, 2], [1, 3]])
    False

    
    Returns True if array is arranged in Fortran-order in memory
    and not C-order.

    Parameters
    ----------
    a : ndarray
        Input array.


    Examples
    --------

    np.array allows to specify whether the array is written in C-contiguous
    order (last index varies the fastest), or FORTRAN-contiguous order in
    memory (first index varies the fastest).

    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
    >>> a
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> np.isfortran(a)
    False

    >>> b = np.array([[1, 2, 3], [4, 5, 6]], order='FORTRAN')
    >>> b
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> np.isfortran(b)
    True


    The transpose of a C-ordered array is a FORTRAN-ordered array.

    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
    >>> a
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> np.isfortran(a)
    False
    >>> b = a.T
    >>> b
    array([[1, 4],
           [2, 5],
           [3, 6]])
    >>> np.isfortran(b)
    True

    C-ordered arrays evaluate as False even if they are also FORTRAN-ordered.

    >>> np.isfortran(np.array([1, 2], order='FORTRAN'))
    False

    shape-mismatch for sum(   t   at   bt   axest   axes_at   axes_bt   nat   nbt   as_t   ndat   bst   ndbt   equalt   kt   notint	   newaxes_at   N2t   axist
   newshape_at   oldat	   newaxes_bt
   newshape_bt   oldbt   att   btt   res0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZMmFDGefdguvalSHORTBHILQPbhilqpibytesIntTypeIntnameefdgFDGintnameloweredupperedLONGLONGLongTypeTypeTypeUIntnamecharnameissctypeuintnameutypeobjFloatTypenumcoerceto_removeucharnameAllIntegerBufferTypememoryviewtype_pairsUnicodeTypebBhHiIlLqQpPmaximum_sctype?bhilqpBHILQPefdgFDGSUVOMm[   s   bools   int8s   uint8s   int16s   uint16s   int32s   uint32s   int64s   uint64s   int128s   uint128s   float16s   float32s   float64s   float80s   float96s   float128s   float256s	   complex32s	   complex64s
   complex128s
   complex160s
   complex192s
   complex256s
   complex512s   object[   s
   sctypeDicts   sctypeNAs   typeDicts   typeNAs   sctypess
   ScalarTypes
   obj2sctypes   casts   nbytess   sctype2chars   maximum_sctypes   issctypes	   typecodess   find_common_types
   issubdtypes   datetime_datas   datetime_as_strings   busday_offsets   busday_counts	   is_busdays   busdaycalendar[   (   s   complex_s   cdouble(   s   int0s   intp(   s   uint0s   uintp(   s   singles   float(   s   csingles   cfloat(   s   singlecomplexs   cfloat(   s   float_s   double(   s   intcs   int(   s   uintcs   uint(   s   int_s   long(   s   uints   ulong(   s   cfloats   cdouble(   s	   longfloats
   longdouble(   s
   clongfloats   clongdouble(   s   longcomplexs   clongdouble(   s   bool_s   bool(   s   unicode_s   unicode(   s   object_s   objecti%d
    Determines whether the given object represents a scalar data-type.

    Parameters
    ----------
    rep : any
        If `rep` is an instance of a scalar dtype, True is returned. If not,
        False is returned.

    Returns
    -------
    out : bool
        Boolean result of check whether `rep` is a scalar dtype.

    See Also
    --------
    issubsctype, issubdtype, obj2sctype, sctype2char

    Examples
    --------
    >>> np.issctype(np.int32)
    True
    >>> np.issctype(list)
    False
    >>> np.issctype(1.1)
    False

    Strings are also a scalar type:

    >>> np.issctype(np.dtype('str'))
    True

    /usr/lib/python2.7/dist-packages/numpy/core/numerictypes.pyreturns the type corresponding to a certain Python typeu%d
    Determine if the first argument is a subclass of the second argument.

    Parameters
    ----------
    arg1, arg2 : dtype or dtype specifier
        Data-types.

    Returns
    -------
    out : bool
        The result.

    See Also
    --------
    issctype, issubdtype,obj2sctype

    Examples
    --------
    >>> np.issubsctype('S8', str)
    True
    >>> np.issubsctype(np.array([1]), np.int)
    True
    >>> np.issubsctype(np.array([1]), np.float)
    False

    
    Base object for a dictionary for look-up with any alias for an array dtype.

    Instances of `_typedict` can not be used as dictionaries directly,
    first they have to be populated.

    
    Return the scalar type of highest precision of the same kind as the input.

    Parameters
    ----------
    t : dtype or dtype specifier
        The input data type. This can be a `dtype` object or an object that
        is convertible to a `dtype`.

    Returns
    -------
    out : dtype
        The highest precision data type of the same kind (`dtype.kind`) as `t`.

    See Also
    --------
    obj2sctype, mintypecode, sctype2char
    dtype

    Examples
    --------
    >>> np.maximum_sctype(np.int)
    <type 'numpy.int64'>
    >>> np.maximum_sctype(np.uint8)
    <type 'numpy.uint64'>
    >>> np.maximum_sctype(np.complex)
    <type 'numpy.complex192'>

    >>> np.maximum_sctype(str)
    <type 'numpy.string_'>

    >>> np.maximum_sctype('i2')
    <type 'numpy.int64'>
    >>> np.maximum_sctype('f4')
    <type 'numpy.float96'>

     Apply English case rules to convert ASCII strings to all lower case.

    This is an internal utility function to replace calls to str.lower() such
    that we can avoid changing behavior with changing locales. In particular,
    Turkish has distinct dotted and dotless variants of the Latin letter "I" in
    both lowercase and uppercase. Thus, "I".lower() != "i" in a "tr" locale.

    Parameters
    ----------
    s : str

    Returns
    -------
    lowered : str

    Examples
    --------
    >>> from numpy.core.numerictypes import english_lower
    >>> english_lower('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_')
    'abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz0123456789_'
    >>> english_lower('')
    ''
    unrecognized typeInt%d
    Determine common type following standard coercion rules.

    Parameters
    ----------
    array_types : sequence
        A list of dtypes or dtype convertible objects representing arrays.
    scalar_types : sequence
        A list of dtypes or dtype convertible objects representing scalars.

    Returns
    -------
    datatype : dtype
        The common data type, which is the maximum of `array_types` ignoring
        `scalar_types`, unless the maximum of `scalar_types` is of a
        different kind (`dtype.kind`). If the kind is not understood, then
        None is returned.

    See Also
    --------
    dtype, common_type, can_cast, mintypecode

    Examples
    --------
    >>> np.find_common_type([], [np.int64, np.float32, np.complex])
    dtype('complex128')
    >>> np.find_common_type([np.int64, np.float32], [])
    dtype('float64')

    The standard casting rules ensure that a scalar cannot up-cast an
    array unless the scalar is of a fundamentally different kind of data
    (i.e. under a different hierarchy in the data type hierarchy) then
    the array:

    >>> np.find_common_type([np.float32], [np.int64, np.float64])
    dtype('float32')

    Complex is of a different type, so it up-casts the float in the
    `array_types` argument:

    >>> np.find_common_type([np.float32], [np.complex])
    dtype('complex128')

    Type specifier strings are convertible to dtypes and can therefore
    be used instead of dtypes:

    >>> np.find_common_type(['f4', 'f4', 'i4'], ['c8'])
    dtype('complex128')

    
    Return the scalar dtype or NumPy equivalent of Python type of an object.

    Parameters
    ----------
    rep : any
        The object of which the type is returned.
    default : any, optional
        If given, this is returned for objects whose types can not be
        determined. If not given, None is returned for those objects.

    Returns
    -------
    dtype : dtype or Python type
        The data type of `rep`.

    See Also
    --------
    sctype2char, issctype, issubsctype, issubdtype, maximum_sctype

    Examples
    --------
    >>> np.obj2sctype(np.int32)
    <type 'numpy.int32'>
    >>> np.obj2sctype(np.array([1., 2.]))
    <type 'numpy.float64'>
    >>> np.obj2sctype(np.array([1.j]))
    <type 'numpy.complex128'>

    >>> np.obj2sctype(dict)
    <type 'numpy.object_'>
    >>> np.obj2sctype('string')
    <type 'numpy.string_'>

    >>> np.obj2sctype(1, default=list)
    <type 'list'>

    int%dUInt%d Apply English case rules to convert the first character of an ASCII
    string to upper case.

    This is an internal utility function to replace calls to str.capitalize()
    such that we can avoid changing behavior with changing locales.

    Parameters
    ----------
    s : str

    Returns
    -------
    capitalized : str

    Examples
    --------
    >>> from numpy.core.numerictypes import english_capitalize
    >>> english_capitalize('int8')
    'Int8'
    >>> english_capitalize('Int8')
    'Int8'
    >>> english_capitalize('')
    ''
    
    Determine if a class is a subclass of a second class.

    `issubclass_` is equivalent to the Python built-in ``issubclass``,
    except that it returns False instead of raising a TypeError is one
    of the arguments is not a class.

    Parameters
    ----------
    arg1 : class
        Input class. True is returned if `arg1` is a subclass of `arg2`.
    arg2 : class or tuple of classes.
        Input class. If a tuple of classes, True is returned if `arg1` is a
        subclass of any of the tuple elements.

    Returns
    -------
    out : bool
        Whether `arg1` is a subclass of `arg2` or not.

    See Also
    --------
    issubsctype, issubdtype, issctype

    Examples
    --------
    >>> np.issubclass_(np.int32, np.int)
    True
    >>> np.issubclass_(np.int32, np.float)
    False

    
    Return the string representation of a scalar dtype.

    Parameters
    ----------
    sctype : scalar dtype or object
        If a scalar dtype, the corresponding string character is
        returned. If an object, `sctype2char` tries to infer its scalar type
        and then return the corresponding string character.

    Returns
    -------
    typechar : str
        The string character corresponding to the scalar type.

    Raises
    ------
    ValueError
        If `sctype` is an object for which the type can not be inferred.

    See Also
    --------
    obj2sctype, issctype, issubsctype, mintypecode

    Examples
    --------
    >>> for sctype in [np.int32, np.float, np.complex, np.string_, np.ndarray]:
    ...     print np.sctype2char(sctype)
    l
    d
    D
    S
    O

    >>> x = np.array([1., 2-1.j])
    >>> np.sctype2char(x)
    'D'
    >>> np.sctype2char(list)
    'O'

     Apply English case rules to convert ASCII strings to all upper case.

    This is an internal utility function to replace calls to str.upper() such
    that we can avoid changing behavior with changing locales. In particular,
    Turkish has distinct dotted and dotless variants of the Latin letter "I" in
    both lowercase and uppercase. Thus, "i".upper() != "I" in a "tr" locale.

    Parameters
    ----------
    s : str

    Returns
    -------
    uppered : str

    Examples
    --------
    >>> from numpy.core.numerictypes import english_upper
    >>> english_upper('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_')
    'ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_'
    >>> english_upper('')
    ''
    
    Returns True if first argument is a typecode lower/equal in type hierarchy.

    Parameters
    ----------
    arg1, arg2 : dtype_like
        dtype or string representing a typecode.

    Returns
    -------
    out : bool

    See Also
    --------
    issubsctype, issubclass_
    numpy.core.numerictypes : Overview of numpy type hierarchy.

    Examples
    --------
    >>> np.issubdtype('S1', str)
    True
    >>> np.issubdtype(np.float64, np.float32)
    False

    
numerictypes: Define the numeric type objects

This module is designed so "from numerictypes import \*" is safe.
Exported symbols include:

  Dictionary with all registered number types (including aliases):
    typeDict

  Type objects (not all will be available, depends on platform):
      see variable sctypes for which ones you have

    Bit-width names

    int8 int16 int32 int64 int128
    uint8 uint16 uint32 uint64 uint128
    float16 float32 float64 float96 float128 float256
    complex32 complex64 complex128 complex192 complex256 complex512
    datetime64 timedelta64

    c-based names

    bool_

    object_

    void, str_, unicode_

    byte, ubyte,
    short, ushort
    intc, uintc,
    intp, uintp,
    int_, uint,
    longlong, ulonglong,

    single, csingle,
    float_, complex_,
    longfloat, clongfloat,

   As part of the type-hierarchy:    xx -- is bit-width

   generic
     +-> bool_                                  (kind=b)
     +-> number                                 (kind=i)
     |     integer
     |     signedinteger   (intxx)
     |     byte
     |     short
     |     intc
     |     intp           int0
     |     int_
     |     longlong
     +-> unsignedinteger  (uintxx)              (kind=u)
     |     ubyte
     |     ushort
     |     uintc
     |     uintp          uint0
     |     uint_
     |     ulonglong
     +-> inexact
     |   +-> floating           (floatxx)       (kind=f)
     |   |     half
     |   |     single
     |   |     float_  (double)
     |   |     longfloat
     |   \-> complexfloating    (complexxx)     (kind=c)
     |         csingle  (singlecomplex)
     |         complex_ (cfloat, cdouble)
     |         clongfloat (longcomplex)
     +-> flexible
     |     character
     |     void                                 (kind=V)
     |
     |     str_     (string_, bytes_)           (kind=S)    [Python 2]
     |     unicode_                             (kind=U)    [Python 2]
     |
     |     bytes_   (string_)                   (kind=S)    [Python 3]
     |     str_     (unicode_)                  (kind=U)    [Python 3]
     |
     \-> object_ (not used much)                (kind=O)

uint%dReturn a bit-width name for a given type objectfstatnumfmt_nfieldsshapeprodshapesizetestshape_f_formatsnbytesread_createdescr_parseFormats_setfieldnames{t   Bt   >t   lt   <t   it   |t   bR   t   St   sR   R   t   IR   R   R   t   nt   =t   NR   R   R   R   R   t   LR   R   R   0Pretty-print all fields.Create an array from binary file data

    If file is a string then that file is opened, else it is assumed
    to be a file object.

    >>> from tempfile import TemporaryFile
    >>> a = np.empty(10,dtype='f8,i4,a5')
    >>> a[5] = (0.5,10,'abcde')
    >>>
    >>> fd=TemporaryFile()
    >>> a = a.newbyteorder('<')
    >>> a.tofile(fd)
    >>>
    >>> fd.seek(0)
    >>> r=np.core.records.fromfile(fd, formats='f8,i4,a5', shape=10,
    ... byteorder='<')
    >>> print r[5]
    (0.5, 10, 'abcde')
    >>> r.shape
    (10,)
    
    Construct an ndarray that allows field access using attributes.

    Arrays may have a data-types containing fields, analogous
    to columns in a spread sheet.  An example is ``[(x, int), (y, float)]``,
    where each entry in the array is a pair of ``(int, float)``.  Normally,
    these attributes are accessed using dictionary lookups such as ``arr['x']``
    and ``arr['y']``.  Record arrays allow the fields to be accessed as members
    of the array, using ``arr.x`` and ``arr.y``.

    Parameters
    ----------
    shape : tuple
        Shape of output array.
    dtype : data-type, optional
        The desired data-type.  By default, the data-type is determined
        from `formats`, `names`, `titles`, `aligned` and `byteorder`.
    formats : list of data-types, optional
        A list containing the data-types for the different columns, e.g.
        ``['i4', 'f8', 'i4']``.  `formats` does *not* support the new
        convention of using types directly, i.e. ``(int, float, int)``.
        Note that `formats` must be a list, not a tuple.
        Given that `formats` is somewhat limited, we recommend specifying
        `dtype` instead.
    names : tuple of str, optional
        The name of each column, e.g. ``('x', 'y', 'z')``.
    buf : buffer, optional
        By default, a new array is created of the given shape and data-type.
        If `buf` is specified and is an object exposing the buffer interface,
        the array will use the memory from the existing buffer.  In this case,
        the `offset` and `strides` keywords are available.

    Other Parameters
    ----------------
    titles : tuple of str, optional
        Aliases for column names.  For example, if `names` were
        ``('x', 'y', 'z')`` and `titles` is
        ``('x_coordinate', 'y_coordinate', 'z_coordinate')``, then
        ``arr['x']`` is equivalent to both ``arr.x`` and ``arr.x_coordinate``.
    byteorder : {'<', '>', '='}, optional
        Byte-order for all fields.
    aligned : bool, optional
        Align the fields in memory as the C-compiler would.
    strides : tuple of ints, optional
        Buffer (`buf`) is interpreted according to these strides (strides
        define how many bytes each array element, row, column, etc.
        occupy in memory).
    offset : int, optional
        Start reading buffer (`buf`) from this offset onwards.
    order : {'C', 'F'}, optional
        Row-major or column-major order.

    Returns
    -------
    rec : recarray
        Empty array of the given shape and type.

    See Also
    --------
    rec.fromrecords : Construct a record array from data.
    record : fundamental data-type for `recarray`.
    format_parser : determine a data-type from formats, names, titles.

    Notes
    -----
    This constructor can be compared to ``empty``: it creates a new record
    array but does not fill it with data.  To create a record array from data,
    use one of the following methods:

    1. Create a standard ndarray and convert it to a record array,
       using ``arr.view(np.recarray)``
    2. Use the `buf` keyword.
    3. Use `np.rec.fromrecords`.

    Examples
    --------
    Create an array with two fields, ``x`` and ``y``:

    >>> x = np.array([(1.0, 2), (3.0, 4)], dtype=[('x', float), ('y', int)])
    >>> x
    array([(1.0, 2), (3.0, 4)],
          dtype=[('x', '<f8'), ('y', '<i4')])

    >>> x['x']
    array([ 1.,  3.])

    View the array as a record array:

    >>> x = x.view(np.recarray)

    >>> x.x
    array([ 1.,  3.])

    >>> x.y
    array([2, 4])

    Create a new, empty record array:

    >>> np.recarray((2,),
    ... dtype=[('x', int), ('y', float), ('z', int)]) #doctest: +SKIP
    rec.array([(-1073741821, 1.2249118382103472e-301, 24547520),
           (3471280, 1.2134086255804012e-316, 0)],
          dtype=[('x', '<i4'), ('y', '<f8'), ('z', '<i4')])

    
Record Arrays
=============
Record arrays expose the fields of structured arrays as properties.

Most commonly, ndarrays contain elements of a single type, e.g. floats, integers,
bools etc.  However, it is possible for elements to be combinations of these,
such as::

  >>> a = np.array([(1, 2.0), (1, 2.0)], dtype=[('x', int), ('y', float)])
  >>> a
  array([(1, 2.0), (1, 2.0)],
        dtype=[('x', '<i4'), ('y', '<f8')])

Here, each element consists of two fields: x (and int), and y (a float).
This is known as a structured array.  The different fields are analogous
to columns in a spread-sheet.  The different fields can be accessed as
one would a dictionary::

  >>> a['x']
  array([1, 1])

  >>> a['y']
  array([ 2.,  2.])

Record arrays allow us to access fields as properties::

  >>> ar = a.view(np.recarray)

  >>> ar.x
  array([1, 1])

  >>> ar.y
  array([ 2.,  2.])

Must have dtype= or formats=Need formats argumentconvert input field names into a list and assign to the _names
        attribute  create a recarray from a list of records in text form

        The data in the same field can be heterogeneous, they will be promoted
        to the highest data type.  This method is intended for creating
        smaller record arrays.  If used to create large array without formats
        defined

        r=fromrecords([(2,3.,'abc')]*100000)

        it can be slow.

        If formats is None, then this will auto-detect formats. Use list of
        tuples rather than list of lists for faster processing.

    >>> r=np.core.records.fromrecords([(456,'dbe',1.2),(2,'de',1.3)],
    ... names='col1,col2,col3')
    >>> print r[0]
    (456, 'dbe', 1.2)
    >>> r.col1
    array([456,   2])
    >>> r.col2
    chararray(['dbe', 'de'],
          dtype='|S3')
    >>> import pickle
    >>> print pickle.loads(pickle.dumps(r))
    [(456, 'dbe', 1.2) (2, 'de', 1.3)]
    /usr/lib/python2.7/dist-packages/numpy/core/records.pyConstruct a record array from a wide-variety of objects.
     create a record array from a (flat) list of arrays

    >>> x1=np.array([1,2,3,4])
    >>> x2=np.array(['a','dd','xyz','12'])
    >>> x3=np.array([1.1,2,3,4])
    >>> r = np.core.records.fromarrays([x1,x2,x3],names='a,b,c')
    >>> print r[1]
    (2, 'dd', 2.0)
    >>> x1[1]=34
    >>> r.a
    array([1, 2, 3, 4])
    Find duplication in a list, return a list of duplicated elementsDidn't read as many bytes as expectedMust define formats (or dtype) if object is None, string, or an open fileCan only deal with 1-d array.%% %ds: %%sNot enough bytes left in file for specified shape and type
    Class to convert formats, names, titles description to a dtype.

    After constructing the format_parser object, the dtype attribute is
    the converted data-type:
    ``dtype = format_parser(formats, names, titles).dtype``

    Attributes
    ----------
    dtype : dtype
        The converted data-type.

    Parameters
    ----------
    formats : str or list of str
        The format description, either specified as a string with
        comma-separated format descriptions in the form ``'f8, i4, a5'``, or
        a list of format description strings  in the form
        ``['f8', 'i4', 'a5']``.
    names : str or list/tuple of str
        The field names, either specified as a comma-separated string in the
        form ``'col1, col2, col3'``, or as a list or tuple of strings in the
        form ``['col1', 'col2', 'col3']``.
        An empty list can be used, in that case default field names
        ('f0', 'f1', ...) are used.
    titles : sequence
        Sequence of title strings. An empty list can be used to leave titles
        out.
    aligned : bool, optional
        If True, align the fields by padding as the C-compiler would.
        Default is False.
    byteorder : str, optional
        If specified, all the fields will be changed to the
        provided byte-order.  Otherwise, the default byte-order is
        used. For all available string specifiers, see `dtype.newbyteorder`.

    See Also
    --------
    dtype, typename, sctype2char

    Examples
    --------
    >>> np.format_parser(['f8', 'i4', 'a5'], ['col1', 'col2', 'col3'],
    ...                  ['T1', 'T2', 'T3']).dtype
    dtype([(('T1', 'col1'), '<f8'), (('T2', 'col2'), '<i4'),
           (('T3', 'col3'), '|S5')])

    `names` and/or `titles` can be empty lists. If `titles` is an empty list,
    titles will simply not appear. If `names` is empty, default field names
    will be used.

    >>> np.format_parser(['f8', 'i4', 'a5'], ['col1', 'col2', 'col3'],
    ...                  []).dtype
    dtype([('col1', '<f8'), ('col2', '<i4'), ('col3', '|S5')])
    >>> np.format_parser(['f8', 'i4', 'a5'], [], []).dtype
    dtype([('f0', '<f8'), ('f1', '<i4'), ('f2', '|S5')])

    array-shape mismatch in array %dA data-type scalar that allows field access as attribute lookup.
    item in the array list must be an ndarray.Cannot set '%s' attribute'record' object has no attribute '%s'Unknown input type Parse the field formats Duplicate field names: %s create a (read-only) record array from binary data contained in
    a stringmismatch between the number of fields and the number of arraysMust define a shape if obj is Nonenumpy.core.shape_base
    View inputs as arrays with at least three dimensions.

    Parameters
    ----------
    arys1, arys2, ... : array_like
        One or more array-like sequences.  Non-array inputs are converted to
        arrays.  Arrays that already have three or more dimensions are
        preserved.

    Returns
    -------
    res1, res2, ... : ndarray
        An array, or tuple of arrays, each with ``a.ndim >= 3``.  Copies are
        avoided where possible, and views with three or more dimensions are
        returned.  For example, a 1-D array of shape ``(N,)`` becomes a view
        of shape ``(1, N, 1)``, and a 2-D array of shape ``(M, N)`` becomes a
        view of shape ``(M, N, 1)``.

    See Also
    --------
    atleast_1d, atleast_2d

    Examples
    --------
    >>> np.atleast_3d(3.0)
    array([[[ 3.]]])

    >>> x = np.arange(3.0)
    >>> np.atleast_3d(x).shape
    (1, 3, 1)

    >>> x = np.arange(12.0).reshape(4,3)
    >>> np.atleast_3d(x).shape
    (4, 3, 1)
    >>> np.atleast_3d(x).base is x
    True

    >>> for arr in np.atleast_3d([1, 2], [[1, 2]], [[[1, 2]]]):
    ...     print arr, arr.shape
    ...
    [[[1]
      [2]]] (1, 2, 1)
    [[[1]
      [2]]] (1, 2, 1)
    [[[1 2]]] (1, 1, 2)

    
    Convert inputs to arrays with at least one dimension.

    Scalar inputs are converted to 1-dimensional arrays, whilst
    higher-dimensional inputs are preserved.

    Parameters
    ----------
    arys1, arys2, ... : array_like
        One or more input arrays.

    Returns
    -------
    ret : ndarray
        An array, or sequence of arrays, each with ``a.ndim >= 1``.
        Copies are made only if necessary.

    See Also
    --------
    atleast_2d, atleast_3d

    Examples
    --------
    >>> np.atleast_1d(1.0)
    array([ 1.])

    >>> x = np.arange(9.0).reshape(3,3)
    >>> np.atleast_1d(x)
    array([[ 0.,  1.,  2.],
           [ 3.,  4.,  5.],
           [ 6.,  7.,  8.]])
    >>> np.atleast_1d(x) is x
    True

    >>> np.atleast_1d(1, [3, 4])
    [array([1]), array([3, 4])]

    
    Stack arrays in sequence horizontally (column wise).

    Take a sequence of arrays and stack them horizontally to make
    a single array. Rebuild arrays divided by `hsplit`.

    Parameters
    ----------
    tup : sequence of ndarrays
        All arrays must have the same shape along all but the second axis.

    Returns
    -------
    stacked : ndarray
        The array formed by stacking the given arrays.

    See Also
    --------
    vstack : Stack arrays in sequence vertically (row wise).
    dstack : Stack arrays in sequence depth wise (along third axis).
    concatenate : Join a sequence of arrays together.
    hsplit : Split array along second axis.

    Notes
    -----
    Equivalent to ``np.concatenate(tup, axis=1)``

    Examples
    --------
    >>> a = np.array((1,2,3))
    >>> b = np.array((2,3,4))
    >>> np.hstack((a,b))
    array([1, 2, 3, 2, 3, 4])
    >>> a = np.array([[1],[2],[3]])
    >>> b = np.array([[2],[3],[4]])
    >>> np.hstack((a,b))
    array([[1, 2],
           [2, 3],
           [3, 4]])

    /usr/lib/python2.7/dist-packages/numpy/core/shape_base.py
    View inputs as arrays with at least two dimensions.

    Parameters
    ----------
    arys1, arys2, ... : array_like
        One or more array-like sequences.  Non-array inputs are converted
        to arrays.  Arrays that already have two or more dimensions are
        preserved.

    Returns
    -------
    res, res2, ... : ndarray
        An array, or tuple of arrays, each with ``a.ndim >= 2``.
        Copies are avoided where possible, and views with two or more
        dimensions are returned.

    See Also
    --------
    atleast_1d, atleast_3d

    Examples
    --------
    >>> np.atleast_2d(3.0)
    array([[ 3.]])

    >>> x = np.arange(3.0)
    >>> np.atleast_2d(x)
    array([[ 0.,  1.,  2.]])
    >>> np.atleast_2d(x).base is x
    True

    >>> np.atleast_2d(1, [1, 2], [[1, 2]])
    [array([[1]]), array([[1, 2]]), array([[1, 2]])]

    
    Stack arrays in sequence vertically (row wise).

    Take a sequence of arrays and stack them vertically to make a single
    array. Rebuild arrays divided by `vsplit`.

    Parameters
    ----------
    tup : sequence of ndarrays
        Tuple containing arrays to be stacked. The arrays must have the same
        shape along all but the first axis.

    Returns
    -------
    stacked : ndarray
        The array formed by stacking the given arrays.

    See Also
    --------
    hstack : Stack arrays in sequence horizontally (column wise).
    dstack : Stack arrays in sequence depth wise (along third dimension).
    concatenate : Join a sequence of arrays together.
    vsplit : Split array into a list of multiple sub-arrays vertically.

    Notes
    -----
    Equivalent to ``np.concatenate(tup, axis=0)`` if `tup` contains arrays that
    are at least 2-dimensional.

    Examples
    --------
    >>> a = np.array([1, 2, 3])
    >>> b = np.array([2, 3, 4])
    >>> np.vstack((a,b))
    array([[1, 2, 3],
           [2, 3, 4]])

    >>> a = np.array([[1], [2], [3]])
    >>> b = np.array([[2], [3], [4]])
    >>> np.vstack((a,b))
    array([[1],
           [2],
           [3],
           [2],
           [3],
           [4]])

    cdll__ref__keep_ndim_c_bytec_uint_shape_c_floatc_ubyteso_ext2so_ext3_length_as_arrayc_ushortaddressofas_ctypesndpointerfrom_paramc_ulonglongfrom_address_check_retval_ctypes_load_libraryctypes is not available.%c%darray must have data type %sGiven a ctypes pointer object, construct and
        attach an __array_interface__ property to it if it does not
        yet have one.
        All features of ctypes interface may not work with ctypes < 1.0.1only __array_interface__ version 3 supportedGiven a ctypes simple type, construct and attach an
        __array_interface__ property to it if it does not yet have one.
        no file with expected extensionreadonly arrays unsupportedGiven a ctypes array type, construct and attach an
        __array_interface__ property to it if it does not yet have one.
        Create a numpy array from a ctypes array or a ctypes POINTER.
        The numpy array shares the memory with the ctypes object.

        The size parameter must be given if converting from a ctypes POINTER.
        The size parameter is ignored if converting from a ctypes array
        array must have flags %s
============================
``ctypes`` Utility Functions
============================

See Also
---------
load_library : Load a C library.
ndpointer : Array restype/argtype with verification.
as_ctypes : Create a ctypes array from an ndarray.
as_array : Create an ndarray from a ctypes array.

References
----------
.. [1] "SciPy Cookbook: ctypes", http://www.scipy.org/Cookbook/Ctypes

Examples
--------
Load the C library:

>>> _lib = np.ctypeslib.load_library('libmystuff', '.')     #doctest: +SKIP

Our result type, an ndarray that must be of type double, be 1-dimensional
and is C-contiguous in memory:

>>> array_1d_double = np.ctypeslib.ndpointer(
...                          dtype=np.double,
...                          ndim=1, flags='CONTIGUOUS')    #doctest: +SKIP

Our C-function typically takes an array and updates its values
in-place.  For example::

    void foo_func(double* x, int length)
    {
        int i;
        for (i = 0; i < length; i++) {
            x[i] = i*i;
        }
    }

We wrap it using:

>>> _lib.foo_func.restype = None                      #doctest: +SKIP
>>> _lib.foo_func.argtypes = [array_1d_double, c_int] #doctest: +SKIP

Then, we're ready to call ``foo_func``:

>>> out = np.empty(15, dtype=np.double)
>>> _lib.foo_func(out, len(out))                #doctest: +SKIP

.%s-%s.sostrided arrays not supported
    Array-checking restype/argtypes.

    An ndpointer instance is used to describe an ndarray in restypes
    and argtypes specifications.  This approach is more flexible than
    using, for example, ``POINTER(c_double)``, since several restrictions
    can be specified, which are verified upon calling the ctypes function.
    These include data type, number of dimensions, shape and flags.  If a
    given array does not satisfy the specified restrictions,
    a ``TypeError`` is raised.

    Parameters
    ----------
    dtype : data-type, optional
        Array data-type.
    ndim : int, optional
        Number of array dimensions.
    shape : tuple of ints, optional
        Array shape.
    flags : str or tuple of str
        Array flags; may be one or more of:

          - C_CONTIGUOUS / C / CONTIGUOUS
          - F_CONTIGUOUS / F / FORTRAN
          - OWNDATA / O
          - WRITEABLE / W
          - ALIGNED / A
          - UPDATEIFCOPY / U

    Returns
    -------
    klass : ndpointer type object
        A type object, which is an ``_ndtpr`` instance containing
        dtype, ndim, shape and flags information.

    Raises
    ------
    TypeError
        If a given array does not satisfy the specified restrictions.

    Examples
    --------
    >>> clib.somefunc.argtypes = [np.ctypeslib.ndpointer(dtype=np.float64,
    ...                                                  ndim=1,
    ...                                                  flags='C_CONTIGUOUS')]
    ... #doctest: +SKIP
    >>> clib.somefunc(np.array([1, 2, 3], dtype=np.float64))
    ... #doctest: +SKIP

    array must have %d dimension(s)
        Dummy object that raises an ImportError if ctypes is not available.

        Raises
        ------
        ImportError
            If ctypes is not available.

        argument must be an ndarrayinvalid flags specificationCreate and return a ctypes object from a numpy array.  Actually
        anything that exposes the __array_interface__ is accepted./usr/lib/python2.7/dist-packages/numpy/ctypeslib.pyarray must have shape %sndpointer_%sThis method is called when this class is used as the .restype
        asttribute for a shared-library function.   It constructs a numpy
        array from a void pointer./usr/lib/python2.7/dist-packages/numpy/distutils/__init__.py/usr/lib/python2.7/dist-packages/numpy/distutils/__config__.py/usr/lib/python2.7/dist-packages/numpy/distutils/__version__.pybcppemxcunixcabsoftintelepathcccygwincintelem_get_cc_argslink_objectspathccompilerversion_matchIntelCCompiler_setup_compileintelccompilerundefine_macroset_include_dirsset_link_objectsPathScaleCCompilerIntelEM64TCCompilersimple_version_matchIntelItaniumCCompiler_distutils_new_compilerset_runtime_library_dirsdistutils.can't compile C/C++ code: unable to load module '%s'Intel C Itanium Compiler for Itanium-based applications with '%s' compiler#### %s #######-Wstrict-prototypesdon't know how to compile C/C++ code on platform '%s'Command "%s" failed with exit status %d%s
    Return compiler version, or None if compiler is not available.

    Parameters
    ----------
    force : bool, optional
        If True, force a new determination of the version, even if the
        compiler already has a version attribute. Default is False.
    ok_status : list of int, optional
        The list of status values returned by the version look-up process
        for which a version string is returned. If the status value is not
        in `ok_status`, None is returned. Default is ``[0]``.

    Returns
    -------
    version : str or None
        Version string, in the format of `distutils.version.LooseVersion`.

    
    Simple matching of version numbers, for use in CCompiler and FCompiler.

    Parameters
    ----------
    pat : str, optional
        A regular expression matching version numbers.
        Default is ``r'[-.\d]+'``.
    ignore : str, optional
        A regular expression matching patterns to skip.
        Default is ``''``, in which case nothing is skipped.
    start : str, optional
        A regular expression matching the start of where to start looking
        for version numbers.
        Default is ``''``, in which case searching is started at the
        beginning of the version string given to `matcher`.

    Returns
    -------
    matcher : callable
        A function that is appropriate to use as the ``.version_match``
        attribute of a `CCompiler` class. `matcher` takes a single parameter,
        a version string.

    
    Print the compiler customizations to stdout.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Notes
    -----
    Printing is only done if the distutils log threshold is < 2.

    Intel C Compiler for 32-bit applicationsToo many open filesC compiler: %s

    Execute a command in a sub-process.

    Parameters
    ----------
    cmd : str
        The command to execute.
    display : str or sequence of str, optional
        The text to add to the log file kept by `numpy.distutils`.
        If not given, `display` is equal to `cmd`.

    Returns
    -------
    None

    Raises
    ------
    DistutilsExecError
        If the command failed, i.e. the exit status was not 0.

    Intel C Compiler for 64-bit applicationscustomize %s using %s%-
    Compile one or more source files.

    Please refer to the Python distutils API reference for more details.

    Parameters
    ----------
    sources : list of str
        A list of filenames
    output_dir : str, optional
        Path to the output directory.
    macros : list of tuples
        A list of macro definitions.
    include_dirs : list of str, optional
        The directories to add to the default include file search path for
        this compilation only.
    debug : bool, optional
        Whether or not to output debug symbols in or alongside the object
        file(s).
    extra_preargs, extra_postargs : ?
        Extra pre- and post-arguments.
    depends : list of str, optional
        A list of file names that all targets depend on.

    Returns
    -------
    objects : list of str
        A list of object file names, one per source file `sources`.

    Raises
    ------
    CompileError
        If compilation fails.

    ********************************************************************************/usr/lib/python2.7/dist-packages/numpy/distutils/ccompiler.pyPathScale Compiler for SiCortex-based applications
    Return the name of the object files for the given source files.

    Parameters
    ----------
    source_filenames : list of str
        The list of paths to source files. Paths can be either relative or
        absolute, this is handled transparently.
    strip_dir : bool, optional
        Whether to strip the directory from the returned paths. If True,
        the file name prepended by `output_dir` is returned. Default is False.
    output_dir : str, optional
        If given, this path is prepended to the returned paths to the
        object files.

    Returns
    -------
    obj_names : list of str
        The list of paths to the object files corresponding to the source
        files in `source_filenames`.

    bad string (mismatched %s quotes?)this can't happen (bad char '%c')
    Do any platform-specific customization of a compiler instance.

    This method calls `distutils.sysconfig.customize_compiler` for
    platform-specific customization, as well as optionally remove a flag
    to suppress spurious warnings in case C++ code is being compiled.

    Parameters
    ----------
    dist : object
        This parameter is not used for anything.
    need_cxx : bool, optional
        Whether or not C++ has to be compiled. If so (True), the
        ``"-Wstrict-prototypes"`` option is removed to prevent spurious
        warnings. Default is False.

    Returns
    -------
    None

    Notes
    -----
    All the default options used by distutils can be extracted with::

      from distutils import sysconfig
      sysconfig.get_config_vars('CC', 'CXX', 'OPT', 'BASECFLAGS',
                                'CCSHARED', 'LDSHARED', 'SO')

    linux.*compile options: '%s'
    Customize compiler using distutils command.

    Parameters
    ----------
    cmd : class instance
        An instance inheriting from `distutils.cmd.Command`.
    ignore : sequence of str, optional
        List of `CCompiler` commands (without ``'set_'``) that should not be
        altered. Strings that are checked for are:
        ``('include_dirs', 'define', 'undef', 'libraries', 'library_dirs',
        'rpath', 'link_objects')``.

    Returns
    -------
    None

    "(?:[^"\\]|\\.)*"
extra options: '%s'
Try rerunning setup command until build succeeds.can't compile C/C++ code: unable to find class '%s' in module '%s'[^\\\'\"%s ]*'(?:[^'\\]|\\.)*'Missing compiler_cxx fix for new_compiler returns %s
    Return the C++ compiler.

    Parameters
    ----------
    None

    Returns
    -------
    cxx : class instance
        The C++ compiler, as a `CCompiler` instance.

    %s in numpy.distutils; trying from distutilsFortran %s compiler: %sSetting mingw32 as default compiler for nt.Mingw32 port of GNU C Compiler for Win32(for MSC built Python)numpy.distutils.(   t   selft   sourcest
   output_dirt   macrost   include_dirst   debugt   extra_preargst   extra_postargst   dependst	   FCompilert   displayt   fct   fcompt   ccompt   objectst   pp_optst   buildt   cc_argst   objects_to_buildt   objt   srct   extpayloadbdist_dumb/usr/lib/python2.7/dist-packages/numpy/distutils/command/__init__.py$Id: __init__.py,v 1.3 2005/05/16 11:08:49 pearu Exp $distutils.command

Package containing implementation of all the standard Distutils
commands.

test_na_writable_attributes_deletion__inlineautodist__inline__Return True if the C compiler is GCC 4.x.This module implements additional tests ala autoconf which can be useful.


#ifndef __cplusplus
static %(inline)s int static_func (void)
{
    return 0;
}
%(inline)s int nostatic_func (void)
{
    return 0;
}
#endifReturn the inline identifier (may be empty)./usr/lib/python2.7/dist-packages/numpy/distutils/command/autodist.py
int
main()
{
#ifndef __GNUC__ && (__GNUC__ >= 4)
die in an horrible death
#endif
}
numpy.distutils.command.bdist_rpm/usr/lib/python2.7/dist-packages/numpy/distutils/command/bdist_rpm.pydistutils.command.build/usr/lib/python2.7/dist-packages/numpy/distutils/command/build.pynumpy.distutils.command.build_f_compilercxx_objectsbase_config_fchave_f_sourcesbuild_a_librarybuild_librarieshave_cxx_sourcescheck_library_listextra_compiler_argsbuild-clibbuild-tempBuild in-placenumpy.distutils.command.build_clib/usr/lib/python2.7/dist-packages/numpy/distutils/command/build_clib.py Modified version of build_clib that handles fortran source files.
using additional config_fc from setup script for fortran compiler: %sin 'libraries' option (library '%s'), 'sources' must be present and must be a list of source filenamesbuild C/C++/F libraries used by Python extensionsskipping '%s' library (up-to-date)building '%s' librarylibrary %s has Fortran sources but no Fortran compiler found("   t   selft
   build_infot   lib_namet	   librariest   compilert	   fcompilert   sourcest	   c_sourcest   cxx_sourcest	   f_sourcest   fmodule_sourcest
   requiref90t   source_languagest   lib_filet   dependst	   config_fct   new_fcompilert   distt   base_config_fct   macrost   include_dirst   extra_postargst   module_dirst   module_build_dirt   objectst   cxx_compilert   cxx_objectst	   f_objectst   existing_modulest   ft   tt   clib_librariest   lnamet   binfodst_namehave_runnew_c_libs_f77_compilerbuild_extensiondetect_languagebuild_extensionsneed_cxx_compilerneed_f77_compilerget_export_symbolslink_shared_object_gfortran_workaround_add_dummy_mingwex_sym_libs_with_msvc_and_fortranupdating extension %r libraries from %r to %rgfortran_vs2003_hack.cextension %r has C++ libraries but no C++ linker found, using default linkerf77_compiler=%s is not available.building '%s' extensionbuild_clib already run, it is too late to ensure in-place build of build_clibin 'ext_modules' option (extension '%s'), 'sources' must be present and must be a list of source filenames Modified version of build_ext that handles fortran source files.

numpy.distutils.command.build_extextension %r has C++ sourcesbut no C++ compiler foundextension %r has Fortran libraries but no Fortran linker found, using default linkerf90_compiler=%s is not available.resetting extension %r language from %r to %r.library %r defined more than once, overwriting build_info
%s... 
with
%s.../Zm1000skipping '%s' extension (up-to-date)build C/C++/F extensions (compile/link to build directory)extension %r has Fortran sources but no Fortran compiler found/usr/lib/python2.7/dist-packages/numpy/distutils/command/build_ext.pyextending extension %r defined_macros with %r(#   t   selft   extt   sourcest   fullnamet   modpatht   packaget   baset   build_pyt   package_dirt   ext_filenamet   dependst
   extra_argst   macrost   undeft	   c_sourcest   cxx_sourcest	   f_sourcest   fmodule_sourcest	   fcompilert   cxx_compilert   kwst
   output_dirt   include_dirst	   c_objectst   extra_postargst	   f_objectst   module_dirst   module_build_dirt   existing_modulest   ft   tt   objectst	   librariest   library_dirst   linker(   t   selft
   build_clibt   new_compilert   new_fcompilert   compiler_typet   clibst   libnamet
   build_infot   all_languagest   extt   ext_languagest   c_libst
   c_lib_dirst   macrost   binfot   mt   lt
   new_c_libst   ext_languaget   need_f90_compilert   need_f77_compilert   need_cxx_compilert   compilert   ctypet	   fcompilerfind_modulesfind_package_modulesdistutils.command.build_py/usr/lib/python2.7/dist-packages/numpy/distutils/command/build_py.pynumpy.distutils.command.build_pygenerate_scripts Modified version of build_scripts that handles building scripts from functions.

/usr/lib/python2.7/dist-packages/numpy/distutils/command/build_scripts.py  adding '%s' to scriptsnumpy.distutils.command.build_scriptstyp2Pyrexoutstrpkg_pathswig_cppf2pyflagsfinalizedswigflagsnum_errorsext_packageinstall_cmdlibname_infopyrex_resultbuild_sourcesgenerated_dirpyrex_sourcesext_target_dirfilter_h_filesgenerated_pathdefault_optionsfilter_py_filesfull_install_dirgenerate_sourcestemplate_sourcesCompilationOptionsbuild_npy_pkg_config_build_npy_pkg_configbuild_library_sourcesbuild_extension_sourcesgenerate_a_pyrex_sourcebuild_data_files_sourcesbuild_py_modules_sources[	   (   s
   build-src=t   ds   directory to "build" sources to(   s
   f2py-opts=Ns!   list of f2py command line options(   s   swig=Ns   path to the SWIG executable(   s
   swig-opts=Ns!   list of SWIG command line options(   s   swig-cppNsA   make SWIG create C++ files (default is autodetected from sources)(   s
   f2pyflags=Ns3   additional flags to f2py (use --f2py-opts= instead)(   s
   swigflags=Ns3   additional flags to swig (use --swig-opts= instead)(   s   forcet   fs2   forcibly build everything (ignore file timestamps)(   s   inplacet   isi   ignore build-lib and put compiled extensions into the source directory alongside your pure Python modules.hppignoring --f2pyflags as --f2py-opts already usedf2py target_c file %r not foundfrom_template:> %s  skipping '%s' f2py interface (up-to-date)/usr/lib/python2.7/dist-packages/numpy/distutils/command/build_src.py  skipping f2py fortran files for '%s' (up-to-date)%r missingf2py options: %sPyrex required for compiling %r but not available, using old target %rresetting swig target to c++ (some targets may have .c extension)  target %s does not exist:
   Assuming %s_wrap.{c,cpp} was generated with "build_src --inplace" command.building library "%s" sourcesassuming that %r has c++ swig target  source %s does not exist: skipping swig'ing.  adding '%s' to sources.@([a-zA-Z_]+)@using "%s=%s" option from build_ext commandbuilding data_files sources-python\s*%module\s*(.*\(\s*package\s*=\s*"(?P<package>[\w_]+)".*\)|)\s*(?P<name>[\w_]+)%d errors while compiling %r with Pyrexonly one .pyf file is allowed per extension module but got more: %r-outdirexpected %r but source %r defines %r swig targetbuilding py_modules sources\s*python\s*module\s*(?P<name>[\w_]+)  source %s does not exist: skipping f2py'ing.-[*]-\s*c\s*-[*]-%s_wrap%sPyrex.Compiler.Main  adding '%s' to include_dirs.  skipping '%s' swig interface (up-to-date)f2py target_h file %r not foundf2py target file %r not generatedbuild_src: building npy-pkg config files.src-[*]-\s*c[+][+]\s*-[*]--f2pywrappers.fbuilding extension "%s" sources-c++build sources from SWIG, F2PY files or a functionpyrexc:> %sboth build_src and build_ext define %s optionPyrex required for compiling %r but notavailableignoring --swigflags as --swig-opts already used\s*python\s*module\s*(?P<name>[\w_]*?__user__[\w_]*)  target %s does not exist:
   Assuming %smodule.c was generated with "build_src --inplace" command.f2py: %smismatch of extension names: %s provides %r but expected %r-f2pywrappers2.f90conv_template:> %s.*[.](inc|h|hpp)\Z%s - nothing done with h_files = %sSubstitute any occurence of @foo@ by d['foo'] from source file into
    target. Build swig, f2py, pyrex sources.
f2py:> %ssource %r does not define swig target, assuming %s swig target@%s@   Yes! Using %r as up-to-date target.(   t   selft   sourcest	   extensiont   new_sourcest   swig_sourcest   swig_targetst   target_dirst   py_filest
   target_extt   typt   is_cppt	   skip_swigt   ext_namet   sourcet   baset   extt
   target_dirt   py_target_dirt   namet   typ2t   target_filet   dt   swigt   swig_cmdt   targett   depends(   t   selft   sourcest	   extensiont   new_sourcest   f2py_sourcest	   f_sourcest   f2py_targetst   target_dirst   ext_namet	   skip_f2pyt   sourcet   baset   extt
   target_dirt   namet   target_filet   dt   f2py_optionst
   build_infot   dependss   numpyt   target_ct   target_ht   source_ct   source_ht   name_extt   filenameSIGINTtry_runWTERMSIGtry_linkcheck_declcheck_funccheck_typesys_stdoutWIFSIGNALED_wrap_methodcheck_headercheck_type_sizecheck_funcs_oncecheck_macro_trueCheck type availability. Return True if the type can be compiled,
        False otherwise
typedef %(type)s npy_check_sizeof_type;
int main ()
{
    static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) <= %(size)s)];
    test_array [0] = 0

    ;
    return 0;
}
  %s(%s);
+++++++++++++++++++++++++++++++++++++++++++++++++
Usage of get_output is deprecated: please do not 
use it anymore, and avoid configuration checks 
involving running executable on the target machine.
+++++++++++++++++++++++++++++++++++++++++++++++++
distutils.command.config  %s;#ifdef _MSC_VERCheck a list of functions at once.

        This is useful to speed up things, since all the functions in the funcs
        list will be put in one compilation unit.

        Arguments
        ---------
        funcs : seq
            list of functions to test
        include_dirs : seq
            list of header paths
        libraries : seq
            list of libraries to link the code snippet to
        libraru_dirs : seq
            list of library paths
        decl : dict
            for every (key, value), the declaration in the value will be
            used for function in key. If a function is not in the
            dictionay, no declaration will be used.
        call : dict
            for every item (f, value), if the value is True, a call will be
            done to the function f.
        /usr/lib/python2.7/dist-packages/numpy/distutils/command/config.pyReturn the inline keyword recognized by the compiler, empty string
        otherwise.Return True if the C compiler is gcc >= 4.Check size of a given type.Try to compile, link to an executable, and run a program
        built from 'body' and 'headers'. Returns the exit status code
        of the program and its output.
        #pragma function(%s)
+++++++++++++++++++++++++++++++++++++++++++++++++
Usage of try_run is deprecated: please do not 
use it anymore, and avoid configuration checks 
involving running executable on the target machine.
+++++++++++++++++++++++++++++++++++++++++++++++++

int main() {
  if ((%(name)s *) 0)
    return 0;
  if (sizeof (%(name)s))
    return 0;
}

int main()
{
#ifndef %s
    (void) %s;
#endif
    ;
    return 0;
}
typedef %(type)s npy_check_sizeof_type;
int main ()
{
    static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
    test_array [0] = 0

    ;
    return 0;
}
success!Could not initialize compiler instance: do you have Visual Studio
installed ? If you are trying to build with mingw, please use python setup.py
build -c mingw32 instead ). If you have Visual Studio installed, check it is
correctly installed, and the right version (VS 2008 for python 2.6, VS 2003 for
2.5, etc...). Original exception was: %s, and the Compiler
class was %s
============================================================================/* we need a dummy line to make distutils happy */
int main()
{
#if %s
#else
#error false or undefined macro
#endif
    ;
    return 0;
}subprocess exited with signal %dint main (void) {int %s (void);
typedef %(type)s npy_check_sizeof_type;
int main ()
{
    static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == %(size)s)];
    test_array [0] = 0

    ;
    return 0;
}
f77execf90exec[
   (   s
   fcompiler=Ns   specify Fortran compiler type(   s   f77exec=Ns   specify F77 compiler command(   s   f90exec=Ns   specify F90 compiler command(   s	   f77flags=Ns   specify F77 compiler flags(   s	   f90flags=Ns   specify F90 compiler flags(   s   opt=Ns   specify optimization flags(   s   arch=Ns0   specify architecture specific optimization flags(   s   debugt   gs"   compile with debugging information(   s   nooptNs   compile without optimization(   s   noarchNs+   compile without arch-dependent optimization  commands have different --%s options: %s, using first in list as default Distutils command to hold user specified options
    to Fortran compilers.

    config_fc command is used by the FCompiler.customize() method.
    /usr/lib/python2.7/dist-packages/numpy/distutils/command/config_compiler.pyspecify C/C++ compiler informationunifing config_cc, config, build_clib, build_ext, build commands --compiler optionsspecify C/C++ compiler type Distutils command to hold user specified options
    to C/C++ compilers.
    unifing config_fc, config, build_clib, build_ext, build commands --fcompiler optionsspecify Fortran 77/Fortran 90 compiler information Override the develop command from setuptools so we can ensure that our
generated files (from build_src or build_scripts) are properly converted to real
files with filenames.

numpy.distutils.command.develop/usr/lib/python2.7/dist-packages/numpy/distutils/command/develop.py/usr/lib/python2.7/dist-packages/numpy/distutils/command/egg_info.pynumpy.distutils.command.egg_infosetuptools_runnumpy.distutils.command.install/usr/lib/python2.7/dist-packages/numpy/distutils/command/install.py The setuptools version of the .run() method.

        We must pull in the entire code so we can override the level used in the
        _getframe() call since we wrap this call by one more level.
        re-writing list of installed files to '%s'build_clib_cmdnumpy.distutils.command.install_clib/usr/lib/python2.7/dist-packages/numpy/distutils/command/install_clib.pyCommand to install installable C libraries/usr/lib/python2.7/dist-packages/numpy/distutils/command/install_data.pydistutils.command.install_datanumpy.distutils.command.install_datadistutils.command.install_headers/usr/lib/python2.7/dist-packages/numpy/distutils/command/install_headers.pynumpy.distutils.command.install_headershas_headershas_data_files/usr/lib/python2.7/dist-packages/numpy/distutils/command/sdist.pynumpy.distutils.command.sdistSmall modules to cope with python 2 vs 3 incompatibilities inside
numpy.distutils

/usr/lib/python2.7/dist-packages/numpy/distutils/compat.pynewenvnumrependlineloopbegloopendnewcodeex_namesNo substitution variables found
/*
 *****************************************************************************
 **       This file was autogenerated from a template  DO NOT EDIT!!!!      **
 **       Changes should be made to the original source (.src) file         **
 *****************************************************************************
 */

/**end repeat**//usr/lib/python2.7/dist-packages/numpy/distutils/conv_template.py
takes templated file .xxx.src and produces .xxx file  where .xxx is
.i or .c or .h, using the following template rules

/**begin repeat  -- on a line by itself marks the start of a repeated code
                    segment
/**end repeat**/ -- on a line by itself marks it's end

After the /**begin repeat and before the */, all the named templates are placed
these should all have the same number of replacements

Repeat blocks can be nested, with each nested block labeled with its depth,
i.e.
/**begin repeat1
 *....
 */
/**end repeat1**/

When using nested loops, you can optionally exlude particular
combinations of the variables using (inside the comment portion of the inner loop):

 :exclude: var1=value1, var2=value2, ...

This will exlude the pattern where var1 is value1 and var2 is value2 when
the result is being generated.


In the main body each replace will use one entry from the list of named replacements

 Note that all #..# forms in a block must have the same number of
   comma-separated entries.

Example:

    An input file containing

        /**begin repeat
         * #a = 1,2,3#
         * #b = 1,2,3#
         */

        /**begin repeat1
         * #c = ted, jim#
         */
        @a@, @b@, @c@
        /**end repeat1**/

        /**end repeat**/

    produces

        line 1 "template.c.src"

        /*
         *********************************************************************
         **       This file was autogenerated from a template  DO NOT EDIT!!**
         **       Changes should be made to the original source (.src) file **
         *********************************************************************
         */

        #line 9
        1, 1, ted

        #line 9
        1, 1, jim

        #line 9
        2, 2, ted

        #line 9
        2, 2, jim

        #line 9
        3, 3, ted

        #line 9
        3, 3, jim

#line 1 "%s"
%s#line %d
/**begin repeat%d#\s*(\w*)\s*=([^#]*)#Mismatch in number of values:
%s = %s(\w*)=(\w*)[(]([^)]*)[)]\*(\d+)(\n|\A)#include\s*['\"](?P<name>[\w\d./\\]+[.]src)['\"]Find all named replacements in the header

    Returns a list of dictionaries, one for each loop iteration,
    where each key is a name to be substituted and the corresponding
    value is the replacement string.

    Also return a list of exclusions.  The exclusions are dictionaries
     of key value pairs. There can be more than one exclusion.
     [{'var1':'value1', 'var2', 'value2'[,...]}, ...]

    \n\s*\*?In "%s" loop at %s([^*]+)\*(\d+)/**end repeat%d**/@([\w]+)@line %d: %sline %d: no definition of key "%s"
    The returned line number is from the beginning of the string, starting
    at zero. Returns an empty list if no loops found.

    (   t   astrt   envt   levelt   linet   linenot   replacet   codet   structt   oldendt   newlevelt   subt   preft   headt   textt   newlinet   envlistt   et   msgt   newenvt   newcodet   sufflibitemold_distold_stopcommandlinedisplay_options_setup_stop_afterdisplay_option_names--help Return True if command line does not contain any
    help or display requests.
    [1] libraries list contains %r with no build_info[0] libraries list contains %r with different build_info[3] libraries list contains %r with different build_info[2] libraries list contains %r with no build_infoinvalid description of extension module library %r[4] libraries list contains %r with no build_info/usr/lib/python2.7/dist-packages/numpy/distutils/core.pyEV4EV5FMLMDLSTP603e604eEV56SUNWi486phndpkeysrchsun4vtpePCA56nbitsorionsparcNumCPUget_ipis_AMDEnumKeyMACHINEOpenKey_is_AMD_is_EV4_is_EV5_is_ppcsparcv7sparcv8sparcv9uname_Xuname_iuname_mStepping_has_mmx_has_sse_is_EV56_is_IP19_is_IP20_is_IP21_is_IP22_is_IP24_is_IP25_is_IP26_is_IP27_is_IP28_is_IP30_is_IP32_is_SUNW_is_XEON_is_Xeon_is_i386_is_i486_is_i586_is_i686_is_sun4f00f_bugfdiv_bughas_sse3is_AMD64is_Alphais_Core2is_IntelEnumValueProcessorWIFEXITED__cputype__machine_getNCPUs_has_sse2_has_sse3_is_32bit_is_64bit_is_AMD64_is_AMDK5_is_AMDK6_is_AMDK7_is_Alpha_is_Am486_is_Core2_is_Intel_is_PCA56_is_r2000_is_r3000_is_r3900_is_r4000_is_r4100_is_r4300_is_r4400_is_r4600_is_r4650_is_r5000_is_r6000_is_r8000_is_sparc_is_ultra_not_impl_try_callhas_ssse3isainfo_bisainfo_nprocessorsysctl_hwvendor_idIdentifierPROCESSORS_has_3dnow_has_ssse3_is_Am5x86_is_Hammer_is_Nocona_is_ppc403_is_ppc505_is_ppc601_is_ppc602_is_ppc603_is_ppc604_is_ppc620_is_ppc630_is_ppc740_is_ppc750_is_ppc801_is_ppc821_is_ppc823_is_ppc860_is_r10000_is_r12000_is_rorion_is_ultra1_is_ultra2_is_ultra4_is_ultra5__get_nbits_is_AMDK6_2_is_AMDK6_3_is_Celeron_is_IP22_4k_is_IP22_5k_is_IP32_5k_is_Itanium_is_Opteron_is_Pentium_is_ppc603e_is_ppc604e_is_ppc7400_is_ppc7450_is_sparcv9_is_sunfire_is_ultra30_is_ultra60_is_ultra80is_Pentium4is_PentiumMAuthenticAMDGenuineIntel_is_Athlon64_is_AthlonHX_is_AthlonK6_is_AthlonK7_is_AthlonMP_is_IP32_10k_is_PentiumM_is_Prescott_is_ultra250is_PentiumIV_has_3dnowext_has_f00f_bug_has_fdiv_bug_is_PentiumII_is_PentiumIV_is_singleCPU_is_ultra5_10NUM_PROCESSORS_is_AthlonK6_2_is_AthlonK6_3_is_PentiumIII_is_PentiumMMX_is_PentiumPro_is_cpusparcv7_is_cpusparcv8_is_cpusparcv9VendorIdentifier_is_sparcstation5HKEY_LOCAL_MACHINE_is_Power_Macintosh_is_ultraenterprice_IRIXCPUInfo__cputype_IRIXCPUInfo__machine_is_ultraenterprice10k_CPUInfoBase__get_nbits_DarwinCPUInfo__machineisainfo -nisainfo -b.*?XEON\b.*Ultra.*?\b3dnow\b.*?Pentium.*?\bssse3\b.*?Athlon\(tm\) 64\b.*Ultra-60.*?Itanium\b.*?\bpni\br%s.*Ultra-1Power Macintosh.*?Hammer\b.*Sun-Firefamily\s+(?P<FML>\d+)\s+model\s+(?P<MDL>\d+)\s+stepping\s+(?P<STP>\d+)hw.machine.*?Pentium.*?M\b.*?Core\(TM\)2\buname -mppc%s.*?Celeron.*Ultra-2.*?Athlon\(tm\) MP\b.*?\bmmx\b.*?Athlon HX\bHolds CPU information and provides methods for requiring
    the availability of various CPU features.
    cpu family.*?Pentium.*?II\bsysctl hwpsrinfo -v 0HARDWARE\DESCRIPTION\System\CentralProcessor\s*The (?P<p>[\w\d]+) processor operates at.*?Pentium.*?(IV|4)\b.*?Pentium.*?MMX\b(ignoring)ip%s.*Ultra-30.*Ultra-250.*?AMD-K6
cpuinfo

Copyright 2002 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@cens.ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy (BSD style) license.  See LICENSE.txt that came with
this distribution for specifics.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
Pearu Peterson

.*Ultra-5cpu model.*?PentiumPro\buname -X.*?\bsse2\b.*Ultra-80.*SPARCstation-5.*Ultra-Enterprise.*Ultra-5_10.*Ultra-Enterprise-10000.*?AMD-K7.*?\bsse\b.*?\b3dnowext\b/usr/lib/python2.7/dist-packages/numpy/distutils/cpuinfo.py.*Ultra-4model name/proc/cpuinfo.*?Pentium.*?III\b.*?Opteron\b(\d+)bithw.ncpu.*?\blm\b_get_var_conf_keys_hook_handlerdump_variabledump_variables_distutils_section%s.%s:/usr/lib/python2.7/dist-packages/numpy/distutils/environment.py  hook   : %s  config : %s  environ: %sAAABBBHeydosos2TereX_OKdup2echoHeipaHelloSHELLPYTHONP_WAITCOMSPECPYTHONWcmdfiledefpathspawnvestsfiletest_clspawnvpetest_svnpython_execommand_strstatus_textsplitcmdlineextra_suffixestest_execute_inusing_cygwin_echothis_is_not_a_command.bat%s -c "import sys;sys.exit(15)"sys.path.insert(0,%r)
/usr/lib/python2.7/dist-packages/numpy/distutils/exec_command.py -c "import os;print os.environ.get('AAA','')"%s -c "print open(%r,'r').read()"python -c "raise 'Ignore me.'"Found executable %secho "$BBB"_preserve_environment(%r)echo path=%path%python -c "import sys,os;sys.stderr.write(os.name)"| tr -cd "\n" | tr "\n" "."; echo/bin/shfrom exec_command import exec_command
echo "$AAA"%r is not a filesvn ok( %s ; echo $? > %s ) 2>&1 | tee %s %sf=open(%r,"w")
f.write(o)
f.close()
Retaining cwd: %sRunning %s(%s,%r,%r,os.environ)os.environ = %r
_exec_command(...)del sys.path[0]
Could not locate executable %s%s -c "import sys;sys.stderr.write('0');sys.stderr.write('1');sys.stderr.write('2')"python -c "import sys;sys.stderr.write('0');sys.stderr.write('1');sys.stderr.write('2')"%s -c "print 'Heipa'"Running os.system(%r)splitcmdline is deprecated; use shlex.splitNew cwd: %s%r failedexec_command(%r,%s)python -c "import sys;sys.exit(15)"exec_command tests for echo $AAA
exec_command

Implements exec_command function that is (almost) equivalent to
commands.getstatusoutput function but on NT, DOS systems the
returned status is actually correct (though, the returned status
values may be different by a factor). In addition, exec_command
takes keyword arguments for (re-)defining environment variables.

Provides functions:
  exec_command  --- execute command in a specified directory and
                    in the modified environment.
  find_executable --- locate a command using info from environment
                    variable PATH. Equivalent to posix `which`
                    command.

Author: Pearu Peterson <pearu@cens.ioc.ee>
Created: 11 January 2003

Requires: Python 2.x

Succesfully tested on:
  os.name | sys.platform | comments
  --------+--------------+----------
  posix   | linux2       | Debian (sid) Linux, Python 2.1.3+, 2.2.3+, 2.3.3
                           PyCrust 0.9.3, Idle 1.0.2
  posix   | linux2       | Red Hat 9 Linux, Python 2.1.3, 2.2.2, 2.3.2
  posix   | sunos5       | SunOS 5.9, Python 2.2, 2.3.2
  posix   | darwin       | Darwin 7.2.0, Python 2.3
  nt      | win32        | Windows Me
                           Python 2.3(EE), Idle 1.0, PyCrust 0.7.2
                           Python 2.1.1 Idle 0.8
  nt      | win32        | Windows 98, Python 2.1.1. Idle 0.8
  nt      | win32        | Cygwin 98-4.10, Python 2.1.1(MSC) - echo tests
                           fail i.e. redefining environment variables may
                           not work. FIXED: don't use cygwin echo!
                           Comment: also `cmd /c echo` will not work
                           but redefining environment variables do work.
  posix   | cygwin       | Cygwin 98-4.10, Python 2.3.3(cygming special)
  nt      | win32        | Windows XP, Python 2.3.3

Known bugs:
- Tests, that send messages to stderr, fail when executed from MSYS prompt
  because the messages are lost at some point.
 Return (status,output) of executed command.

    command is a concatenated string of executable and arguments.
    The output contains both stdout and stderr messages.
    The following special keyword arguments can be used:
      use_shell - execute `sh -c command`
      use_tee   - pipe the output of command through tee
      execute_in - before run command `cd execute_in` and after `cd -`.

    On NT, DOS systems the returned status is correct for external commands.
    Wild cards will not work for non-posix systems or when use_shell=0.
    _exec_command_posix(...)%s -c "print 'Ignore the following IOError:',open(%r,'r')"_update_environment(...)echo path=$PATH_exec_command_python(...)%s=%rfind_executable(%r)f=open(%r,"w")
f.write(str(s))
f.close()
( %s ; echo $? > %s ) > %s 2>&1 -c "import os;print os.environ.get('AAA')"Return full path of a executable or None.

    Symbolic links are not followed.
     -c "import os;print os.environ.get('BBB','')"echo Hellocl ok/VRestored cwd to %s%s -c "raise 'Ignore me.'"%s -c "import sys;sys.stderr.write(sys.platform)"
    Returns True if 'stream' supports the file descriptor and allows fileno().
    cmd = %r
_exec_command_posix failed (status=%s)Executable %s does not exists,o = exec_command(cmd, _with_python=0, **%r)
Using cygwin echo in win32 environment is not supportedpython -c "print 'Heipa'"(   t   commandt	   use_shellt   use_teet   envt   using_commandt   sht   argvt   spawn_commandt   _so_has_filenot   _se_has_filenot   so_flusht   se_flusht	   so_filenot   so_dupt	   se_filenot   se_dupt   outfilet   foutt   errfilet   ferrt   argv0t   statust   errmesst   texthas_f2py_sources/usr/lib/python2.7/dist-packages/numpy/distutils/extension.pydistutils.extension

Provides the Extension class, used to describe C/C++ extension
modules in setup scripts.

Overridden to support f2py.

swig_opts is specified as a string instead of a list(   t   selft   namet   sourcest   include_dirst   define_macrost   undef_macrost   library_dirst	   librariest   runtime_library_dirst   extra_objectst   extra_compile_argst   extra_link_argst   export_symbolst	   swig_optst   dependst   languaget   f2py_optionst   module_dirst   extra_f77_compile_argst   extra_f90_compile_argst   warningst   msg(   t   selft   namet   sourcest   include_dirst   define_macrost   undef_macrost   library_dirst	   librariest   runtime_library_dirst   extra_objectst   extra_compile_argst   extra_link_argst   export_symbolst	   swig_optst   dependst   languaget   f2py_optionst   module_dirst   extra_f77_compile_argst   extra_f90_compile_args<F77><F90>FOPTFARCHFDEBUGFFLAGSfcnamefdebugfflagso_argss_argsARFLAGSLDFLAGSarflagsld_argsldflagsopt_f77opt_f90set_exeF77FLAGSF90FLAGSarch_f77arch_f90FREEFLAGSdebug_f77debug_f90flag_varsget_flagspic_flagsEXECUTABLE_exe_cacheget_flags_print_helppython_expextra_flagsset_commandcommand_varscompiler_f77compiler_f90compiler_fixget_flags_arset_commandsstandard_lib_fix_lib_argsgenerate_helpget_flags_f77get_flags_f90get_flags_fixget_flags_opt_is_customiseddistutils_varsget_flags_archget_flags_freelanguage_orderlibrary_optionlibrary_switchpretty_printerset_executabledump_propertiesget_flags_debuglinker_so_flags_executable_keysexe_from_environget_library_dirslinker_exe_flags_command_property_environment_hookget_flags_opt_f77get_flags_opt_f90shared_lib_formatstatic_lib_format_get_command_flagsdummy_fortran_fileget_flags_arch_f77get_flags_arch_f90library_dir_optionupdate_executablesget_flags_debug_f77get_flags_debug_f90get_flags_linker_soverify_command_formget_flags_linker_exepossible_executablesstatic_lib_extensionmodule_include_switchsuggested_f90_compiler.F90.f95.f77.ftn{t   compiler_f77(   s   exe.compiler_f77s   F77s   f77execNt   compiler_fix(   s   exe.compiler_fixs   F90s   f90execNt   distutils_sections	   config_fct   ranlib(   Ns   RANLIBs   ranlibNt
   linker_exe(   s   exe.linker_exes   LDs   ldNt   archiver(   Ns   ARs   arNt   version_cmd(   s   exe.version_cmdNNNt	   linker_so(   s   exe.linker_sos   LDSHAREDs   ldsharedNt   compiler_f90(   s   exe.compiler_f90s   F90s   f90execN0{s   version_cmd[   s   f77s   -vs   compiler_fix[   s   f90s   -fixeds   ranlibNs
   linker_exe[   s   f90s   archiver[   s   ars   -crs   compiler_f77[   s   f77s	   linker_so[   s   f90s   -shareds   compiler_f90[   s   f900flags.debug_find_existing_fcompiler: compiler_type='%s' not foundList of Fortran 90 free format specific flags.List of compiler flags to compile with debugging information.flags.opt_f90:fixXXX: Fix module_include_switch for f90 not supported by %s needed for %sPrint list of available compilers (used by the "--help-fcompiler"
    option to "config_fc").
    flags.arch*.pyalias %r defined for both %s and %sFor compiler details, run 'config_fc --verbose' setup command.List of Fortran 90 specific flags.%s value %r is invalid in class %snumpy.distutils.fcompiler

Contains FCompiler, an abstract base class that defines the interface
for the numpy.distutils Fortran compiler abstraction model.

Terminology:

To be consistent, where the term 'executable' is used, it means the single
file, like 'gcc', that is executed, and should be a string. In contrast,
'command' means the entire command line, like ['gcc', '-c', 'file.c'], and
should be a list.

But note that FCompiler.executables is actually a dictionary of commands.

flags.f90Generate an instance of some FCompiler subclass for the supplied
    platform/compiler combination.
    flags.debug_f90XXX: module_build_dir=%r option ignoredunknown executable '%s' for class %sXXX: Fix module_dir_switch for -bI:%s instance properties:List of compiler libraries.List of architecture independent compiler flags.distutils.fancy_getoptCalled at the beginning of customisation. Subclasses should
        override this if they need to set up the executables dictionary.

        Note that self.find_executables() is run afterwards, so the
        self.executables dictionary values can contain <F77> or <F90> as
        the command, which will be replaced by the found F77 or F90
        compiler.
        %s does not support compiling f90 codes, skipping.List of architecture dependent compiler flags.:f77 with '%s' compiler.List of Fortran 77 specific flags.Compile 'src' to product 'obj'.List of compiler library directories.python.expflags.freeFortran compilers found:Customize Fortran compiler.

        This method gets Fortran compiler specific information from
        (i) class definition, (ii) environment, (iii) distutils config
        files, and (iv) command line (later overrides earlier).

        This method should be always called after constructing a
        compiler instance. But not in __init__ because Distribution
        instance is needed for (iii) and (iv).
        flags.opt_f77Determine the default Fortran compiler to use for the given
    platform.%s: no Fortran 77 compiler foundCompilers not available on this platform:flags.linker_soflags.f77List of flags common to all compiler types./usr/lib/python2.7/dist-packages/numpy/distutils/fcompilerflags.arch_f77%s: f90 nor f77XXX: module_dirs=%r option ignoredflags.arch_f90/usr/lib/python2.7/dist-packages/numpy/distutils/fcompiler/__init__.pylib%s%sCache all the FCompiler classes found in modules in the
    numpy.distutils.fcompiler package.
    
    Search the first 20 lines of fortran 77 code for line pattern
      `CF77FLAGS(<fcompiler type>)=<f77 flags>`
    Return a dictionary {<fcompiler type>:<f77 flags>}.
    -o self.get_flagsflags.debug_f77%s: no Fortran 90 compiler foundList of linker flags to build an executable.Compilers available for this platform, but not found:'output_dir' must be a string or Nonef90 (fixed) not supported by %s needed for %sTrying %r compiler as suggested by %r compiler for f90 support.List of Fortran 90 fixed format specific flags. Supported compilers are: %s)numpy.distutils.fcompiler.flags.linker_exeshow_fcompilers: %s not foundAbstract base class to define the interface that must be implemented
    by real Fortran compiler classes.

    Methods that subclasses may redefine:

        update_executables(), find_executables(), get_version()
        get_flags(), get_flags_opt(), get_flags_arch(), get_flags_debug()
        get_flags_f77(), get_flags_opt_f77(), get_flags_arch_f77(),
        get_flags_debug_f77(), get_flags_f90(), get_flags_opt_f90(),
        get_flags_arch_f90(), get_flags_debug_f90(),
        get_flags_fix(), get_flags_linker_so()

    DON'T call these methods (except get_version) after
    constructing a compiler instance or inside any other method.
    All methods, except update_executables() and find_executables(),
    may call the get_version() method.

    After constructing a compiler instance, always call customize(dist=None)
    method that finalizes compiler construction and makes the following
    attributes available:
      compiler_f77
      compiler_f90
      compiler_fix
      linker_so
      archiver
      ranlib
      libraries
      library_dirs
    Go through the self.executables dictionary, and attempt to
        find and assign appropiate executables.

        Executable names are looked for in the environment (environment
        variables, the distutils.cfg, and command line), the 0th-element of
        the command list, and the self.possible_executables list.

        Also, if the 0th element is "<F77>" or "<F90>", the Fortran 77
        or the Fortran 90 compiler executable is used, unless overridden
        by an environment setting.

        Subclasses should call this if overriden.
        _find_existing_fcompiler: compiler_type='%s' raised DistutilsModuleError:f90(c|)f77flags\s*\(\s*(?P<fcname>\w+)\s*\)\s*=\s*(?P<fflags>.*)don't know how to compile Fortran code on platform '%s'using compile options from source: %rList of archiver flags. List of linker flags to build a shared library.[^c*!]\s*[^\s\d\t]extra %s options: %rflags.fixPrint out the attributes of a compiler instance.      subroutine dummy()
      end
(   t   selft   distt   nooptt   noarcht   debugt   f77t   f90t   f77flagst   f90flagst	   freeflagst   fixflagst   fixt   oflagst   aflagst   dflagst	   get_flagst   fflagst	   linker_sot   linker_so_flagst
   python_libt	   ld_so_aixt
   python_expt
   linker_exet   linker_exe_flagst   art   arflags(   t   selft   target_desct   objectst   output_filenamet
   output_dirt	   librariest   library_dirst   runtime_library_dirst   export_symbolst   debugt   extra_preargst   extra_postargst
   build_tempt   target_langt   lib_optst   o_argst   ld_argst   linkert   commandt   msg(
   (   s   win32(	   s   gnus   intelvs   absofts   compaqvs   intelevs   gnu95s   g95s   intelvems   intelem(   s   cygwin.*(   s   gnus   intelvs   absofts   compaqvs   intelevs   gnu95s   g95(   s   linux.*(   s   gnu95s   intels   laheys   pgs   absofts   nags   vasts   compaqs   inteles   intelems   gnus   g95s   pathf95(   s   darwin.*(   s   gnu95s   nags   absofts   ibms   intels   gnus   g95s   pg(   s   sunos.*(   s   suns   gnus   gnu95s   g95(   s   irix.*(   s   mipss   gnus   gnu95(   s   aix.*(   s   ibms   gnus   gnu95(   s   posix(   s   gnus   gnu95(   s   nt(   s   gnus   gnu95(   s   mac(   s   gnu95s   gnus   pglistrepl/usr/lib/python2.7/dist-packages/numpy/distutils/from_template.py__l%s Obtain a unique key given a dictionary.\><\s*((.*?))\s*> Return a list of tuples for each function or subroutine each
    tuple is the start and end of a subroutine or function to be
    expanded.
    @leftarrow@\,\A\s*(\w[\w\d]*)\s*\Z(\n|\A)\s*include\s*['\"](?P<name>[\w\d./\\]+[.]src)['\"]@rightarrow@
     $<%s>

process_file(filename)

  takes templated file .xxx.src and produces .xxx file where .xxx
  is .pyf .f90 or .f using the following template rules:

  '<..>' denotes a template.

  All function and subroutine blocks in a source file with names that
  contain '<..>' will be replicated according to the rules in '<..>'.

  The number of comma-separeted words in '<..>' will determine the number of
  replicates.

  '<..>' may have two different forms, named and short. For example,

  named:
   <p=d,s,z,c> where anywhere inside a block '<p>' will be replaced with
   'd', 's', 'z', and 'c' for each replicate of the block.

   <_c>  is already defined: <_c=s,d,c,z>
   <_t>  is already defined: <_t=real,double precision,complex,double complex>

  short:
   <s,d,c,z>, a short form of the named, useful when no <p> appears inside
   a block.

  In general, '<..>' contains a comma separated list of arbitrary
  expressions. If these expression must contain a comma|leftarrow|rightarrow,
  then prepend the comma|leftarrow|rightarrow with a backslash.

  If an expression matches '\<index>' then it will be replaced
  by <index>-th expression.

  Note that all '<..>' forms in a block must have the same number of
  comma-separated entries.

 Predefined named template rules:
  <prefix=s,d,c,z>
  <ftype=real,double precision,complex,double complex>
  <ftypereal=real,double precision,\0,\1>
  <ctype=float,double,complex_float,complex_double>
  <ctypereal=float,double,\0,\1>

\n     (\$|\*)\s*function\b<\s*(\w[\w\d]*)\s*>
<_c=s,d,c,z>
<_t=real,double precision,complex,double complex>
<prefix=s,d,c,z>
<ftype=real,double precision,complex,double complex>
<ctype=float,double,complex_float,complex_double>
<ftypereal=real,double precision,\0,\1>
<ctypereal=float,double,\0,\1>
<\s*(\w[\w\d]*)\s*=\s*(.*?)\s*>\A\\(?P<index>\d+)\ZNo replicates found for <%s><\1>Mismatch in number of replacements (base <%s=%s>) for <%s=%s>. Ignoring.(\n|\A)((     (\$|\*))|)\s*(subroutine|function)\b\n\s*end\s*(subroutine|function)\b.*(\n|\Z)@comma@
Enhanced distutils with Fortran compilers support and more.
/usr/lib/python2.7/dist-packages/numpy/distutils/info.py
        If we log WARN messages, log this message as a 'nice' anti-warn
        message.

        numpy.distutils.logset_threshold: setting threshold to DEBUG level, it can be changed only with force argumentset_threshold: not changing threshold from DEBUG level %s to %s/usr/lib/python2.7/dist-packages/numpy/distutils/log.pyexextgetnmmsvcvmanxmlnm_cmdwinsxsdlltooldllwrapdef_namedll_fileout_nameparse_nmsystem32nm_outputDEFAULT_NMDEF_HEADERSYSTEMROOTlinker_dllout_stringoutput_defgcc_versionmanifest_rcwinsxs_pathmsvcr_successmsvcr_versionmsvcr_dll_nameCygwinCCompilercygwinccompilerset_executables_find_dll_in_pathget_build_versionmsvcr_dbg_success__MSVCRT_VERSION___find_dll_in_winsxsCRT_ASSEMBLY_VERSION_gen_temp_sourcefileNPY_MINGW_USE_CUSTOM_MSVCRg++ -mno-cygwingcc -mno-cygwin -O2 -Wall -Wstrict-prototypesg++ -mno-cygwin -sharedgcc -ggcc -g -DDEBUG -DMS_WIN64 -O0 -Wall -Wstrict-prototypesgcc -g -sharedgcc -O2 -Wall -Wstrict-prototypesg++ -sharedgcc -g -mno-cygwingcc -g -DDEBUG -DMS_WIN64 -mno-cygwin -O0 -Wall -Wstrict-prototypesgcc -g -mno-cygwin -shared.rcReturn the rc file used to generate the res file which will be embedded
    as manifest for given manifest file name, of given type ('dll' or
    'exe').

    Parameters
    ----------
    name : str
            name of the manifest file to embed
    type : str {'dll', 'exe'}
            type of the binary which will embed the manifest

    .manifestSkip building msvcr library: "%s" exists
Support code for building Python extensions on Windows.

    # NT stuff
    # 1. Make sure libpython<version>.a exists for gcc.  If not, build it.
    # 2. Force windows to use gcc (we're struggling with MSVC and g77 support)
    # 3. Force windows to use g77

Version %d,%d of MSVCRT not supported yet A modified MingW32 compiler compatible with an MSVC built Python.

    --entry _DllMain@123.0.0Building import library (arch=AMD64): "%s" (from %s)libpython%d%d.apython%d%d.defCannot import msvcrt: using manifest will not be possibleGiven a dll file location,  get all its exported symbols and dump them
    into the given def file.

    The .def file will be overwritten^\s+\[([\s*[0-9]*)\] ([a-zA-Z0-9_]*)%s not found in %s2.91.570x%03i0distutils.cygwinccompilerDiscrepancy between linked msvcr (%d) and the one about to be embedded (%d)No symbols found in %s;CODE          PRELOAD MOVEABLE DISCARDABLE
Failed to build import library for gcc. Linking will fail.python%d%d.dll/usr/lib/python2.7/dist-packages/numpy/distutils/mingw32ccompiler.pymsver is the ms runtime version used for the MANIFEST.#include "winuser.h"
%d RT_MANIFEST %s\[Ordinal/Name Pointer\] TableBuilding msvcr library: "%s" (from %s)gcc -mno-cygwin -O2 -wSkip building msvcr library: custom functionality not presentGiven a major and minor version of the MSVCR, returns the
    corresponding XML file.Cannot build msvcr library: "%s" not foundBuilding import library (ARCH=x86): "%s"Looking for %sLIBRARY        %s
10.0.30319.460 Build the import libraries for Mingw32-gcc on Windows
    Skip building import library: "%s" exists<assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
  <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
    <security>
      <requestedPrivileges>
        <requestedExecutionLevel level="asInvoker" uiAccess="false"></requestedExecutionLevel>
      </requestedPrivileges>
    </security>
  </trustInfo>
  <dependency>
    <dependentAssembly>
      <assemblyIdentity type="win32" name="Microsoft.VC%(maj)d%(min)d.CRT" version="%(fullver)s" processorArchitecture="*" publicKeyToken="1fc8b3b9a1e18e3b"></assemblyIdentity>
    </dependentAssembly>
  </dependency>
</assembly>;DATA          PRELOAD SINGLE
dlltool --dllname %s --def %s --output-lib %sUnhandled arch %s8.0.50727.42(\d+\.\d+)
EXPORTS
python%d%d.libCannot build import library: "%s" not foundSymbol table not foundgcc -mno-cygwin -mdll -O2 -w -Wstrict-prototypes9.0.21022.8Type %s not supportedobjdump.exe%s -mno-cygwin -mdll -static %slib%s.def-dumpversionCVSscp1310140015001600apathnew_vnoisysetabsetafOSTYPE__OF__bgcodefdopenfgcodeMINGW32MSYSTEMabs_dirmsc_posmsc_vermsvcr70msvcr71msvcr80msvcr90rm_filetopdownmsvcr100old_pathsplittedtigetnumtigetstrUSE_COLORblue_textbranch_fnclose_fdsdict_keyshave_f77chave_f90clist_keyspathdrivesetuptermEXT_SUFFIX_dict_keys_list_keysconfig_cmdextra_keys_extra_keysadd_headersadd_libraryadd_scriptscaller_filedump_sourcefo_setup_pygnukfreebsdset_optionsyellow_text_add_libraryadd_data_dircaller_framecommonprefixfix_args_py2fix_args_py3get_languageget_mathlibsadd_data_filesadd_subpackageget_config_cmdget_subpackagemake_config_py_fix_paths_dictbranch_cache_fnpath_in_package_get_hg_revisionadd_include_dirsis_bootstrapping_get_svn_revisionadd_define_macrosadd_npy_pkg_configget_build_temp_dirmake_hg_version_pydefault_config_dictignore_setup_xxx_pymake_svn_version_pySVN_ASP_DOT_NET_HACK_optimize_data_filesadd_installed_libraryDistutilsInternalError_MSVCCompiler__versiongenerate_hg_version_pygenerate_svn_version_py_wildcard_get_subpackageadd_numarray_include_dirssimple_fortran_subroutinedelegate_options_to_subpackagesassume_default_configuration[(   s   Configurations   get_numpy_include_dirss   default_config_dicts   dict_appends
   appendpaths   generate_config_pys   get_cmds   allpaths   get_mathlibss   terminal_has_colorss   red_texts
   green_texts   yellow_texts	   blue_texts	   cyan_texts	   cyg2win32s   mingw32s   all_stringss   has_f_sourcess   has_cxx_sourcess   filter_sourcess   get_dependenciess   is_local_src_dirs   get_ext_source_filess   get_script_filess   get_lib_source_filess   get_data_filess   dot_joins	   get_frames
   minrelpaths   njoins   is_sequences	   is_strings   as_lists   gpathss   get_languages
   quote_argss   get_build_architectures   get_infos   get_pkg_info_get_configuration_from_setup_pyReturn path's Mercurial revision number.
        [%sm%s[0mReturn path relative to parent_path.
    ----->Return list of subpackage configurations.

        Parameters
        ----------
        subpackage_name : str or None
            Name of the subpackage to get the configuration. '*' in
            subpackage_name is handled as a wildcard.
        subpackage_path : str
            If None, then the path is assumed to be the local path plus the
            subpackage_name. If a setup.py file is not found in the
            subpackage_path, then a default configuration is used.
        parent_name : str
            Parent name.
        Return true when using mingw32 environment.
    either subpackage_name or subpackage_path must be specifiednot a string: %r*.hCreating %s (version=%r)
        subroutine simple
        end
        Get resources information.

        Return information (from system_info.get_info) for all of the names in
        the argument list in a single dictionary.
        Ignoring attempt to set %r (from %r to %r)Return path's SVN revision number.
        Add installable headers to configuration.

        Add the given sequence of files to the beginning of the headers list.
        By default, headers will be installed under <python-
        include>/<self.name.replace('.','/')>/ directory. If an item of files
        is a tuple, then its first argument specifies the actual installation
        location relative to the <python-include> path.

        Parameters
        ----------
        files : str or seq
            Argument(s) can be either:

                * 2-sequence (<includedir suffix>,<path to header file(s)>)
                * path(s) to header file(s) where python includedir suffix will
                  default to package name.
        %r is not a directoryDon't know about key=%rReturn version major and minor of compiler instance if it is
    MSVC, raise an exception otherwise.Join two or more pathname components +
    - convert a /-separated pathname to one using the OS's path separator.
    - resolve `..` and `.` from path.

    Either passing n arguments as in njoin('a','b'), or a sequence
    of n names as in njoin(['a','b']) is handled, or a mixture of such arguments.
    cannot fill pattern %r with %rGenerate config.py file containing system_info information
    used during building the package.

    Usage:
        config['py_modules'].append((packagename, '__config__',generate_config_py))
    Check for availability of Fortran 90 compiler.

        Use it inside source generating function to ensure that
        setup distribution instance has been initialized.

        Notes
        -----
        True if a Fortran 90 compiler is available (because a simple Fortran
        90 code was able to be compiled successfully)
        could not resolve pattern in %r: %rReturn the distutils distribution object for self.Unknown option: Appends a data function to the data_files list that will generate
        __svn_version__.py file to the current package directory.

        Generate package __svn_version__.py file from SVN revision number,
        it will be removed after python exits but will be available
        when sdist, etc commands are executed.

        Notes
        -----
        If __svn_version__.py existed before, nothing is done.

        This is
        intended for working with source directories that are in an SVN
        repository.
        Common implementation for add_library and add_installed_library. Do
        not use directly
        Generate and install a npy-pkg config file from a template.

        The config file generated from `template` is installed in the
        given install directory, using `subst_dict` for variable substitution.

        Parameters
        ----------
        template : str
            The path of the template, relatively to the current package path.
        install_dir : str
            Where to install the npy-pkg config file, relatively to the current
            package path.
        subst_dict : dict, optional
            If given, any string of the form ``@key@`` will be replaced by
            ``subst_dict[key]`` in the template file when installed. The install
            prefix is always available through the variable ``@prefix@``, since the
            install prefix is not easy to get reliably from setup.py.

        See also
        --------
        add_installed_library, get_info

        Notes
        -----
        This works for both standard installs and in-place builds, i.e. the
        ``@prefix@`` refer to the source directory for in-place builds.

        Examples
        --------
        ::

            config.add_npy_pkg_config('foo.ini.in', 'lib', {'foo': bar})

        Assuming the foo.ini.in file has the following content::

            [meta]
            Name=@foo@
            Version=1.0
            Description=dummy description

            [default]
            Cflags=-I@prefix@/include
            Libs=

        The generated file will have the following content::

            [meta]
            Name=bar
            Version=1.0
            Description=dummy description

            [default]
            Cflags=-Iprefix_dir/include
            Libs=

        and will be installed as foo.ini in the 'lib' subpath.

        
        Add library to configuration.

        Parameters
        ----------
        name : str
            Name of the extension.
        sources : sequence
            List of the sources. The list of sources may contain functions
            (called source generators) which must take an extension instance
            and a build directory as inputs and return a source file or list of
            source files or None. If None is returned then no sources are
            generated. If the Extension instance has no sources after
            processing all source generators, then no extension module is
            built.
        build_info : dict, optional
            The following keys are allowed:

                * depends
                * macros
                * include_dirs
                * extra_compiler_args
                * extra_f77_compiler_args
                * extra_f90_compiler_args
                * f2py_options
                * language

        Return path of the module given a frame object from the call stack.

    Returned path is relative to parent_path when given,
    otherwise it is absolute path.
    npy-pkg-config__all__ = ["get_info","show"]


    Return an info dict for a given C library.

    The info dict contains the necessary options to use the C library.

    Parameters
    ----------
    pkgname : str
        Name of the package (should match the name of the .ini file, without
        the extension, e.g. foo for the file foo.ini).
    dirs : sequence, optional
        If given, should be a sequence of additional directories where to look
        for npy-pkg-config files. Those directories are searched prior to the
        NumPy directory.

    Returns
    -------
    info : dict
        The dictionary with build information.

    Raises
    ------
    PkgNotFound
        If the package is not found.

    See Also
    --------
    Configuration.add_npy_pkg_config, Configuration.add_installed_library,
    get_pkg_info

    Examples
    --------
    To get the necessary information for the npymath library from NumPy:

    >>> npymath_info = np.distutils.misc_util.get_info('npymath')
    >>> npymath_info                                    #doctest: +SKIP
    {'define_macros': [], 'libraries': ['npymath'], 'library_dirs':
    ['.../numpy/core/lib'], 'include_dirs': ['.../numpy/core/include']}

    This info dict can then be used as input to a `Configuration` instance::

      config.add_extension('foo', sources=['foo.c'], extra_info=npymath_info)

    
    Container to hold information on an installable library.

    Parameters
    ----------
    name : str
        Name of the installed library.
    build_info : dict
        Dictionary holding build information.
    target_dir : str
        Absolute path specifying where to install the library.

    See Also
    --------
    Configuration.add_installed_library

    Notes
    -----
    The three parameters are stored as attributes with the same names.

    Configuration of _numpyconfig.h
    Return library info for the given package.

    Parameters
    ----------
    pkgname : str
        Name of the package (should match the name of the .ini file, without
        the extension, e.g. foo for the file foo.ini).
    dirs : sequence, optional
        If given, should be a sequence of additional directories where to look
        for npy-pkg-config files. Those directories are searched prior to the
        NumPy directory.

    Returns
    -------
    pkginfo : class instance
        The `LibraryInfo` instance containing the build information.

    Raises
    ------
    PkgNotFound
        If the package is not found.

    See Also
    --------
    Configuration.add_npy_pkg_config, Configuration.add_installed_library,
    get_info

    _version.py#define MATHLIBAppends a data function to the data_files list that will generate
        __hg_version__.py file to the current package directory.

        Generate package __hg_version__.py file from Mercurial revision,
        it will be removed after python exits but will be available
        when sdist, etc commands are executed.

        Notes
        -----
        If __hg_version__.py existed before, nothing is done.

        This is intended for working with source directories that are
        in an Mercurial repository.
        setup_%s.pyReturn the path where to find the npy-pkg-config directory.Subpackage %r configuration returned as %rResolve `..` and '.' from path.
    Return True if sources contains Fortran files Assuming default configuration (%s does not define configuration())Add data files to configuration data_files.

        Parameters
        ----------
        files : sequence
            Argument(s) can be either

                * 2-sequence (<datadir prefix>,<path to data file(s)>)
                * paths to data files where python datadir prefix defaults
                  to package dir.

        Notes
        -----
        The form of each element of the files sequence is very flexible
        allowing many combinations of where to get the files from the package
        and where they should ultimately be installed on the system. The most
        basic usage is for an element of the files argument sequence to be a
        simple filename. This will cause that file from the local path to be
        installed to the installation path of the self.name package (package
        path). The file argument can also be a relative path in which case the
        entire relative path will be installed into the package directory.
        Finally, the file can be an absolute path name in which case the file
        will be found at the absolute path name but installed to the package
        path.

        This basic behavior can be augmented by passing a 2-tuple in as the
        file argument. The first element of the tuple should specify the
        relative path (under the package install directory) where the
        remaining sequence of files should be installed to (it has nothing to
        do with the file-names in the source distribution). The second element
        of the tuple is the sequence of files that should be installed. The
        files in this sequence can be filenames, relative paths, or absolute
        paths. For absolute paths the file will be installed in the top-level
        package installation directory (regardless of the first argument).
        Filenames and relative path names will be installed in the package
        install directory under the path name given as the first element of
        the tuple.

        Rules for installation paths:

          #. file.txt -> (., file.txt)-> parent/file.txt
          #. foo/file.txt -> (foo, foo/file.txt) -> parent/foo/file.txt
          #. /foo/bar/file.txt -> (., /foo/bar/file.txt) -> parent/file.txt
          #. *.txt -> parent/a.txt, parent/b.txt
          #. foo/*.txt -> parent/foo/a.txt, parent/foo/b.txt
          #. */*.txt -> (*, */*.txt) -> parent/c/a.txt, parent/d/b.txt
          #. (sun, file.txt) -> parent/sun/file.txt
          #. (sun, bar/file.txt) -> parent/sun/file.txt
          #. (sun, /foo/bar/file.txt) -> parent/sun/file.txt
          #. (sun, *.txt) -> parent/sun/a.txt, parent/sun/b.txt
          #. (sun, bar/*.txt) -> parent/sun/a.txt, parent/sun/b.txt
          #. (sun/*, */*.txt) -> parent/sun/c/a.txt, parent/d/b.txt

        An additional feature is that the path to a data-file can actually be
        a function that takes no arguments and returns the actual path(s) to
        the data-files. This is useful when the data files are generated while
        building the package.

        Examples
        --------
        Add files to the list of data_files to be included with the package.

            >>> self.add_data_files('foo.dat',
            ...     ('fun', ['gun.dat', 'nun/pun.dat', '/tmp/sun.dat']),
            ...     'bar/cat.dat',
            ...     '/full/path/to/can.dat')                   #doctest: +SKIP

        will install these data files to::

            <package install directory>/
             foo.dat
             fun/
               gun.dat
               nun/
                 pun.dat
             sun.dat
             bar/
               car.dat
             can.dat

        where <package install directory> is the package (or sub-package)
        directory such as '/usr/lib/python2.4/site-packages/mypackage' ('C:
        \Python2.4 \Lib \site-packages \mypackage') or
        '/usr/lib/python2.4/site- packages/mypackage/mysubpackage' ('C:
        \Python2.4 \Lib \site-packages \mypackage \mysubpackage').
        Warning: %sAppend libraries, include_dirs to extension or library item.
        Apply glob to paths and prepend local_path if needed.

        Applies glob.glob(...) to each path in the sequence (if needed) and
        pre-pends the local_path if needed. Because this is called on all
        source lists, this allows wildcard characters to be specified in lists
        of sources for extension modules and libraries and scripts and allows
        path-names be relative to the source directory.

        Compiler instance is not msvc (%s)
def get_info(name):
    g = globals()
    return g.get(name, g.get(name + "_info", {}))

def show():
    for name,info_dict in globals().items():
        if name[0] == "_" or type(info_dict) is not type({}): continue
        print(name + ":")
        if not info_dict:
            print("  NOT AVAILABLE")
        for k,v in info_dict.items():
            v = str(v)
            if k == "sources" and len(v) > 200:
                v = v[:60] + " ...\n... " + v[-60:]
            print("    %s = %s" % (k,v))
    Determine language value (c,f77,f90) from sources revision="(?P<revision>\d+)"distutils distribution has been initialized, it may be too late to add a subpackage Return True if all items in lst are string objects. Use Configuration(%r,%r,top_path=%r) instead of deprecated default_config_dict(%r,%r,%r)distutils distribution has been initialized, it may be too late to add a library version = %r
/usr/lib/python2.7/dist-packages/numpy/distutils/misc_util.pyReturn frame object from call stack with given level.
    Try to get version string of a package.

        Return a version string of the current package or None if the version
        information could not be detected.

        Notes
        -----
        This method scans files named
        __version__.py, <packagename>_version.py, version.py, and
        __svn_version__.py for string variables version, __version\__, and
        <packagename>_version, until a version number is found.
        Return the MATHLIB line from numpyconfig.h
    No configuration returned, assuming unavailable.Return a list of Fortran f90 module names that
    given source file defines.
    /cygdriveGenerate package __config__.py file containing system_info
        information used during building the package.

        This file is installed to the
        package installation directory.

        Return a configuration dictionary for usage in
    configuration() function defined in file setup_<name>.py.
    Add paths to configuration include directories.

        Add the given sequence of paths to the beginning of the include_dirs
        list. This list will be visible to all extension modules of the
        current package.
        Return true if directory is local directory.
    mismatch of pattern_list=%s and path_list=%sAdd define macros to configuration

        Add the given sequence of macro name and value duples to the beginning
        of the define_macros list This list will be visible to all extension
        modules of the current package.
        non-existing path in %r: %rReturn four lists of filenames containing
    C, C++, Fortran, and Fortran 90 module sources,
    respectively.
    Inheriting attribute %r=%r from %rhg identify --numMSC v.
        Similar to add_library, but the specified library is installed.

        Most C libraries used with `distutils` are only used to build python
        extensions, but libraries built through this method will be installed
        so that they can be reused by third-party packages.

        Parameters
        ----------
        name : str
            Name of the installed library.
        sources : sequence
            List of the library's source files. See `add_library` for details.
        install_dir : str
            Path to install the library, relative to the current sub-package.
        build_info : dict, optional
            The following keys are allowed:

                * depends
                * macros
                * include_dirs
                * extra_compiler_args
                * extra_f77_compiler_args
                * extra_f90_compiler_args
                * f2py_options
                * language

        Returns
        -------
        None

        See Also
        --------
        add_library, add_npy_pkg_config, get_info

        Notes
        -----
        The best way to encode the options required to link against the specified
        C libraries is to use a "libname.ini" file, and use `get_info` to
        retrieve the required options (see `add_npy_pkg_config` for more
        information).

        .hgRecursively add files under data_path to data_files list.

        Recursively add files under data_path to the list of data_files to be
        installed (and distributed). The data_path can be either a relative
        path-name, or an absolute path-name, or a 2-tuple where the first
        argument shows where in the install directory the data directory
        should be installed to.

        Parameters
        ----------
        data_path : seq or str
            Argument can be either

                * 2-sequence (<datadir suffix>, <path to data directory>)
                * path to data directory where python datadir suffix defaults
                  to package dir.

        Notes
        -----
        Rules for installation paths:
          foo/bar -> (foo/bar, foo/bar) -> parent/foo/bar
          (gun, foo/bar) -> parent/gun
          foo/* -> (foo/a, foo/a), (foo/b, foo/b) -> parent/foo/a, parent/foo/b
          (gun, foo/*) -> (gun, foo/a), (gun, foo/b) -> gun
          (gun/*, foo/*) -> parent/gun/a, parent/gun/b
          /foo/bar -> (bar, /foo/bar) -> parent/bar
          (gun, /foo/bar) -> parent/gun
          (fun/*/gun/*, sun/foo/bar) -> parent/fun/foo/gun/bar

        Examples
        --------
        For example suppose the source directory contains fun/foo.dat and
        fun/bar/car.dat::

            >>> self.add_data_dir('fun')                       #doctest: +SKIP
            >>> self.add_data_dir(('sun', 'fun'))              #doctest: +SKIP
            >>> self.add_data_dir(('gun', '/full/path/to/fun'))#doctest: +SKIP

        Will install data-files to the locations::

            <package install directory>/
              fun/
                foo.dat
                bar/
                  car.dat
              sun/
                foo.dat
                bar/
                  car.dat
              gun/
                foo.dat
                car.dat
        Return True if sources contains C++ files "'Add extension to configuration.

        Create and add an Extension instance to the ext_modules list. This
        method also takes the following optional keyword arguments that are
        passed on to the Extension constructor.

        Parameters
        ----------
        name : str
            name of the extension
        sources : seq
            list of the sources. The list of sources may contain functions
            (called source generators) which must take an extension instance
            and a build directory as inputs and return a source file or list of
            source files or None. If None is returned then no sources are
            generated. If the Extension instance has no sources after
            processing all source generators, then no extension module is
            built.
        include_dirs :
        define_macros :
        undef_macros :
        library_dirs :
        libraries :
        runtime_library_dirs :
        extra_objects :
        extra_compile_args :
        extra_link_args :
        extra_f77_compile_args :
        extra_f90_compile_args :
        export_symbols :
        swig_opts :
        depends :
            The depends list contains paths to files or directories that the
            sources of the extension module depend on. If any path in the
            depends list is newer than the extension module, then the module
            will be rebuilt.
        language :
        f2py_options :
        module_dirs :
        extra_info : dict or list
            dict or list of dict of keywords to be appended to keywords.

        Notes
        -----
        The self.paths(...) method is applied to all lists that may contain
        paths.
        Add scripts to configuration.

        Add the sequence of files to the beginning of the scripts list.
        Scripts will be installed under the <prefix>/bin/ directory.

        Add a sub-package to the current Configuration instance.

        This is useful in a setup.py script for adding sub-packages to a
        package.

        Parameters
        ----------
        subpackage_name : str
            name of the subpackage
        subpackage_path : str
            if given, the subpackage path such as the subpackage is in
            subpackage_path / subpackage_name. If None,the subpackage is
            assumed to be located in the local path / subpackage_name.
        standalone : bool
        distutils distribution has been initialized, it may be too late to add an extension Convert a /-separated pathname to one using the OS's path separator.Assuming default configuration (%s/{setup_%s,setup}.py was not found)dir[\n\r]+(?P<revision>\d+)Not a directory, skipping# This file is generated by %s
Appending %s configuration to %s.*[.](f90|f95)\Z
        Returns the numpy.distutils config command instance.
        _numpyconfig.h not found in numpy include dirs %r%s=%r
Return the correct file extension for shared libraries.

    Parameters
    ----------
    is_python_ext : bool, optional
        Whether the shared library is a Python extension.  Default is False.

    Returns
    -------
    so_ext : str
        The shared library extension.

    Notes
    -----
    For Python shared libs, `so_ext` will typically be '.so' on Linux and OS X,
    and '.pyd' on Windows.  For Python >= 3.2 `so_ext` has a tag prepended on
    POSIX systems according to PEP 3149.  For Python 3.2 this is implemented on
    Linux, but not on OS X.

    Not existing data file:Return name of MSVC runtime library if Python was built with MSVC >= 7Return a directory name relative to top_path and
    files contained.
    (?:[~#]|\.py[co]|\.o)$branch.cache<-----

        Return a dictionary compatible with the keyword arguments of distutils
        setup function.

        Examples
        --------
        >>> setup(**config.todict())                           #doctest: +SKIP
        
        Return a path to a temporary directory where temporary files should be
        placed.
        Construct configuration instance of a package.

        package_name -- name of the package
                        Ex.: 'distutils'
        parent_name  -- name of the parent package
                        Ex.: 'numpy'
        top_path     -- directory of the toplevel package
                        Ex.: the directory where the numpy package source sits
        package_path -- directory of package. Will be computed by magic from the
                        directory of the caller module if not specified
                        Ex.: the directory where numpy.distutils is
        caller_level -- frame level to caller namespace, internal parameter.
        Return the processor architecture.

        Possible results are "Intel", "Itanium", or "AMD64".
        .*[.](f90|f95|f77|for|ftn|f)\Zsetup distribution instance not initialized
        Configure Configuration instance.

        The following options are available:
         - ignore_setup_xxx_py
         - assume_default_configuration
         - delegate_options_to_subpackages
         - quiet

        Apply glob to paths and prepend local_path if needed.
     bit (# It contains system_info results at the time of building this package.
Check for availability of Fortran 77 compiler.

        Use it inside source generating function to ensure that
        setup distribution instance has been initialized.

        Notes
        -----
        True if a Fortran 77 compiler is available (because a simple Fortran 77
        code was able to be compiled successfully).
        nmetanreqspkgdir_re_sub_raw_dataget_tokenhas_optionnext_token_init_parse_interpolateparse_sections_init_parse_varparse_variableswhitespace_split
    Parse a line from a config file containing compile flags.

    Parameters
    ----------
    line : str
        A single line containing one or more compile flags.

    Returns
    -------
    d : dict
        Dictionary of parsed flags, split into relevant categories.
        These categories are the keys of `d`:

        * 'include_dirs'
        * 'library_dirs'
        * 'libraries'
        * 'macros'
        * 'ignored'

    
    Exception thrown when there is a problem parsing a configuration file.

    Name: %sNo meta section found !%s.iniVersion: %s\$\{([a-zA-Z0-9_-]+)\}Requires: %s
    Object containing build information about a library.

    Parameters
    ----------
    name : str
        The library name.
    description : str
        Description of the library.
    version : str
        Version string.
    sections : dict
        The sections of the configuration file for the library. The keys are
        the section headers, the values the text under each header.
    vars : class instance
        A `VariableSet` instance, which contains ``(name, value)`` pairs for
        variables defined in the configuration file for the library.
    requires : sequence, optional
        The required libraries for the library to be installed.

    Notes
    -----
    All input parameters (except "sections" which is a method) are available as
    attributes of the same name.

    
    Container object for the variables defined in a config file.

    `VariableSet` can be used as a plain dictionary, with the variable names
    as keys.

    Parameters
    ----------
    d : dict
        Dict of items in the "variables" section of the configuration file.

    
    Return library info for a package from its configuration file.

    Parameters
    ----------
    pkgname : str
        Name of the package (should match the name of the .ini file, without
        the extension, e.g. foo for the file foo.ini).
    dirs : sequence, optional
        If given, should be a sequence of directories - usually including
        the NumPy base directory - where to look for npy-pkg-config files.

    Returns
    -------
    pkginfo : class instance
        The `LibraryInfo` instance containing the build information.

    Raises
    ------
    PkgNotFound
        If the package is not found.

    See Also
    --------
    misc_util.get_info, misc_util.get_pkg_info

    Examples
    --------
    >>> npymath_info = np.distutils.npy_pkg_config.read_config('npymath')
    >>> type(npymath_info)
    <class 'numpy.distutils.npy_pkg_config.LibraryInfo'>
    >>> print npymath_info
    Name: npymath
    Description: Portable, core math library implementing C99 standard
    Requires:
    Version: 0.1  #random

    Option %s (section [meta]) is mandatory, but not found
        Return the list of variable names.

        Parameters
        ----------
        None

        Returns
        -------
        names : list of str
            The names of all variables in the `VariableSet` instance.

        Could not find file(s) %sYou should import %s to get information on %s\$\{%s\}Exception raised when a package can not be located./usr/lib/python2.7/dist-packages/numpy/distutils/npy_pkg_config.py
        Return the section headers of the config file.

        Parameters
        ----------
        None

        Returns
        -------
        keys : list of str
            The list of section headers.

        Description: %sNo variables section found !scons_datahas_scons_scriptsnumpy_distribution/usr/lib/python2.7/dist-packages/numpy/distutils/numpy_distribution.pyMKLSRCvmlvrsAGG2msg3sdczBOOSTFFTW3blas1blas2blas3em64trfftwdrfftwgetenvsclauxslasrcsrfftwx86_64MKLROOTNUMERIXPTATLASUMFPACK_gdict_atlas_rf77blasmklrootptcblaspthreadsysfileBLAS_SRCOPENBLAS_lib_mklamd_libscz_lasrcf2py_dirget_libshas_infolib_infomkl_libspre_dirssd_lasrcset_infosrcs_dirver_infox11_libsWX_CONFIG_lib_listalapack_rblas_libscalc_infodefaultedfblas_srcget_pathslib_dirs2libdjbfftptf77blasuser_fileATLAS_INFOLAPACK_SRCPKG_CONFIGWX_RELEASEWX_VERSION_lib_atlas_lib_namescheck_libsgetbooleanld_so_confmkl_lapackEXEC_PREFIXGDK_VERSIONGTK_VERSIONSCIPY_AMD_HSCIPY_MKL_HXFT_VERSION_check_libs_lib_lapackcflags_flagcheck_libs2dir_env_varflapack_srcfound_libs1static_extsSCIPY_FFTW_Hdefault_dirsget_lib_dirsget_src_dirsmkl_lapack32mkl_lapack64py_pincl_dirumfpack_libsversion_flagATLAS_VERSIONSCIPY_DFFTW_HSCIPY_FFTW3_HSCIPY_SFFTW_Hcalc_ver_infonotfounderroropenblas_libsplat_specificrfftw_threadsSCIPY_DJBFFT_Hconfig_env_vardrfftw_threadsget_config_exeget_python_inclocal_prefixesopt_found_libssrfftw_threadsGDK_X11_VERSIONGTK_X11_VERSIONLD_LIBRARY_PATHSCIPY_UMFPACK_Hget_mkl_rootdirboost_python_srcget_include_dirsFREETYPE2_VERSIONappend_config_exeget_config_outputGDK_PIXBUF_VERSIONdefault_config_exelibrary_extensionsrelease_macro_nameversion_macro_namecalc_libraries_infosearch_static_firstATLAS_WITHOUT_LAPACKSCIPY_FFTW_THREADS_HSCIPY_DFFTW_THREADS_HSCIPY_SFFTW_THREADS_HATLAS_REQUIRES_GFORTRANATLAS_WITH_LAPACK_ATLASGDK_PIXBUF_XLIB_VERSIONfftw3.hdfftw threadsdfftw_threads.hdrfftw_threads.hdfftw.hdrfftw.hsfftw threadssfftw_threads.hsrfftw_threads.hbe verbose and print more messagessfftw.hsrfftw.hatlas*ATLAS*/usr/X11R6/include/usr/X11/include/usr/includefftc8.hfftfreq.h-Wl,-framework-Wl,vecLib[   {s   libs[   s   fftw3s   macros[   (   s   SCIPY_FFTW3_HNs   names   fftw3s   includes[   s   fftw3.h0{s   libs[   s   rfftws   fftws   macros[   (   s   SCIPY_FFTW_HNs   names   fftw2s   includes[   s   fftw.hs   rfftw.h0-Wl,Accelerate/usr/local/lib/opt/lib/opt/local/lib/sw/lib/usr/lib/X11/include/usr/include/X11/usr/X11R6/lib/usr/X11/lib/usr/local/include/opt/include/opt/local/include/ufsparse/sw/include/usr/include/suitesparse/usr/local/src/opt/src/sw/src
    Numeric (http://www.numpy.org/) module not found.
    Get it from above location, install it, and retry setup.py.wx-configc%s.f...
...
...
    FFTW (http://www.fftw.org/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [fftw]) or by setting
    the FFTW environment variable.-faltivecz%s.fgdk-pixbuf-2.0Returns a list of files named 'fname' from
    1) System-wide directory (directory-location of this module)
    2) Users HOME directory (os.environ['HOME'])
    3) Local directory
    
*********************************************************************
    Lapack library (from ATLAS) is probably incomplete:
      size of %s is %sk (expected >4000k)

    Follow the instructions in the KNOWN PROBLEMS section of the file
    numpy/INSTALL.txt.
*********************************************************************
/etc/ld.so.confnumerix selector must be either 'Numeric' or 'numarray' or 'numpy' but the value obtained from the %s was '%s'.
*****************************************************
Linkage with ATLAS requires gfortran. Use

  python setup.py config_fc --fcompiler=gnu95 ...

when building extension libraries that use ATLAS.
Make sure that -lgfortran is used for C++ extensions.
*****************************************************

        cgemm csymm ctrsm dsyrk sgemm strmm zhemm zsyr2k chemm csyr2k
        dgemm dtrmm ssymm strsm zher2k zsyrk cher2k csyrk dsymm dtrsm
        ssyr2k zherk ztrmm cherk ctrmm dsyr2k ssyrk zgemm zsymm ztrsm
        X11 libraries not found.libdjbfft.aX11/X.h
        cgbmv chpmv ctrsv dsymv dtrsv sspr2 strmv zhemv ztpmv cgemv
        chpr dgbmv dsyr lsame ssymv strsv zher ztpsv cgerc chpr2 dgemv
        dsyr2 sgbmv ssyr xerbla zher2 ztrmv cgeru ctbmv dger dtbmv
        sgemv ssyr2 zgbmv zhpmv ztrsv chbmv ctbsv dsbmv dtbsv sger
        stbmv zgemv zhpr chemv ctpmv dspmv dtpmv ssbmv stbsv zgerc
        zhpr2 cher ctpsv dspr dtpsv sspmv stpmv zgeru ztbmv cher2
        ctrmv dspr2 dtrmv sspr stpsv zhbmv ztbsv
        C:\--libs*.cpp
    DJBFFT (http://cr.yp.to/djbfft.html) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [djbfft]) or by setting
    the DJBFFT environment variable.dgesv.f?.?.?larfp.fusage: %prog [-v] [info objs]
    Atlas (http://math-atlas.sourceforge.net/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [atlas]) or by setting
    the ATLAS environment variable.
    Blas (http://www.netlib.org/blas/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [blas]) or by setting
    the BLAS environment variable.If static or shared libraries are available then return
        their info dictionary.

        Checks for all libraries as shared libraries first, then
        static (or vice versa if self.search_static_first is True).
        Output: %sFile not found: %s. Cannot determine %s info. srot srscl lc.f--modversionStatus: %d( %s = %s )
*********************************************************************
    Could not find lapack library within the ATLAS installation.
*********************************************************************
 Return a list of existing paths composed by all combinations of
        items from arguments.
     econd 
        gbbrd gbcon gbequ gbrfs gbsv gbsvx gbtf2 gbtrf gbtrs gebak
        gebal gebd2 gebrd gecon geequ gees geesx geev geevx gegs gegv
        gehd2 gehrd gelq2 gelqf gels gelsd gelss gelsx gelsy geql2
        geqlf geqp3 geqpf geqr2 geqrf gerfs gerq2 gerqf gesc2 gesdd
        gesv gesvd gesvx getc2 getf2 getrf getri getrs ggbak ggbal
        gges ggesx ggev ggevx ggglm gghrd gglse ggqrf ggrqf ggsvd
        ggsvp gtcon gtrfs gtsv gtsvx gttrf gttrs gtts2 hgeqz hsein
        hseqr labrd lacon laein lags2 lagtm lahqr lahrd laic1 lals0
        lalsa lalsd langb lange langt lanhs lansb lansp lansy lantb
        lantp lantr lapll lapmt laqgb laqge laqp2 laqps laqsb laqsp
        laqsy lar1v lar2v larf larfb larfg larft larfx largv larrv
        lartv larz larzb larzt laswp lasyf latbs latdf latps latrd
        latrs latrz latzm lauu2 lauum pbcon pbequ pbrfs pbstf pbsv
        pbsvx pbtf2 pbtrf pbtrs pocon poequ porfs posv posvx potf2
        potrf potri potrs ppcon ppequ pprfs ppsv ppsvx pptrf pptri
        pptrs ptcon pteqr ptrfs ptsv ptsvx pttrs ptts2 spcon sprfs
        spsv spsvx sptrf sptri sptrs stegr stein sycon syrfs sysv
        sysvx sytf2 sytrf sytri sytrs tbcon tbrfs tbtrs tgevc tgex2
        tgexc tgsen tgsja tgsna tgsy2 tgsyl tpcon tprfs tptri tptrs
        trcon trevc trexc trrfs trsen trsna trsyl trti2 trtri trtrs
        tzrqf tzrzf

        lacn2 lahr2 stemr laqr0 laqr1 laqr2 laqr3 laqr4 laqr5
        amd.hInvalid bit size in libpaths: 32 or 64 only--cflags  %s not found icmax1 scsum1 
        laexc lag2 lagv2 laln2 lanv2 laqtr lasy2 opgtr opmtr org2l
        org2r orgbr orghr orgl2 orglq orgql orgqr orgr2 orgrq orgtr
        orm2l orm2r ormbr ormhr orml2 ormlq ormql ormqr ormr2 ormr3
        ormrq ormrz ormtr rscl sbev sbevd sbevx sbgst sbgv sbgvd sbgvx
        sbtrd spev spevd spevx spgst spgv spgvd spgvx sptrd stev stevd
        stevr stevx syev syevd syevr syevx sygs2 sygst sygv sygvd
        sygvx sytd2 sytrd
        Specified path %s is invalid.umfpack.h
    Blas (http://www.netlib.org/blas/) sources not found.
    Directories to search for the sources can be specified in the
    numpy/distutils/site.cfg file (section [blas_src]) or by setting
    the BLAS_SRC environment variable.Find mandatory and optional libs in expected paths.

        Missing optional libraries are silently forgotten.
        gtk+-2.0  libraries %s not found in %s
    Lapack (http://www.netlib.org/lapack/) sources not found.
    Directories to search for the sources can be specified in the
    numpy/distutils/site.cfg file (section [lapack_src]) or by setting
    the LAPACK_SRC environment variable..numpy-site.cfg izmax1 dzsum1 Returns True on successful version detection, else FalseATLAS_(?P<version>\d+[.]\d+[.]\d+)_agg_win32_bmp.cpp/System/Library/Frameworks/Accelerate.framework/Replacing _lib_names[0]==%r with %rlamch.fagg_affine_matrix.cppReturn a list of library paths valid on 32 or 64 bit systems.

    Inputs:
      paths : sequence
        A sequence of strings (typically paths)
      bits : int
        An integer, the only valid values are 32 or 64.  A ValueError exception
      is raised otherwise.

    Examples:

    Consider a list of directories
    >>> paths = ['/usr/X11R6/lib','/usr/X11/lib','/usr/lib']

    For a 32-bit platform, this is already valid:
    >>> np.distutils.system_info.libpaths(paths,32)
    ['/usr/X11R6/lib', '/usr/X11/lib', '/usr/lib']

    On 64 bits, we prepend the '64' postfix
    >>> np.distutils.system_info.libpaths(paths,64)
    ['/usr/X11R6/lib64', '/usr/X11R6/lib', '/usr/X11/lib64', '/usr/X11/lib',
    '/usr/lib64', '/usr/lib']
    boost*-I/System/Library/Frameworks/vecLib.framework/Headersgtk+-x11-2.0/usr/lib/*/libX11.so
    notfound_action:
      0 - do nothing
      1 - display warning message
      2 - raise error
    daxpy.fgdk-x11-2.0d%s.f"\"%s\""-msse3
        ilaenv ieeeck lsame lsamen xerbla
        iparmq
        
        caxpy csscal dnrm2 dzasum saxpy srotg zdotc ccopy cswap drot
        dznrm2 scasum srotm zdotu cdotc dasum drotg icamax scnrm2
        srotmg zdrot cdotu daxpy drotm idamax scopy sscal zdscal crotg
        dcabs1 drotmg isamax sdot sswap zrotg cscal dcopy dscal izamax
        snrm2 zaxpy zscal csrot ddot dswap sasum srot zcopy zswap
        scabs1
        
    UMFPACK sparse solver (http://www.cise.ufl.edu/research/sparse/umfpack/)
    not found. Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [umfpack]) or by setting
    the UMFPACK environment variable.agg_platform_support.cpp(%s is None)
This file defines a set of system_info classes for getting
information about various resources (libraries, library directories,
include directories, etc.) in the system. Currently, the following
classes are available:

  atlas_info
  atlas_threads_info
  atlas_blas_info
  atlas_blas_threads_info
  lapack_atlas_info
  blas_info
  lapack_info
  openblas_info
  blas_opt_info       # usage recommended
  lapack_opt_info     # usage recommended
  fftw_info,dfftw_info,sfftw_info
  fftw_threads_info,dfftw_threads_info,sfftw_threads_info
  djbfft_info
  x11_info
  lapack_src_info
  blas_src_info
  numpy_info
  numarray_info
  numpy_info
  boost_python_info
  agg2_info
  wx_info
  gdk_pixbuf_xlib_2_info
  gdk_pixbuf_2_info
  gdk_x11_2_info
  gtkp_x11_2_info
  gtkp_2_info
  xft_info
  freetype2_info
  umfpack_info

Usage:
    info_dict = get_info(<name>)
  where <name> is a string 'atlas','x11','fftw','lapack','blas',
  'lapack_src', 'blas_src', etc. For a complete list of allowed names,
  see the definition of get_info() function below.

  Returned info_dict is a dictionary which is compatible with
  distutils.setup keyword arguments. If info_dict == {}, then the
  asked resource is not available (system_info could not find it).

  Several *_info classes specify an environment variable to specify
  the locations of software. When setting the corresponding environment
  variable to 'None' then the software will be ignored, even when it
  is available in system.

Global parameters:
  system_info.search_static_first - search static libraries (.a)
             in precedence to shared ones (.so, .sl) if enabled.
  system_info.verbosity - output the results to stdout if enabled.

The file 'site.cfg' is looked for in

1) Directory of main setup.py file being run.
2) Home directory of user running the setup.py file as ~/.numpy-site.cfg
3) System wide directory (location of this file...)

The first one found is used to get system configuration options The
format is that used by ConfigParser (i.e., Windows .INI style). The
section ALL has options that are the default for each section. The
available sections are fftw, atlas, and x11. Appropiate defaults are
used if nothing is specified.

The order of finding the locations of resources is the following:
 1. environment variable
 2. section in site.cfg
 3. ALL section in site.cfg
Only the first complete match is returned.

Example:
----------
[ALL]
library_dirs = /usr/lib:/usr/local/lib:/opt/lib
include_dirs = /usr/include:/usr/local/include:/opt/include
src_dirs = /usr/local/src:/opt/src
# search static libraries (.a) in preference to shared ones (.so)
search_static_first = 0

[fftw]
fftw_libs = rfftw, fftw
fftw_opt_libs = rfftw_threaded, fftw_threaded
# if the above aren't found, look for {s,d}fftw_libs and {s,d}fftw_opt_libs

[atlas]
library_dirs = /usr/lib/3dnow:/usr/lib/3dnow/atlas
# for overriding the names of the atlas libraries
atlas_libs = lapack, f77blas, cblas, atlas

[x11]
library_dirs = /usr/X11R6/lib
include_dirs = /usr/X11R6/include
----------

Authors:
  Pearu Peterson <pearu@cens.ioc.ee>, February 2002
  David M. Cooke <cookedm@physics.mcmaster.ca>, April 2002

Copyright 2002 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@cens.ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy (BSD style) license.  See LICENSE.txt that came with
this distribution for specifics.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.

Disabled %s: %sInfo classes not defined: %s
        bdsdc bdsqr disna labad lacpy ladiv lae2 laebz laed0 laed1
        laed2 laed3 laed4 laed5 laed6 laed7 laed8 laed9 laeda laev2
        lagtf lagts lamch lamrg lanst lapy2 lapy3 larnv larrb larre
        larrf lartg laruv las2 lascl lasd0 lasd1 lasd2 lasd3 lasd4
        lasd5 lasd6 lasd7 lasd8 lasd9 lasda lasdq lasdt laset lasq1
        lasq2 lasq3 lasq4 lasq5 lasq6 lasr lasrt lassq lasv2 pttrf
        stebz stedc steqr sterf

        larra larrc larrd larr larrk larrj larrr laneg laisnan isnan
        lazq3 lazq4
        Some third-party program or library is not found.--cxxflagsSetting %s=%s3.2.1_pre3.3.6s%s.fmodule.cpp
/* This file is generated from numpy/distutils/system_info.py */
void ATL_buildinfo(void);
int main(void) {
  ATL_buildinfo();
  return 0;
}
ATLAS version (?P<version>\d+[.]\d+[.]\d+)Library %s was not found. Ignoringagg2*undefined reference to `_gfortran drot drscl gdk-pixbuf-xlib-2.0undefined symbol: ATL_buildinfocblas.h  FOUND: get_info() is the only public method. Don't use others.
     Return a dictonary with items that are compatible
            with numpy.distutils.setup keyword arguments.
        -print-multiarchReturn a list of existing paths composed by all combinations
        of items from the arguments.
        lr.f/usr/lib/python2.7/dist-packages/numpy/distutils/system_info.py.dll.amkl*gdk-2.0--releaseIf static or shared libraries are available then return
        their info dictionary.

        Checks each library for shared or static.
        
    Lapack (http://www.netlib.org/lapack/) libraries not found.
    Directories to search for the libraries can be specified in the
    numpy/distutils/site.cfg file (section [lapack]) or by setting
    the LAPACK environment variable. secnd LAPACK*/SRC
        bdsqr hbev hbevd hbevx hbgst hbgv hbgvd hbgvx hbtrd hecon heev
        heevd heevr heevx hegs2 hegst hegv hegvd hegvx herfs hesv
        hesvx hetd2 hetf2 hetrd hetrf hetri hetrs hpcon hpev hpevd
        hpevx hpgst hpgv hpgvd hpgvx hprfs hpsv hpsvx hptrd hptrf
        hptri hptrs lacgv lacp2 lacpy lacrm lacrt ladiv laed0 laed7
        laed8 laesy laev2 lahef lanhb lanhe lanhp lanht laqhb laqhe
        laqhp larcm larnv lartg lascl laset lasr lassq pttrf rot spmv
        spr stedc steqr symv syr ung2l ung2r ungbr unghr ungl2 unglq
        ungql ungqr ungr2 ungrq ungtr unm2l unm2r unmbr unmhr unml2
        unmlq unmql unmqr unmr2 unmr3 unmrq unmrz unmtr upgtr upmtr
        (paths: %s)(   t   selft   src_dirst   src_dirt   dt   allauxt   lauxt   lasrct   sd_lasrct   cz_lasrct   sclauxt   dzlauxt   slasrct   dlasrct   clasrct   zlasrct   oclasrct   ozlasrct   ft   sourcest   src_dir2t   pt   info(   t   selft   lib_dirst   infot
   atlas_libst   lapack_libst   atlast   lapackt   atlas_1t   dt   lapack_atlast	   lib_dirs2t   include_dirst   ht   messaget
   lapack_dirt   lapack_namet
   lapack_libt   lib_prefixest   et   prefixt   fnt   szt   atlas_versiont   atlas_extra_infoaCC-AA-Ae
    Build a static library in a separate sub-process.

    Parameters
    ----------
    objects : list or tuple of str
        List of paths to object files used to build the static library.
    output_libname : str
        The library name as an absolute or relative (if `output_dir` is used)
        path.
    output_dir : str, optional
        The path to the output directory. Default is None, in which case
        the ``output_dir`` attribute of the UnixCCompiler instance.
    debug : bool, optional
        This parameter is not used.
    target_lang : str, optional
        This parameter is not used.

    Returns
    -------
    None

    -AaCompile a single source files with a Unix-style compiler.%s:@ %s/usr/lib/python2.7/dist-packages/numpy/distutils/unixccompiler.py
unixccompiler - can handle very long argument lists for ar.

%s: adding %d object files to %srestore_all
Aliases for functions which may be accelerated by Scipy.

Scipy_ can be built to use accelerated or otherwise improved libraries
for FFTs, linear algebra, and special functions. This module allows
developers to transparently support these accelerated functions when
scipy is available but still support users who have only installed
Numpy.

.. _Scipy : http://www.scipy.org

/usr/lib/python2.7/dist-packages/numpy/dual.py%s not a dual function.NamedTemporaryFile/usr/lib/python2.7/dist-packages/numpy/f2py -c -m %s %s %s%s -c "import numpy.f2py as f2py2e;f2py2e.main()" %s Build extension module from processing source with f2py.
    Read the source of this function for more information.
    /usr/lib/python2.7/dist-packages/numpy/f2py/__init__.pynumpy.f2py.__version__/usr/lib/python2.7/dist-packages/numpy/f2py/__version__.pyistruesize_tisfalseINTENT_COPTIONALINTENT_INismutablesupertextINTENT_OUTproto_argsINTENT_HIDEischaracterINTENT_CACHEINTENT_INOUThasvariablesINTENT_INPLACEissigned_arrayINTENT_ALIGNED4INTENT_ALIGNED8isunsignedarrayINTENT_ALIGNED16issigned_chararrayissigned_shortarrayhasinitvalueasstring#%s#

Auxiliary functions for f2py2e.

Copyright 1999,2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy (BSD style) LICENSE.


NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/07/24 19:01:55 $
Pearu Peterson

/*%s %s %s*/applyrules: ignoring rule %s.

	/* end multiline ()*/warning: callstatement is defined without callprotoargument
    **************************************************************
        Warning: code with a function returning complex value
        may not work correctly with your Fortran compiler.
        Run the following test before using it in your applications:
        $(f2py install dir)/test-site/{b/runme_scalar,e/runme}
        When using GNU gcc/g77 compilers, codes should work correctly.
    **************************************************************
%s,f%d=f[%d]f%d(v)numpy.f2py.auxfuncslambda v,f=f:not f(v)

  var = %s
  Message: %s
%s multiline block should end with `'''`: %s
) */
/usr/lib/python2.7/dist-packages/numpy/f2py/auxfuncs.py	/* start Failed to use fortranname from %s
ddimcbnamecbdocstrinoutputarrdocstrauxiliarycbnamekeycbsetdimsvarname_iMODULENAMEname_loweroutvarnamereturncptrvarrformatFORTRANNAMEcallbacknamepydocsignoutvardebuginfovarshowvalueF90MODULENAMEcblatexdocstrf90modulenametexmodulenameF2PY_INTENT_INcommon_sign2mapshowvalueformatF_WRAPPEDFUNC_UStexf90modulenamevardebugshowvalueinterface_usercoderoutdebugshowvalue{s   complex_doubles   NPY_CDOUBLEs   shorts	   NPY_SHORTs   signed_chars   NPY_BYTEs   strings   NPY_CHARs   long_doubles   NPY_LONGDOUBLEs   ints   NPY_INTs   unsigned_chars	   NPY_UBYTEs   floats	   NPY_FLOATs   unsigneds   NPY_UINTs   longs   NPY_LONGs   doubles
   NPY_DOUBLEs   chars   NPY_BYTEs   complex_floats
   NPY_CFLOATs   complex_long_doubles   NPY_CDOUBLEs	   long_longs   NPY_LONGLONGs   unsigned_longs	   NPY_ULONGs   unsigned_shorts
   NPY_USHORTs   unsigned_long_longs   NPY_ULONGLONG0{s   complex_doubles   NPY_CDOUBLEs   shorts	   NPY_SHORTs   signed_chars   NPY_BYTEs   strings   NPY_CHARs   long_doubles
   NPY_DOUBLEs   ints   NPY_INTs   unsigned_chars	   NPY_UBYTEs   floats	   NPY_FLOATs   unsigneds   NPY_UINTs   longs   NPY_LONGs   chars   NPY_CHARs   complex_floats
   NPY_CFLOATs   complex_long_doubles   NPY_CDOUBLEs	   long_longs   NPY_LONGs   doubles
   NPY_DOUBLEs   unsigned_shorts
   NPY_USHORT0{s   complex_doublet   Ns   shortt   hs   signed_chart   bs   stringt   zs   intt   is   doublet   ds   floatt   fs   longt   ls   charR   s   complex_floatR    s   complex_long_doubleR    s	   long_longt   L0{s   complex_doublet   Ds   shortt   ss   signed_chart   1s   stringt   cs   long_doublet   ds   intt   is   unsigned_chart   bs   floatt   fs   unsignedt   us   longt   ls   charR   s   complex_floatt   Fs   complex_long_doubleR    s	   long_longt   Ls   doubleR   s   unsigned_shortt   w0{s   complex_doublet   Ds   shortt   hs   signed_chart   bs   stringt   Ss   long_doublet   gs   intt   is   unsigned_chart   Bs   floatt   fs   unsignedt   Is   longt   ls   doublet   ds   charR   s   complex_floatt   Fs   complex_long_doublet   Gs	   long_longt   qs   unsigned_longt   Ls   unsigned_shortt   Hs   unsigned_long_longt   Q0{s   real{t    s   floatt   8s   doubles   12s   long_doublet   4s   floats   16s   long_double0s   double precision{R    s   double0s   complexkind{R    s   complex_floatR   s   complex_doubles   12s   complex_long_doubleR   s   complex_floats   16s   complex_long_double0s	   character{R    s   string0s   logical{t   1s   charR   s	   long_longt   2s   shortR   s   intR    s   int0s   double complex{R    s   complex_double0s   complex{s   24s   complex_long_doubles   32s   complex_long_doubleR   s   complex_floatR    s   complex_floats   16s   complex_double0s   integer{R    s   intR   s   signed_chars   -4s   unsignedR   s   shorts   -1s   unsigned_charR   s   ints   -2s   unsigned_shortR   s	   long_longs   -8s   unsigned_long_long0s   byte{R    s   char00{s   complex_doubles   (%g,%g)s   shorts   %hds   signed_chars   %ds   strings   %ss   long_doubles   %Lgs   ints   %ds   unsigned_chars   %hhus   floats   %gs   unsigneds   %us   longs   %lds   doubles   %gs   chars   %ds   complex_floats   (%g,%g)s   complex_long_doubles	   (%Lg,%Lg)s	   long_longs   %lds   unsigned_longs   %lus   unsigned_shorts   %hu0{s   complex_doubles   complexs   shorts   ints   signed_chars   ints   strings   strings   long_doubles   floats   ints   ints   unsigned_chars   ints   floats   floats   unsigneds   ints   longs   ints   chars   ints   complex_floats   complexs   complex_long_doubles   complexs	   long_longs   longs   doubles   floats   unsigned_shorts   int0%s : %s rank-0 array(string(len=%s),'c')%sgetctype: "%s(kind=%s)" is mapped to C "%s" (to override define dict(%s = dict(%s="<C typespec>")) in %s/.f2py_f2cmap file).
complex functiongetpydocsign: Could not resolve docsignature for "%s".\n
    varname,ctype,atype
    init,init.r,init.i,pytype
    vardebuginfo,vardebugshowvalue,varshowvalue
    varrfromat
    intent
    %s : %s rank-0 array(%s,'%s')%s(capi_c.r=%s,capi_c.i=%s,capi_c)routsign2map: Confused: function %s has externals %s but no "use" statement.
%s : %s rank-%s array('%s') with bounds (%s)%s
    Determines C type
    #name#:slen(%s)=%%d %s=\"%%s\"getinit: expected complex number `(r,i)' but got `%s' as initial value of %r. 1.60 
#ifdef F2PY_CB_RETURNCOMPLEX
return_value=
#endif
See elsewhere.end of %s%s|%snumpy.f2py.capi_maps%s : string(len=%s)%s : call-back function%sstring arraygetstrlength: function %s has no return value?!
complex scalar	Ignoring map {'%s':{'%s':'%s'}}: '%s' must be in %s
%s(%s,%s) => %ssign2map: Confused: external %s is not in lcb_map%s.
cb_%s_in_%sslen(%s)=%s%s#varname#_Dims[%d]=%s,
    name,NAME,begintitle,endtitle
    rname,ctype,rformat
    routdebugshowvalue
    debug-capi:%s=>%s:%s
    name,begintitle,endtitle,argname
    ctype,rctype,maxnofargs,nofoptargs,returncptr
    .*?\b%s\b.*getarrdims:warning: assumed shape array, using 0 instead of %r
	Warning: redefinition of {'%s':{'%s':'%s'->'%s'}}
Failed to apply user defined changes from .f2py_f2cmap: %s. Skipping.
	Mapping "%s(kind=%s)" to "%s"


Copyright 1999,2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/05/06 10:57:33 $
Pearu Peterson

routsign2map: no c2buildvalue key for type %s
([*]|[:])debug-capi:slen(%s)=%%d %s=\"%%s\", optional\n    Default: %s#name#:%s=%sdebug-capi:%s=%s/usr/lib/python2.7/dist-packages/numpy/f2py/capi_maps.py%s : rank-%s array('%s') with bounds (%s) and %s storage%s : %s %s%sroutsign2map: expected explicit specification of the length of the string returned by the fortran function %s; taking 10.
getctype: "%s %s %s" not supported.
in/outputdebug-capi:%s=%%pdims(%s)getctype: No C-type found in "%s", assuming void.
getstrlength:intent(hide): expected a string with defined length but got: %s
getstrlength: expected a signature of a string but got: %s
getctype: function %s has no return value?!
F2PY_%s
    modulename
    %s : rank-0 array(%s,'%s')Reading .f2py_f2cmap ...

#ifdef F2PY_CB_RETURNCOMPLEX
#ctype#
#else
void
#endif
\(\s*([*]|[:])\s*\)rank*[-1]%s : %s string(len=%s)%s%s : rank-0 array(string(len=%s),'c')getarrdims: If in call-back function: array argument %s must have bounded dimensions: got %s
debug-capi:%s %s=%s:%sSuccesfully applied user defined changes from .f2py_f2cmap
noargsargs_nmargs_td_optionalcbtypedefsoptargs_nmoptargs_tdstrarglensdocstrshortstrarglens_nmstrarglens_tdlatexdocsignature
#begintitle#
PyObject *#name#_capi = NULL;/*was Py_None*/
PyTupleObject *#name#_args_capi = NULL;
int #name#_nofargs = 0;
jmp_buf #name#_jmpbuf;
/*typedef #rctype#(*#name#_typedef)(#optargs_td##args_td##strarglens_td##noargs#);*/
#static# #rctype# #callbackname# (#optargs##args##strarglens##noargs#) {
	PyTupleObject *capi_arglist = #name#_args_capi;
	PyObject *capi_return = NULL;
	PyObject *capi_tmp = NULL;
	int capi_j,capi_i = 0;
	int capi_longjmp_ok = 1;
#decl#
#ifdef F2PY_REPORT_ATEXIT
f2py_cb_start_clock();
#endif
	CFUNCSMESS("cb:Call-back function #name# (maxnofargs=#maxnofargs#(-#nofoptargs#))\n");
	CFUNCSMESSPY("cb:#name#_capi=",#name#_capi);
	if (#name#_capi==NULL) {
		capi_longjmp_ok = 0;
		#name#_capi = PyObject_GetAttrString(#modulename#_module,"#argname#");
	}
	if (#name#_capi==NULL) {
		PyErr_SetString(#modulename#_error,"cb: Callback #argname# not defined (as an argument or module #modulename# attribute).\n");
		goto capi_fail;
	}
	if (F2PyCapsule_Check(#name#_capi)) {
	#name#_typedef #name#_cptr;
	#name#_cptr = F2PyCapsule_AsVoidPtr(#name#_capi);
	#returncptr#(*#name#_cptr)(#optargs_nm##args_nm##strarglens_nm#);
	#return#
	}
	if (capi_arglist==NULL) {
		capi_longjmp_ok = 0;
		capi_tmp = PyObject_GetAttrString(#modulename#_module,"#argname#_extra_args");
		if (capi_tmp) {
			capi_arglist = (PyTupleObject *)PySequence_Tuple(capi_tmp);
			if (capi_arglist==NULL) {
				PyErr_SetString(#modulename#_error,"Failed to convert #modulename#.#argname#_extra_args to tuple.\n");
				goto capi_fail;
			}
		} else {
			PyErr_Clear();
			capi_arglist = (PyTupleObject *)Py_BuildValue("()");
		}
	}
	if (capi_arglist == NULL) {
		PyErr_SetString(#modulename#_error,"Callback #argname# argument list is not set.\n");
		goto capi_fail;
	}
#setdims#
#pyobjfrom#
	CFUNCSMESSPY("cb:capi_arglist=",capi_arglist);
	CFUNCSMESS("cb:Call-back calling Python function #argname#.\n");
#ifdef F2PY_REPORT_ATEXIT
f2py_cb_start_call_clock();
#endif
	capi_return = PyObject_CallObject(#name#_capi,(PyObject *)capi_arglist);
#ifdef F2PY_REPORT_ATEXIT
f2py_cb_stop_call_clock();
#endif
	CFUNCSMESSPY("cb:capi_return=",capi_return);
	if (capi_return == NULL) {
		fprintf(stderr,"capi_return is NULL\n");
		goto capi_fail;
	}
	if (capi_return == Py_None) {
		Py_DECREF(capi_return);
		capi_return = Py_BuildValue("()");
	}
	else if (!PyTuple_Check(capi_return)) {
		capi_return = Py_BuildValue("(N)",capi_return);
	}
	capi_j = PyTuple_Size(capi_return);
	capi_i = 0;
#frompyobj#
	CFUNCSMESS("cb:#name#:successful\n");
	Py_DECREF(capi_return);
#ifdef F2PY_REPORT_ATEXIT
f2py_cb_stop_clock();
#endif
	goto capi_return_pt;
capi_fail:
	fprintf(stderr,"Call-back #name# failed.\n");
	Py_XDECREF(capi_return);
	if (capi_longjmp_ok)
		longjmp(#name#_jmpbuf,-1);
capi_return_pt:
	;
#return#
}
#endtitle#
	def #argname#(#docsignature#): return #docreturn#\n\
#docstrsigns#
{{}\verb@def #argname#(#latexdocsignature#): return #docreturn#@{}}
#routnote#

#latexdocstrsigns#{s   decls   
s   args_nmt   ,s   args_tdR    s
   optargs_nmt    s	   pyobjfroms   
s   argsR    s   latexdocstrcbss   
s   latexdocstropts   
s   setdimss   
s   optargsR   s   latexdocstrsignss   
s   docstrsignss   \n"
"s	   frompyobjs   
s   latexdocstrouts   
s
   optargs_tdR   s   freemems   
s   latexdocstrreqs   
0	fprintf(stderr,"debug-capi:cb:#varname#=\"#showvalueformat#\":%d:\n",#varname_i#,#varname_i#_cb_len);numpy.f2py.cb_rules	fprintf(stderr,"#showvalueformat#.\n",#varname_i#);#ctype# #varname_i#	CFUNCSMESS("cb:Getting #varname#->");	fprintf(stderr,"#showvalueformat#\".\n",return_value);#ctype# ,intreturn_value,&return_value_len	Constructing call-back function "cb_%s_in_%s"
		#pydocsignout#/*setdims*/warning: empty body for %s
	#ctype# return_value;/usr/lib/python2.7/dist-packages/numpy/f2py/cb_rules.py	Return objects:intent(c,out) is forbidden for callback scalar arguments
#ifdef F2PY_CB_RETURNCOMPLEX
	return return_value;
#else
	return;
#endif
	CFUNCSMESS("cb:Getting return_value->");	if (capi_j>capi_i)
		GETSCALARFROMPYTUPLE(capi_return,capi_i++,#varname_i#_cb_capi,#ctype#,"#ctype#_from_pyobj failed in converting argument #varname# of call-back function #name# to C #ctype#\n");,capi_tmp);
		if (rv_cb_arr == NULL) {
			fprintf(stderr,"rv_cb_arr is NULL\n");
			goto capi_fail;
		}
		MEMCOPY(#varname_i#,rv_cb_arr->data,PyArray_NBYTES(rv_cb_arr));
		if (capi_tmp != (PyObject *)rv_cb_arr) {
			Py_DECREF(rv_cb_arr);
		}
	}	fprintf(stderr,"debug-capi:cb:#varname#\n");,int #varname_i#_cb_len
#ifdef F2PY_CB_RETURNCOMPLEX
	fprintf(stderr,"#showvalueformat#.\n",(return_value).r,(return_value).i);
#else
	fprintf(stderr,"#showvalueformat#.\n",(*return_value).r,(*return_value).i);
#endif

	if (capi_j>capi_i)
		GETSTRFROMPYTUPLE(capi_return,capi_i++,return_value,return_value_len);	fprintf(stderr,"#showvalueformat#\":%d:.\n",#varname_i#,#varname_i#_cb_len);	CFUNCSMESS("cb:Getting #varname#->\"");	if (capi_j>capi_i)
		GETSCALARFROMPYTUPLE(capi_return,capi_i++,&return_value,#ctype#,"#ctype#_from_pyobj failed in converting return_value of call-back function #name# to C #ctype#\n");#ctype# *#varname_i#_cb_capi#docsignopt#	if (#name#_nofargs>capi_i) {
		PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,#rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,0,NPY_CARRAY,NULL); /*XXX: Hmm, what will destroy this array??? */
	Call-back functions:	if (capi_j>capi_i)
#ifdef F2PY_CB_RETURNCOMPLEX
		GETSCALARFROMPYTUPLE(capi_return,capi_i++,&return_value,#ctype#,"#ctype#_from_pyobj failed in converting return_value of call-back function #name# to C #ctype#\n");
#else
		GETSCALARFROMPYTUPLE(capi_return,capi_i++,return_value,#ctype#,"#ctype#_from_pyobj failed in converting return_value of call-back function #name# to C #ctype#\n");
#endif
	fprintf(stderr,"#showvalueformat#.\n",(#varname_i#).r,(#varname_i#).i);	#cbsetdims#;
#ifndef F2PY_CB_RETURNCOMPLEX
,
#endif
	fprintf(stderr,"#showvalueformat#.\n",return_value);

Build call-back mechanism for f2py2e.

Copyright 2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/07/20 11:27:58 $
Pearu Peterson

|F2PY_INTENT_C		#pydocsign#
		if (tmp_arr==NULL)
			goto capi_fail;
		if (PyTuple_SetItem((PyObject *)capi_arglist,capi_i++,(PyObject *)tmp_arr))
			goto capi_fail;
}	if (capi_j>capi_i) {
		PyArrayObject *rv_cb_arr = NULL;
		if ((capi_tmp = PyTuple_GetItem(capi_return,capi_i++))==NULL) goto capi_fail;
		rv_cb_arr =  array_from_pyobj(#atype#,#varname_i#_Dims,#rank#,F2PY_INTENT_IN	Required arguments:	fprintf(stderr,"<-.\n");	  %s
	fprintf(stderr,"#showvalueformat#.\n",*#varname_i#_cb_capi);
#ifndef F2PY_CB_RETURNCOMPLEX
#ctype# *
#endif
	if (#name#_nofargs>capi_i) {
		PyArrayObject *tmp_arr = (PyArrayObject *)PyArray_New(&PyArray_Type,#rank#,#varname_i#_Dims,#atype#,NULL,(char*)#varname_i#,0,NPY_FARRAY,NULL); /*XXX: Hmm, what will destroy this array??? */
	if (#name#_nofargs>capi_i) {
		int #varname_i#_cb_dims[] = {#varname_i#_cb_len};
		if (PyTuple_SetItem((PyObject *)capi_arglist,capi_i++,pyarr_from_p_#ctype#1(#varname_i#,#varname_i#_cb_dims)))
			goto capi_fail;
	}	CFUNCSMESS("cb:Getting return_value->\"");	if (#name#_nofargs>capi_i)
		if (PyTuple_SetItem((PyObject *)capi_arglist,capi_i++,pyarr_from_p_#ctype#1(#varname_i#_cb_capi)))
			goto capi_fail;#ctype# return_value,int return_value_len	if (#name#_nofargs>capi_i)
		if (PyTuple_SetItem((PyObject *)capi_arglist,capi_i++,pyobj_from_#ctype#1size(#varname_i#,#varname_i#_cb_len)))
			goto capi_fail;	npy_intp #varname_i#_Dims[#rank#] = {#rank*[-1]#};	if (#name#_nofargs>capi_i)
		if (PyTuple_SetItem((PyObject *)capi_arglist,capi_i++,pyobj_from_#ctype#1(#varname_i#)))
			goto capi_fail;	fprintf(stderr,"#showvalueformat#.\n",(*#varname_i#_cb_capi).r,(*#varname_i#_cb_capi).i);	fprintf(stderr,"debug-capi:cb:#name#:%d:\n",return_value_len);	Optional arguments:	if (capi_j>capi_i)
		GETSTRFROMPYTUPLE(capi_return,capi_i++,#varname_i#,#varname_i#_cb_len);
#ifdef F2PY_CB_RETURNCOMPLEX
	#ctype# return_value;
#endif

#ifndef F2PY_CB_RETURNCOMPLEX
#ctype# *return_value
#endif
	#ctype# #varname_i#=(*#varname_i#_cb_capi);
#ifndef F2PY_CB_RETURNCOMPLEX
return_value
#endif
nnnARRSIZEFAILNULLOLDPYNUMf2py_sizeSTRINGCOPYSWAPUNSAFESTRINGCOPYNSTRINGMALLOCcalcarrindexPRINTPYOBJERRcalcarrindextrint_from_pyobjchar_from_pyobjlong_from_pyobjpyobj_from_int1float_from_pyobjpyobj_from_char1pyobj_from_long1short_from_pyobjdouble_from_pyobjpyobj_from_float1pyobj_from_short1string_from_pyobjTRYPYARRAYTEMPLATEinsinged_long_longpyobj_from_double1pyobj_from_string1try_pyarr_from_inttry_pyarr_from_chartry_pyarr_from_longlong_long_from_pyobjtry_pyarr_from_floattry_pyarr_from_shortinitf90modhooksstaticpyobj_from_long_long1try_pyarr_from_doubletry_pyarr_from_stringinitf90modhooksdynamiclong_double_from_pyobjpyobj_from_string1sizesigned_char_from_pyobjpyobj_from_long_double1complex_float_from_pyobjtry_pyarr_from_long_longTRYCOMPLEXPYARRAYTEMPLATEcomplex_double_from_pyobjpyobj_from_complex_float1pyobj_from_complex_double1try_pyarr_from_signed_char/*initf90modhooksstatic*//*initf90modhooksdynamic*//*need_f90modhooks*//*need_cppmacros*//*need_initcommonhooks*//*need_commonhooks*//*need_typedefs*//*need_userincludes*//*need_cfuncs*//*need_callbacks*//*need_includes0*//*need_typedefs_generated*//*need_includes*/try_pyarr_from_complex_floattry_pyarr_from_unsigned_chartry_pyarr_from_complex_doublecomplex_long_double_from_pyobjpyobj_from_complex_long_double1typedef unsigned long unsigned_long;#ifdef _WIN32
typedef __uint64 long_long;
#else
typedef unsigned long long unsigned_long_long;
#endif
static int try_pyarr_from_int(PyObject* obj,int* v) {
	TRYPYARRAYTEMPLATE(int,'i');
}
#ifdef OLDPYNUM
#error You need to intall Numeric Python version 13 or higher. Get it from http:/sourceforge.net/project/?group_id=1369
#endif
#define pyobj_from_string1size(v,len) (PyString_FromStringAndSize((char *)v, len))static struct { int nd;npy_intp *d;int *i,*i_tr,tr; } forcombcache;
static int initforcomb(npy_intp *dims,int nd,int tr) {
  int k;
  if (dims==NULL) return 0;
  if (nd<0) return 0;
  forcombcache.nd = nd;
  forcombcache.d = dims;
  forcombcache.tr = tr;
  if ((forcombcache.i = (int *)malloc(sizeof(int)*nd))==NULL) return 0;
  if ((forcombcache.i_tr = (int *)malloc(sizeof(int)*nd))==NULL) return 0;
  for (k=1;k<nd;k++) {
    forcombcache.i[k] = forcombcache.i_tr[nd-k-1] = 0;
  }
  forcombcache.i[0] = forcombcache.i_tr[nd-1] = -1;
  return 1;
}
static int *nextforcomb(void) {
  int j,*i,*i_tr,k;
  int nd=forcombcache.nd;
  if ((i=forcombcache.i) == NULL) return NULL;
  if ((i_tr=forcombcache.i_tr) == NULL) return NULL;
  if (forcombcache.d == NULL) return NULL;
  i[0]++;
  if (i[0]==forcombcache.d[0]) {
    j=1;
    while ((j<nd) && (i[j]==forcombcache.d[j]-1)) j++;
    if (j==nd) {
      free(i);
      free(i_tr);
      return NULL;
    }
    for (k=0;k<j;k++) i[k] = i_tr[nd-k-1] = 0;
    i[j]++;
    i_tr[nd-j-1]++;
  } else
    i_tr[nd-1]++;
  if (forcombcache.tr) return i_tr;
  return i;
}#define CHECKSTRING(check,tcheck,name,show,var)\
	if (!(check)) {\
		char errstring[256];\
		sprintf(errstring, "%s: "show, "("tcheck") failed for "name, slen(var), var);\
		PyErr_SetString(#modulename#_error, errstring);\
		/*goto capi_fail;*/\
	} else #if defined(F90MOD2CCONV1) /*E.g. Compaq Fortran */
#if defined(NO_APPEND_FORTRAN)
#define F_MODFUNCNAME(m,f) $ ## m ## $ ## f
#else
#define F_MODFUNCNAME(m,f) $ ## m ## $ ## f ## _
#endif
#endif

#if defined(F90MOD2CCONV2) /*E.g. IBM XL Fortran, not tested though */
#if defined(NO_APPEND_FORTRAN)
#define F_MODFUNCNAME(m,f)  __ ## m ## _MOD_ ## f
#else
#define F_MODFUNCNAME(m,f)  __ ## m ## _MOD_ ## f ## _
#endif
#endif

#if defined(F90MOD2CCONV3) /*E.g. MIPSPro Compilers */
#if defined(NO_APPEND_FORTRAN)
#define F_MODFUNCNAME(m,f)  f ## .in. ## m
#else
#define F_MODFUNCNAME(m,f)  f ## .in. ## m ## _
#endif
#endif
/*
#if defined(UPPERCASE_FORTRAN)
#define F_MODFUNC(m,M,f,F) F_MODFUNCNAME(M,F)
#else
#define F_MODFUNC(m,M,f,F) F_MODFUNCNAME(m,f)
#endif
*/

#define F_MODFUNC(m,f) (*(f2pymodstruct##m##.##f))
typedef unsigned short unsigned_short;#define %s(v) (PyArray_SimpleNewFromData(0,NULL,%s,(char *)v))static int signed_char_from_pyobj(signed_char* v,PyObject *obj,const char *errmess) {
	int i=0;
	if (int_from_pyobj(&i,obj,errmess)) {
		*v = (signed_char)i;
		return 1;
	}
	return 0;
}


C declarations, CPP macros, and C functions for f2py2e.
Only required declarations/macros/functions will be used.

Copyright 1999,2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/05/06 11:42:34 $
Pearu Peterson

#define pyobj_from_complex_long_double1(v) (PyComplex_FromDoubles(v.r,v.i))typedef signed char signed_char;#define PRINTPYOBJERR(obj)\
	fprintf(stderr,"#modulename#.error is related to ");\
	PyObject_Print((PyObject *)obj,stderr,Py_PRINT_RAW);\
	fprintf(stderr,"\n");
#define TRYCOMPLEXPYARRAYTEMPLATEOBJECT case NPY_OBJECT: (arr->descr->f->setitem)(pyobj_from_complex_ ## ctype ## 1((*v)),arr->data, arr); break;
#define TRYCOMPLEXPYARRAYTEMPLATE(ctype,typecode)\
        PyArrayObject *arr = NULL;\
        if (!obj) return -2;\
        if (!PyArray_Check(obj)) return -1;\
        if (!(arr=(PyArrayObject *)obj)) {fprintf(stderr,"TRYCOMPLEXPYARRAYTEMPLATE:");PRINTPYOBJERR(obj);return 0;}\
        if (arr->descr->type==typecode) {\
            *(ctype *)(arr->data)=(*v).r;\
            *(ctype *)(arr->data+sizeof(ctype))=(*v).i;\
            return 1;\
        }\
        switch (arr->descr->type_num) {\
                case NPY_CDOUBLE: *(double *)(arr->data)=(*v).r;*(double *)(arr->data+sizeof(double))=(*v).i;break;\
                case NPY_CFLOAT: *(float *)(arr->data)=(*v).r;*(float *)(arr->data+sizeof(float))=(*v).i;break;\
                case NPY_DOUBLE: *(double *)(arr->data)=(*v).r; break;\
                case NPY_LONG: *(long *)(arr->data)=(*v).r; break;\
                case NPY_FLOAT: *(float *)(arr->data)=(*v).r; break;\
                case NPY_INT: *(int *)(arr->data)=(*v).r; break;\
                case NPY_SHORT: *(short *)(arr->data)=(*v).r; break;\
                case NPY_UBYTE: *(unsigned char *)(arr->data)=(*v).r; break;\
                case NPY_BYTE: *(signed char *)(arr->data)=(*v).r; break;\
                case NPY_BOOL: *(npy_bool *)(arr->data)=((*v).r!=0 && (*v).i!=0); break;\
                case NPY_USHORT: *(npy_ushort *)(arr->data)=(*v).r; break;\
                case NPY_UINT: *(npy_uint *)(arr->data)=(*v).r; break;\
                case NPY_ULONG: *(npy_ulong *)(arr->data)=(*v).r; break;\
                case NPY_LONGLONG: *(npy_longlong *)(arr->data)=(*v).r; break;\
                case NPY_ULONGLONG: *(npy_ulonglong *)(arr->data)=(*v).r; break;\
                case NPY_LONGDOUBLE: *(npy_longdouble *)(arr->data)=(*v).r; break;\
                case NPY_CLONGDOUBLE: *(npy_longdouble *)(arr->data)=(*v).r;*(npy_longdouble *)(arr->data+sizeof(npy_longdouble))=(*v).i;break;\
                case NPY_OBJECT: (arr->descr->f->setitem)(pyobj_from_complex_ ## ctype ## 1((*v)),arr->data, arr); break;\
                default: return -2;\
        };\
        return -1;
typedef struct {float r,i;} complex_float;#define pyobj_from_char1(v) (PyInt_FromLong(v))#include <stdarg.h>#define pyobj_from_complex_double1(v) (PyComplex_FromDoubles(v.r,v.i))#include "Python.h"static int try_pyarr_from_unsigned_char(PyObject* obj,unsigned_char* v) {
	TRYPYARRAYTEMPLATE(unsigned_char,'b');
}
#define GETSCALARFROMPYTUPLE(tuple,index,var,ctype,mess) {\
		if ((capi_tmp = PyTuple_GetItem((tuple),(index)))==NULL) goto capi_fail;\
		if (!(ctype ## _from_pyobj((var),capi_tmp,mess)))\
			goto capi_fail;\
	}
static int complex_double_from_pyobj(complex_double* v,PyObject *obj,const char *errmess) {
	Py_complex c;
	if (PyComplex_Check(obj)) {
		c=PyComplex_AsCComplex(obj);
		(*v).r=c.real, (*v).i=c.imag;
		return 1;
	}
	if (PyArray_IsScalar(obj, ComplexFloating)) {
		if (PyArray_IsScalar(obj, CFloat)) {
			npy_cfloat new;
			PyArray_ScalarAsCtype(obj, &new);
			(*v).r = (double)new.real;
			(*v).i = (double)new.imag;
		}
		else if (PyArray_IsScalar(obj, CLongDouble)) {
			npy_clongdouble new;
			PyArray_ScalarAsCtype(obj, &new);
			(*v).r = (double)new.real;
			(*v).i = (double)new.imag;
		}
		else { /* if (PyArray_IsScalar(obj, CDouble)) */
			PyArray_ScalarAsCtype(obj, v);
		}
		return 1;
	}
	if (PyArray_CheckScalar(obj)) { /* 0-dim array or still array scalar */
		PyObject *arr;
		if (PyArray_Check(obj)) {
			arr = PyArray_Cast((PyArrayObject *)obj, NPY_CDOUBLE);
		}
		else {
			arr = PyArray_FromScalar(obj, PyArray_DescrFromType(NPY_CDOUBLE));
		}
		if (arr==NULL) return 0;
		(*v).r = ((npy_cdouble *)PyArray_DATA(arr))->real;
		(*v).i = ((npy_cdouble *)PyArray_DATA(arr))->imag;
		return 1;
	}
	/* Python does not provide PyNumber_Complex function :-( */
	(*v).i=0.0;
	if (PyFloat_Check(obj)) {
#ifdef __sgi
		(*v).r = PyFloat_AsDouble(obj);
#else
		(*v).r = PyFloat_AS_DOUBLE(obj);
#endif
		return 1;
	}
	if (PyInt_Check(obj)) {
		(*v).r = (double)PyInt_AS_LONG(obj);
		return 1;
	}
	if (PyLong_Check(obj)) {
		(*v).r = PyLong_AsDouble(obj);
		return (!PyErr_Occurred());
	}
	if (PySequence_Check(obj) && !(PyString_Check(obj) || PyUnicode_Check(obj))) {
		PyObject *tmp = PySequence_GetItem(obj,0);
		if (tmp) {
			if (complex_double_from_pyobj(v,tmp,errmess)) {
				Py_DECREF(tmp);
				return 1;
			}
			Py_DECREF(tmp);
		}
	}
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL)
			err = PyExc_TypeError;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
static int try_pyarr_from_complex_double(PyObject* obj,complex_double* v) {
	TRYCOMPLEXPYARRAYTEMPLATE(double,'D');
}
#if defined(PREPEND_FORTRAN)
#if defined(NO_APPEND_FORTRAN)
#if defined(UPPERCASE_FORTRAN)
#define F_WRAPPEDFUNC(f,F) _F2PYWRAP##F
#else
#define F_WRAPPEDFUNC(f,F) _f2pywrap##f
#endif
#else
#if defined(UPPERCASE_FORTRAN)
#define F_WRAPPEDFUNC(f,F) _F2PYWRAP##F##_
#else
#define F_WRAPPEDFUNC(f,F) _f2pywrap##f##_
#endif
#endif
#else
#if defined(NO_APPEND_FORTRAN)
#if defined(UPPERCASE_FORTRAN)
#define F_WRAPPEDFUNC(f,F) F2PYWRAP##F
#else
#define F_WRAPPEDFUNC(f,F) f2pywrap##f
#endif
#else
#if defined(UPPERCASE_FORTRAN)
#define F_WRAPPEDFUNC(f,F) F2PYWRAP##F##_
#else
#define F_WRAPPEDFUNC(f,F) f2pywrap##f##_
#endif
#endif
#endif
#if defined(UNDERSCORE_G77)
#define F_WRAPPEDFUNC_US(f,F) F_WRAPPEDFUNC(f##_,F##_)
#else
#define F_WRAPPEDFUNC_US(f,F) F_WRAPPEDFUNC(f,F)
#endif
typedef unsigned char unsigned_char;static int int_from_pyobj(int* v,PyObject *obj,const char *errmess) {
	PyObject* tmp = NULL;
	if (PyInt_Check(obj)) {
		*v = (int)PyInt_AS_LONG(obj);
		return 1;
	}
	tmp = PyNumber_Int(obj);
	if (tmp) {
		*v = PyInt_AS_LONG(tmp);
		Py_DECREF(tmp);
		return 1;
	}
	if (PyComplex_Check(obj))
		tmp = PyObject_GetAttrString(obj,"real");
	else if (PyString_Check(obj) || PyUnicode_Check(obj))
		/*pass*/;
	else if (PySequence_Check(obj))
		tmp = PySequence_GetItem(obj,0);
	if (tmp) {
		PyErr_Clear();
		if (int_from_pyobj(v,tmp,errmess)) {Py_DECREF(tmp); return 1;}
		Py_DECREF(tmp);
	}
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL) err = #modulename#_error;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
\
#define FAILNULL(p) do {                                            \
    if ((p) == NULL) {                                              \
        PyErr_SetString(PyExc_MemoryError, "NULL pointer found");   \
        goto capi_fail;                                             \
    }                                                               \
} while (0)
static int try_pyarr_from_long_long(PyObject* obj,long_long* v) {
	TRYPYARRAYTEMPLATE(long_long,'L');
}
#define pyobj_from_int1(v) (PyInt_FromLong(v))static int char_from_pyobj(char* v,PyObject *obj,const char *errmess) {
	int i=0;
	if (int_from_pyobj(&i,obj,errmess)) {
		*v = (char)i;
		return 1;
	}
	return 0;
}
static int try_pyarr_from_float(PyObject* obj,float* v) {
	TRYPYARRAYTEMPLATE(float,'f');
}
#define pyobj_from_float1(v) (PyFloat_FromDouble(v))#include <string.h>get_needs: no progress in sorting needs, probably circular dependence, skipping.
append_needs: unknown need %s
typedef char * string;#define STRINGMALLOC(str,len)\
	if ((str = (string)malloc(sizeof(char)*(len+1))) == NULL) {\
		PyErr_SetString(PyExc_MemoryError, "out of memory");\
		goto capi_fail;\
	} else {\
		(str)[len] = '\0';\
	}
static int try_pyarr_from_long(PyObject* obj,long* v) {
	TRYPYARRAYTEMPLATE(long,'l');
}
static int try_pyarr_from_signed_char(PyObject* obj,signed_char* v) {
	TRYPYARRAYTEMPLATE(signed_char,'1');
}
#ifndef _LONG_DOUBLE
typedef long double long_double;
#endif
#define pyobj_from_short1(v) (PyInt_FromLong(v))#define CHECKSCALAR(check,tcheck,name,show,var)\
	if (!(check)) {\
		char errstring[256];\
		sprintf(errstring, "%s: "show, "("tcheck") failed for "name, var);\
		PyErr_SetString(#modulename#_error,errstring);\
		/*goto capi_fail;*/\
	} else static int string_from_pyobj(string *str,int *len,const string inistr,PyObject *obj,const char *errmess) {
	PyArrayObject *arr = NULL;
	PyObject *tmp = NULL;
#ifdef DEBUGCFUNCS
fprintf(stderr,"string_from_pyobj(str='%s',len=%d,inistr='%s',obj=%p)\n",(char*)str,*len,(char *)inistr,obj);
#endif
	if (obj == Py_None) {
		if (*len == -1)
			*len = strlen(inistr); /* Will this cause problems? */
		STRINGMALLOC(*str,*len);
		STRINGCOPYN(*str,inistr,*len+1);
		return 1;
	}
	if (PyArray_Check(obj)) {
		if ((arr = (PyArrayObject *)obj) == NULL)
			goto capi_fail;
		if (!ISCONTIGUOUS(arr)) {
			PyErr_SetString(PyExc_ValueError,"array object is non-contiguous.");
			goto capi_fail;
		}
		if (*len == -1)
			*len = (arr->descr->elsize)*PyArray_SIZE(arr);
		STRINGMALLOC(*str,*len);
		STRINGCOPYN(*str,arr->data,*len+1);
		return 1;
	}
	if (PyString_Check(obj)) {
		tmp = obj;
		Py_INCREF(tmp);
	}
#if PY_VERSION_HEX >= 0x03000000
	else if (PyUnicode_Check(obj)) {
		tmp = PyUnicode_AsASCIIString(obj);
	}
	else {
		PyObject *tmp2;
		tmp2 = PyObject_Str(obj);
		if (tmp2) {
			tmp = PyUnicode_AsASCIIString(tmp2);
			Py_DECREF(tmp2);
		}
		else {
			tmp = NULL;
		}
	}
#else
	else {
		tmp = PyObject_Str(obj);
	}
#endif
	if (tmp == NULL) goto capi_fail;
	if (*len == -1)
		*len = PyString_GET_SIZE(tmp);
	STRINGMALLOC(*str,*len);
	STRINGCOPYN(*str,PyString_AS_STRING(tmp),*len+1);
	Py_DECREF(tmp);
	return 1;
capi_fail:
	Py_XDECREF(tmp);
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL) err = #modulename#_error;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
#define %s(v,dims) (PyArray_SimpleNewFromData(1,dims,NPY_CHAR,(char *)v))#define STRINGFREE(str) do {if (!(str == NULL)) free(str);} while (0)
static int calcarrindex(int *i,PyArrayObject *arr) {
	int k,ii = i[0];
	for (k=1; k < arr->nd; k++)
		ii += (ii*(arr->dimensions[k] - 1)+i[k]); /* assuming contiguous arr */
	return ii;
}#define SWAP(a,b) (size_t)(a) = ((size_t)(a) ^ (size_t)(b));\
 (size_t)(b) = ((size_t)(a) ^ (size_t)(b));\
 (size_t)(a) = ((size_t)(a) ^ (size_t)(b))
#define ARRSIZE(dims,rank) (_PyArray_multiply_list(dims,rank))#define PY_ARRAY_UNIQUE_SYMBOL PyArray_API
#include "arrayobject.h"#define STRINGCOPY(to,from)\
    do { FAILNULL(to); FAILNULL(from); (void)strcpy(to,from); } while (0)
static int float_from_pyobj(float* v,PyObject *obj,const char *errmess) {
	double d=0.0;
	if (double_from_pyobj(&d,obj,errmess)) {
		*v = (float)d;
		return 1;
	}
	return 0;
}
#define pyobj_from_string1(v) (PyString_FromString((char *)v))typedef struct {double r,i;} complex_double;#define pyobj_from_long_double1(v) (PyFloat_FromDouble(v))append_needs: expected list or string but got :%s
static int try_pyarr_from_short(PyObject* obj,short* v) {
	TRYPYARRAYTEMPLATE(short,'s');
}
#define CHECKARRAY(check,tcheck,name) \
	if (!(check)) {\
		PyErr_SetString(#modulename#_error,"("tcheck") failed for "name);\
		/*goto capi_fail;*/\
	} else #include <setjmp.h>#define CHECKGENERIC(check,tcheck,name) \
	if (!(check)) {\
		PyErr_SetString(#modulename#_error,"("tcheck") failed for "name);\
		/*goto capi_fail;*/\
	} else static int try_pyarr_from_char(PyObject* obj,char* v) {
	TRYPYARRAYTEMPLATE(char,'c');
}
static int create_cb_arglist(PyObject* fun,PyTupleObject* xa,const int maxnofargs,const int nofoptargs,int *nofargs,PyTupleObject **args,const char *errmess) {
	PyObject *tmp = NULL;
	PyObject *tmp_fun = NULL;
	int tot,opt,ext,siz,i,di=0;
	CFUNCSMESS("create_cb_arglist\n");
	tot=opt=ext=siz=0;
	/* Get the total number of arguments */
	if (PyFunction_Check(fun))
		tmp_fun = fun;
	else {
		di = 1;
		if (PyObject_HasAttrString(fun,"im_func")) {
			tmp_fun = PyObject_GetAttrString(fun,"im_func");
		}
		else if (PyObject_HasAttrString(fun,"__call__")) {
			tmp = PyObject_GetAttrString(fun,"__call__");
			if (PyObject_HasAttrString(tmp,"im_func"))
				tmp_fun = PyObject_GetAttrString(tmp,"im_func");
			else {
				tmp_fun = fun; /* built-in function */
				tot = maxnofargs;
				if (xa != NULL)
					tot += PyTuple_Size((PyObject *)xa);
			}
			Py_XDECREF(tmp);
		}
		else if (PyFortran_Check(fun) || PyFortran_Check1(fun)) {
			tot = maxnofargs;
			if (xa != NULL)
				tot += PyTuple_Size((PyObject *)xa);
			tmp_fun = fun;
		}
		else if (F2PyCapsule_Check(fun)) {
			tot = maxnofargs;
			if (xa != NULL)
				ext = PyTuple_Size((PyObject *)xa);
			if(ext>0) {
				fprintf(stderr,"extra arguments tuple cannot be used with CObject call-back\n");
				goto capi_fail;
			}
			tmp_fun = fun;
		}
	}
if (tmp_fun==NULL) {
fprintf(stderr,"Call-back argument must be function|instance|instance.__call__|f2py-function but got %s.\n",(fun==NULL?"NULL":Py_TYPE(fun)->tp_name));
goto capi_fail;
}
#if PY_VERSION_HEX >= 0x03000000
	if (PyObject_HasAttrString(tmp_fun,"__code__")) {
		if (PyObject_HasAttrString(tmp = PyObject_GetAttrString(tmp_fun,"__code__"),"co_argcount"))
#else
	if (PyObject_HasAttrString(tmp_fun,"func_code")) {
		if (PyObject_HasAttrString(tmp = PyObject_GetAttrString(tmp_fun,"func_code"),"co_argcount"))
#endif
			tot = PyInt_AsLong(PyObject_GetAttrString(tmp,"co_argcount")) - di;
		Py_XDECREF(tmp);
	}
	/* Get the number of optional arguments */
#if PY_VERSION_HEX >= 0x03000000
	if (PyObject_HasAttrString(tmp_fun,"__defaults__")) {
		if (PyTuple_Check(tmp = PyObject_GetAttrString(tmp_fun,"__defaults__")))
#else
	if (PyObject_HasAttrString(tmp_fun,"func_defaults")) {
		if (PyTuple_Check(tmp = PyObject_GetAttrString(tmp_fun,"func_defaults")))
#endif
			opt = PyTuple_Size(tmp);
		Py_XDECREF(tmp);
	}
	/* Get the number of extra arguments */
	if (xa != NULL)
		ext = PyTuple_Size((PyObject *)xa);
	/* Calculate the size of call-backs argument list */
	siz = MIN(maxnofargs+ext,tot);
	*nofargs = MAX(0,siz-ext);
#ifdef DEBUGCFUNCS
	fprintf(stderr,"debug-capi:create_cb_arglist:maxnofargs(-nofoptargs),tot,opt,ext,siz,nofargs=%d(-%d),%d,%d,%d,%d,%d\n",maxnofargs,nofoptargs,tot,opt,ext,siz,*nofargs);
#endif
	if (siz<tot-opt) {
		fprintf(stderr,"create_cb_arglist: Failed to build argument list (siz) with enough arguments (tot-opt) required by user-supplied function (siz,tot,opt=%d,%d,%d).\n",siz,tot,opt);
		goto capi_fail;
	}
	/* Initialize argument list */
	*args = (PyTupleObject *)PyTuple_New(siz);
	for (i=0;i<*nofargs;i++) {
		Py_INCREF(Py_None);
		PyTuple_SET_ITEM((PyObject *)(*args),i,Py_None);
	}
	if (xa != NULL)
		for (i=(*nofargs);i<siz;i++) {
			tmp = PyTuple_GetItem((PyObject *)xa,i-(*nofargs));
			Py_INCREF(tmp);
			PyTuple_SET_ITEM(*args,i,tmp);
		}
	CFUNCSMESS("create_cb_arglist-end\n");
	return 1;
capi_fail:
	if ((PyErr_Occurred())==NULL)
		PyErr_SetString(#modulename#_error,errmess);
	return 0;
}
pyarr_from_p_%s1#define pyobj_from_long1(v) (PyLong_FromLong(v))static int complex_float_from_pyobj(complex_float* v,PyObject *obj,const char *errmess) {
	complex_double cd={0.0,0.0};
	if (complex_double_from_pyobj(&cd,obj,errmess)) {
		(*v).r = (float)cd.r;
		(*v).i = (float)cd.i;
		return 1;
	}
	return 0;
}
#ifdef HAVE_LONG_LONG
#define pyobj_from_long_long1(v) (PyLong_FromLongLong(v))
#else
#warning HAVE_LONG_LONG is not available. Redefining pyobj_from_long_long.
#define pyobj_from_long_long1(v) (PyLong_FromLong(v))
#endif
/* New SciPy */
#define TRYPYARRAYTEMPLATECHAR case NPY_STRING: *(char *)(arr->data)=*v; break;
#define TRYPYARRAYTEMPLATELONG case NPY_LONG: *(long *)(arr->data)=*v; break;
#define TRYPYARRAYTEMPLATEOBJECT case NPY_OBJECT: (arr->descr->f->setitem)(pyobj_from_ ## ctype ## 1(*v),arr->data); break;

#define TRYPYARRAYTEMPLATE(ctype,typecode) \
        PyArrayObject *arr = NULL;\
        if (!obj) return -2;\
        if (!PyArray_Check(obj)) return -1;\
        if (!(arr=(PyArrayObject *)obj)) {fprintf(stderr,"TRYPYARRAYTEMPLATE:");PRINTPYOBJERR(obj);return 0;}\
        if (arr->descr->type==typecode)  {*(ctype *)(arr->data)=*v; return 1;}\
        switch (arr->descr->type_num) {\
                case NPY_DOUBLE: *(double *)(arr->data)=*v; break;\
                case NPY_INT: *(int *)(arr->data)=*v; break;\
                case NPY_LONG: *(long *)(arr->data)=*v; break;\
                case NPY_FLOAT: *(float *)(arr->data)=*v; break;\
                case NPY_CDOUBLE: *(double *)(arr->data)=*v; break;\
                case NPY_CFLOAT: *(float *)(arr->data)=*v; break;\
                case NPY_BOOL: *(npy_bool *)(arr->data)=(*v!=0); break;\
                case NPY_UBYTE: *(unsigned char *)(arr->data)=*v; break;\
                case NPY_BYTE: *(signed char *)(arr->data)=*v; break;\
                case NPY_SHORT: *(short *)(arr->data)=*v; break;\
                case NPY_USHORT: *(npy_ushort *)(arr->data)=*v; break;\
                case NPY_UINT: *(npy_uint *)(arr->data)=*v; break;\
                case NPY_ULONG: *(npy_ulong *)(arr->data)=*v; break;\
                case NPY_LONGLONG: *(npy_longlong *)(arr->data)=*v; break;\
                case NPY_ULONGLONG: *(npy_ulonglong *)(arr->data)=*v; break;\
                case NPY_LONGDOUBLE: *(npy_longdouble *)(arr->data)=*v; break;\
                case NPY_CLONGDOUBLE: *(npy_longdouble *)(arr->data)=*v; break;\
                case NPY_OBJECT: (arr->descr->f->setitem)(pyobj_from_ ## ctype ## 1(*v),arr->data, arr); break;\
        default: return -2;\
        };\
        return 1
static int double_from_pyobj(double* v,PyObject *obj,const char *errmess) {
	PyObject* tmp = NULL;
	if (PyFloat_Check(obj)) {
#ifdef __sgi
		*v = PyFloat_AsDouble(obj);
#else
		*v = PyFloat_AS_DOUBLE(obj);
#endif
		return 1;
	}
	tmp = PyNumber_Float(obj);
	if (tmp) {
#ifdef __sgi
		*v = PyFloat_AsDouble(tmp);
#else
		*v = PyFloat_AS_DOUBLE(tmp);
#endif
		Py_DECREF(tmp);
		return 1;
	}
	if (PyComplex_Check(obj))
		tmp = PyObject_GetAttrString(obj,"real");
	else if (PyString_Check(obj) || PyUnicode_Check(obj))
		/*pass*/;
	else if (PySequence_Check(obj))
		tmp = PySequence_GetItem(obj,0);
	if (tmp) {
		PyErr_Clear();
		if (double_from_pyobj(v,tmp,errmess)) {Py_DECREF(tmp); return 1;}
		Py_DECREF(tmp);
	}
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL) err = #modulename#_error;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
#define rank(var) var ## _Rank
#define shape(var,dim) var ## _Dims[dim]
#define old_rank(var) (((PyArrayObject *)(capi_ ## var ## _tmp))->nd)
#define old_shape(var,dim) (((PyArrayObject *)(capi_ ## var ## _tmp))->dimensions[dim])
#define fshape(var,dim) shape(var,rank(var)-dim-1)
#define len(var) shape(var,0)
#define flen(var) fshape(var,0)
#define old_size(var) PyArray_SIZE((PyArrayObject *)(capi_ ## var ## _tmp))
/* #define index(i) capi_i ## i */
#define slen(var) capi_ ## var ## _len
#define size(var, ...) f2py_size((PyArrayObject *)(capi_ ## var ## _tmp), ## __VA_ARGS__, -1)
#ifdef _WIN32
typedef __int64 long_long;
#else
typedef long long long_long;
typedef unsigned long long unsigned_long_long;
#endif
static int try_pyarr_from_string(PyObject *obj,const string str) {
	PyArrayObject *arr = NULL;
	if (PyArray_Check(obj) && (!((arr = (PyArrayObject *)obj) == NULL)))
		{ STRINGCOPYN(arr->data,str,PyArray_NBYTES(arr)); }
	return 1;
capi_fail:
	PRINTPYOBJERR(obj);
	PyErr_SetString(#modulename#_error,"try_pyarr_from_string failed");
	return 0;
}
static int long_from_pyobj(long* v,PyObject *obj,const char *errmess) {
	PyObject* tmp = NULL;
	if (PyInt_Check(obj)) {
		*v = PyInt_AS_LONG(obj);
		return 1;
	}
	tmp = PyNumber_Int(obj);
	if (tmp) {
		*v = PyInt_AS_LONG(tmp);
		Py_DECREF(tmp);
		return 1;
	}
	if (PyComplex_Check(obj))
		tmp = PyObject_GetAttrString(obj,"real");
	else if (PyString_Check(obj) || PyUnicode_Check(obj))
		/*pass*/;
	else if (PySequence_Check(obj))
		tmp = PySequence_GetItem(obj,0);
	if (tmp) {
		PyErr_Clear();
		if (long_from_pyobj(v,tmp,errmess)) {Py_DECREF(tmp); return 1;}
		Py_DECREF(tmp);
	}
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL) err = #modulename#_error;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
#include "fortranobject.h"#include <math.h>#define STRINGCOPYN(to,from,buf_size)                           \
    do {                                                        \
        int _m = (buf_size);                                    \
        char *_to = (to);                                       \
        char *_from = (from);                                   \
        FAILNULL(_to); FAILNULL(_from);                         \
        (void)strncpy(_to, _from, sizeof(char)*_m);             \
        _to[_m-1] = '\0';                                      \
        /* Padding with spaces instead of nulls */              \
        for (_m -= 2; _m >= 0 && _to[_m] == '\0'; _m--) {      \
            _to[_m] = ' ';                                      \
        }                                                       \
    } while (0)
static int f2py_size(PyArrayObject* var, ...)
{
  npy_int sz = 0;
  npy_int dim;
  npy_int rank;
  va_list argp;
  va_start(argp, var);
  dim = va_arg(argp, npy_int);
  if (dim==-1)
    {
      sz = PyArray_SIZE(var);
    }
  else
    {
      rank = PyArray_NDIM(var);
      if (dim>=1 && dim<=rank)
        sz = PyArray_DIM(var, dim-1);
      else
        fprintf(stderr, "f2py_size: 2nd argument value=%d fails to satisfy 1<=value<=%d. Result will be 0.\n", dim, rank);
    }
  va_end(argp);
  return sz;
}
static int long_double_from_pyobj(long_double* v,PyObject *obj,const char *errmess) {
	double d=0;
	if (PyArray_CheckScalar(obj)){
		if PyArray_IsScalar(obj, LongDouble) {
			PyArray_ScalarAsCtype(obj, v);
			return 1;
		}
		else if (PyArray_Check(obj) && PyArray_TYPE(obj)==NPY_LONGDOUBLE) {
			(*v) = *((npy_longdouble *)PyArray_DATA(obj));
			return 1;
		}
	}
	if (double_from_pyobj(&d,obj,errmess)) {
		*v = (long_double)d;
		return 1;
	}
	return 0;
}
typedef struct {long double r,i;} complex_long_double;#define GETSTRFROMPYTUPLE(tuple,index,str,len) {\
		PyObject *rv_cb_str = PyTuple_GetItem((tuple),(index));\
		if (rv_cb_str == NULL)\
			goto capi_fail;\
		if (PyString_Check(rv_cb_str)) {\
			str[len-1]='\0';\
			STRINGCOPYN((str),PyString_AS_STRING((PyStringObject*)rv_cb_str),(len));\
		} else {\
			PRINTPYOBJERR(rv_cb_str);\
			PyErr_SetString(#modulename#_error,"string object expected");\
			goto capi_fail;\
		}\
	}
numpy.f2py.cfuncs#define SWAP(a,b,t) {\
	t *c;\
	c = a;\
	a = b;\
	b = c;}
/usr/lib/python2.7/dist-packages/numpy/f2py/cfuncs.py#ifndef max
#define max(a,b) ((a > b) ? (a) : (b))
#endif
#ifndef min
#define min(a,b) ((a < b) ? (a) : (b))
#endif
#ifndef MAX
#define MAX(a,b) ((a > b) ? (a) : (b))
#endif
#ifndef MIN
#define MIN(a,b) ((a < b) ? (a) : (b))
#endif
static int try_pyarr_from_complex_float(PyObject* obj,complex_float* v) {
	TRYCOMPLEXPYARRAYTEMPLATE(float,'F');
}
#ifdef DEBUGCFUNCS
#define CFUNCSMESS(mess) fprintf(stderr,"debug-capi:"mess);
#define CFUNCSMESSPY(mess,obj) CFUNCSMESS(mess) \
	PyObject_Print((PyObject *)obj,stderr,Py_PRINT_RAW);\
	fprintf(stderr,"\n");
#else
#define CFUNCSMESS(mess)
#define CFUNCSMESSPY(mess,obj)
#endif
static int calcarrindextr(int *i,PyArrayObject *arr) {
	int k,ii = i[arr->nd-1];
	for (k=1; k < arr->nd; k++)
		ii += (ii*(arr->dimensions[arr->nd-k-1] - 1)+i[arr->nd-k-1]); /* assuming contiguous arr */
	return ii;
}#define pyobj_from_complex_float1(v) (PyComplex_FromDoubles(v.r,v.i))static int long_long_from_pyobj(long_long* v,PyObject *obj,const char *errmess) {
	PyObject* tmp = NULL;
	if (PyLong_Check(obj)) {
		*v = PyLong_AsLongLong(obj);
		return (!PyErr_Occurred());
	}
	if (PyInt_Check(obj)) {
		*v = (long_long)PyInt_AS_LONG(obj);
		return 1;
	}
	tmp = PyNumber_Long(obj);
	if (tmp) {
		*v = PyLong_AsLongLong(tmp);
		Py_DECREF(tmp);
		return (!PyErr_Occurred());
	}
	if (PyComplex_Check(obj))
		tmp = PyObject_GetAttrString(obj,"real");
	else if (PyString_Check(obj) || PyUnicode_Check(obj))
		/*pass*/;
	else if (PySequence_Check(obj))
		tmp = PySequence_GetItem(obj,0);
	if (tmp) {
		PyErr_Clear();
		if (long_long_from_pyobj(v,tmp,errmess)) {Py_DECREF(tmp); return 1;}
		Py_DECREF(tmp);
	}
	{
		PyObject* err = PyErr_Occurred();
		if (err==NULL) err = #modulename#_error;
		PyErr_SetString(err,errmess);
	}
	return 0;
}
#if defined(PREPEND_FORTRAN)
#if defined(NO_APPEND_FORTRAN)
#if defined(UPPERCASE_FORTRAN)
#define F_FUNC(f,F) _##F
#else
#define F_FUNC(f,F) _##f
#endif
#else
#if defined(UPPERCASE_FORTRAN)
#define F_FUNC(f,F) _##F##_
#else
#define F_FUNC(f,F) _##f##_
#endif
#endif
#else
#if defined(NO_APPEND_FORTRAN)
#if defined(UPPERCASE_FORTRAN)
#define F_FUNC(f,F) F
#else
#define F_FUNC(f,F) f
#endif
#else
#if defined(UPPERCASE_FORTRAN)
#define F_FUNC(f,F) F##_
#else
#define F_FUNC(f,F) f##_
#endif
#endif
#endif
#if defined(UNDERSCORE_G77)
#define F_FUNC_US(f,F) F_FUNC(f##_,F##_)
#else
#define F_FUNC_US(f,F) F_FUNC(f,F)
#endif
static int try_pyarr_from_double(PyObject* obj,double* v) {
	TRYPYARRAYTEMPLATE(double,'d');
}
#define pyobj_from_double1(v) (PyFloat_FromDouble(v))#define MEMCOPY(to,from,n)\
    do { FAILNULL(to); FAILNULL(from); (void)memcpy(to,from,n); } while (0)
static int short_from_pyobj(short* v,PyObject *obj,const char *errmess) {
	int i=0;
	if (int_from_pyobj(&i,obj,errmess)) {
		*v = (short)i;
		return 1;
	}
	return 0;
}
static int complex_long_double_from_pyobj(complex_long_double* v,PyObject *obj,const char *errmess) {
	complex_double cd={0.0,0.0};
	if (PyArray_CheckScalar(obj)){
		if PyArray_IsScalar(obj, CLongDouble) {
			PyArray_ScalarAsCtype(obj, v);
			return 1;
		}
		else if (PyArray_Check(obj) && PyArray_TYPE(obj)==NPY_CLONGDOUBLE) {
			(*v).r = ((npy_clongdouble *)PyArray_DATA(obj))->real;
			(*v).i = ((npy_clongdouble *)PyArray_DATA(obj))->imag;
			return 1;
		}
	}
	if (complex_double_from_pyobj(&cd,obj,errmess)) {
		(*v).r = (long_double)cd.r;
		(*v).i = (long_double)cd.i;
		return 1;
	}
	return 0;
}
inames1_tps"COMMON blocks:\n"\subsection{Common block \texttt{%s}}
	int i_f2py=0;static void f2py_setup_%s(%s) {

Build common block mechanism for f2py2e.

Copyright 2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/05/06 10:57:33 $
Pearu Peterson

numpy.f2py.common_rules 1.19 	{NULL}
};"	/%s/ %s\n"/usr/lib/python2.7/dist-packages/numpy/f2py/common_rules.py		Constructing COMMON block support for "%s"...
		  %s
		  Hidden: %s
subroutine f2pyinit%s(setupfunc)extern void %s(f2pyinit%s,F2PYINIT%s)(void(*)(%s));call setupfunc(%s)	F2PyDict_SetItemString(d, "%s", PyFortranObject_New(f2py_%s_def,f2py_init_%s));common /%s/ %scommon %sexternal setupfunc(   t   mt   rett   fwrapt   faddt   chookst   caddt   ihookst   iaddt   doct   daddt   namet   vnamest   varst
   lower_namet   hnamest   inamest   nt   idimst   ctt   att   dmt   dmst   inames1t   st   inames1_tpst   F_FUNCt   tnamet   notecc1fn1pr1kind2mblockcharlenfromskynotonlyunknown_FileInput_MAXCACHEfilelinenoisfirstlinepyffilename_BLOCK_DATA_getblocknamegetextensionparent_blockpythonmoduleskipfunctions_user_interfaceascii_lowercase__user__routinesunknown_interface_is_intent_callback                .unknown__user__routinesblock datacrackline: groupcounter(=%s) is nonpositive. Check the blocks.)/(%s)analyzeline: Failed to evaluate %r. Ignoring: %s
\s*(\(\s*(kind\s*=)?\s*(?P<kind>.*)\s*\)|[*]\s*(?P<kind2>.*?))\s*\Z@:@%s-(%s)+1updatevars: attempt to change the type of "%s" ("%s") to "%s". Ignoring.
program|block\s*data(?P<line>.*)&\s*\Zanalyzeline: Could not crack the use statement.
%s%s(%s,%s)%sappenddecl: Unknown variable definition key:crackline:%d: No pattern for line
%s%s%s=>%s(?P<before>.*?)\banalyzeline: implied-DO list "%s" is not supported. Skipping.
analyzeline: changing init expression of "%s" ("%s") to "%s"
cracktypespec0: no kind/char_selector pattern found for line.
%s+%srmbadname1: Replacing "%s" with "%s".
numpy.f2py.crackfortran/usr/lib/python2.7/dist-packages/numpy/f2py/crackfortran.py[\w]*?-%s)/(%s)analyzevars: character array "character*%s %s(%s)" is considered as "character %s(%s)"; "intent(c)" is forced.
\A\(.*\)\Zsortvarnames: failed to compute dependencies because of cyclic dependencies between \s*\(.*?\).*\w\s*\([^)]*\banalyzeline: appending intent(callback) %s to %s arguments

! This file was auto-generated with f2py (version:%s).
! See http://cens.ioc.ee/projects/f2py2e/
\s*(?P<before>''')(?P<this>.*?)(?P<after>''')\s*\Zcharacter|logical|integer|real|complex|double\s*(precision\s*(complex|)|complex)|type(?=\s*\([\w\s,=(*)]*\))|byte%s%sintent(%s) %s	Reading file %s (format:%s%s)
\A\b\w+\b\Z([-+]?((?:\d+(?:\.\d*)?|\d*\.\d+))[eE]((?:[-+]?\d+)?)|(\d+\.\d*))[a-z\s]*?updatevars: no name pattern found for entity=%s. Skipping.
analyzeline: could not extract types pattern of implicit statement part "%s"
\A\(.+?[,].+?\)\ZPost-processing...
@_@\w[\w\d_$]*.*?'''intent|depend|note|checkanalyzeline: no group yet. Creating program group with name "%s".
kind("\1")vars2fortran: No definition for argument "%s".
+%s*%s\s*(?P<name>\b[\w$]+\b)\s*@\(@\s*(?P<args>.*)\s*@\)@\s*\Z\bkind\s*\(\s*(?P<value>.*)\s*\),strict(end\s*(if|do|where|select|while|forall))|(module\s*procedure)get_useparameters: no module %s info used by %s
analyzeline: Overwriting the value of parameter "%s" ("%s") with "%s".
(?P<before>[^"]*)\b%s\b\s*@\(@(?P<args>[^@]*)@\)@.*\Zcracktypespec: no charselector pattern found for %s
analyzeline: cannot handle multiple attributes without type specification. Ignoring %r.
\A(?P<name>\w+)\s*\(.*?\)\s*\Zanalyzeline: intent(callback) %s is ignoredanalyzeline: Not local=>use pattern found in %s
analyzeline: argument list is malformed (missing argument).

analyzeline: expected "<char>-<char>" instead of "%s" in range list of implicit statement
Post-processing (stage 2)...
vars2fortran: Warning: cross-dependence between variables "%s" and "%s"
\A\s*\b(?P<name>.*?)\b\s*(\((?P<dims>.*?)\)|)\s*\ZFlag sourcecodeform must be either 'fix' or 'free': %s
crackfortran --- read fortran (77,90) code and extract declaration information.

Copyright 1999-2004 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/09/27 07:13:49 $
Pearu Peterson


Usage of crackfortran:
======================
Command line keys: -quiet,-verbose,-fix,-f77,-f90,-show,-h <pyffilename>
                   -m <module name for f77 routines>,--ignore-contains
Functions: crackfortran, crack2fortran
The following Fortran statements/constructions are supported
(or will be if needed):
   block data,byte,call,character,common,complex,contains,data,
   dimension,double complex,double precision,end,external,function,
   implicit,integer,intent,interface,intrinsic,
   logical,module,optional,parameter,private,public,
   program,real,(sequence?),subroutine,type,use,virtual,
   include,pythonmodule
Note: 'virtual' is mapped to 'dimension'.
Note: 'implicit integer (z) static (z)' is 'implicit static (z)' (this is minor bug).
Note: code after 'contains' will be ignored until its scope ends.
Note: 'common' statement is extended: dimensions are moved to variable definitions
Note: f2py directive: <commentchar>f2py<line> is read as <line>
Note: pythonmodule is introduced to represent Python module

Usage:
  `postlist=crackfortran(files,funcs)`
  `postlist` contains declaration information read from the list of files `files`.
  `crack2fortran(postlist)` returns a fortran code to be saved to pyf-file

  `postlist` has the following structure:
 *** it is a list of dictionaries containing `blocks':
     B = {'block','body','vars','parent_block'[,'name','prefix','args','result',
          'implicit','externals','interfaced','common','sortvars',
          'commonvars','note']}
     B['block'] = 'interface' | 'function' | 'subroutine' | 'module' |
                  'program' | 'block data' | 'type' | 'pythonmodule'
     B['body'] --- list containing `subblocks' with the same structure as `blocks'
     B['parent_block'] --- dictionary of a parent block:
                             C['body'][<index>]['parent_block'] is C
     B['vars'] --- dictionary of variable definitions
     B['sortvars'] --- dictionary of variable definitions sorted by dependence (independent first)
     B['name'] --- name of the block (not if B['block']=='interface')
     B['prefix'] --- prefix string (only if B['block']=='function')
     B['args'] --- list of argument names if B['block']== 'function' | 'subroutine'
     B['result'] --- name of the return value (only if B['block']=='function')
     B['implicit'] --- dictionary {'a':<variable definition>,'b':...} | None
     B['externals'] --- list of variables being external
     B['interfaced'] --- list of variables being external and defined
     B['common'] --- dictionary of common blocks (list of objects)
     B['commonvars'] --- list of variables used in common blocks (dimensions are moved to variable definitions)
     B['from'] --- string showing the 'parents' of the current block
     B['use'] --- dictionary of modules used in current block:
         {<modulename>:{['only':<0|1>],['map':{<local_name1>:<use_name1>,...}]}}
     B['note'] --- list of LaTeX comments on the block
     B['f2pyenhancements'] --- optional dictionary
          {'threadsafe':'','fortranname':<name>,
           'callstatement':<C-expr>|<multi-line block>,
           'callprotoargument':<C-expr-list>,
           'usercode':<multi-line block>|<list of multi-line blocks>,
           'pymethoddef:<multi-line block>'
           }
     B['entry'] --- dictionary {entryname:argslist,..}
     B['varnames'] --- list of variable names given in the order of reading the
                       Fortran code, useful for derived types.
     B['saved_interface'] --- a string of scanned routine signature, defines explicit interface
 *** Variable definition is a dictionary
     D = B['vars'][<variable name>] =
     {'typespec'[,'attrspec','kindselector','charselector','=','typename']}
     D['typespec'] = 'byte' | 'character' | 'complex' | 'double complex' |
                     'double precision' | 'integer' | 'logical' | 'real' | 'type'
     D['attrspec'] --- list of attributes (e.g. 'dimension(<arrayspec>)',
                       'external','intent(in|out|inout|hide|c|callback|cache|aligned4|aligned8|aligned16)',
                       'optional','required', etc)
     K = D['kindselector'] = {['*','kind']} (only if D['typespec'] =
                         'complex' | 'integer' | 'logical' | 'real' )
     C = D['charselector'] = {['*','len','kind']}
                             (only if D['typespec']=='character')
     D['='] --- initialization expression string
     D['typename'] --- name of the type if D['typespec']=='type'
     D['dimension'] --- list of dimension bounds
     D['intent'] --- list of intent specifications
     D['depend'] --- list of variable names on which current variable depends on
     D['check'] --- list of C-expressions; if C-expr returns zero, exception is raised
     D['note'] --- list of LaTeX comments on the variable
 *** Meaning of kind/char selectors (few examples):
     D['typespec>']*K['*']
     D['typespec'](kind=K['kind'])
     character*C['*']
     character(len=C['len'],kind=C['kind'])
     (see also fortran type declaration statement formats below)

Fortran 90 type declaration statement format (F77 is subset of F90)
====================================================================
(Main source: IBM XL Fortran 5.1 Language Reference Manual)
type declaration = <typespec> [[<attrspec>]::] <entitydecl>
<typespec> = byte                          |
             character[<charselector>]     |
             complex[<kindselector>]       |
             double complex                |
             double precision              |
             integer[<kindselector>]       |
             logical[<kindselector>]       |
             real[<kindselector>]          |
             type(<typename>)
<charselector> = * <charlen>               |
             ([len=]<len>[,[kind=]<kind>]) |
             (kind=<kind>[,len=<len>])
<kindselector> = * <intlen>                |
             ([kind=]<kind>)
<attrspec> = comma separated list of attributes.
             Only the following attributes are used in
             building up the interface:
                external
                (parameter --- affects '=' key)
                optional
                intent
             Other attributes are ignored.
<intentspec> = in | out | inout
<arrayspec> = comma separated list of dimension bounds.
<entitydecl> = <name> [[*<charlen>][(<arrayspec>)] | [(<arrayspec>)]*<charlen>]
                      [/<init_expr>/ | =<init_expr>] [,<entitydecl>]

In addition, the following attributes are used: check,depend,note

TODO:
    * Apply 'parameter' attribute (e.g. 'integer parameter :: i=2' 'real x(i)'
                                   -> 'real x(2)')
    The above may be solved by creating appropriate preprocessor program, for example.

analyzeline: could not extract info of implicit statement part "%s"
(\s*&|)(?P<line>.*)%s%sexternal %sanalyzeline: No context for multiline block.
%s%sdepend(%s).*\b%s\b\s*(\((?P<lenkind>.*)\)|[*]\s*(?P<charlen>.*))\s*\Zselected_int_kind(\1)
    reset=-1  --- initialize
    reset=0   --- crack the line
    reset=1   --- final check if mismatch of blocks occured

    Cracked data is saved in grouplist[0].
    determineexprtype: selected kind types not supported (%s)
\A\s*(?P<local>\b[\w]+\b)\s*=\s*>\s*(?P<use>\b[\w]+\b)\s*\Z%s%s%s %s%s%s %s%s%s%s%s%s%send %s %sanalyzecommon: failed to extract "<name>[(<dims>)]" from "%s" in common /%s/.
%s-%s-%spostcrack: Expected block dictionary instead of analyzeline: previously defined common block encountered. Skipping.
updatevars: attempt to change the kindselector "%s" of "%s" ("%s") to "%s". Ignoring.
%s%suse %s,analyzeline: Overwriting earlier "implicit none" statement.
\s*\(\s*(?P<name>\w+)\s*\)intent\s*\(.*?\bcallback\bAll arguments will have attribute %s%s
\s*(?P<this>(@\(@.*?@\)@|[*][\d*]+|[*]\s*@\(@.*?@\)@|))(?P<after>.*)\Zdouble\s*complex\b[a-z][\w$]*\b\s*(?P<before>%s(?=\s*(\b(%s)\b)))\s*(?P<this>(\b(%s)\b))\s*(?P<after>%s)\s*\Zreadfortrancode: Found non-(space,digit) char in the first column.
	Are you sure that this code is in fix form?
	line=%s+1j*(%slen(%s)%s>=%sabcdefghopqrstuvwxyz$_undo_rmbadname1: Replacing "%s" with "%s".
analyzeline: could not extract name,expr in parameter statement "%s" of "%s"
\n\n\s*(@\(@\s*(?!/)\s*(?P<array>.*?)\s*@\)@\s*[*]\s*(?P<len>.*?)|([*]\s*(?P<len2>.*?)|)\s*(@\(@\s*(?!/)\s*(?P<array2>.*?)\s*@\)@|))\s*(=\s*(?P<init>.*?)|(@\(@|)/\s*(?P<init2>.*?)\s*/(@\)@|)|)\s*\Z%s :: %s=%sbuildimplicitrules: no implicit rules for routine %s.
Line #%d in %s:"%s"
	callfun %s(%s) result (%s)dimension|virtualdimension(%s)(?P<start>[a-zA-Z]+)updatevars:%s: attempt to change empty charselector to %r. Ignoring.

    TODO:
          function return values
          determine expression types if in argument list
    ([-+]?(?:\d+(?:\.\d*)?|\d*\.\d+))[dD]((?:[-+]?\d+)?)\A[+-]?[\d.]+[\d+-de.]*(_(P<name>[\w]+)|)\Z\A[+-]?\d+(_(P<name>[\w]+)|)\Z\bselected_int_kind\s*\(\s*(?P<value>.*)\s*\)
    Read fortran codes from files and
     1) Get rid of comments, line continuations, and empty lines; lower cases.
     2) Call dowithline(line) on every line.
     3) Recursively call itself when statement "include '<filename>'" is met.
    analyzevars: charselector=%r unhandled.%s%scommon %sIn: %s:%s
updatevars: attempt to change the init expression of "%s" ("%s") to "%s". Ignoring.
\s*(kind\s*=\s*(?P<kind>.*?)\s*(@,@\s*len\s*=\s*(?P<len>.*)|)|(len\s*=\s*|)(?P<len2>.*?)\s*(@,@\s*(kind\s*=\s*|)(?P<kind2>.*)|))\s*\Z.false.isintent_%s(var)	getarrlen:variable "%s" undefined
\s*(?P<this>.*?)\s*(\(\s*(?P<after>[a-z-, ]+)\s*\)\s*|)\Z/(1)analyzeline: intent(callback) %s is already in argument list\A\s*(?P<name>\b[\w]+\b)\s*((,(\s*\bonly\b\s*:|(?P<notonly>))\s*(?P<list>.*))|)\s*\Zcracktypespec: no selector used for %s
updatevars: attempt to change the charselector "%s" of "%s" ("%s") to "%s". Ignoring.
%s * %s + %s\s*(?P<name>\b[\w$]+\b)\s*(@\(@\s*(?P<args>[\w\s,]*)\s*@\)@|)\s*((result(\s*@\(@\s*(?P<result>\b[\w$]+\b)\s*@\)@|))|(bind\s*@\(@\s*(?P<bind>.*)\s*@\)@))*\s*\Z%s_%i\A[a-z]+[\w$]*\Zanalyzeline: no name pattern found in %s statement for %s. Skipping.
\b(?P<after>.*)cracktypespec: no kindselector pattern found for %s
analyzeline: expected "<char>-<char>" instead of "%s" in range list of implicit statement (2)
+%s)/(%s)%s%s(%s,%i)%s==%sget_useparameters: mapping for %s not impl.%s%soptional %s%s-%s+%s[^c*]\s*[^\s\d\t]"%s" in evaluating %r (available names: %s)
%s%scommon /%s/ %s%s%sdimension(%s)
    TODO:
    public sub
    ...
    crackline: End group %s does not match with previous Begin group %s
	%supdatevars: attempt to change the typename of "%s" ("%s") to "%s". Ignoring.
get_useparameters: overriding parameter %s with value from module %s([a-z]+[\w\s(=*+-/)]*?|)analyzeline: No code implemented for line.
analyzeline: Creating additional interface block (groupcounter=%s).
%s * %s - %s.true.\s*(?P<result>\b[a-z]+[\w]*\b)\s*[=].*\s*include\s*(\'|")(?P<name>[^\'"]*)(\'|")%s only:%s%sintent(callback) %supdatevars: "%s %s" is mapped to "%s %s(%s)"
\bselected_(int|real)_kind\s*\(\s*(?P<value>.*)\s*\)crackline: could not resolve function call for line=%s.
analyzeline: Creating module block %s
[\w\s]*double\s*precisioncrackline: Mismatch of blocks encountered. Trying to fix it by assuming "end" statement.
cracktypespec: no typename found in %s
\A[a-z]\w*\Zcrackline: groupcounter=%s groupname=%s
! in %s@(@analyzevars: prefix (%s) were not used
analyzevars: typespec of variable %s is not defined in routine %s.
appenddecl: "%s" not implemented.
updatevars: could not crack entity declaration "%s". Ignoring.
-%s*%sanalyzeline: No name/args pattern found for line.
%s(%s)%s|module(?!\s*procedure)|python\s*module|interface|type(?!\s*\()%sBlock: %s
%s%sentry %s(%s)analyzeline: ignoring program arguments
Reading fortran codes...
determineexprtype: could not determine expressions (%s) type.
!    -*- f90 -*-
! Note: the context of this file is case sensitive.
%s%s+%s|static|automatic|undefined\s*(?P<name>\b[\w]+\b)\s*(?P<after>.*)\s*\Z()[]{}=+-/* \d+_%s%scheck(%s)analyzeline: missing __user__ module (could be nothing)
updatevars:%s: attempt to change %r to %r. Ignoring.
get_parameters: got "%s" on %s
readfortrancode: could not find include file %s in %s. Ignoring.
threadsafe|fortranname|callstatement|callprotoargument|usercode|pymethoddef@ @vars2fortran: No typespec for argument "%s".
_get_depend_dict: no dependence info for %s
(?P<line>([^"]*["][^"]*["][^"!]*|[^\']*\'[^\']*\'[^\'!]*|[^!\'"]*))!{1}(?P<rest>.*)end|endprogram|endblockdata|endmodule|endpythonmodule|endinterfaceget_parameters:parameter %s does not have value?!
vars2fortran: Confused?!: "%s" is not defined in vars.
Unexpected end of file when reading multiline
@)@(=   t   mt   caset   linet   blockt   newnamet   namet   argst   resultt   bindt   xt
   needmodulet   needinterfacet   itt   kt   tt   typespect   selectort   attrt   edeclt	   last_namet   llt   it   plt   cht   et   m1t   apt   initexprt   paramst   ttt   vt   msgt   implt   declt   m2t
   kindselectt
   charselectt   typenamet   rt   begct   endct   ot   dlt   ilt   ft   fct   inpt   ct   varst   lt   jt   llent   clt   bnt   olt	   commonkeyt   mmt   isonlyt   rlt   dt   gc(   t   blockt   argst   tabt   grett   urett   gt	   blocktypet   userisdefinedt   useblockt   kt   namet
   interfacedt   mvarst   mnamet   it	   interfacet   et   edeft   jt   bt   bbt   mblock(5   t   blockt   implicitrulest	   attrrulest   varst   gent   nt   kt   svarst   argst   at   paramst   dep_matchest
   name_matcht   vt   mt   ln0t   lt   savelindimst   attrt   dimt   intentt   dependt   checkt   notet   xt   ct   dt   start   pt   dlt   dit   shape_macrot   flagt   it   nit   ddepst   adt   pdt   rt   aat   lengtht   prt   ispuret   isrect   pr1t   typespect   selectort   edeclt
   kindselectt
   charselectt   typenamet
   neededvarst   name(   t   typespect   selectort   attrspect
   entitydeclt	   last_namet
   kindselectt
   charselectt   typenamet   xt   lt   ct   at   mt   st   elt   el1t   et   e1t   enamet   edeclt   not_has_typespect   kt   m1t   d1t   lkt   dmt   dm1(   t   blockt   tabt   as_interfacet   rett   gt   prefixt   namet   argst	   blocktypet   argslt   varst   at   f2pyenhancementst   kt
   intent_lstt   uset   commont   resultt   bodyt   messt   entry_stmtst   i(   t   ffilet
   dowithlinet   istopt   saveglobalst   localdolowercaset   contt	   finallinet   llt   commentlinet   includelinet   cont1t   cont2t
   mline_markt   l1t   _mt   spacedigitst   fint   lt   extt   rt   rlt   origfinallinet   lct   mt   fnt   include_dirst	   foundfilet   inc_dirt   fn1(3   s   ints   doubles   floats   chars   shorts   longs   voids   cases   whiles   returns   signeds   unsigneds   ifs   fors   typedefs   sizeofs   unions   structs   statics   registers   news   breaks   dos   gotos   switchs   continues   elses   inlines   externs   deletes   consts   autos   lens   ranks   shapes   indexs   slens   sizes   _is   maxs   mins   flens   fshapes   strings   complex_doubles   float_doubles   stdins   stderrs   stdouts   types   defaultbuild_flibgettempdirall_compilersnumpy_distutils_versionFound new numpy version %r in %sImporting numpy_distutils.command.cpuinfo ...(ignore it, build_flib is obsolute for numpy.distutils 0.2.2 and up)numpy_distutils.command.build_flibnumpy_distutils.fcompilernumpy_distutils.cpuinfonumpy.f2py.diagnosesys.path=%rChecking availability of supported Fortran compilers:Running %r:Importing numpy.distutils.cpuinfo ...sys.prefix:sys.platform=%rImporting numpy_distutils.command.build_flib ...Found f2py2e version %r in %sImporting numpy_distutils.fcompiler ...Importing numpy.distutils.fcompiler ...sys.version:Found numpy.distutils version %r in %rCPU information:/usr/lib/python2.7/dist-packages/numpy/f2py/diagnose.pyFailed to import f2py2e:Failed to import new numpy:os.name=%rFound numpy_distutils version %r in %rFailed to import numpy_distutils:Importing numpy_distutils.cpuinfo ...(ignore it)f2pydiroptnamenum_infoget_prefixusing_numericusing_numarraynum_include_dirskip:[-][-]((no[-]|)(wrap[-]functions|lower)|debug[-]capi|quiet)|[-]include--overwrite-signature%s-f2pywrappers.fAll blocks must be python module blocks but got %sBuilding modules...
Removing build directory %s
Invalid use of -D:--no-lower

f2py2e - Fortran to Python C/API generator. 2nd Edition.
         See __usage__ below.

Copyright 1999--2011 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@cens.ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/05/06 08:31:19 $
Pearu Peterson

numpy.f2py.f2py2e--build-platlib[.]pyf([.]src|)--f2py-wrapper-output	Module "%s" uses nonexisting "%s" which will be ignored.
[-][-]((f(77|90)(flags|exec)|opt|arch)=|(debug|noopt|noarch|help[-]fcompiler))No %s resources found in system (try `f2py --help-link`)
Creating build directory %sf2py option --include_paths is deprecated, use --include-paths instead.
Skipping Makefile build for module "%s" which is used by %s
/usr/lib/python2.7/dist-packages/numpy/f2py/f2py2e.py--wrap-functions[-][-]link[-]--show-compilers[-][-](verbose)[.](o|a|so)Usage:

1) To construct extension module sources:

      f2py [<options>] <fortran files> [[[only:]||[skip:]] \
                                        <fortran functions> ] \
                                       [: <fortran files> ...]

2) To compile fortran files and build extension modules:

      f2py -c [<options>, <build_flib options>, <extra options>] <fortran files>

3) To generate signature files:

      f2py -h <filename.pyf> ...< same options as in (1) >

Description: This program generates a Python C/API file (<modulename>module.c)
             that contains wrappers for given fortran functions so that they
             can be called from Python. With the -c option the corresponding
             extension modules are built.

Options:

  --2d-numpy       Use numpy.f2py tool with NumPy support. [DEFAULT]
  --2d-numeric     Use f2py2e tool with Numeric support.
  --2d-numarray    Use f2py2e tool with Numarray support.
  --g3-numpy       Use 3rd generation f2py from the separate f2py package.
                   [NOT AVAILABLE YET]

  -h <filename>    Write signatures of the fortran routines to file <filename>
                   and exit. You can then edit <filename> and use it instead
                   of <fortran files>. If <filename>==stdout then the
                   signatures are printed to stdout.
  <fortran functions>  Names of fortran routines for which Python C/API
                   functions will be generated. Default is all that are found
                   in <fortran files>.
  <fortran files>  Paths to fortran/signature files that will be scanned for
                   <fortran functions> in order to determine their signatures.
  skip:            Ignore fortran functions that follow until `:'.
  only:            Use only fortran functions that follow until `:'.
  :                Get back to <fortran files> mode.

  -m <modulename>  Name of the module; f2py generates a Python/C API
                   file <modulename>module.c or extension module <modulename>.
                   Default is 'untitled'.

  --[no-]lower     Do [not] lower the cases in <fortran files>. By default,
                   --lower is assumed with -h key, and --no-lower without -h key.

  --build-dir <dirname>  All f2py generated files are created in <dirname>.
                   Default is tempfile.mkdtemp().

  --overwrite-signature  Overwrite existing signature file.

  --[no-]latex-doc Create (or not) <modulename>module.tex.
                   Default is --no-latex-doc.
  --short-latex    Create 'incomplete' LaTeX document (without commands
                   \documentclass, \tableofcontents, and \begin{document},
                   \end{document}).

  --[no-]rest-doc Create (or not) <modulename>module.rst.
                   Default is --no-rest-doc.

  --debug-capi     Create C/API code that reports the state of the wrappers
                   during runtime. Useful for debugging.

  --[no-]wrap-functions    Create Fortran subroutine wrappers to Fortran 77
                   functions. --wrap-functions is default because it ensures
                   maximum portability/compiler independence.

  --include-paths <path1>:<path2>:...   Search include files from the given
                   directories.

  --help-link [..] List system resources found by system_info.py. See also
                   --link-<resource> switch below. [..] is optional list
                   of resources names. E.g. try 'f2py --help-link lapack_opt'.

  --quiet          Run quietly.
  --verbose        Run with extra verbosity.
  -v               Print f2py version ID and exit.


numpy.distutils options (only effective with -c):

  --fcompiler=         Specify Fortran compiler type by vendor
  --compiler=          Specify C compiler type (as defined by distutils)

  --help-fcompiler     List available Fortran compilers and exit
  --f77exec=           Specify the path to F77 compiler
  --f90exec=           Specify the path to F90 compiler
  --f77flags=          Specify F77 compiler flags
  --f90flags=          Specify F90 compiler flags
  --opt=               Specify optimization flags
  --arch=              Specify architecture specific optimization flags
  --noopt              Compile without optimization
  --noarch             Compile without arch-dependent optimization
  --debug              Compile with debugging information

Extra options (only effective with -c):

  --link-<resource>    Link extension module with <resource> as defined
                       by numpy.distutils/system_info.py. E.g. to link
                       with optimized LAPACK libraries (vecLib on MacOSX,
                       ATLAS elsewhere), use --link-lapack_opt.
                       See also --help-link switch.

  -L/path/to/lib/ -l<libname>
  -D<define> -U<name>
  -I/path/to/include/
  <filename>.o <filename>.so <filename>.a

  Using the following macros may be required with non-gcc Fortran
  compilers:
    -DPREPEND_FORTRAN -DNO_APPEND_FORTRAN -DUPPERCASE_FORTRAN
    -DUNDERSCORE_G77

  When using -DF2PY_REPORT_ATEXIT, a performance report of F2PY
  interface is printed out at exit (platforms: Linux).

  When using -DF2PY_REPORT_ON_ARRAY_COPY=<int>, a message is
  sent to stderr whenever F2PY interface makes a copy of an
  array. Integer <int> sets the threshold for array sizes when
  a message should be shown.

Version:     %s
numpy Version: %s
Requires:    Python 2.3 or higher.
License:     NumPy license (see LICENSE.txt in the NumPy source code)
Copyright 1999 - 2011 Pearu Peterson all rights reserved.
http://cens.ioc.ee/projects/f2py2e/--rest-doc--no-wrap-functionsTip: If your original code is Fortran source then you must use -m option.
h-overwrite[-][-]((f(90)?compiler([-]exec|)|compiler)=|help[-]compiler)Run f2py as if string.join(comline_list,' ') is used as a command line.
    In case of using -h flag, return None.
    do-lowerSignature file "%s" exists!!! Use --overwrite-signature to overwrite.
%s %s
IOError: %s. Skipping file "%s".
--latex-doc--build-base--coutput--build-tempUnknown option %s

    Filter files by prefix and suffix.
    Unknown vendor: "%s"
    Do it all in one call!
    Saving signatures to file "%s"
Stopping. Edit the signature file and then run f2py on the signature file: 	Skipping module "%s" which is used by %s.
(3   t   tempfilet   it   remove_build_dirt	   build_dirt   _reg1t   _mt   sysinfo_flagst   ft   _reg2t
   f2py_flagst   f2py_flags2t   flt   at   _reg3t
   flib_flagst   _reg4t   fc_flagst   del_listt   st   vt	   fcompilert   allowed_keyst   nvt   ovt   vmapt   _reg5t   setup_flagst
   modulenamet   sourcest   optnamet   get_f2py_modulenamet	   pyf_filest   extra_objectst   include_dirst   library_dirst	   librariest   undef_macrost   define_macrost   using_numarrayt   using_numerict
   name_valuet   get_infot   num_include_dirt   num_infot   setupt	   Extensiont   ext_argst   dict_appendt   nt   extt   shutil(   t	   inputlinet   filest   funcst	   skipfuncst	   onlyfuncst   debugt   ft   f2t   f3t   f4t   f5t   f6t   f7t   f8t   f9t   verboset   dolct
   dolatexdoct	   dorestdoct	   wrapfuncst	   buildpatht   include_pathst	   signsfilet
   modulenamet   optionst   lt   detaildiff_memusage2current_memusagememory usage change at step %i:in %.2f secondsnumpy.f2py.f2py_testingcurrent virtual memory size:/usr/lib/python2.7/dist-packages/numpy/f2py/f2py_testing.py\A\d+\Zinitial virtual memory size:"Fortran 90/95 modules:\n" allocate(d(%s))
%s()      end if
      if (allocated(d)) then
         do i=1,r
            s(i) = size(d,i)
         end do
      end if
      flag = 1
      call f2pysetdata(d,allocated(d))

Build F90 module support for f2py2e.

Copyright 2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/02/03 19:30:23 $
Pearu Peterson

	PyDict_SetItemString(d, "%s", PyFortranObject_New(f2py_%s_def,f2py_init_%s));	{NULL}
};
\subsection{Fortran 90/95 module \texttt{%s}}
numpy.f2py.f90mod_rulesinteger flag
		  Variables: %s
	f2py_%s_def[i_f2py++].func = %s;"	%s --- %s"extern void %s(f2pyinit%s,F2PYINIT%s)(void (*)(%s));end subroutine f2pyinit%s
      end if
      if (allocated(d)) then
         do i=1,r
            s(i) = size(d,i)
         end do
         !s(r) must be equal to len(d(1))
      end if
      flag = 2
      call f2pysetdata(d,allocated(d))external f2pysetupfuncvoid (*)(int*,int*,void(*)(char*,int*),int*)static void f2py_setup_%s(%s) {
	int i_f2py=0;%svoid (*%s)(int*,int*,void(*)(char*,int*),int*)f2py_%s_getdims_%scall f2pysetupfunc(%s)end subroutine %s	{"%s",%s,{{%s,%s}},%s},subroutine f2pyinit%s(f2pysetupfunc) 1.27 		Constructing F90 module support for "%s"...
f2pywrap_%s_%s      external f2pysetdata
      logical ns
      integer r,i,j
      integer(%d) s(*)
      ns = .FALSE.
      if (allocated(d)) then
         do i=1,r
            if ((size(d,i).ne.s(i)).and.(s(i).ge.0)) then
               ns = .TRUE.
            end if
         end do
         if (ns) then
            deallocate(d)
         end if
      end if
      if ((.not.allocated(d)).and.(s(1).ge.1)) thenchar *%ssubroutine %s(r,s,f2pysetdata,flag)/usr/lib/python2.7/dist-packages/numpy/f2py/f90mod_rules.py\subsubsection{	{"%s",-1,{{-1}},0,NULL,(void *)f2py_rout_#modulename#_%s_%s,doc_f2py_rout_#modulename#_%s_%s},range(1,%s+1)use %s, only: d => %s
(%   t   pymodt   rulest   rett   fhookst   faddt   doct   daddt   mt   sargst   fargst   efargst   modobjst   notvarst   onlyvarst   sargspt   ifargst   mfargst   bt   nt   vart   chookst   caddt   ihookst   iaddt   vrdt   notet   ctt   att   dmt   dmst   use_fgetdims2t   it   apit   wrapt   art   F_FUNCt   areturn_char_star		Creating wrapper for Fortran function "%s"("%s")...
character*(*)call %s(%s)end subroutine f2pywrap_%s_%sf2py_%s_d%sshape(%s, %s)subroutine f2pywrap_%s_%s (%s)

Rules for building C/API module with f2py2e.

Copyright 1999,2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2004/11/26 11:13:06 $
Pearu Peterson

%sf2pywrap%s = %s(%s)character(len=10)%s(%s=%s)numpy.f2py.func2subr 1.16 out=%svar2fixfortran: No definition for argument "%s".
/usr/lib/python2.7/dist-packages/numpy/f2py/func2subr.pysubroutine f2pywrap%s (%s)character*10%s(len=*)%s = .not.(.not.%s(%s))		Creating wrapper for Fortran subroutine "%s"("%s")...
var2fixfortran: No typespec for argument "%s".
(   t   routt	   signaturet
   extra_argst   varst   at   vt   it   dt   dnt   dvt   need_interfacet   rett   addt   namet   fortrannamet   f90modet   newnamet   argst   lt   return_char_start
   charselectt   sargst   linet   dumped_args(   t   routt	   signaturet
   extra_argst   varst   at   vt   it   dt   dnt   dvt   need_interfacet   rett   addt   namet   fortrannamet   f90modet   argst   sargst   linet   dumped_args/usr/lib/python2.7/dist-packages/numpy/f2py/info.pynumpy.f2py.infoFortran to Python Interface Generator.

cfsltxnb1fsrcpynameasctimekeys_xamodnotetopyarrfunctypekwlistxaxaformatargformatdocsignxakeyformatkeys_capikwlistoptlocaltimesetjmpbufmodulebodycallfortranroutine_defdocsignshortreturnformatclosepyobjfromdocsignxashortroutdebugenterroutdebugleavedocsignoptshortcleanupfrompyobjinitf2pywraphookroutdebugfailurecallcompaqfortrancallfortranappenddocsignatureshortinitf2pywraphooksdeclfortranroutinelatexdocsignatureshort{i    s   thi   s   sti   s   ndi   s   rdi   s   thi   s   thi   s   thi   s   thi   s   thi	   s   th0{s	   docstrouts   
s   decls   
s   routdebugfailures   
s   routdebugleaves   
s   routdebugenters   
s	   docstrreqs   
s   latexdocstrcbss   
s   latexdocstropts   
s	   docstropts   
s	   setjmpbufs    || s	   docstrcbss   
s   latexdocstrsignss   
s   docstrsignss   \n"
"s   latexdocstrouts   
s   callfortranroutines   
s   latexdocstrreqs   
0	CHECKGENERIC(#check#,"#check#","#nth# #varname#") {	} /*CHECKGENERIC(#check#)*/	#ctype# #varname# = NULL;	int slen(#varname#);Module #modulename#
================================================================================
#restdoc#	#ctype# *#varname# = NULL;	npy_intp #varname#_Dims[#rank#] = {#rank*[-1]#};	const int #varname#_Rank = #rank#;\section{Module \texttt{#texmodulename#}}
#modnote#
#latexdoc#	PyObject *#varname#_capi = Py_None;#cbname#	#ctype# #name#_return_value = NULL;	int #name#_return_value_len = 0;	PyArrayObject *capi_#varname#_tmp = NULL;	int capi_#varname#_intent = 0;\subsection{Wrapper function \texttt{#texname#}}

\noindent{{}\verb@#docreturn##name#@{}}\texttt{(#latexdocsignatureshort#)}
#routnote#

#latexdocstrsigns#

#includes#
#includes0#

,capi_#varname#_tmp	slen(#varname#) = #length#;
	f2py_success = #ctype#_from_pyobj(&#varname#,&slen(#varname#),#init#,#varname#_capi,"#ctype#_from_pyobj failed in converting #nth# `#varname#' of #pyname# to C #ctype#");
	if (f2py_success) {	fprintf(stderr,"debug-capi:Python C/API function #modulename#.#name#(#docsignature#)\n");		Constructing wrapper function "%s"...
/*eof body*/	#ctype# #varname# = 0;See f2py2e/common_rules.py: buildhooksSee f2py2e/cb_rules.py: buildcallback!     -*- f90 -*-
extern void #F_WRAPPEDFUNC#(#name_lower#,#NAME#)(#callprotoargument#);		int *_i,capi_i=0;
		CFUNCSMESS("#name#: Initializing #varname#=#init#\n");
		if (initforcomb(capi_#varname#_tmp->dimensions,capi_#varname#_tmp->nd,1)) {
			while ((_i = nextforcomb()))
				#varname#[capi_i++] = #init#; /* fortran way */
		} else {
			if (!PyErr_Occurred())
				PyErr_SetString(#modulename#_error,"Initialization of #nth# #varname# failed (initforcomb).");
			f2py_success = 0;
		}
	}
	if (f2py_success) {	fprintf(stderr,"#vardebugshowvalue#\n",slen(#varname#),#varname#);	#setdims#;	#callstatement#;
	/*(*f2py_func)(#callfortran#);*/	Fortran 90 wrappers are saved to "%s"
overwrite_#varname#,	/* Processing auxiliary variable #varname# */	if (#varname#_capi==Py_None) {#varname#.r = #init.r#, #varname#.i = #init.i#;} else	CHECKSTRING(#check#,"#check#","#nth# #varname#","#varshowvalue#",#varname#) {See f2py2e/f90mod_rules.py: buildhooks	STRINGFREE(#name#_return_value);
#usercode#

/* See f2py2e/rules.py */
#externroutines#

	Py_BEGIN_ALLOW_THREADS		#ctype# capi_c;	if (#varname#_capi == Py_None) #varname# = #init#; else	#varname#_capi = pyobj_from_#ctype#1(#varname#);\nReturns\n-------(setjmp(#cbname#_jmpbuf))		fprintf(stderr,"#vardebugshowvalue# (call-back in C).\n",#cbname#);	if ((#name#_return_value = (string)malloc(sizeof(char)*(#name#_return_value_len+1))) == NULL) {#varname#_extra_args,#initf2pywraphook#	Building module "%s"...
evision: $");
	PyDict_SetItemString(d, "__version__", s);
#if PY_VERSION_HEX >= 0x03000000
	s = PyUnicode_FromString(
#else
	s = PyString_FromString(
#endif
		"This module '#modulename#' is auto-generated with f2py (version:#f2py_version#).\nFunctions:\n"
#docs#".");
	PyDict_SetItemString(d, "__doc__", s);
	#modulename#_error = PyErr_NewException ("#modulename#.error", NULL, NULL);
	Py_DECREF(s);
	for(i=0;f2py_routine_defs[i].name!=NULL;i++)
		PyDict_SetItemString(d, f2py_routine_defs[i].name,PyFortranObject_NewAsAttr(&f2py_routine_defs[i]));
#initf2pywraphooks#
#initf90modhooks#
#initcommonhooks#
#interface_usercode#

#ifdef F2PY_REPORT_ATEXIT
	if (! PyErr_Occurred())
		on_exit(f2py_report_on_exit,(void*)"#modulename#");
#endif

	return RETVAL;
}
#ifdef __cplusplus
}
#endif
	PyTupleObject *#varname#_xa_capi = NULL;		#varname# = (#ctype#)PyObject_IsTrue(#varname#_capi);
		f2py_success = 1;
	if (f2py_success) {extern void #fortranname#(#callprotoargument#);	#varname#_nofargs_capi = #cbname#_nofargs;
	if (create_cb_arglist(#varname#_capi,#varname#_xa_capi,#maxnofargs#,#nofoptargs#,&#cbname#_nofargs,&#varname#_args_capi,"failed in processing argument list for call-back #varname#.")) {
		jmp_buf #varname#_jmpbuf;	} /*CHECKSCALAR(#check#)*/	/* End of cleaning variable #varname# */	#ctype# #name#_return_value=0;ate:$
 * Do not edit this file directly unless you know what you are doing!!!
 */
#ifdef __cplusplus
extern "C" {
#endif

	PyTupleObject *#varname#_args_capi = NULL;
#f90modhooks#


    {
      extern void #F_FUNC#(#name_lower#,#NAME#)(void);
      PyObject* o = PyDict_GetItemString(d,"#name#");
      PyObject_SetAttrString(o,"_cpointer", F2PyCapsule_FromVoidPtr((void*)#F_FUNC#(#name_lower#,#NAME#),NULL));
#if PY_VERSION_HEX >= 0x03000000
      PyObject_SetAttrString(o,"__name__", PyUnicode_FromString("#name#"));
#else
      PyObject_SetAttrString(o,"__name__", PyString_FromString("#name#"));
#endif
    }
    "#varname#_extra_args",#declfortranroutine#	#varname# = #init#;"#varname#",#callfortran# 0,#callfortranappend#%s-f2pywrappers2.f90/*eof initf90modhooks*/#rformat#"	#docreturn##name#(#docsignature#)\n"
	capi_#varname#_tmp = array_from_pyobj(#atype#,#varname#_Dims,#varname#_Rank,capi_#varname#_intent,Py_None);	}  /*if (f2py_success) of #varname# frompyobj*/	} /*if (f2py_success) of #varname# pyobjfrom*/	capi_#varname#_intent |= #intent#;#varname#_extra_args=(),		Py_XDECREF(capi_#varname#_tmp);	fprintf(stderr,"debug-capi:Python C/API function #modulename#.#name#: failure.\n");/*topyarr*/"overwrite_#varname#",			  %s
--- #resultnote#	fprintf(stderr,"debug-capi:Fortran function #ctype# #fortranname#(#callfortran#)\n");
	} /* if (f2py_success) after (string)malloc */				(*f2py_func)(#callfortran#);	} /*CHECKARRAY(#check#)*/O!	{"#name#",-1,{{-1}},0,NULL,(f2py_init_func)#apiname#,doc_#apiname#},See f2py2e/cfuncs.py: cppmacros#docsignopt##docsignxa#
 * $R	} /*if (f2py_success) of #varname#*/&
     &See f2py2e/cfuncs.py: userincludes%% This file is auto-generated with f2py (version:%s)
buildmodule: unknown need %s.
	if (#varname#_capi != Py_None)
#cppmacros#


#typedefs#

overwrite_#varname#=0,	#callstatement#;
/*	#name#_return_value = (*f2py_func)(#callfortran#);*/
C     It contains Fortran 77 wrappers to fortran functions.
	}  /*if (f2py_success) of #varname# init*/	fprintf(stderr,"debug-capi:Fortran subroutine `#fortranname#(#callfortran#)'\n");See f2py2e/cfuncs.py: includes#ifdef USESCOMPAQFORTRAN
		(*f2py_func)(#callcompaqfortran#);
#else
		(*f2py_func)(#callfortran#);
#endif
/*end of cleanupfrompyobj*/	#ctype# #varname#;		fprintf(stderr,"debug-capi:Assuming %d arguments; at most #maxnofargs#(-#nofoptargs#) is expected.\n",#cbname#_nofargs);
		CFUNCSMESSPY("for #varname#=",#cbname#_capi);module.rest	fprintf(stderr,"#routdebugshowvalue#\n",#name#_return_value.r,#name#_return_value.i);		Py_BEGIN_ALLOW_THREADS,&#varname#_capi/usr/lib/python2.7/dist-packages/numpy/f2py/rules.pyoverwrite_#varname# : input int, optional\n    Default: 1			Py_END_ALLOW_THREADS#cbdocstr#
#callbacks#

\nNotes\n-----\nCall-back functions::\n	PyObject *#name#_return_value_capi = Py_None;numpy.f2py.rules#ifdef USESCOMPAQFORTRAN
	fprintf(stderr,"debug-capi:Fortran function #ctype# #fortranname#(#callcompaqfortran#)\n");
#else
	fprintf(stderr,"debug-capi:Fortran function #ctype# #fortranname#(#callfortran#)\n");
#endif

     &
#routine_def#		STRINGFREE(#varname#);
	}  /*if (f2py_success) of #varname#*/\item[]{{}\verb@#varname#_extra_args := () input tuple@{}} --- Extra arguments for call-back function {{}\verb@#varname#@{}}./*eof initcommonhooks*/See f2py2e/cfuncs.py: typedefs_generated	fprintf(stderr,"#vardebugshowvalue#\n",#varname#.r,#varname#.i);	#name#_return_value_len = #rlength#;	int #varname#_nofargs_capi = 0;

Rules for building C/API module with f2py2e.

Here is a skeleton of a new wrapper function (13Dec2001):

wrapper_function(args)
  declarations
  get_python_arguments, say, `a' and `b'

  get_a_from_python
  if (successful) {

    get_b_from_python
    if (successful) {

      callfortran
      if (succesful) {

        put_a_to_python
        if (succesful) {

          put_b_to_python
          if (succesful) {

            buildvalue = ...

          }

        }

      }

    }
    cleanup_b

  }
  cleanup_a

  return buildvalue

Copyright 1999,2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2005/08/30 08:58:42 $
Pearu Peterson

		} /*if (f2py_success) of #varname# pyobjfrom*/#varname#_extra_args : input tuple, optional\n    Default: ()		if (#setjmpbuf#) {
			f2py_success = 0;
		} else {/*routdebugenter*/	CHECKARRAY(#check#,"#check#","#nth# #varname#") {buildmodule: Could not found the body of interfaced routine "%s". Skipping.
!     This file is autogenerated with f2py (version:%s)

static PyObject *#modulename#_error;
static PyObject *#modulename#_module;

if (#varname#_capi==Py_None) {
  #varname#_capi = PyObject_GetAttrString(#modulename#_module,"#varname#");
  if (#varname#_capi) {
    if (#varname#_xa_capi==NULL) {
      if (PyObject_HasAttrString(#modulename#_module,"#varname#_extra_args")) {
        PyObject* capi_tmp = PyObject_GetAttrString(#modulename#_module,"#varname#_extra_args");
        if (capi_tmp)
          #varname#_xa_capi = (PyTupleObject *)PySequence_Tuple(capi_tmp);
        else
          #varname#_xa_capi = (PyTupleObject *)Py_BuildValue("()");
        if (#varname#_xa_capi==NULL) {
          PyErr_SetString(#modulename#_error,"Failed to convert #modulename#.#varname#_extra_args to tuple.\n");
          return NULL;
        }
      }
    }
  }
  if (#varname#_capi==NULL) {
    PyErr_SetString(#modulename#_error,"Callback #varname# not defined (as an argument or module #modulename# attribute).\n");
    return NULL;
  }
}

#typedefs_generated#

#docsign##docsignopt##docsignxa#	if (#varname#_capi == Py_None) {			Constructing wrapper function "%s.%s"...
	f2py_success = try_pyarr_from_#ctype#(#varname#_capi,&#varname#);
	if (f2py_success) {#callfortran##callfortranappend#/*eof initf2pywraphooks*/	int capi_overwrite_#varname# = 1;	CHECKSCALAR(#check#,"#check#","#nth# #varname#","#varshowvalue#",#varname#) { 1.129 
    {
      extern #ctype# #F_FUNC#(#name_lower#,#NAME#)(void);
      PyObject* o = PyDict_GetItemString(d,"#name#");
      PyObject_SetAttrString(o,"_cpointer", F2PyCapsule_FromVoidPtr((void*)#F_FUNC#(#name_lower#,#NAME#),NULL));
#if PY_VERSION_HEX >= 0x03000000
      PyObject_SetAttrString(o,"__name__", PyUnicode_FromString("#name#"));
#else
      PyObject_SetAttrString(o,"__name__", PyString_FromString("#name#"));
#endif
    }
    See f2py2e/capi_rules.py: usercode\nParameters\n----------

static FortranDataDef f2py_routine_defs[] = {
#routine_defs#
	{NULL}
};

static PyMethodDef f2py_module_methods[] = {
#pymethoddef#
	{NULL,NULL}
};

#if PY_VERSION_HEX >= 0x03000000
static struct PyModuleDef moduledef = {
	PyModuleDef_HEAD_INIT,
	"#modulename#",
	NULL,
	-1,
	f2py_module_methods,
	NULL,
	NULL,
	NULL,
	NULL
};
#endif

#if PY_VERSION_HEX >= 0x03000000
#define RETVAL m
PyMODINIT_FUNC PyInit_#modulename#(void) {
#else
#define RETVAL
PyMODINIT_FUNC init#modulename#(void) {
#endif
	int i;
	PyObject *m,*d, *s;
#if PY_VERSION_HEX >= 0x03000000
	m = #modulename#_module = PyModule_Create(&moduledef);
#else
	m = #modulename#_module = Py_InitModule("#modulename#", f2py_module_methods);
#endif
	Py_TYPE(&PyFortran_Type) = &PyType_Type;
	import_array();
	if (PyErr_Occurred())
		{PyErr_SetString(PyExc_ImportError, "can't initialize module #modulename# (failed to import numpy)"); return RETVAL;}
	d = PyModule_GetDict(m);
	s = PyString_FromString("$Roverwrite_#varname# : input int, optional\n    Default: 0\nOther Parameters\n----------------See f2py2e/rules.py: module_rules['modulebody']		f2py_success = #ctype#_from_pyobj(&#varname#,#varname#_capi,"#pyname#() #nth# (#varname#) can't be converted to #ctype#");
	if (f2py_success) {	fprintf(stderr,"#vardebugshowvalue#\n",#varname#);See f2py2e/cfuncs.py: cfuncs,#name#_return_value_capiSee f2py2e/capi_rules.py: usercode1	#varname#.r = #init.r#, #varname#.i = #init.i#;	#ctype# #name#_return_value={0,0};See f2py2e/rules.py: buildapi
#cfuncs#

extern void #F_FUNC#(#fortranname#,#FORTRANNAME#)(#callprotoargument#);\item[] #cblatexdocstr#	if (#setjmpbuf#) {
		f2py_success = 0;
	} else {overwrite_#varname#=1,	fprintf(stderr,"debug-capi:Checking `#check#'\n");	if((PyObject *)capi_#varname#_tmp!=#varname#_capi) {
		Py_XDECREF(capi_#varname#_tmp); }See f2py2e/rules.py: mod_rules['modulebody']f2py_rout_#modulename#_#name#/*eof routine_defs*/	fprintf(stderr,"#vardebuginfo#\n");	}  /*if (capi_#varname#_tmp == NULL) ... else of #varname#*/	/* Processing variable #varname# */.. -*- rest -*-
		fprintf(stderr,"#routdebugshowvalue#\n",#name#_return_value_len,#name#_return_value);#modulename#.#f90modulename#.#name#	Fortran 77 wrappers are saved to "%s"
	int capi_overwrite_#varname# = 0;	#name#_return_value_capi = pyobj_from_#ctype#1(#name#_return_value);f2py_rout_#modulename#_#f90modulename#_#name#	Wrote C/API module "%s" to file "%s"
/* File: #modulename#module.c
 * This file is auto-generated with f2py (version:#f2py_version#).
 * f2py is a Fortran to Python Interface Generator (FPIG), Second Edition,
 * written by Pearu Peterson <pearu@cens.ioc.ee>.
 * See http://cens.ioc.ee/projects/f2py2e/
 * Generation date: 	{"#name#",-1,{{-1}},0,(char *)#F_FUNC#(#fortranname#,#FORTRANNAME#),(f2py_init_func)#apiname#,doc_#apiname#},/*eof externroutines*/
#commonhooks#

	Documentation is saved to file "%s/%smodule.tex"
,&PyTuple_Type,&#varname#_xa_capi/*routdebugleave*/	#cbname#_typedef #varname#_cptr;!     It contains Fortran 90 wrappers to fortran functions.
/*eof method*/#varname#=#showinit#,		(#name#_return_value)[#name#_return_value_len] = '\0';#define DEBUGCFUNCSbuildmodule: Expected interface block. Skipping.
extern #ctype# #F_FUNC#(#fortranname#,#FORTRANNAME#)(#callprotoargument#);	fprintf(stderr,"#routdebugshowvalue#\n",#name#_return_value);evision:$
 * $D
    Return
    	capi_#varname#_tmp = array_from_pyobj(#atype#,#varname#_Dims,#varname#_Rank,capi_#varname#_intent,#varname#_capi);		CFUNCSMESS("Saving jmpbuf for `#varname#`.\n");
		SWAP(#varname#_capi,#cbname#_capi,PyObject);
		SWAP(#varname#_args_capi,#cbname#_args_capi,PyTupleObject);
		memcpy(&#varname#_jmpbuf,&#cbname#_jmpbuf,sizeof(jmp_buf));#name#_return_value,#name#_return_value_len,C     This file is autogenerated with f2py (version:%s)
	f2py_success = try_pyarr_from_#ctype#(#varname#_capi,#varname#);
	if (f2py_success) {
#usercode1#


#body#

/*callfortranroutine*/	capi_#varname#_intent |= (capi_overwrite_#varname#?0:F2PY_INTENT_COPY);	{"#name#",-1,{{-1}},0,(char *)#F_WRAPPEDFUNC#(#name_lower#,#NAME#),(f2py_init_func)#apiname#,doc_#apiname#},#varname#_cptr,	fprintf(stderr,"debug-capi:Fortran subroutine `f2pywrap#name_lower#(#callfortran#)'\n");	ReST Documentation is saved to file "%s/%smodule.rest"
/*end of closepyobjfrom*/#varrformat#	if (capi_#varname#_tmp == NULL) {
		if (!PyErr_Occurred())
			PyErr_SetString(#modulename#_error,"failed in converting #nth# `#varname#' of #pyname# to C/Fortran array" );
	} else {
		#varname# = (#ctype# *)(capi_#varname#_tmp->data);
		f2py_success = try_pyarr_from_#ctype#(#varname#_capi,&#varname#);
		if (f2py_success) {
#begintitle#
static char doc_#apiname#[] = "\
#docreturn##name#(#docsignatureshort#)\n\nWrapper for ``#name#``.\
\n#docstrsigns#";
/* #declfortranroutine# */
static PyObject *#apiname#(const PyObject *capi_self,
                           PyObject *capi_args,
                           PyObject *capi_keywds,
                           #functype# (*f2py_func)(#callprotoargument#)) {
	PyObject * volatile capi_buildvalue = NULL;
	volatile int f2py_success = 1;
#decl#
	static char *capi_kwlist[] = {#kwlist##kwlistopt##kwlistxa#NULL};
#usercode#
#routdebugenter#
#ifdef F2PY_REPORT_ATEXIT
f2py_start_clock();
#endif
	if (!PyArg_ParseTupleAndKeywords(capi_args,capi_keywds,\
		"#argformat##keyformat##xaformat#:#pyname#",\
		capi_kwlist#args_capi##keys_capi##keys_xa#))
		return NULL;
#frompyobj#
/*end of frompyobj*/
#ifdef F2PY_REPORT_ATEXIT
f2py_start_call_clock();
#endif
#callfortranroutine#
if (PyErr_Occurred())
  f2py_success = 0;
#ifdef F2PY_REPORT_ATEXIT
f2py_stop_call_clock();
#endif
/*end of callfortranroutine*/
		if (f2py_success) {
#pyobjfrom#
/*end of pyobjfrom*/
		CFUNCSMESS("Building return value.\n");
		capi_buildvalue = Py_BuildValue("#returnformat#"#return#);
/*closepyobjfrom*/
#closepyobjfrom#
		} /*if (f2py_success) after callfortranroutine*/
/*cleanupfrompyobj*/
#cleanupfrompyobj#
	if (capi_buildvalue == NULL) {
#routdebugfailure#
	} else {
#routdebugleave#
	}
	CFUNCSMESS("Freeing memory.\n");
#freemem#
#ifdef F2PY_REPORT_ATEXIT
f2py_stop_clock();
#endif
	return capi_buildvalue;
}
#endtitle#
if(F2PyCapsule_Check(#varname#_capi)) {
  #varname#_cptr = F2PyCapsule_AsVoidPtr(#varname#_capi);
} else {
  #varname#_cptr = #cbname#;
}
				#callstatement#;
				/*(*f2py_func)(#callfortran#);*/		CFUNCSMESS("Restoring jmpbuf for `#varname#`.\n");
		#cbname#_capi = #varname#_capi;
		Py_DECREF(#cbname#_args_capi);
		#cbname#_args_capi = #varname#_args_capi;
		#cbname#_nofargs = #varname#_nofargs_capi;
		memcpy(&#cbname#_jmpbuf,&#varname#_jmpbuf,sizeof(jmp_buf));
	}	{"#name#",-1,{{-1}},0,(char *)#fortranname#,(f2py_init_func)#apiname#,doc_#apiname#},#note#	} /*CHECKSTRING(#check#)*/Wrapped function ``#name#``
--------------------------------------------------------------------------------			Py_BEGIN_ALLOW_THREADS	fprintf(stderr,"debug-capi:Python C/API function #modulename#.#name#: successful.\n");#outvarname#,/*routdebugfailure*/,&capi_overwrite_#varname#flen(#varname#),\documentclass{article}
\usepackage{a4wide}
\begin{document}
\tableofcontents

extern #ctype# #fortranname#(#callprotoargument#);
#userincludes#

C     -*- fortran -*-
(   t   routt   wrapt   argst   depargst   vart   at   auxvarst   vrdt   rdt   rt   art   ntht   nthkt   savevrdt   _rulest   ct   optargst   cfst   kt	   argformat(   t   mt   umt   rett	   mod_rulest   vrdt   rdt   funcwrapperst   funcwrappers2t   nt   nbt   bit   bt   nb_listt   kt   at   nb1t   apit   wrapt   art   crt   mrt   ut   needst   codet   ct   rt   fnt   ft   wnt   linest   l(   s   decls	   frompyobjs   cleanupfrompyobjs   topyarrs   methods	   pyobjfroms   closepyobjfroms   freemems   userincludess	   includes0s   includess   typedefss   typedefs_generateds	   cppmacross   cfuncss	   callbackss   latexdocs   restdocs   routine_defss   externroutiness   initf2pywraphookss   commonhookss   initcommonhookss   f90modhookss   initf90modhooksREALNAMEtexnamenameUSEMODULENAME{i    s   Roi   s   Rii   s   Riii   s   Riiii   s   Rivi   s   Rvi   s   Rvii   s   Rviii   s   Rviiii	   s   Rix0
#begintitle#
static char doc_#apiname#[] = "\
Variable wrapper signature:\n\
	 #name# = get_#name#()\n\
Arguments:\n\
#docstr#";
extern F_MODFUNC(#usemodulename#,#USEMODULENAME#,#realname#,#REALNAME#);
static PyObject *#apiname#(PyObject *capi_self, PyObject *capi_args) {
/*#decl#*/
	if (!PyArg_ParseTuple(capi_args, "")) goto capi_fail;
printf("c: %d\n",F_MODFUNC(#usemodulename#,#USEMODULENAME#,#realname#,#REALNAME#));
	return Py_BuildValue("");
capi_fail:
	return NULL;
}
	{"get_#name#",#apiname#,METH_VARARGS|METH_KEYWORDS,doc_#apiname#},#modulename#_use_%s_from_%s		Building use variable hooks for module "%s" (feature only for F90/F95)...
			Variable "%s<=%s" is already mapped by "%s". Skipping.
			Ignoring map "%s=>%s". See above.
			Constructing wrapper function for variable "%s=>%s"...
			No definition for variable "%s=>%s". Skipping.


Build 'use others module data' mechanism for f2py2e.

Unfinished.

Copyright 2000 Pearu Peterson all rights reserved,
Pearu Peterson <pearu@ioc.ee>
Permission to use, modify, and distribute this software is given under the
terms of the NumPy License.

NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.
$Date: 2000/09/10 12:35:43 $
Pearu Peterson

numpy.f2py.use_rules/usr/lib/python2.7/dist-packages/numpy/f2py/use_rules.pyend of %s=>%s/usr/lib/python2.7/dist-packages/numpy/fft/usr/lib/python2.7/dist-packages/numpy/fft/__init__.pycfftbcfftfcfftiihfftrfft2rfftbrfftfrfftiirfft2shapelessfftpack_lite
    Compute the one-dimensional discrete Fourier Transform for real input.

    This function computes the one-dimensional *n*-point discrete Fourier
    Transform (DFT) of a real-valued array by means of an efficient algorithm
    called the Fast Fourier Transform (FFT).

    Parameters
    ----------
    a : array_like
        Input array
    n : int, optional
        Number of points along transformation axis in the input to use.
        If `n` is smaller than the length of the input, the input is cropped.
        If it is larger, the input is padded with zeros. If `n` is not given,
        the length of the input (along the axis specified by `axis`) is used.
    axis : int, optional
        Axis over which to compute the FFT. If not given, the last axis is
        used.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axis
        indicated by `axis`, or the last one if `axis` is not specified.
        If `n` is even, the length of the transformed axis is ``(n/2)+1``.
        If `n` is odd, the length is ``(n+1)/2``.

    Raises
    ------
    IndexError
        If `axis` is larger than the last axis of `a`.

    See Also
    --------
    numpy.fft : For definition of the DFT and conventions used.
    irfft : The inverse of `rfft`.
    fft : The one-dimensional FFT of general (complex) input.
    fftn : The *n*-dimensional FFT.
    rfftn : The *n*-dimensional FFT of real input.

    Notes
    -----
    When the DFT is computed for purely real input, the output is
    Hermite-symmetric, i.e. the negative frequency terms are just the complex
    conjugates of the corresponding positive-frequency terms, and the
    negative-frequency terms are therefore redundant.  This function does not
    compute the negative frequency terms, and the length of the transformed
    axis of the output is therefore ``n//2+1``.

    When ``A = rfft(a)`` and fs is the sampling frequency, ``A[0]`` contains
    the zero-frequency term 0*fs, which is real due to Hermitian symmetry.

    If `n` is even, ``A[-1]`` contains the term representing both positive
    and negative Nyquist frequency (+fs/2 and -fs/2), and must also be purely
    real. If `n` is odd, there is no term at fs/2; ``A[-1]`` contains
    the largest positive frequency (fs/2*(n-1)/n), and is complex in the
    general case.

    If the input `a` contains an imaginary part, it is silently discarded.

    Examples
    --------
    >>> np.fft.fft([0, 1, 0, 0])
    array([ 1.+0.j,  0.-1.j, -1.+0.j,  0.+1.j])
    >>> np.fft.rfft([0, 1, 0, 0])
    array([ 1.+0.j,  0.-1.j, -1.+0.j])

    Notice how the final element of the `fft` output is the complex conjugate
    of the second element, for real input. For `rfft`, this symmetry is
    exploited to compute only the non-negative frequency terms.

    
    Compute the N-dimensional discrete Fourier Transform.

    This function computes the *N*-dimensional discrete Fourier Transform over
    any number of axes in an *M*-dimensional array by means of the Fast Fourier
    Transform (FFT).

    Parameters
    ----------
    a : array_like
        Input array, can be complex.
    s : sequence of ints, optional
        Shape (length of each transformed axis) of the output
        (`s[0]` refers to axis 0, `s[1]` to axis 1, etc.).
        This corresponds to `n` for `fft(x, n)`.
        Along any axis, if the given shape is smaller than that of the input,
        the input is cropped.  If it is larger, the input is padded with zeros.
        if `s` is not given, the shape of the input (along the axes specified
        by `axes`) is used.
    axes : sequence of ints, optional
        Axes over which to compute the FFT.  If not given, the last ``len(s)``
        axes are used, or all axes if `s` is also not specified.
        Repeated indices in `axes` means that the transform over that axis is
        performed multiple times.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or by a combination of `s` and `a`,
        as explained in the parameters section above.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    numpy.fft : Overall view of discrete Fourier transforms, with definitions
        and conventions used.
    ifftn : The inverse of `fftn`, the inverse *n*-dimensional FFT.
    fft : The one-dimensional FFT, with definitions and conventions used.
    rfftn : The *n*-dimensional FFT of real input.
    fft2 : The two-dimensional FFT.
    fftshift : Shifts zero-frequency terms to centre of array

    Notes
    -----
    The output, analogously to `fft`, contains the term for zero frequency in
    the low-order corner of all axes, the positive frequency terms in the
    first half of all axes, the term for the Nyquist frequency in the middle
    of all axes and the negative frequency terms in the second half of all
    axes, in order of decreasingly negative frequency.

    See `numpy.fft` for details, definitions and conventions used.

    Examples
    --------
    >>> a = np.mgrid[:3, :3, :3][0]
    >>> np.fft.fftn(a, axes=(1, 2))
    array([[[  0.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j]],
           [[  9.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j]],
           [[ 18.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j],
            [  0.+0.j,   0.+0.j,   0.+0.j]]])
    >>> np.fft.fftn(a, (2, 2), axes=(0, 1))
    array([[[ 2.+0.j,  2.+0.j,  2.+0.j],
            [ 0.+0.j,  0.+0.j,  0.+0.j]],
           [[-2.+0.j, -2.+0.j, -2.+0.j],
            [ 0.+0.j,  0.+0.j,  0.+0.j]]])

    >>> import matplotlib.pyplot as plt
    >>> [X, Y] = np.meshgrid(2 * np.pi * np.arange(200) / 12,
    ...                      2 * np.pi * np.arange(200) / 34)
    >>> S = np.sin(X) + np.cos(Y) + np.random.uniform(0, 1, X.shape)
    >>> FS = np.fft.fftn(S)
    >>> plt.imshow(np.log(np.abs(np.fft.fftshift(FS))**2))
    <matplotlib.image.AxesImage object at 0x...>
    >>> plt.show()

    
    Compute the inverse of the n-point DFT for real input.

    This function computes the inverse of the one-dimensional *n*-point
    discrete Fourier Transform of real input computed by `rfft`.
    In other words, ``irfft(rfft(a), len(a)) == a`` to within numerical
    accuracy. (See Notes below for why ``len(a)`` is necessary here.)

    The input is expected to be in the form returned by `rfft`, i.e. the
    real zero-frequency term followed by the complex positive frequency terms
    in order of increasing frequency.  Since the discrete Fourier Transform of
    real input is Hermite-symmetric, the negative frequency terms are taken
    to be the complex conjugates of the corresponding positive frequency terms.

    Parameters
    ----------
    a : array_like
        The input array.
    n : int, optional
        Length of the transformed axis of the output.
        For `n` output points, ``n//2+1`` input points are necessary.  If the
        input is longer than this, it is cropped.  If it is shorter than this,
        it is padded with zeros.  If `n` is not given, it is determined from
        the length of the input (along the axis specified by `axis`).
    axis : int, optional
        Axis over which to compute the inverse FFT.

    Returns
    -------
    out : ndarray
        The truncated or zero-padded input, transformed along the axis
        indicated by `axis`, or the last one if `axis` is not specified.
        The length of the transformed axis is `n`, or, if `n` is not given,
        ``2*(m-1)`` where `m` is the length of the transformed axis of the
        input. To get an odd number of output points, `n` must be specified.

    Raises
    ------
    IndexError
        If `axis` is larger than the last axis of `a`.

    See Also
    --------
    numpy.fft : For definition of the DFT and conventions used.
    rfft : The one-dimensional FFT of real input, of which `irfft` is inverse.
    fft : The one-dimensional FFT.
    irfft2 : The inverse of the two-dimensional FFT of real input.
    irfftn : The inverse of the *n*-dimensional FFT of real input.

    Notes
    -----
    Returns the real valued `n`-point inverse discrete Fourier transform
    of `a`, where `a` contains the non-negative frequency terms of a
    Hermite-symmetric sequence. `n` is the length of the result, not the
    input.

    If you specify an `n` such that `a` must be zero-padded or truncated, the
    extra/removed values will be added/removed at high frequencies. One can
    thus resample a series to `m` points via Fourier interpolation by:
    ``a_resamp = irfft(rfft(a), m)``.


    Examples
    --------
    >>> np.fft.ifft([1, -1j, -1, 1j])
    array([ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j])
    >>> np.fft.irfft([1, -1j, -1])
    array([ 0.,  1.,  0.,  0.])

    Notice how the last term in the input to the ordinary `ifft` is the
    complex conjugate of the second term, and the output has zero imaginary
    part everywhere.  When calling `irfft`, the negative frequencies are not
    specified, and the output array is purely real.

    numpy.fft.fftpack
    Compute the one-dimensional inverse discrete Fourier Transform.

    This function computes the inverse of the one-dimensional *n*-point
    discrete Fourier transform computed by `fft`.  In other words,
    ``ifft(fft(a)) == a`` to within numerical accuracy.
    For a general description of the algorithm and definitions,
    see `numpy.fft`.

    The input should be ordered in the same way as is returned by `fft`,
    i.e., ``a[0]`` should contain the zero frequency term,
    ``a[1:n/2+1]`` should contain the positive-frequency terms, and
    ``a[n/2+1:]`` should contain the negative-frequency terms, in order of
    decreasingly negative frequency.  See `numpy.fft` for details.

    Parameters
    ----------
    a : array_like
        Input array, can be complex.
    n : int, optional
        Length of the transformed axis of the output.
        If `n` is smaller than the length of the input, the input is cropped.
        If it is larger, the input is padded with zeros.  If `n` is not given,
        the length of the input (along the axis specified by `axis`) is used.
        See notes about padding issues.
    axis : int, optional
        Axis over which to compute the inverse DFT.  If not given, the last
        axis is used.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axis
        indicated by `axis`, or the last one if `axis` is not specified.

    Raises
    ------
    IndexError
        If `axes` is larger than the last axis of `a`.

    See Also
    --------
    numpy.fft : An introduction, with definitions and general explanations.
    fft : The one-dimensional (forward) FFT, of which `ifft` is the inverse
    ifft2 : The two-dimensional inverse FFT.
    ifftn : The n-dimensional inverse FFT.

    Notes
    -----
    If the input parameter `n` is larger than the size of the input, the input
    is padded by appending zeros at the end.  Even though this is the common
    approach, it might lead to surprising results.  If a different padding is
    desired, it must be performed before calling `ifft`.

    Examples
    --------
    >>> np.fft.ifft([0, 4, 0, 0])
    array([ 1.+0.j,  0.+1.j, -1.+0.j,  0.-1.j])

    Create and plot a band-limited signal with random phases:

    >>> import matplotlib.pyplot as plt
    >>> t = np.arange(400)
    >>> n = np.zeros((400,), dtype=complex)
    >>> n[40:60] = np.exp(1j*np.random.uniform(0, 2*np.pi, (20,)))
    >>> s = np.fft.ifft(n)
    >>> plt.plot(t, s.real, 'b-', t, s.imag, 'r--')
    [<matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>]
    >>> plt.legend(('real', 'imaginary'))
    <matplotlib.legend.Legend object at 0x...>
    >>> plt.show()

    
    Compute the 2-dimensional inverse FFT of a real array.

    Parameters
    ----------
    a : array_like
        The input array
    s : sequence of ints, optional
        Shape of the inverse FFT.
    axes : sequence of ints, optional
        The axes over which to compute the inverse fft.
        Default is the last two axes.

    Returns
    -------
    out : ndarray
        The result of the inverse real 2-D FFT.

    See Also
    --------
    irfftn : Compute the inverse of the N-dimensional FFT of real input.

    Notes
    -----
    This is really `irfftn` with different defaults.
    For more details see `irfftn`.

    
    Compute the 2-dimensional FFT of a real array.

    Parameters
    ----------
    a : array
        Input array, taken to be real.
    s : sequence of ints, optional
        Shape of the FFT.
    axes : sequence of ints, optional
        Axes over which to compute the FFT.

    Returns
    -------
    out : ndarray
        The result of the real 2-D FFT.

    See Also
    --------
    rfftn : Compute the N-dimensional discrete Fourier Transform for real
            input.

    Notes
    -----
    This is really just `rfftn` with different default behavior.
    For more details see `rfftn`.

    
    Compute the 2-dimensional inverse discrete Fourier Transform.

    This function computes the inverse of the 2-dimensional discrete Fourier
    Transform over any number of axes in an M-dimensional array by means of
    the Fast Fourier Transform (FFT).  In other words, ``ifft2(fft2(a)) == a``
    to within numerical accuracy.  By default, the inverse transform is
    computed over the last two axes of the input array.

    The input, analogously to `ifft`, should be ordered in the same way as is
    returned by `fft2`, i.e. it should have the term for zero frequency
    in the low-order corner of the two axes, the positive frequency terms in
    the first half of these axes, the term for the Nyquist frequency in the
    middle of the axes and the negative frequency terms in the second half of
    both axes, in order of decreasingly negative frequency.

    Parameters
    ----------
    a : array_like
        Input array, can be complex.
    s : sequence of ints, optional
        Shape (length of each axis) of the output (``s[0]`` refers to axis 0,
        ``s[1]`` to axis 1, etc.).  This corresponds to `n` for ``ifft(x, n)``.
        Along each axis, if the given shape is smaller than that of the input,
        the input is cropped.  If it is larger, the input is padded with zeros.
        if `s` is not given, the shape of the input (along the axes specified
        by `axes`) is used.  See notes for issue on `ifft` zero padding.
    axes : sequence of ints, optional
        Axes over which to compute the FFT.  If not given, the last two
        axes are used.  A repeated index in `axes` means the transform over
        that axis is performed multiple times.  A one-element sequence means
        that a one-dimensional FFT is performed.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or the last two axes if `axes` is not given.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length, or `axes` not given and
        ``len(s) != 2``.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    numpy.fft : Overall view of discrete Fourier transforms, with definitions
         and conventions used.
    fft2 : The forward 2-dimensional FFT, of which `ifft2` is the inverse.
    ifftn : The inverse of the *n*-dimensional FFT.
    fft : The one-dimensional FFT.
    ifft : The one-dimensional inverse FFT.

    Notes
    -----
    `ifft2` is just `ifftn` with a different default for `axes`.

    See `ifftn` for details and a plotting example, and `numpy.fft` for
    definition and conventions used.

    Zero-padding, analogously with `ifft`, is performed by appending zeros to
    the input along the specified dimension.  Although this is the common
    approach, it might lead to surprising results.  If another form of zero
    padding is desired, it must be performed before `ifft2` is called.

    Examples
    --------
    >>> a = 4 * np.eye(4)
    >>> np.fft.ifft2(a)
    array([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
           [ 0.+0.j,  0.+0.j,  0.+0.j,  1.+0.j],
           [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],
           [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j]])

    
    Compute the 2-dimensional discrete Fourier Transform

    This function computes the *n*-dimensional discrete Fourier Transform
    over any axes in an *M*-dimensional array by means of the
    Fast Fourier Transform (FFT).  By default, the transform is computed over
    the last two axes of the input array, i.e., a 2-dimensional FFT.

    Parameters
    ----------
    a : array_like
        Input array, can be complex
    s : sequence of ints, optional
        Shape (length of each transformed axis) of the output
        (`s[0]` refers to axis 0, `s[1]` to axis 1, etc.).
        This corresponds to `n` for `fft(x, n)`.
        Along each axis, if the given shape is smaller than that of the input,
        the input is cropped.  If it is larger, the input is padded with zeros.
        if `s` is not given, the shape of the input (along the axes specified
        by `axes`) is used.
    axes : sequence of ints, optional
        Axes over which to compute the FFT.  If not given, the last two
        axes are used.  A repeated index in `axes` means the transform over
        that axis is performed multiple times.  A one-element sequence means
        that a one-dimensional FFT is performed.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or the last two axes if `axes` is not given.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length, or `axes` not given and
        ``len(s) != 2``.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    numpy.fft : Overall view of discrete Fourier transforms, with definitions
         and conventions used.
    ifft2 : The inverse two-dimensional FFT.
    fft : The one-dimensional FFT.
    fftn : The *n*-dimensional FFT.
    fftshift : Shifts zero-frequency terms to the center of the array.
        For two-dimensional input, swaps first and third quadrants, and second
        and fourth quadrants.

    Notes
    -----
    `fft2` is just `fftn` with a different default for `axes`.

    The output, analogously to `fft`, contains the term for zero frequency in
    the low-order corner of the transformed axes, the positive frequency terms
    in the first half of these axes, the term for the Nyquist frequency in the
    middle of the axes and the negative frequency terms in the second half of
    the axes, in order of decreasingly negative frequency.

    See `fftn` for details and a plotting example, and `numpy.fft` for
    definitions and conventions used.


    Examples
    --------
    >>> a = np.mgrid[:5, :5][0]
    >>> np.fft.fft2(a)
    array([[  0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],
           [  5.+0.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],
           [ 10.+0.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],
           [ 15.+0.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j],
           [ 20.+0.j,   0.+0.j,   0.+0.j,   0.+0.j,   0.+0.j]])

    /usr/lib/python2.7/dist-packages/numpy/fft/fftpack.py
    Compute the inverse of the N-dimensional FFT of real input.

    This function computes the inverse of the N-dimensional discrete
    Fourier Transform for real input over any number of axes in an
    M-dimensional array by means of the Fast Fourier Transform (FFT).  In
    other words, ``irfftn(rfftn(a), a.shape) == a`` to within numerical
    accuracy. (The ``a.shape`` is necessary like ``len(a)`` is for `irfft`,
    and for the same reason.)

    The input should be ordered in the same way as is returned by `rfftn`,
    i.e. as for `irfft` for the final transformation axis, and as for `ifftn`
    along all the other axes.

    Parameters
    ----------
    a : array_like
        Input array.
    s : sequence of ints, optional
        Shape (length of each transformed axis) of the output
        (``s[0]`` refers to axis 0, ``s[1]`` to axis 1, etc.). `s` is also the
        number of input points used along this axis, except for the last axis,
        where ``s[-1]//2+1`` points of the input are used.
        Along any axis, if the shape indicated by `s` is smaller than that of
        the input, the input is cropped.  If it is larger, the input is padded
        with zeros. If `s` is not given, the shape of the input (along the
        axes specified by `axes`) is used.
    axes : sequence of ints, optional
        Axes over which to compute the inverse FFT. If not given, the last
        `len(s)` axes are used, or all axes if `s` is also not specified.
        Repeated indices in `axes` means that the inverse transform over that
        axis is performed multiple times.

    Returns
    -------
    out : ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or by a combination of `s` or `a`,
        as explained in the parameters section above.
        The length of each transformed axis is as given by the corresponding
        element of `s`, or the length of the input in every axis except for the
        last one if `s` is not given.  In the final transformed axis the length
        of the output when `s` is not given is ``2*(m-1)`` where `m` is the
        length of the final transformed axis of the input.  To get an odd
        number of output points in the final axis, `s` must be specified.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    rfftn : The forward n-dimensional FFT of real input,
            of which `ifftn` is the inverse.
    fft : The one-dimensional FFT, with definitions and conventions used.
    irfft : The inverse of the one-dimensional FFT of real input.
    irfft2 : The inverse of the two-dimensional FFT of real input.

    Notes
    -----
    See `fft` for definitions and conventions used.

    See `rfft` for definitions and conventions used for real input.

    Examples
    --------
    >>> a = np.zeros((3, 2, 2))
    >>> a[0, 0, 0] = 3 * 2 * 2
    >>> np.fft.irfftn(a)
    array([[[ 1.,  1.],
            [ 1.,  1.]],
           [[ 1.,  1.],
            [ 1.,  1.]],
           [[ 1.,  1.],
            [ 1.,  1.]]])

    
    Compute the one-dimensional discrete Fourier Transform.

    This function computes the one-dimensional *n*-point discrete Fourier
    Transform (DFT) with the efficient Fast Fourier Transform (FFT)
    algorithm [CT].

    Parameters
    ----------
    a : array_like
        Input array, can be complex.
    n : int, optional
        Length of the transformed axis of the output.
        If `n` is smaller than the length of the input, the input is cropped.
        If it is larger, the input is padded with zeros.  If `n` is not given,
        the length of the input (along the axis specified by `axis`) is used.
    axis : int, optional
        Axis over which to compute the FFT.  If not given, the last axis is
        used.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axis
        indicated by `axis`, or the last one if `axis` is not specified.

    Raises
    ------
    IndexError
        if `axes` is larger than the last axis of `a`.

    See Also
    --------
    numpy.fft : for definition of the DFT and conventions used.
    ifft : The inverse of `fft`.
    fft2 : The two-dimensional FFT.
    fftn : The *n*-dimensional FFT.
    rfftn : The *n*-dimensional FFT of real input.
    fftfreq : Frequency bins for given FFT parameters.

    Notes
    -----
    FFT (Fast Fourier Transform) refers to a way the discrete Fourier
    Transform (DFT) can be calculated efficiently, by using symmetries in the
    calculated terms.  The symmetry is highest when `n` is a power of 2, and
    the transform is therefore most efficient for these sizes.

    The DFT is defined, with the conventions used in this implementation, in
    the documentation for the `numpy.fft` module.

    References
    ----------
    .. [CT] Cooley, James W., and John W. Tukey, 1965, "An algorithm for the
            machine calculation of complex Fourier series," *Math. Comput.*
            19: 297-301.

    Examples
    --------
    >>> np.fft.fft(np.exp(2j * np.pi * np.arange(8) / 8))
    array([ -3.44505240e-16 +1.14383329e-17j,
             8.00000000e+00 -5.71092652e-15j,
             2.33482938e-16 +1.22460635e-16j,
             1.64863782e-15 +1.77635684e-15j,
             9.95839695e-17 +2.33482938e-16j,
             0.00000000e+00 +1.66837030e-15j,
             1.14383329e-17 +1.22460635e-16j,
             -1.64863782e-15 +1.77635684e-15j])

    >>> import matplotlib.pyplot as plt
    >>> t = np.arange(256)
    >>> sp = np.fft.fft(np.sin(t))
    >>> freq = np.fft.fftfreq(t.shape[-1])
    >>> plt.plot(freq, sp.real, freq, sp.imag)
    [<matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>]
    >>> plt.show()

    In this example, real input has an FFT which is Hermitian, i.e., symmetric
    in the real part and anti-symmetric in the imaginary part, as described in
    the `numpy.fft` documentation.

    Shape and axes have different lengths.
    Compute the N-dimensional discrete Fourier Transform for real input.

    This function computes the N-dimensional discrete Fourier Transform over
    any number of axes in an M-dimensional real array by means of the Fast
    Fourier Transform (FFT).  By default, all axes are transformed, with the
    real transform performed over the last axis, while the remaining
    transforms are complex.

    Parameters
    ----------
    a : array_like
        Input array, taken to be real.
    s : sequence of ints, optional
        Shape (length along each transformed axis) to use from the input.
        (``s[0]`` refers to axis 0, ``s[1]`` to axis 1, etc.).
        The final element of `s` corresponds to `n` for ``rfft(x, n)``, while
        for the remaining axes, it corresponds to `n` for ``fft(x, n)``.
        Along any axis, if the given shape is smaller than that of the input,
        the input is cropped.  If it is larger, the input is padded with zeros.
        if `s` is not given, the shape of the input (along the axes specified
        by `axes`) is used.
    axes : sequence of ints, optional
        Axes over which to compute the FFT.  If not given, the last ``len(s)``
        axes are used, or all axes if `s` is also not specified.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or by a combination of `s` and `a`,
        as explained in the parameters section above.
        The length of the last axis transformed will be ``s[-1]//2+1``,
        while the remaining transformed axes will have lengths according to
        `s`, or unchanged from the input.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    irfftn : The inverse of `rfftn`, i.e. the inverse of the n-dimensional FFT
         of real input.
    fft : The one-dimensional FFT, with definitions and conventions used.
    rfft : The one-dimensional FFT of real input.
    fftn : The n-dimensional FFT.
    rfft2 : The two-dimensional FFT of real input.

    Notes
    -----
    The transform for real input is performed over the last transformation
    axis, as by `rfft`, then the transform over the remaining axes is
    performed as by `fftn`.  The order of the output is as for `rfft` for the
    final transformation axis, and as for `fftn` for the remaining
    transformation axes.

    See `fft` for details, definitions and conventions used.

    Examples
    --------
    >>> a = np.ones((2, 2, 2))
    >>> np.fft.rfftn(a)
    array([[[ 8.+0.j,  0.+0.j],
            [ 0.+0.j,  0.+0.j]],
           [[ 0.+0.j,  0.+0.j],
            [ 0.+0.j,  0.+0.j]]])

    >>> np.fft.rfftn(a, axes=(2, 0))
    array([[[ 4.+0.j,  0.+0.j],
            [ 4.+0.j,  0.+0.j]],
           [[ 0.+0.j,  0.+0.j],
            [ 0.+0.j,  0.+0.j]]])

    Invalid number of FFT data points (%d) specified.
    Compute the FFT of a signal whose spectrum has Hermitian symmetry.

    Parameters
    ----------
    a : array_like
        The input array.
    n : int, optional
        The length of the FFT.
    axis : int, optional
        The axis over which to compute the FFT, assuming Hermitian symmetry
        of the spectrum. Default is the last axis.

    Returns
    -------
    out : ndarray
        The transformed input.

    See also
    --------
    rfft : Compute the one-dimensional FFT for real input.
    ihfft : The inverse of `hfft`.

    Notes
    -----
    `hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the
    opposite case: here the signal is real in the frequency domain and has
    Hermite symmetry in the time domain. So here it's `hfft` for which
    you must supply the length of the result if it is to be odd:
    ``ihfft(hfft(a), len(a)) == a``, within numerical accuracy.

    Examples
    --------
    >>> signal = np.array([[1, 1.j], [-1.j, 2]])
    >>> np.conj(signal.T) - signal   # check Hermitian symmetry
    array([[ 0.-0.j,  0.+0.j],
           [ 0.+0.j,  0.-0.j]])
    >>> freq_spectrum = np.fft.hfft(signal)
    >>> freq_spectrum
    array([[ 1.,  1.],
           [ 2., -2.]])

    
    Compute the N-dimensional inverse discrete Fourier Transform.

    This function computes the inverse of the N-dimensional discrete
    Fourier Transform over any number of axes in an M-dimensional array by
    means of the Fast Fourier Transform (FFT).  In other words,
    ``ifftn(fftn(a)) == a`` to within numerical accuracy.
    For a description of the definitions and conventions used, see `numpy.fft`.

    The input, analogously to `ifft`, should be ordered in the same way as is
    returned by `fftn`, i.e. it should have the term for zero frequency
    in all axes in the low-order corner, the positive frequency terms in the
    first half of all axes, the term for the Nyquist frequency in the middle
    of all axes and the negative frequency terms in the second half of all
    axes, in order of decreasingly negative frequency.

    Parameters
    ----------
    a : array_like
        Input array, can be complex.
    s : sequence of ints, optional
        Shape (length of each transformed axis) of the output
        (``s[0]`` refers to axis 0, ``s[1]`` to axis 1, etc.).
        This corresponds to ``n`` for ``ifft(x, n)``.
        Along any axis, if the given shape is smaller than that of the input,
        the input is cropped.  If it is larger, the input is padded with zeros.
        if `s` is not given, the shape of the input (along the axes specified
        by `axes`) is used.  See notes for issue on `ifft` zero padding.
    axes : sequence of ints, optional
        Axes over which to compute the IFFT.  If not given, the last ``len(s)``
        axes are used, or all axes if `s` is also not specified.
        Repeated indices in `axes` means that the inverse transform over that
        axis is performed multiple times.

    Returns
    -------
    out : complex ndarray
        The truncated or zero-padded input, transformed along the axes
        indicated by `axes`, or by a combination of `s` or `a`,
        as explained in the parameters section above.

    Raises
    ------
    ValueError
        If `s` and `axes` have different length.
    IndexError
        If an element of `axes` is larger than than the number of axes of `a`.

    See Also
    --------
    numpy.fft : Overall view of discrete Fourier transforms, with definitions
         and conventions used.
    fftn : The forward *n*-dimensional FFT, of which `ifftn` is the inverse.
    ifft : The one-dimensional inverse FFT.
    ifft2 : The two-dimensional inverse FFT.
    ifftshift : Undoes `fftshift`, shifts zero-frequency terms to beginning
        of array.

    Notes
    -----
    See `numpy.fft` for definitions and conventions used.

    Zero-padding, analogously with `ifft`, is performed by appending zeros to
    the input along the specified dimension.  Although this is the common
    approach, it might lead to surprising results.  If another form of zero
    padding is desired, it must be performed before `ifftn` is called.

    Examples
    --------
    >>> a = np.eye(4)
    >>> np.fft.ifftn(np.fft.fftn(a, axes=(0,)), axes=(1,))
    array([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],
           [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],
           [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],
           [ 0.+0.j,  0.+0.j,  0.+0.j,  1.+0.j]])


    Create and plot an image with band-limited frequency content:

    >>> import matplotlib.pyplot as plt
    >>> n = np.zeros((200,200), dtype=complex)
    >>> n[60:80, 20:40] = np.exp(1j*np.random.uniform(0, 2*np.pi, (20, 20)))
    >>> im = np.fft.ifftn(n).real
    >>> plt.imshow(im)
    <matplotlib.image.AxesImage object at 0x...>
    >>> plt.show()

    
Discrete Fourier Transforms

Routines in this module:

fft(a, n=None, axis=-1)
ifft(a, n=None, axis=-1)
rfft(a, n=None, axis=-1)
irfft(a, n=None, axis=-1)
hfft(a, n=None, axis=-1)
ihfft(a, n=None, axis=-1)
fftn(a, s=None, axes=None)
ifftn(a, s=None, axes=None)
rfftn(a, s=None, axes=None)
irfftn(a, s=None, axes=None)
fft2(a, s=None, axes=(-2,-1))
ifft2(a, s=None, axes=(-2, -1))
rfft2(a, s=None, axes=(-2,-1))
irfft2(a, s=None, axes=(-2, -1))

i = inverse transform
r = transform of purely real data
h = Hermite transform
n = n-dimensional transform
2 = 2-dimensional transform
(Note: 2D routines are just nD routines with different default
behavior.)

The underlying code for these functions is an f2c-translated and modified
version of the FFTPACK routines.


    Compute the inverse FFT of a signal whose spectrum has Hermitian symmetry.

    Parameters
    ----------
    a : array_like
        Input array.
    n : int, optional
        Length of the inverse FFT.
    axis : int, optional
        Axis over which to compute the inverse FFT, assuming Hermitian
        symmetry of the spectrum. Default is the last axis.

    Returns
    -------
    out : ndarray
        The transformed input.

    See also
    --------
    hfft, irfft

    Notes
    -----
    `hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the
    opposite case: here the signal is real in the frequency domain and has
    Hermite symmetry in the time domain. So here it's `hfft` for which
    you must supply the length of the result if it is to be odd:
    ``ihfft(hfft(a), len(a)) == a``, within numerical accuracy.

    mylistrfftfreq
    The inverse of fftshift.

    Parameters
    ----------
    x : array_like
        Input array.
    axes : int or shape tuple, optional
        Axes over which to calculate.  Defaults to None, which shifts all axes.

    Returns
    -------
    y : ndarray
        The shifted array.

    See Also
    --------
    fftshift : Shift zero-frequency component to the center of the spectrum.

    Examples
    --------
    >>> freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)
    >>> freqs
    array([[ 0.,  1.,  2.],
           [ 3.,  4., -4.],
           [-3., -2., -1.]])
    >>> np.fft.ifftshift(np.fft.fftshift(freqs))
    array([[ 0.,  1.,  2.],
           [ 3.,  4., -4.],
           [-3., -2., -1.]])

    
Discrete Fourier Transforms - helper.py


    Return the Discrete Fourier Transform sample frequencies
    (for usage with rfft, irfft).

    The returned float array `f` contains the frequency bin centers in cycles
    per unit of the sample spacing (with zero at the start).  For instance, if
    the sample spacing is in seconds, then the frequency unit is cycles/second.

    Given a window length `n` and a sample spacing `d`::

      f = [0, 1, ...,     n/2-1,     n/2] / (d*n)   if n is even
      f = [0, 1, ..., (n-1)/2-1, (n-1)/2] / (d*n)   if n is odd

    Unlike `fftfreq` (but like `scipy.fftpack.rfftfreq`)
    the Nyquist frequency component is considered to be positive.

    Parameters
    ----------
    n : int
        Window length.
    d : scalar, optional
        Sample spacing (inverse of the sampling rate). Defaults to 1.

    Returns
    -------
    f : ndarray
        Array of length ``n//2 + 1`` containing the sample frequencies.

    Examples
    --------
    >>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5, -3, 4], dtype=float)
    >>> fourier = np.fft.rfft(signal)
    >>> n = signal.size
    >>> sample_rate = 100
    >>> freq = np.fft.fftfreq(n, d=1./sample_rate)
    >>> freq
    array([  0.,  10.,  20.,  30.,  40., -50., -40., -30., -20., -10.])
    >>> freq = np.fft.rfftfreq(n, d=1./sample_rate)
    >>> freq
    array([  0.,  10.,  20.,  30.,  40.,  50.])

    
    Return the Discrete Fourier Transform sample frequencies.

    The returned float array `f` contains the frequency bin centers in cycles
    per unit of the sample spacing (with zero at the start).  For instance, if
    the sample spacing is in seconds, then the frequency unit is cycles/second.

    Given a window length `n` and a sample spacing `d`::

      f = [0, 1, ...,   n/2-1,     -n/2, ..., -1] / (d*n)   if n is even
      f = [0, 1, ..., (n-1)/2, -(n-1)/2, ..., -1] / (d*n)   if n is odd

    Parameters
    ----------
    n : int
        Window length.
    d : scalar, optional
        Sample spacing (inverse of the sampling rate). Defaults to 1.

    Returns
    -------
    f : ndarray
        Array of length `n` containing the sample frequencies.

    Examples
    --------
    >>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float)
    >>> fourier = np.fft.fft(signal)
    >>> n = signal.size
    >>> timestep = 0.1
    >>> freq = np.fft.fftfreq(n, d=timestep)
    >>> freq
    array([ 0.  ,  1.25,  2.5 ,  3.75, -5.  , -3.75, -2.5 , -1.25])

    numpy.fft.helper
    Shift the zero-frequency component to the center of the spectrum.

    This function swaps half-spaces for all axes listed (defaults to all).
    Note that ``y[0]`` is the Nyquist component only if ``len(x)`` is even.

    Parameters
    ----------
    x : array_like
        Input array.
    axes : int or shape tuple, optional
        Axes over which to shift.  Default is None, which shifts all axes.

    Returns
    -------
    y : ndarray
        The shifted array.

    See Also
    --------
    ifftshift : The inverse of `fftshift`.

    Examples
    --------
    >>> freqs = np.fft.fftfreq(10, 0.1)
    >>> freqs
    array([ 0.,  1.,  2.,  3.,  4., -5., -4., -3., -2., -1.])
    >>> np.fft.fftshift(freqs)
    array([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])

    Shift the zero-frequency component only along the second axis:

    >>> freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)
    >>> freqs
    array([[ 0.,  1.,  2.],
           [ 3.,  4., -4.],
           [-3., -2., -1.]])
    >>> np.fft.fftshift(freqs, axes=(1,))
    array([[ 2.,  0.,  1.],
           [-4.,  3.,  4.],
           [-1., -3., -2.]])

    /usr/lib/python2.7/dist-packages/numpy/fft/helper.pyn should be an integernumpy.fft.info
Discrete Fourier Transform (:mod:`numpy.fft`)
=============================================

.. currentmodule:: numpy.fft

Standard FFTs
-------------

.. autosummary::
   :toctree: generated/

   fft       Discrete Fourier transform.
   ifft      Inverse discrete Fourier transform.
   fft2      Discrete Fourier transform in two dimensions.
   ifft2     Inverse discrete Fourier transform in two dimensions.
   fftn      Discrete Fourier transform in N-dimensions.
   ifftn     Inverse discrete Fourier transform in N dimensions.

Real FFTs
---------

.. autosummary::
   :toctree: generated/

   rfft      Real discrete Fourier transform.
   irfft     Inverse real discrete Fourier transform.
   rfft2     Real discrete Fourier transform in two dimensions.
   irfft2    Inverse real discrete Fourier transform in two dimensions.
   rfftn     Real discrete Fourier transform in N dimensions.
   irfftn    Inverse real discrete Fourier transform in N dimensions.

Hermitian FFTs
--------------

.. autosummary::
   :toctree: generated/

   hfft      Hermitian discrete Fourier transform.
   ihfft     Inverse Hermitian discrete Fourier transform.

Helper routines
---------------

.. autosummary::
   :toctree: generated/

   fftfreq   Discrete Fourier Transform sample frequencies.
   rfftfreq  DFT sample frequencies (for usage with rfft, irfft).
   fftshift  Shift zero-frequency component to center of spectrum.
   ifftshift Inverse of fftshift.


Background information
----------------------

Fourier analysis is fundamentally a method for expressing a function as a
sum of periodic components, and for recovering the function from those
components.  When both the function and its Fourier transform are
replaced with discretized counterparts, it is called the discrete Fourier
transform (DFT).  The DFT has become a mainstay of numerical computing in
part because of a very fast algorithm for computing it, called the Fast
Fourier Transform (FFT), which was known to Gauss (1805) and was brought
to light in its current form by Cooley and Tukey [CT]_.  Press et al. [NR]_
provide an accessible introduction to Fourier analysis and its
applications.

Because the discrete Fourier transform separates its input into
components that contribute at discrete frequencies, it has a great number
of applications in digital signal processing, e.g., for filtering, and in
this context the discretized input to the transform is customarily
referred to as a *signal*, which exists in the *time domain*.  The output
is called a *spectrum* or *transform* and exists in the *frequency
domain*.

Implementation details
----------------------

There are many ways to define the DFT, varying in the sign of the
exponent, normalization, etc.  In this implementation, the DFT is defined
as

.. math::
   A_k =  \sum_{m=0}^{n-1} a_m \exp\left\{-2\pi i{mk \over n}\right\}
   \qquad k = 0,\ldots,n-1.

The DFT is in general defined for complex inputs and outputs, and a
single-frequency component at linear frequency :math:`f` is
represented by a complex exponential
:math:`a_m = \exp\{2\pi i\,f m\Delta t\}`, where :math:`\Delta t`
is the sampling interval.

The values in the result follow so-called "standard" order: If ``A =
fft(a, n)``, then ``A[0]`` contains the zero-frequency term (the mean of
the signal), which is always purely real for real inputs. Then ``A[1:n/2]``
contains the positive-frequency terms, and ``A[n/2+1:]`` contains the
negative-frequency terms, in order of decreasingly negative frequency.
For an even number of input points, ``A[n/2]`` represents both positive and
negative Nyquist frequency, and is also purely real for real input.  For
an odd number of input points, ``A[(n-1)/2]`` contains the largest positive
frequency, while ``A[(n+1)/2]`` contains the largest negative frequency.
The routine ``np.fft.fftfreq(n)`` returns an array giving the frequencies
of corresponding elements in the output.  The routine
``np.fft.fftshift(A)`` shifts transforms and their frequencies to put the
zero-frequency components in the middle, and ``np.fft.ifftshift(A)`` undoes
that shift.

When the input `a` is a time-domain signal and ``A = fft(a)``, ``np.abs(A)``
is its amplitude spectrum and ``np.abs(A)**2`` is its power spectrum.
The phase spectrum is obtained by ``np.angle(A)``.

The inverse DFT is defined as

.. math::
   a_m = \frac{1}{n}\sum_{k=0}^{n-1}A_k\exp\left\{2\pi i{mk\over n}\right\}
   \qquad m = 0,\ldots,n-1.

It differs from the forward transform by the sign of the exponential
argument and the normalization by :math:`1/n`.

Real and Hermitian transforms
-----------------------------

When the input is purely real, its transform is Hermitian, i.e., the
component at frequency :math:`f_k` is the complex conjugate of the
component at frequency :math:`-f_k`, which means that for real
inputs there is no information in the negative frequency components that
is not already available from the positive frequency components.
The family of `rfft` functions is
designed to operate on real inputs, and exploits this symmetry by
computing only the positive frequency components, up to and including the
Nyquist frequency.  Thus, ``n`` input points produce ``n/2+1`` complex
output points.  The inverses of this family assumes the same symmetry of
its input, and for an output of ``n`` points uses ``n/2+1`` input points.

Correspondingly, when the spectrum is purely real, the signal is
Hermitian.  The `hfft` family of functions exploits this symmetry by
using ``n/2+1`` complex points in the input (time) domain for ``n`` real
points in the frequency domain.

In higher dimensions, FFTs are used, e.g., for image analysis and
filtering.  The computational efficiency of the FFT means that it can
also be a faster way to compute large convolutions, using the property
that a convolution in the time domain is equivalent to a point-by-point
multiplication in the frequency domain.

Higher dimensions
-----------------

In two dimensions, the DFT is defined as

.. math::
   A_{kl} =  \sum_{m=0}^{M-1} \sum_{n=0}^{N-1}
   a_{mn}\exp\left\{-2\pi i \left({mk\over M}+{nl\over N}\right)\right\}
   \qquad k = 0, \ldots, M-1;\quad l = 0, \ldots, N-1,

which extends in the obvious way to higher dimensions, and the inverses
in higher dimensions also extend in the same way.

References
----------

.. [CT] Cooley, James W., and John W. Tukey, 1965, "An algorithm for the
        machine calculation of complex Fourier series," *Math. Comput.*
        19: 297-301.

.. [NR] Press, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P.,
        2007, *Numerical Recipes: The Art of Scientific Computing*, ch.
        12-13.  Cambridge Univ. Press, Cambridge, UK.

Examples
--------

For examples, see the various functions.

/usr/lib/python2.7/dist-packages/numpy/fft/info.pyemath/usr/lib/python2.7/dist-packages/numpy/lib/__init__.pyufrag_fname_isurl_iszippardiruqueryzipext_loadeduparams_baseurl_destpath_findfile_fullpathopenedurlsplitpathRepository_istmpdest_iswritemode_splitzipext_possible_names_sanitize_relative_pathCache the file specified by path.

        Creates a copy of the file in the datasource cache.

        Create a DataSource with a local path at destpath.Create a Repository with a shared url or directory of baseurl.
        Open and return file-like object prepending Repository base URL.

        If `path` is an URL, it will be downloaded, stored in the DataSource
        directory and opened from there.

        Parameters
        ----------
        path : str
            Local file path or URL to open. This may, but does not have to,
            include the `baseurl` with which the `Repository` was initialized.
        mode : {'r', 'w', 'a'}, optional
            Mode to open `path`.  Mode 'r' for reading, 'w' for writing, 'a' to
            append. Available modes depend on the type of object specified by
            `path`. Default is 'r'.

        Returns
        -------
        out : file object
            File object.

        A file interface for handling local and remote data files.
The goal of datasource is to abstract some of the file system operations when
dealing with data files so the researcher doesn't have to know all the
low-level details.  Through datasource, a researcher can obtain and use a
file with one function call, regardless of location of the file.

DataSource is meant to augment standard python libraries, not replace them.
It should work seemlessly with standard file IO operations and the os module.

DataSource files can originate locally or remotely:

- local files : '/home/guido/src/local/data.txt'
- URLs (http, ftp, ...) : 'http://www.scipy.org/not/real/data.txt'

DataSource files can also be compressed or uncompressed.  Currently only gzip
and bz2 are supported.

Example::

    >>> # Create a DataSource, use os.curdir (default) for local storage.
    >>> ds = datasource.DataSource()
    >>>
    >>> # Open a remote file.
    >>> # DataSource downloads the file, stores it locally in:
    >>> #     './www.google.com/index.html'
    >>> # opens the file and returns a file object.
    >>> fp = ds.open('http://www.google.com/index.html')
    >>>
    >>> # Use the file as you normally would
    >>> fp.read()
    >>> fp.close()

Test if the given mode will open a file for writing.Extend DataSource method to prepend baseurl to ``path``./usr/lib/python2.7/dist-packages/numpy/lib/_datasource.py
        Return absolute path of file in the Repository directory.

        If `path` is an URL, then `abspath` will return either the location
        the file exists locally or the location it would exist when opened
        using the `open` method.

        Parameters
        ----------
        path : str
            Can be a local file or a remote URL. This may, but does not have
            to, include the `baseurl` with which the `Repository` was initialized.

        Returns
        -------
        out : str
            Complete path, including the `DataSource` destination directory.

        Return a sanitised relative path for which
        os.path.abspath(os.path.join(base, path)).startswith(base)
        
    Open `path` with `mode` and return the file object.

    If ``path`` is an URL, it will be downloaded, stored in the `DataSource`
    `destpath` directory and opened from there.

    Parameters
    ----------
    path : str
        Local file path or URL to open.
    mode : str, optional
        Mode to open `path`. Mode 'r' for reading, 'w' for writing, 'a' to
        append. Available modes depend on the type of object specified by path.
        Default is 'r'.
    destpath : str, optional
        Path to the directory where the source file gets downloaded to for use.
        If `destpath` is None, a temporary directory will be created. The
        default path is the current directory.

    Returns
    -------
    out : file object
        The opened file.

    Notes
    -----
    This is a convenience function that instantiates a `DataSource` and
    returns the file object from ``DataSource.open(path)``.

    Searches for ``path`` and returns full path if found.

        If path is an URL, _findfile will cache a local copy and return
        the path to the cached file.
        If path is a local file, _findfile will return a path to that local
        file.

        The search will include possible compressed versions of the file and
        return the first occurence found.

        
        Open and return file-like object.

        If `path` is an URL, it will be downloaded, stored in the `DataSource`
        directory and opened from there.

        Parameters
        ----------
        path : str
            Local file path or URL to open.
        mode : {'r', 'w', 'a'}, optional
            Mode to open `path`.  Mode 'r' for reading, 'w' for writing, 'a' to
            append. Available modes depend on the type of object specified by
            `path`. Default is 'r'.

        Returns
        -------
        out : file object
            File object.

        
    DataSource(destpath='.')

    A generic data source file (file, http, ftp, ...).

    DataSources can be local files or remote files/URLs.  The files may
    also be compressed or uncompressed. DataSource hides some of the low-level
    details of downloading the file, allowing you to simply pass in a valid
    file path (or URL) and obtain a file object.

    Parameters
    ----------
    destpath : str or None, optional
        Path to the directory where the source file gets downloaded to for use.
        If `destpath` is None, a temporary directory will be created.
        The default path is the current directory.

    Notes
    -----
    URLs require a scheme string (``http://``) to be used, without it they
    will fail::

        >>> repos = DataSource()
        >>> repos.exists('www.google.com/index.html')
        False
        >>> repos.exists('http://www.google.com/index.html')
        True

    Temporary directories are deleted when the DataSource is deleted.

    Examples
    --------
    ::

        >>> ds = DataSource('/home/guido')
        >>> urlname = 'http://www.google.com/index.html'
        >>> gfile = ds.open('http://www.google.com/index.html')  # remote file
        >>> ds.abspath(urlname)
        '/home/guido/www.google.com/site/index.html'

        >>> ds = DataSource(None)  # use with temporary file
        >>> ds.open('/home/guido/foobar.txt')
        <open file '/home/guido.foobar.txt', mode 'r' at 0x91d4430>
        >>> ds.abspath('/home/guido/foobar.txt')
        '/tmp/tmpy4pgsP/home/guido/foobar.txt'

    
        Return absolute path of file in the DataSource directory.

        If `path` is an URL, then `abspath` will return either the location
        the file exists locally or the location it would exist when opened
        using the `open` method.

        Parameters
        ----------
        path : str
            Can be a local file or a remote URL.

        Returns
        -------
        out : str
            Complete path, including the `DataSource` destination directory.

        Notes
        -----
        The functionality is based on `os.path.abspath`.

        
        List files in the source Repository.

        Returns
        -------
        files : list of str
            List of file names (not containing a directory part).

        Notes
        -----
        Does not currently work for remote repositories.

        URLs are not writeableURL not found: %sReturn a tuple containing compressed filename variations.
        Test if path exists prepending Repository base URL to path.

        Test if `path` exists as (and in this order):

        - a local file.
        - a remote URL that has been downloaded and stored locally in the
          `DataSource` directory.
        - a remote URL that has not been downloaded, but is valid and
          accessible.

        Parameters
        ----------
        path : str
            Can be a local file or a remote URL. This may, but does not have
            to, include the `baseurl` with which the `Repository` was initialized.

        Returns
        -------
        out : bool
            True if `path` exists.

        Notes
        -----
        When `path` is an URL, `exists` will return True if it's either stored
        locally in the `DataSource` directory, or is a valid remote URL.
        `DataSource` does not discriminate between the two, the file is accessible
        if it exists in either location.

        Test if the filename is a zip file by looking at the file extension.
        Directory listing of URLs, not supported yet.Test if path is a net location.  Tests the scheme and netloc.
    Container for different methods to open (un-)compressed files.

    `_FileOpeners` contains a dictionary that holds one method for each
    supported file format. Attribute lookup is implemented in such a way that
    an instance of `_FileOpeners` itself can be indexed with the keys of that
    dictionary. Currently uncompressed files as well as files
    compressed with ``gzip`` or ``bz2`` compression are supported.

    Notes
    -----
    `_file_openers`, an instance of `_FileOpeners`, is made available for
    use in the `_datasource` module.

    Examples
    --------
    >>> np.lib._datasource._file_openers.keys()
    [None, '.bz2', '.gz']
    >>> np.lib._datasource._file_openers['.gz'] is gzip.open
    True

    numpy.lib._datasourceReturn complete path for path.  Prepends baseurl if necessary.%s not found.
        Test if path exists.

        Test if `path` exists as (and in this order):

        - a local file.
        - a remote URL that has been downloaded and stored locally in the
          `DataSource` directory.
        - a remote URL that has not been downloaded, but is valid and accessible.

        Parameters
        ----------
        path : str
            Can be a local file or a remote URL.

        Returns
        -------
        out : bool
            True if `path` exists.

        Notes
        -----
        When `path` is an URL, `exists` will return True if it's either stored
        locally in the `DataSource` directory, or is a valid remote URL.
        `DataSource` does not discriminate between the two, the file is accessible
        if it exists in either location.

        
        Return the keys of currently supported file openers.

        Parameters
        ----------
        None

        Returns
        -------
        keys : list
            The keys are None for uncompressed files and the file extension
            strings (i.e. ``'.gz'``, ``'.bz2'``) for supported compression
            methods.

        Split zip extension from filename and return filename.

        *Returns*:
            base, zip_ext : {tuple}

        
    Repository(baseurl, destpath='.')

    A data repository where multiple DataSource's share a base URL/directory.

    `Repository` extends `DataSource` by prepending a base URL (or directory)
    to all the files it handles. Use `Repository` when you will be working
    with multiple files from one base URL.  Initialize `Repository` with the
    base URL, then refer to each file by its filename only.

    Parameters
    ----------
    baseurl : str
        Path to the local directory or remote location that contains the
        data files.
    destpath : str or None, optional
        Path to the directory where the source file gets downloaded to for use.
        If `destpath` is None, a temporary directory will be created.
        The default path is the current directory.

    Examples
    --------
    To analyze all files in the repository, do something like this
    (note: this is not self-contained code)::

        >>> repos = np.lib._datasource.Repository('/home/user/data/dir/')
        >>> for filename in filelist:
        ...     fp = repos.open(filename)
        ...     fp.analyze()
        ...     fp.close()

    Similarly you could use a URL for a repository::

        >>> repos = np.lib._datasource.Repository('http://www.xyz.edu/data')

    _locked_mappernbnames_getdtype_statusmax_defaultfill_defaultfunc_defaulttype_dtypeortype_getsubdtype_to_filehandleupgrade_mapper_callingfunction_initial_defaultdefaultdeletecharsdefaultexcludelist_delimited_splitter_fixedwidth_splitter_variablewidth_splitter<   t   !t    t   #t   %t   $t   't   &t   )t   (t   +t   *t   -t   ,t   /t   .t   ;t   :t   =t   <t   ?t   >t   @t   [t   ]t   \t   ^t   {t   }t   |t   ~The input argument `dtype` is neither a function or a dtype (got '%s' instead)
    Warning issued when a string converter has a problem.

    Notes
    -----
    In `genfromtxt` a `ConversionWarning` is issued if raising exceptions
    is explicitly suppressed with the "invalid_raise" keyword.

    
    Tries to transform a string supposed to represent a boolean to a boolean.

    Parameters
    ----------
    value : str
        The string that is transformed to a boolean.

    Returns
    -------
    boolval : bool
        The boolean representation of `value`.

    Raises
    ------
    ValueError
        If the string is not 'True' or 'False' (case independent)

    Examples
    --------
    >>> np.lib._iotools.str2bool('TRUE')
    True
    >>> np.lib._iotools.str2bool('false')
    False

    
    Upgrade the mapper of a StringConverter by adding a new function and its
    corresponding default.

    The input function (or sequence of functions) and its associated default
    value (if any) is inserted in penultimate position of the mapper.
    The corresponding type is estimated from the dtype of the default value.

    Parameters
    ----------
    func : var
        Function, or sequence of functions

    Examples
    --------
    >>> import dateutil.parser
    >>> import datetime
    >>> dateparser = datetustil.parser.parse
    >>> defaultdate = datetime.date(2000, 1, 1)
    >>> StringConverter.upgrade_mapper(dateparser, default=defaultdate)
        Cannot convert string '%s'
    Convenience function to create a `np.dtype` object.

    The function processes the input `dtype` and matches it with the given
    names.

    Parameters
    ----------
    ndtype : var
        Definition of the dtype. Can be any string or dictionary
        recognized by the `np.dtype` function, or a sequence of types.
    names : str or sequence, optional
        Sequence of strings to use as field names for a structured dtype.
        For convenience, `names` can be a string of a comma-separated list of
        names.
    defaultfmt : str, optional
        Format string used to define missing names, such as ``"f%i"``
        (default) or ``"fields_%02i"``.
    validationargs : optional
        A series of optional arguments used to initialize a `NameValidator`.

    Examples
    --------
    >>> np.lib._iotools.easy_dtype(float)
    dtype('float64')
    >>> np.lib._iotools.easy_dtype("i4, f8")
    dtype([('f0', '<i4'), ('f1', '<f8')])
    >>> np.lib._iotools.easy_dtype("i4, f8", defaultfmt="field_%03i")
    dtype([('field_000', '<i4'), ('field_001', '<f8')])

    >>> np.lib._iotools.easy_dtype((int, float, float), names="a,b,c")
    dtype([('a', '<i8'), ('b', '<f8'), ('c', '<f8')])
    >>> np.lib._iotools.easy_dtype(float, names="a,b,c")
    dtype([('a', '<f8'), ('b', '<f8'), ('c', '<f8')])

    
        Validate a list of strings to use as field names for a structured array.

        Parameters
        ----------
        names : sequence of str
            Strings to be validated.
        defaultfmt : str, optional
            Default format string, used if validating a given string reduces its
            length to zero.
        nboutput : integer, optional
            Final number of validated names, used to expand or shrink the initial
            list of names.

        Returns
        -------
        validatednames : list of str
            The list of validated field names.

        Notes
        -----
        A `NameValidator` instance can be called directly, which is the same as
        calling `validate`. For examples, see `NameValidator`.

        
    Object to split a string at a given delimiter or at given places.

    Parameters
    ----------
    delimiter : str, int, or sequence of ints, optional
        If a string, character used to delimit consecutive fields.
        If an integer or a sequence of integers, width(s) of each field.
    comment : str, optional
        Character used to mark the beginning of a comment. Default is '#'.
    autostrip : bool, optional
        Whether to strip each individual field. Default is True.

    Converter is locked and cannot be upgradedCould not find a valid conversion function
    Exception raised when an error occurs in a converter for string values.

    Returns the type of the dtype of the input variable.
    Returns the filehandle corresponding to a string or a file.
    If the string ends in '.gz', the file is automatically unzipped.

    Parameters
    ----------
    fname : string, filehandle
        Name of the file whose filehandle must be returned.
    flag : string, optional
        Flag indicating the status of the file ('r' for read, 'w' for write).
    return_opened : boolean, optional
        Whether to return the opening status of the file.
    
    Check whether obj behaves like a string.
    
        Try to find the best converter for a given string, and return the result.

        The supplied string `value` is converted by testing different
        converters in order. First the `func` method of the `StringConverter`
        instance is tried, if this fails other available converters are tried.
        The order in which these other converters are tried is determined by the
        `_status` attribute of the instance.

        Parameters
        ----------
        value : str
            The string to convert.

        Returns
        -------
        out : any
            The result of converting `value` with the appropriate converter.

        
        Wrapper to strip each member of the output of `method`.

        Parameters
        ----------
        method : function
            Function that takes a single argument and returns a sequence of
            strings.

        Returns
        -------
        wrapped : function
            The result of wrapping `method`. `wrapped` takes a single input
            argument and returns a list of strings that are stripped of
            white-space.

        
    Check whether obj behaves like a bytes object.
    
    Returns whether one or several fields of a dtype are nested.

    Parameters
    ----------
    ndtype : dtype
        Data-type of a structured array.

    Raises
    ------
    AttributeError
        If `ndtype` does not have a `names` attribute.

    Examples
    --------
    >>> dt = np.dtype([('name', 'S4'), ('x', float), ('y', float)])
    >>> np.lib._iotools.has_nested_fields(dt)
    False

    A collection of functions designed to help I/O with ascii files.

Returns dtype for datetime64 and type of dtype otherwise.
    Unpack a structured data-type by collapsing nested fields and/or fields
    with a shape.

    Note that the field names are lost.

    Parameters
    ----------
    ndtype : dtype
        The datatype to collapse
    flatten_base : {False, True}, optional
        Whether to transform a field with a shape into several fields or not.

    Examples
    --------
    >>> dt = np.dtype([('name', 'S4'), ('x', float), ('y', float),
    ...                ('block', int, (2, 3))])
    >>> np.lib._iotools.flatten_dtype(dt)
    [dtype('|S4'), dtype('float64'), dtype('float64'), dtype('int32')]
    >>> np.lib._iotools.flatten_dtype(dt, flatten_base=True)
    [dtype('|S4'), dtype('float64'), dtype('float64'), dtype('int32'),
     dtype('int32'), dtype('int32'), dtype('int32'), dtype('int32'),
     dtype('int32')]

    
    Object to validate a list of strings to use as field names.

    The strings are stripped of any non alphanumeric character, and spaces
    are replaced by '_'. During instantiation, the user can define a list of
    names to exclude, as well as a list of invalid characters. Names in the
    exclusion list are appended a '_' character.

    Once an instance has been created, it can be called with a list of names,
    and a list of valid names will be created.
    The `__call__` method accepts an optional keyword "default" that sets
    the default name in case of ambiguity. By default this is 'f', so
    that names will default to `f0`, `f1`, etc.

    Parameters
    ----------
    excludelist : sequence, optional
        A list of names to exclude. This list is appended to the default list
        ['return', 'file', 'print']. Excluded names are appended an underscore:
        for example, `file` becomes `file_` if supplied.
    deletechars : str, optional
        A string combining invalid characters that must be deleted from the
        names.
    casesensitive : {True, False, 'upper', 'lower'}, optional
        * If True, field names are case-sensitive.
        * If False or 'upper', field names are converted to upper case.
        * If 'lower', field names are converted to lower case.

        The default value is True.
    replace_space : '_', optional
        Character(s) used in replacement of white spaces.

    Notes
    -----
    Calling an instance of `NameValidator` is the same as calling its method
    `validate`.

    Examples
    --------
    >>> validator = np.lib._iotools.NameValidator()
    >>> validator(['file', 'field2', 'with space', 'CaSe'])
    ['file_', 'field2', 'with_space', 'CaSe']

    >>> validator = np.lib._iotools.NameValidator(excludelist=['excl'],
                                                  deletechars='q',
                                                  case_sensitive='False')
    >>> validator(['excl', 'field2', 'no_q', 'with space', 'CaSe'])
    ['excl_', 'field2', 'no_', 'with_space', 'case']

    
    Exception raised when an attempt is made to upgrade a locked converter.

     

    Factory class for function transforming a string into another object (int,
    float).

    After initialization, an instance can be called to transform a string
    into another object. If the string is recognized as representing a missing
    value, a default value is returned.

    Attributes
    ----------
    func : function
        Function used for the conversion.
    default : any
        Default value to return when the input corresponds to a missing value.
    type : type
        Type of the output.
    _status : int
        Integer representing the order of the conversion.
    _mapper : sequence of tuples
        Sequence of tuples (dtype, function, default value) to evaluate in
        order.
    _locked : bool
        Holds `locked` parameter.

    Parameters
    ----------
    dtype_or_func : {None, dtype, function}, optional
        If a `dtype`, specifies the input data type, used to define a basic
        function and a default value for missing data. For example, when
        `dtype` is float, the `func` attribute is set to `float` and the
        default value to `np.nan`.
        If a function, this function is used to convert a string to another
        object. In this case, it is recommended to give an associated default
        value as input.
    default : any, optional
        Value to return by default, that is, when the string to be converted
        is flagged as missing. If not given, `StringConverter` tries to supply
        a reasonable default value.
    missing_values : sequence of str, optional
        Sequence of strings indicating a missing value.
    locked : bool, optional
        Whether the StringConverter should be locked to prevent automatic
        upgrade or not. Default is False.

    Invalid booleannumpy.lib._iotools
        Set StringConverter attributes directly.

        Parameters
        ----------
        func : function
            Conversion function.
        default : any, optional
            Value to return by default, that is, when the string to be converted
            is flagged as missing. If not given, `StringConverter` tries to supply
            a reasonable default value.
        testing_value : str, optional
            A string representing a standard input value of the converter.
            This string is used to help defining a reasonable default value.
        missing_values : sequence of str, optional
            Sequence of strings indicating a missing value.
        locked : bool, optional
            Whether the StringConverter should be locked to prevent automatic
            upgrade or not. Default is False.

        Notes
        -----
        `update` takes the same parameters as the constructor of `StringConverter`,
        except that `func` does not accept a `dtype` whereas `dtype_or_func` in
        the constructor does.

        Returns the dtype of the input variable./usr/lib/python2.7/dist-packages/numpy/lib/_iotools.pyslopeedge_arredge_padpadshapeinitshapemax_chunkmax_slicemed_chunkmed_slicemin_chunkmin_sliceref_slicesym_sliceedge_sliceend_valuesmean_chunkmean_slicewrap_sliceedge_slice1edge_slice2linear_rampstat_lengthwrap_chunk1wrap_chunk2reflect_typeconstant_values
    Prepend `pad_amt` maximum values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    num : int
        Depth into `arr` along `axis` to calculate maximum.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        prepended region is the maximum of the first `num` values along
        `axis`.

    
    Prepend `pad_amt` minimum values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    num : int
        Depth into `arr` along `axis` to calculate minimum.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values prepended along `axis`. The
        prepended region is the minimum of the first `num` values along
        `axis`.

    
    Private function which does some checks and normalizes the possibly
    much simpler representations of 'pad_width', 'stat_length',
    'constant_values', 'end_values'.

    Parameters
    ----------
    narray : ndarray
        Input ndarray
    shape : {sequence, int}, optional
        The width of padding (pad_width) or the number of elements on the
        edge of the narray used for statistics (stat_length).
        ((before_1, after_1), ... (before_N, after_N)) unique number of
        elements for each axis where `N` is rank of `narray`.
        ((before, after),) yields same before and after constants for each
        axis.
        (constant,) or int is a shortcut for before = after = constant for
        all axes.

    Returns
    -------
    _normalize_shape : tuple of tuples
        int                               => ((int, int), (int, int), ...)
        [[int1, int2], [int3, int4], ...] => ((int1, int2), (int3, int4), ...)
        ((int1, int2), (int3, int4), ...) => no change
        [[int1, int2], ]                  => ((int1, int2), (int1, int2), ...)
        ((int1, int2), )                  => ((int1, int2), (int1, int2), ...)
        [[int ,     ], ]                  => ((int, int), (int, int), ...)
        ((int ,     ), )                  => ((int, int), (int, int), ...)

    %s cannot contain negative values.
    Pads an array.

    Parameters
    ----------
    array : array_like of rank N
        Input array
    pad_width : {sequence, int}
        Number of values padded to the edges of each axis.
        ((before_1, after_1), ... (before_N, after_N)) unique pad widths
        for each axis.
        ((before, after),) yields same before and after pad for each axis.
        (pad,) or int is a shortcut for before = after = pad width for all
        axes.
    mode : {str, function}
        One of the following string values or a user supplied function.

        'constant'      Pads with a constant value.
        'edge'          Pads with the edge values of array.
        'linear_ramp'   Pads with the linear ramp between end_value and the
                        array edge value.
        'maximum'       Pads with the maximum value of all or part of the
                        vector along each axis.
        'mean'          Pads with the mean value of all or part of the
                        vector along each axis.
        'median'        Pads with the median value of all or part of the
                        vector along each axis.
        'minimum'       Pads with the minimum value of all or part of the
                        vector along each axis.
        'reflect'       Pads with the reflection of the vector mirrored on
                        the first and last values of the vector along each
                        axis.
        'symmetric'     Pads with the reflection of the vector mirrored
                        along the edge of the array.
        'wrap'          Pads with the wrap of the vector along the axis.
                        The first values are used to pad the end and the
                        end values are used to pad the beginning.
        <function>      Padding function, see Notes.
    stat_length : {sequence, int}, optional
        Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of
        values at edge of each axis used to calculate the statistic value.

        ((before_1, after_1), ... (before_N, after_N)) unique statistic
        lengths for each axis.

        ((before, after),) yields same before and after statistic lengths
        for each axis.

        (stat_length,) or int is a shortcut for before = after = statistic
        length for all axes.

        Default is ``None``, to use the entire axis.
    constant_values : {sequence, int}, optional
        Used in 'constant'.  The values to set the padded values for each
        axis.

        ((before_1, after_1), ... (before_N, after_N)) unique pad constants
        for each axis.

        ((before, after),) yields same before and after constants for each
        axis.

        (constant,) or int is a shortcut for before = after = constant for
        all axes.

        Default is 0.
    end_values : {sequence, int}, optional
        Used in 'linear_ramp'.  The values used for the ending value of the
        linear_ramp and that will form the edge of the padded array.

        ((before_1, after_1), ... (before_N, after_N)) unique end values
        for each axis.

        ((before, after),) yields same before and after end values for each
        axis.

        (constant,) or int is a shortcut for before = after = end value for
        all axes.

        Default is 0.
    reflect_type : str {'even', 'odd'}, optional
        Used in 'reflect', and 'symmetric'.  The 'even' style is the
        default with an unaltered reflection around the edge value.  For
        the 'odd' style, the extented part of the array is created by
        subtracting the reflected values from two times the edge value.

    Returns
    -------
    pad : ndarray
        Padded array of rank equal to `array` with shape increased
        according to `pad_width`.

    Notes
    -----
    .. versionadded:: 1.7.0

    For an array with rank greater than 1, some of the padding of later
    axes is calculated from padding of previous axes.  This is easiest to
    think about with a rank 2 array where the corners of the padded array
    are calculated by using padded values from the first axis.

    The padding function, if used, should return a rank 1 array equal in
    length to the vector argument with padded values replaced. It has the
    following signature:

        padding_func(vector, iaxis_pad_width, iaxis, **kwargs)

    where

        vector : ndarray
            A rank 1 array already padded with zeros.  Padded values are
            vector[:pad_tuple[0]] and vector[-pad_tuple[1]:].
        iaxis_pad_width : tuple
            A 2-tuple of ints, iaxis_pad_width[0] represents the number of
            values padded at the beginning of vector where
            iaxis_pad_width[1] represents the number of values padded at
            the end of vector.
        iaxis : int
            The axis currently being calculated.
        kwargs : misc
            Any keyword arguments the function requires.

    Examples
    --------
    >>> a = [1, 2, 3, 4, 5]
    >>> np.lib.pad(a, (2,3), 'constant', constant_values=(4,6))
    array([4, 4, 1, 2, 3, 4, 5, 6, 6, 6])

    >>> np.lib.pad(a, (2,3), 'edge')
    array([1, 1, 1, 2, 3, 4, 5, 5, 5, 5])

    >>> np.lib.pad(a, (2,3), 'linear_ramp', end_values=(5,-4))
    array([ 5,  3,  1,  2,  3,  4,  5,  2, -1, -4])

    >>> np.lib.pad(a, (2,), 'maximum')
    array([5, 5, 1, 2, 3, 4, 5, 5, 5])

    >>> np.lib.pad(a, (2,), 'mean')
    array([3, 3, 1, 2, 3, 4, 5, 3, 3])

    >>> np.lib.pad(a, (2,), 'median')
    array([3, 3, 1, 2, 3, 4, 5, 3, 3])

    >>> a = [[1,2], [3,4]]
    >>> np.lib.pad(a, ((3, 2), (2, 3)), 'minimum')
    array([[1, 1, 1, 2, 1, 1, 1],
           [1, 1, 1, 2, 1, 1, 1],
           [1, 1, 1, 2, 1, 1, 1],
           [1, 1, 1, 2, 1, 1, 1],
           [3, 3, 3, 4, 3, 3, 3],
           [1, 1, 1, 2, 1, 1, 1],
           [1, 1, 1, 2, 1, 1, 1]])

    >>> a = [1, 2, 3, 4, 5]
    >>> np.lib.pad(a, (2,3), 'reflect')
    array([3, 2, 1, 2, 3, 4, 5, 4, 3, 2])

    >>> np.lib.pad(a, (2,3), 'reflect', reflect_type='odd')
    array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8])

    >>> np.lib.pad(a, (2,3), 'symmetric')
    array([2, 1, 1, 2, 3, 4, 5, 5, 4, 3])

    >>> np.lib.pad(a, (2,3), 'symmetric', reflect_type='odd')
    array([0, 1, 1, 2, 3, 4, 5, 5, 6, 7])

    >>> np.lib.pad(a, (2,3), 'wrap')
    array([4, 5, 1, 2, 3, 4, 5, 1, 2, 3])

    >>> def padwithtens(vector, pad_width, iaxis, kwargs):
    ...     vector[:pad_width[0]] = 10
    ...     vector[-pad_width[1]:] = 10
    ...     return vector

    >>> a = np.arange(6)
    >>> a = a.reshape((2,3))

    >>> np.lib.pad(a, 2, padwithtens)
    array([[10, 10, 10, 10, 10, 10, 10],
           [10, 10, 10, 10, 10, 10, 10],
           [10, 10,  0,  1,  2, 10, 10],
           [10, 10,  3,  4,  5, 10, 10],
           [10, 10, 10, 10, 10, 10, 10],
           [10, 10, 10, 10, 10, 10, 10]])

    
    Private function which does some checks and reformats pad_width and
    stat_length using _normalize_shape.

    Parameters
    ----------
    narray : ndarray
        Input ndarray
    number_elements : {sequence, int}, optional
        The width of padding (pad_width) or the number of elements on the edge
        of the narray used for statistics (stat_length).
        ((before_1, after_1), ... (before_N, after_N)) unique number of
        elements for each axis.
        ((before, after),) yields same before and after constants for each
        axis.
        (constant,) or int is a shortcut for before = after = constant for all
        axes.

    Returns
    -------
    _validate_lengths : tuple of tuples
        int                               => ((int, int), (int, int), ...)
        [[int1, int2], [int3, int4], ...] => ((int1, int2), (int3, int4), ...)
        ((int1, int2), (int3, int4), ...) => no change
        [[int1, int2], ]                  => ((int1, int2), (int1, int2), ...)
        ((int1, int2), )                  => ((int1, int2), (int1, int2), ...)
        [[int ,     ], ]                  => ((int, int), (int, int), ...)
        ((int ,     ), )                  => ((int, int), (int, int), ...)

    
    Rounds arr inplace if destination dtype is integer.

    Parameters
    ----------
    arr : ndarray
        Input array.
    dtype : dtype
        The dtype of the destination array.

    
    Prepend `pad_amt` to `arr` along `axis` by extending edge values.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, extended by `pad_amt` edge values appended along `axis`.

    
    Append constant `val` along `axis` of `arr`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    val : scalar
        Constant value to use. For best results should be of type `arr.dtype`;
        if not `arr.dtype` will be cast to `arr.dtype`.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` constant `val` appended along `axis`.

    
    Append `pad_amt` median values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    num : int
        Depth into `arr` along `axis` to calculate median.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        appended region is the median of the final `num` values along `axis`.

    
    Prepend linear ramp along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    end : scalar
        Constal value to use. For best results should be of type `arr.dtype`;
        if not `arr.dtype` will be cast to `arr.dtype`.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values prepended along `axis`. The
        prepended region ramps linearly from the edge value to `end`.

    
    Append `pad_amt` median values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    num : int
        Depth into `arr` along `axis` to calculate minimum.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        appended region is the minimum of the final `num` values along `axis`.

    Unable to create correctly shaped tuple from %s
    Append `pad_amt` to `arr` along `axis` by extending edge values.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, extended by `pad_amt` edge values prepended along
        `axis`.

    %s keyword not in allowed keywords %s
    Prepend constant `val` along `axis` of `arr`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    val : scalar
        Constant value to use. For best results should be of type `arr.dtype`;
        if not `arr.dtype` will be cast to `arr.dtype`.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` constant `val` prepended along `axis`.

    
    Pad one `axis` of `arr` with the maximum of the last `num` elements.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    num : int
        Depth into `arr` along `axis` to calculate maximum.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        appended region is the maximum of the final `num` values along `axis`.

    numpy.lib.arraypad
    Pad `axis` of `arr` by symmetry.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : tuple of ints, length 2
        Padding to (prepend, append) along `axis`.
    method : str
        Controls method of symmetry; options are 'even' or 'odd'.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt[0]` values prepended and `pad_amt[1]`
        values appended along `axis`. Both regions are padded with symmetric
        values from the original array.

    Notes
    -----
    This algorithm DOES pad with repetition, i.e. the edges are repeated.
    For a method that does not repeat edges, use `method='reflect'`.

    The modes 'reflect', 'symmetric', and 'wrap' must be padded with a
    single function, lest the indexing tricks in non-integer multiples of the
    original shape would violate repetition in the final iteration.

    
    Create an ndarray of `shape` with increments along specified `axis`

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    shape : tuple of ints
        Shape of desired array. Should be equivalent to `arr.shape` except
        `shape[axis]` which may have any positive value.
    axis : int
        Axis to increment along.
    reverse : bool
        If False, increment in a positive fashion from 1 to `shape[axis]`,
        inclusive. If True, the bounds are the same but the order reversed.

    Returns
    -------
    padarr : ndarray
        Output array sized to pad `arr` along `axis`, with linear range from
        1 to `shape[axis]` along specified `axis`.

    Notes
    -----
    The range is deliberately 1-indexed for this specific use case. Think of
    this algorithm as broadcasting `np.arange` to a single `axis` of an
    arbitrarily shaped ndarray.

    /usr/lib/python2.7/dist-packages/numpy/lib/arraypad.py
    Append linear ramp along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    end : scalar
        Constal value to use. For best results should be of type `arr.dtype`;
        if not `arr.dtype` will be cast to `arr.dtype`.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        appended region ramps linearly from the edge value to `end`.

    
    Pad `axis` of `arr` by reflection.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : tuple of ints, length 2
        Padding to (prepend, append) along `axis`.
    method : str
        Controls method of reflection; options are 'even' or 'odd'.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt[0]` values prepended and `pad_amt[1]`
        values appended along `axis`. Both regions are padded with reflected
        values from the original array.

    Notes
    -----
    This algorithm does not pad with repetition, i.e. the edges are not
    repeated in the reflection. For that behavior, use `method='symmetric'`.

    The modes 'reflect', 'symmetric', and 'wrap' must be padded with a
    single function, lest the indexing tricks in non-integer multiples of the
    original shape would violate repetition in the final iteration.

    
    Append `pad_amt` mean values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to append.
    num : int
        Depth into `arr` along `axis` to calculate mean.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values appended along `axis`. The
        appended region is the maximum of the final `num` values along `axis`.

    
    Prepend `pad_amt` mean values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    num : int
        Depth into `arr` along `axis` to calculate mean.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values prepended along `axis`. The
        prepended region is the mean of the first `num` values along `axis`.

    
The arraypad module contains a group of functions to pad values onto the edges
of an n-dimensional array.


    Pad `axis` of `arr` via wrapping.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : tuple of ints, length 2
        Padding to (prepend, append) along `axis`.
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt[0]` values prepended and `pad_amt[1]`
        values appended along `axis`. Both regions are padded wrapped values
        from the opposite end of `axis`.

    Notes
    -----
    This method of padding is also known as 'tile' or 'tiling'.

    The modes 'reflect', 'symmetric', and 'wrap' must be padded with a
    single function, lest the indexing tricks in non-integer multiples of the
    original shape would violate repetition in the final iteration.

    Keyword "mode" must be a function or one of %s.
    Prepend `pad_amt` median values along `axis`.

    Parameters
    ----------
    arr : ndarray
        Input array of arbitrary shape.
    pad_amt : int
        Amount of padding to prepend.
    num : int
        Depth into `arr` along `axis` to calculate median.
        Range: [1, `arr.shape[axis]`] or None (entire axis)
    axis : int
        Axis along which to pad `arr`.

    Returns
    -------
    padarr : ndarray
        Output array, with `pad_amt` values prepended along `axis`. The
        prepended region is the median of the first `num` values along `axis`.

    (   t   arrayt	   pad_widtht   modet   kwargst   narrayt   allowedkwargst
   kwdefaultst   keyt   kwt   it   functiont   rankt   total_dim_increaset   offset_slicest	   new_shapet   newmatt   iaxist   axist
   pad_beforet	   pad_aftert
   before_valt	   after_valt   chunk_beforet   chunk_aftert   methodt   safe_padt   repeatt   offsett
   pad_iter_bt
   pad_iter_a(\?
    Find the intersection of two arrays.

    Return the sorted, unique values that are in both of the input arrays.

    Parameters
    ----------
    ar1, ar2 : array_like
        Input arrays.
    assume_unique : bool
        If True, the input arrays are both assumed to be unique, which
        can speed up the calculation.  Default is False.

    Returns
    -------
    intersect1d : ndarray
        Sorted 1D array of common and unique elements.

    See Also
    --------
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Examples
    --------
    >>> np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])
    array([1, 3])

    
    Find the set difference of two arrays.

    Return the sorted, unique values in `ar1` that are not in `ar2`.

    Parameters
    ----------
    ar1 : array_like
        Input array.
    ar2 : array_like
        Input comparison array.
    assume_unique : bool
        If True, the input arrays are both assumed to be unique, which
        can speed up the calculation.  Default is False.

    Returns
    -------
    setdiff1d : ndarray
        Sorted 1D array of values in `ar1` that are not in `ar2`.

    See Also
    --------
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Examples
    --------
    >>> a = np.array([1, 2, 3, 2, 4, 1])
    >>> b = np.array([3, 4, 5, 6])
    >>> np.setdiff1d(a, b)
    array([1, 2])

    
    Find the union of two arrays.

    Return the unique, sorted array of values that are in either of the two
    input arrays.

    Parameters
    ----------
    ar1, ar2 : array_like
        Input arrays. They are flattened if they are not already 1D.

    Returns
    -------
    union1d : ndarray
        Unique, sorted union of the input arrays.

    See Also
    --------
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Examples
    --------
    >>> np.union1d([-1, 0, 1], [-2, 0, 2])
    array([-2, -1,  0,  1,  2])

    
    Find the set exclusive-or of two arrays.

    Return the sorted, unique values that are in only one (not both) of the
    input arrays.

    Parameters
    ----------
    ar1, ar2 : array_like
        Input arrays.
    assume_unique : bool
        If True, the input arrays are both assumed to be unique, which
        can speed up the calculation.  Default is False.

    Returns
    -------
    setxor1d : ndarray
        Sorted 1D array of unique values that are in only one of the input
        arrays.

    Examples
    --------
    >>> a = np.array([1, 2, 3, 2, 4])
    >>> b = np.array([2, 3, 5, 7, 5])
    >>> np.setxor1d(a,b)
    array([1, 4, 5, 7])

    
Set operations for 1D numeric arrays based on sorting.

:Contains:
  ediff1d,
  unique,
  intersect1d,
  setxor1d,
  in1d,
  union1d,
  setdiff1d

:Notes:

For floating point arrays, inaccurate results may appear due to usual round-off
and floating point comparison issues.

Speed could be gained in some operations by an implementation of
sort(), that can provide directly the permutation vectors, avoiding
thus calls to argsort().

To do: Optionally return indices analogously to unique for all functions.

:Author: Robert Cimrman

/usr/lib/python2.7/dist-packages/numpy/lib/arraysetops.py
    Find the unique elements of an array.

    Returns the sorted unique elements of an array. There are two optional
    outputs in addition to the unique elements: the indices of the input array
    that give the unique values, and the indices of the unique array that
    reconstruct the input array.

    Parameters
    ----------
    ar : array_like
        Input array. This will be flattened if it is not already 1-D.
    return_index : bool, optional
        If True, also return the indices of `ar` that result in the unique
        array.
    return_inverse : bool, optional
        If True, also return the indices of the unique array that can be used
        to reconstruct `ar`.

    Returns
    -------
    unique : ndarray
        The sorted unique values.
    unique_indices : ndarray, optional
        The indices of the first occurrences of the unique values in the
        (flattened) original array. Only provided if `return_index` is True.
    unique_inverse : ndarray, optional
        The indices to reconstruct the (flattened) original array from the
        unique array. Only provided if `return_inverse` is True.

    See Also
    --------
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Examples
    --------
    >>> np.unique([1, 1, 2, 2, 3, 3])
    array([1, 2, 3])
    >>> a = np.array([[1, 1], [2, 3]])
    >>> np.unique(a)
    array([1, 2, 3])

    Return the indices of the original array that give the unique values:

    >>> a = np.array(['a', 'b', 'b', 'c', 'a'])
    >>> u, indices = np.unique(a, return_index=True)
    >>> u
    array(['a', 'b', 'c'],
           dtype='|S1')
    >>> indices
    array([0, 1, 3])
    >>> a[indices]
    array(['a', 'b', 'c'],
           dtype='|S1')

    Reconstruct the input array from the unique values:

    >>> a = np.array([1, 2, 6, 4, 2, 3, 2])
    >>> u, indices = np.unique(a, return_inverse=True)
    >>> u
    array([1, 2, 3, 4, 6])
    >>> indices
    array([0, 1, 4, 3, 1, 2, 1])
    >>> u[indices]
    array([1, 2, 6, 4, 2, 3, 2])

    
    Test whether each element of a 1-D array is also present in a second array.

    Returns a boolean array the same length as `ar1` that is True
    where an element of `ar1` is in `ar2` and False otherwise.

    Parameters
    ----------
    ar1 : (M,) array_like
        Input array.
    ar2 : array_like
        The values against which to test each value of `ar1`.
    assume_unique : bool, optional
        If True, the input arrays are both assumed to be unique, which
        can speed up the calculation.  Default is False.
    invert : bool, optional
        If True, the values in the returned array are inverted (that is,
        False where an element of `ar1` is in `ar2` and True otherwise).
        Default is False. ``np.in1d(a, b, invert=True)`` is equivalent
        to (but is faster than) ``np.invert(in1d(a, b))``.

        .. versionadded:: 1.8.0

    Returns
    -------
    in1d : (M,) ndarray, bool
        The values `ar1[in1d]` are in `ar2`.

    See Also
    --------
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Notes
    -----
    `in1d` can be considered as an element-wise function version of the
    python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly
    equivalent to ``np.array([item in b for item in a])``.

    .. versionadded:: 1.4.0

    Examples
    --------
    >>> test = np.array([0, 1, 2, 5, 0])
    >>> states = [0, 2]
    >>> mask = np.in1d(test, states)
    >>> mask
    array([ True, False,  True, False,  True], dtype=bool)
    >>> test[mask]
    array([0, 2, 0])
    >>> mask = np.in1d(test, states, invert=True)
    >>> mask
    array([False,  True, False,  True, False], dtype=bool)
    >>> test[mask]
    array([1, 5])
    
    The differences between consecutive elements of an array.

    Parameters
    ----------
    ary : array_like
        If necessary, will be flattened before the differences are taken.
    to_end : array_like, optional
        Number(s) to append at the end of the returned differences.
    to_begin : array_like, optional
        Number(s) to prepend at the beginning of the returned differences.

    Returns
    -------
    ediff1d : ndarray
        The differences. Loosely, this is ``ary.flat[1:] - ary.flat[:-1]``.

    See Also
    --------
    diff, gradient

    Notes
    -----
    When applied to masked arrays, this function drops the mask information
    if the `to_begin` and/or `to_end` parameters are used.

    Examples
    --------
    >>> x = np.array([1, 2, 4, 7, 0])
    >>> np.ediff1d(x)
    array([ 1,  2,  3, -7])

    >>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99]))
    array([-99,   1,   2,   3,  -7,  88,  99])

    The returned array is always 1D.

    >>> y = [[1, 2, 4], [1, 6, 24]]
    >>> np.ediff1d(y)
    array([ 1,  2, -3,  5, 18])

    Arrayterator_Arrayterator__iterator
    Buffered iterator for big arrays.

    `Arrayterator` creates a buffered iterator for reading big arrays in small
    contiguous blocks. The class is useful for objects stored in the
    file system. It allows iteration over the object *without* reading
    everything in memory; instead, small blocks are read and iterated over.

    `Arrayterator` can be used with any object that supports multidimensional
    slices. This includes NumPy arrays, but also variables from
    Scientific.IO.NetCDF or pynetcdf for example.

    Parameters
    ----------
    var : array_like
        The object to iterate over.
    buf_size : int, optional
        The buffer size. If `buf_size` is supplied, the maximum amount of
        data that will be read into memory is `buf_size` elements.
        Default is None, which will read as many element as possible
        into memory.

    Attributes
    ----------
    var
    buf_size
    start
    stop
    step
    shape
    flat

    See Also
    --------
    ndenumerate : Multidimensional array iterator.
    flatiter : Flat array iterator.
    memmap : Create a memory-map to an array stored in a binary file on disk.

    Notes
    -----
    The algorithm works by first finding a "running dimension", along which
    the blocks will be extracted. Given an array of dimensions
    ``(d1, d2, ..., dn)``, e.g. if `buf_size` is smaller than ``d1``, the
    first dimension will be used. If, on the other hand,
    ``d1 < buf_size < d1*d2`` the second dimension will be used, and so on.
    Blocks are extracted along this dimension, and when the last block is
    returned the process continues from the next dimension, until all
    elements have been read.

    Examples
    --------
    >>> import numpy as np
    >>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6)
    >>> a_itor = np.lib.arrayterator.Arrayterator(a, 2)
    >>> a_itor.shape
    (3, 4, 5, 6)

    Now we can iterate over ``a_itor``, and it will return arrays of size
    two. Since `buf_size` was smaller than any dimension, the first
    dimension will be iterated over first:

    >>> for subarr in a_itor:
    ...     if not subarr.all():
    ...         print subarr, subarr.shape
    ...
    [[[[0 1]]]] (1, 1, 1, 2)

    
A buffered iterator for big arrays.

This module solves the problem of iterating over a big file-based array
without having to read it into memory. The `Arrayterator` class wraps
an array object, and when iterated it will return sub-arrays with at most
a user-specified number of elements.

numpy.lib.arrayterator
        A 1-D flat iterator for Arrayterator objects.

        This iterator returns elements of the array to be iterated over in
        `Arrayterator` one by one. It is similar to `flatiter`.

        See Also
        --------
        `Arrayterator`
        flatiter

        Examples
        --------
        >>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6)
        >>> a_itor = np.lib.arrayterator.Arrayterator(a, 2)

        >>> for subarr in a_itor.flat:
        ...     if not subarr:
        ...         print subarr, type(subarr)
        ...
        0 <type 'numpy.int32'>

        /usr/lib/python2.7/dist-packages/numpy/lib/arrayterator.py
        Return corresponding data.

        
        Return a new arrayterator.

        
        The shape of the array to be iterated over.

        For an example, see `Arrayterator`.

        total_pmt
    Returns the NPV (Net Present Value) of a cash flow series.

    Parameters
    ----------
    rate : scalar
        The discount rate.
    values : array_like, shape(M, )
        The values of the time series of cash flows.  The (fixed) time
        interval between cash flow "events" must be the same as that
        for which `rate` is given (i.e., if `rate` is per year, then
        precisely a year is understood to elapse between each cash flow
        event).  By convention, investments or "deposits" are negative,
        income or "withdrawals" are positive; `values` must begin with
        the initial investment, thus `values[0]` will typically be
        negative.

    Returns
    -------
    out : float
        The NPV of the input cash flow series `values` at the discount `rate`.

    Notes
    -----
    Returns the result of: [G]_

    .. math :: \sum_{t=0}^{M-1}{\frac{values_t}{(1+rate)^{t}}}

    References
    ----------
    .. [G] L. J. Gitman, "Principles of Managerial Finance, Brief," 3rd ed.,
       Addison-Wesley, 2003, pg. 346.

    Examples
    --------
    >>> np.npv(0.281,[-100, 39, 59, 55, 20])
    -0.0084785916384548798

    (Compare with the Example given for numpy.lib.financial.irr)

    Some simple financial calculations

patterned after spreadsheet computations.

There is some complexity in each function
so that the functions behave like ufuncs with
broadcasting and being able to be called with scalars
or arrays (or other sequences).


    Compute the present value.

    Given:
     * a future value, `fv`
     * an interest `rate` compounded once per period, of which
       there are
     * `nper` total
     * a (fixed) payment, `pmt`, paid either
     * at the beginning (`when` = {'begin', 1}) or the end
       (`when` = {'end', 0}) of each period

    Return:
       the value now

    Parameters
    ----------
    rate : array_like
        Rate of interest (per period)
    nper : array_like
        Number of compounding periods
    pmt : array_like
        Payment
    fv : array_like, optional
        Future value
    when : {{'begin', 1}, {'end', 0}}, {string, int}, optional
        When payments are due ('begin' (1) or 'end' (0))

    Returns
    -------
    out : ndarray, float
        Present value of a series of payments or investments.

    Notes
    -----
    The present value is computed by solving the equation::

     fv +
     pv*(1 + rate)**nper +
     pmt*(1 + rate*when)/rate*((1 + rate)**nper - 1) = 0

    or, when ``rate = 0``::

     fv + pv + pmt * nper = 0

    for `pv`, which is then returned.

    References
    ----------
    .. [WRW] Wheeler, D. A., E. Rathke, and R. Weir (Eds.) (2009, May).
       Open Document Format for Office Applications (OpenDocument)v1.2,
       Part 2: Recalculated Formula (OpenFormula) Format - Annotated Version,
       Pre-Draft 12. Organization for the Advancement of Structured Information
       Standards (OASIS). Billerica, MA, USA. [ODT Document].
       Available:
       http://www.oasis-open.org/committees/documents.php?wg_abbrev=office-formula
       OpenDocument-formula-20090508.odt

    Examples
    --------
    What is the present value (e.g., the initial investment)
    of an investment that needs to total $15692.93
    after 10 years of saving $100 every month?  Assume the
    interest rate is 5% (annually) compounded monthly.

    >>> np.pv(0.05/12, 10*12, -100, 15692.93)
    -100.00067131625819

    By convention, the negative sign represents cash flow out
    (i.e., money not available today).  Thus, to end up with
    $15,692.93 in 10 years saving $100 a month at 5% annual
    interest, one's initial deposit should also be $100.

    If any input is array_like, ``pv`` returns an array of equal shape.
    Let's compare different interest rates in the example above:

    >>> a = np.array((0.05, 0.04, 0.03))/12
    >>> np.pv(a, 10*12, -100, 15692.93)
    array([ -100.00067132,  -649.26771385, -1273.78633713])

    So, to end up with the same $15692.93 under the same $100 per month
    "savings plan," for annual interest rates of 4% and 3%, one would
    need initial investments of $649.27 and $1273.79, respectively.

    
    Modified internal rate of return.

    Parameters
    ----------
    values : array_like
        Cash flows (must contain at least one positive and one negative value)
        or nan is returned.  The first value is considered a sunk cost at time zero.
    finance_rate : scalar
        Interest rate paid on the cash flows
    reinvest_rate : scalar
        Interest rate received on the cash flows upon reinvestment

    Returns
    -------
    out : float
        Modified internal rate of return

    
    Compute the number of periodic payments.

    Parameters
    ----------
    rate : array_like
        Rate of interest (per period)
    pmt : array_like
        Payment
    pv : array_like
        Present value
    fv : array_like, optional
        Future value
    when : {{'begin', 1}, {'end', 0}}, {string, int}, optional
        When payments are due ('begin' (1) or 'end' (0))

    Notes
    -----
    The number of periods ``nper`` is computed by solving the equation::

     fv + pv*(1+rate)**nper + pmt*(1+rate*when)/rate*((1+rate)**nper-1) = 0

    but if ``rate = 0`` then::

     fv + pv + pmt*nper = 0

    Examples
    --------
    If you only had $150/month to pay towards the loan, how long would it take
    to pay-off a loan of $8,000 at 7% annual interest?

    >>> print round(np.nper(0.07/12, -150, 8000), 5)
    64.07335

    So, over 64 months would be required to pay off the loan.

    The same analysis could be done with several different interest rates
    and/or payments and/or total amounts to produce an entire table.

    >>> np.nper(*(np.ogrid[0.07/12: 0.08/12: 0.01/12,
    ...                    -150   : -99     : 50    ,
    ...                    8000   : 9001    : 1000]))
    array([[[  64.07334877,   74.06368256],
            [ 108.07548412,  127.99022654]],
           [[  66.12443902,   76.87897353],
            [ 114.70165583,  137.90124779]]])

    
    Compute the future value.

    Given:
     * a present value, `pv`
     * an interest `rate` compounded once per period, of which
       there are
     * `nper` total
     * a (fixed) payment, `pmt`, paid either
     * at the beginning (`when` = {'begin', 1}) or the end
       (`when` = {'end', 0}) of each period

    Return:
       the value at the end of the `nper` periods

    Parameters
    ----------
    rate : scalar or array_like of shape(M, )
        Rate of interest as decimal (not per cent) per period
    nper : scalar or array_like of shape(M, )
        Number of compounding periods
    pmt : scalar or array_like of shape(M, )
        Payment
    pv : scalar or array_like of shape(M, )
        Present value
    when : {{'begin', 1}, {'end', 0}}, {string, int}, optional
        When payments are due ('begin' (1) or 'end' (0)).
        Defaults to {'end', 0}.

    Returns
    -------
    out : ndarray
        Future values.  If all input is scalar, returns a scalar float.  If
        any input is array_like, returns future values for each input element.
        If multiple inputs are array_like, they all must have the same shape.

    Notes
    -----
    The future value is computed by solving the equation::

     fv +
     pv*(1+rate)**nper +
     pmt*(1 + rate*when)/rate*((1 + rate)**nper - 1) == 0

    or, when ``rate == 0``::

     fv + pv + pmt * nper == 0

    References
    ----------
    .. [WRW] Wheeler, D. A., E. Rathke, and R. Weir (Eds.) (2009, May).
       Open Document Format for Office Applications (OpenDocument)v1.2,
       Part 2: Recalculated Formula (OpenFormula) Format - Annotated Version,
       Pre-Draft 12. Organization for the Advancement of Structured Information
       Standards (OASIS). Billerica, MA, USA. [ODT Document].
       Available:
       http://www.oasis-open.org/committees/documents.php?wg_abbrev=office-formula
       OpenDocument-formula-20090508.odt

    Examples
    --------
    What is the future value after 10 years of saving $100 now, with
    an additional monthly savings of $100.  Assume the interest rate is
    5% (annually) compounded monthly?

    >>> np.fv(0.05/12, 10*12, -100, -100)
    15692.928894335748

    By convention, the negative sign represents cash flow out (i.e. money not
    available today).  Thus, saving $100 a month at 5% annual interest leads
    to $15,692.93 available to spend in 10 years.

    If any input is array_like, returns an array of equal shape.  Let's
    compare different interest rates from the example above.

    >>> a = np.array((0.05, 0.06, 0.07))/12
    >>> np.fv(a, 10*12, -100, -100)
    array([ 15692.92889434,  16569.87435405,  17509.44688102])

    
    Return the Internal Rate of Return (IRR).

    This is the "average" periodically compounded rate of return
    that gives a net present value of 0.0; for a more complete explanation,
    see Notes below.

    Parameters
    ----------
    values : array_like, shape(N,)
        Input cash flows per time period.  By convention, net "deposits"
        are negative and net "withdrawals" are positive.  Thus, for example,
        at least the first element of `values`, which represents the initial
        investment, will typically be negative.

    Returns
    -------
    out : float
        Internal Rate of Return for periodic input values.

    Notes
    -----
    The IRR is perhaps best understood through an example (illustrated
    using np.irr in the Examples section below).  Suppose one invests
    100 units and then makes the following withdrawals at regular
    (fixed) intervals: 39, 59, 55, 20.  Assuming the ending value is 0,
    one's 100 unit investment yields 173 units; however, due to the
    combination of compounding and the periodic withdrawals, the
    "average" rate of return is neither simply 0.73/4 nor (1.73)^0.25-1.
    Rather, it is the solution (for :math:`r`) of the equation:

    .. math:: -100 + \frac{39}{1+r} + \frac{59}{(1+r)^2}
     + \frac{55}{(1+r)^3} + \frac{20}{(1+r)^4} = 0

    In general, for `values` :math:`= [v_0, v_1, ... v_M]`,
    irr is the solution of the equation: [G]_

    .. math:: \sum_{t=0}^M{\frac{v_t}{(1+irr)^{t}}} = 0

    References
    ----------
    .. [G] L. J. Gitman, "Principles of Managerial Finance, Brief," 3rd ed.,
       Addison-Wesley, 2003, pg. 348.

    Examples
    --------
    >>> round(irr([-100, 39, 59, 55, 20]), 5)
    0.28095
    >>> round(irr([-100, 0, 0, 74]), 5)
    -0.0955
    >>> round(irr([-100, 100, 0, -7]), 5)
    -0.0833
    >>> round(irr([-100, 100, 0, 7]), 5)
    0.06206
    >>> round(irr([-5, 10.5, 1, -8, 1]), 5)
    0.0886

    (Compare with the Example given for numpy.lib.financial.npv)

    
    Compute the rate of interest per period.

    Parameters
    ----------
    nper : array_like
        Number of compounding periods
    pmt : array_like
        Payment
    pv : array_like
        Present value
    fv : array_like
        Future value
    when : {{'begin', 1}, {'end', 0}}, {string, int}, optional
        When payments are due ('begin' (1) or 'end' (0))
    guess : float, optional
        Starting guess for solving the rate of interest
    tol : float, optional
        Required tolerance for the solution
    maxiter : int, optional
        Maximum iterations in finding the solution

    Notes
    -----
    The rate of interest is computed by iteratively solving the
    (non-linear) equation::

     fv + pv*(1+rate)**nper + pmt*(1+rate*when)/rate * ((1+rate)**nper - 1) = 0

    for ``rate``.

    References
    ----------
    Wheeler, D. A., E. Rathke, and R. Weir (Eds.) (2009, May). Open Document
    Format for Office Applications (OpenDocument)v1.2, Part 2: Recalculated
    Formula (OpenFormula) Format - Annotated Version, Pre-Draft 12.
    Organization for the Advancement of Structured Information Standards
    (OASIS). Billerica, MA, USA. [ODT Document]. Available:
    http://www.oasis-open.org/committees/documents.php?wg_abbrev=office-formula
    OpenDocument-formula-20090508.odt

    
    This function is here to simply have a different name for the 'fv'
    function to not interfere with the 'fv' keyword argument within the 'ipmt'
    function.  It is the 'remaining balance on loan' which might be useful as
    it's own function, but is easily calculated with the 'fv' function.
    
    Compute the payment against loan principal.

    Parameters
    ----------
    rate : array_like
        Rate of interest (per period)
    per : array_like, int
        Amount paid against the loan changes.  The `per` is the period of
        interest.
    nper : array_like
        Number of compounding periods
    pv : array_like
        Present value
    fv : array_like, optional
        Future value
    when : {{'begin', 1}, {'end', 0}}, {string, int}
        When payments are due ('begin' (1) or 'end' (0))

    See Also
    --------
    pmt, pv, ipmt

    
    Compute the interest portion of a payment.

    Parameters
    ----------
    rate : scalar or array_like of shape(M, )
        Rate of interest as decimal (not per cent) per period
    per : scalar or array_like of shape(M, )
        Interest paid against the loan changes during the life or the loan.
        The `per` is the payment period to calculate the interest amount.
    nper : scalar or array_like of shape(M, )
        Number of compounding periods
    pv : scalar or array_like of shape(M, )
        Present value
    fv : scalar or array_like of shape(M, ), optional
        Future value
    when : {{'begin', 1}, {'end', 0}}, {string, int}, optional
        When payments are due ('begin' (1) or 'end' (0)).
        Defaults to {'end', 0}.

    Returns
    -------
    out : ndarray
        Interest portion of payment.  If all input is scalar, returns a scalar
        float.  If any input is array_like, returns interest payment for each
        input element. If multiple inputs are array_like, they all must have
        the same shape.

    See Also
    --------
    ppmt, pmt, pv

    Notes
    -----
    The total payment is made up of payment against principal plus interest.

    ``pmt = ppmt + ipmt``

    Examples
    --------
    What is the amortization schedule for a 1 year loan of $2500 at
    8.24% interest per year compounded monthly?

    >>> principal = 2500.00

    The 'per' variable represents the periods of the loan.  Remember that
    financial equations start the period count at 1!

    >>> per = np.arange(1*12) + 1
    >>> ipmt = np.ipmt(0.0824/12, per, 1*12, principal)
    >>> ppmt = np.ppmt(0.0824/12, per, 1*12, principal)

    Each element of the sum of the 'ipmt' and 'ppmt' arrays should equal
    'pmt'.

    >>> pmt = np.pmt(0.0824/12, 1*12, principal)
    >>> np.allclose(ipmt + ppmt, pmt)
    True

    >>> fmt = '{0:2d} {1:8.2f} {2:8.2f} {3:8.2f}'
    >>> for payment in per:
    ...     index = payment - 1
    ...     principal = principal + ppmt[index]
    ...     print fmt.format(payment, ppmt[index], ipmt[index], principal)
     1  -200.58   -17.17  2299.42
     2  -201.96   -15.79  2097.46
     3  -203.35   -14.40  1894.11
     4  -204.74   -13.01  1689.37
     5  -206.15   -11.60  1483.22
     6  -207.56   -10.18  1275.66
     7  -208.99    -8.76  1066.67
     8  -210.42    -7.32   856.25
     9  -211.87    -5.88   644.38
    10  -213.32    -4.42   431.05
    11  -214.79    -2.96   216.26
    12  -216.26    -1.49    -0.00

    >>> interestpd = np.sum(ipmt)
    >>> np.round(interestpd, 2)
    -112.98

    
    Compute the payment against loan principal plus interest.

    Given:
     * a present value, `pv` (e.g., an amount borrowed)
     * a future value, `fv` (e.g., 0)
     * an interest `rate` compounded once per period, of which
       there are
     * `nper` total
     * and (optional) specification of whether payment is made
       at the beginning (`when` = {'begin', 1}) or the end
       (`when` = {'end', 0}) of each period

    Return:
       the (fixed) periodic payment.

    Parameters
    ----------
    rate : array_like
        Rate of interest (per period)
    nper : array_like
        Number of compounding periods
    pv : array_like
        Present value
    fv : array_like (optional)
        Future value (default = 0)
    when : {{'begin', 1}, {'end', 0}}, {string, int}
        When payments are due ('begin' (1) or 'end' (0))

    Returns
    -------
    out : ndarray
        Payment against loan plus interest.  If all input is scalar, returns a
        scalar float.  If any input is array_like, returns payment for each
        input element. If multiple inputs are array_like, they all must have
        the same shape.

    Notes
    -----
    The payment is computed by solving the equation::

     fv +
     pv*(1 + rate)**nper +
     pmt*(1 + rate*when)/rate*((1 + rate)**nper - 1) == 0

    or, when ``rate == 0``::

      fv + pv + pmt * nper == 0

    for ``pmt``.

    Note that computing a monthly mortgage payment is only
    one use for this function.  For example, pmt returns the
    periodic deposit one must make to achieve a specified
    future balance given an initial deposit, a fixed,
    periodically compounded interest rate, and the total
    number of periods.

    References
    ----------
    .. [WRW] Wheeler, D. A., E. Rathke, and R. Weir (Eds.) (2009, May).
       Open Document Format for Office Applications (OpenDocument)v1.2,
       Part 2: Recalculated Formula (OpenFormula) Format - Annotated Version,
       Pre-Draft 12. Organization for the Advancement of Structured Information
       Standards (OASIS). Billerica, MA, USA. [ODT Document].
       Available:
       http://www.oasis-open.org/committees/documents.php
       ?wg_abbrev=office-formulaOpenDocument-formula-20090508.odt

    Examples
    --------
    What is the monthly payment needed to pay off a $200,000 loan in 15
    years at an annual interest rate of 7.5%?

    >>> np.pmt(0.075/12, 12*15, 200000)
    -1854.0247200054619

    In order to pay-off (i.e., have a future-value of 0) the $200,000 obtained
    today, a monthly payment of $1,854.02 would be required.  Note that this
    example illustrates usage of `fv` having a default value of 0.

    /usr/lib/python2.7/dist-packages/numpy/lib/financial.pytopadmagic_strread_sizehlength_strheader_lengthheader_len_strBlockingIOErrorcurrent_header_lenonly support version (1,0) of file format, not %r
    Read an array header from a filelike object using the 1.0 file format
    version.

    This will leave the file object located just after the header.

    Parameters
    ----------
    fp : filelike object
        A file object or something with a `.read()` method like a file.

    Returns
    -------
    shape : tuple of int
        The shape of the array.
    fortran_order : bool
        The array data will be written out directly if it is either C-contiguous
        or Fortran-contiguous. Otherwise, it will be made contiguous before
        writing it out.
    dtype : dtype
        The dtype of the file's data.

    Raises
    ------
    ValueError
        If the data is invalid.

    Filename must be a string.  Memmap cannot use existing file handles.'%s': %s,  Read the magic string to get the version of the file format.

    Parameters
    ----------
    fp : filelike object

    Returns
    -------
    major : int
    minor : int
    numpy.lib.formatNUMPYHeader is not a dictionary: %rfortran_order is not a valid bool: %r Get the dictionary of header metadata from a numpy.ndarray.

    Parameters
    ----------
    array : numpy.ndarray

    Returns
    -------
    d : dict
        This has the appropriate entries for writing its string representation
        to the header of the file.
    descr is not a valid dtype descriptor: %r
    Read from file-like object until size bytes are read.
    Raises ValueError if not EOF is encountered before size bytes are read.
    Non-blocking objects only supported if they derive from io objects.

    Required as e.g. ZipExtFile in python 2.6 can return less data than
    requested.
    we only support format version (1,0), not %sEOF: reading %s, expected %d bytes got %d
    Read an array from an NPY file.

    Parameters
    ----------
    fp : file_like object
        If this is not a real file object, then this may take extra memory
        and time.

    Returns
    -------
    array : ndarray
        The array from the data on disk.

    Raises
    ------
    ValueError
        If the data is invalid.

    Cannot parse header: %r
Exception: %rran out of dataArray can't be memory-mapped: Python objects in dtype.minor version must be 0 <= minor < 256
    Open a .npy file as a memory-mapped array.

    This may be used to read an existing file or create a new one.

    Parameters
    ----------
    filename : str
        The name of the file on disk.  This may *not* be a file-like
        object.
    mode : str, optional
        The mode in which to open the file; the default is 'r+'.  In
        addition to the standard file modes, 'c' is also accepted to
        mean "copy on write."  See `memmap` for the available mode strings.
    dtype : data-type, optional
        The data type of the array if we are creating a new file in "write"
        mode, if not, `dtype` is ignored.  The default value is None,
        which results in a data-type of `float64`.
    shape : tuple of int
        The shape of the array if we are creating a new file in "write"
        mode, in which case this parameter is required.  Otherwise, this
        parameter is ignored and is thus optional.
    fortran_order : bool, optional
        Whether the array should be Fortran-contiguous (True) or
        C-contiguous (False, the default) if we are creating a new file
        in "write" mode.
    version : tuple of int (major, minor)
        If the mode is a "write" mode, then this is the version of the file
        format used to create the file.  Default: (1,0)

    Returns
    -------
    marray : memmap
        The memory-mapped array.

    Raises
    ------
    ValueError
        If the data or the mode is invalid.
    IOError
        If the file is not found or cannot be opened correctly.

    See Also
    --------
    memmap

    /usr/lib/python2.7/dist-packages/numpy/lib/format.pythe magic string is not correct; expected %r, got %rHeader does not contain the correct keys: %rmajor version must be 0 <= major < 256<H
Define a simple format for saving numpy arrays to disk with the full
information about them.

The ``.npy`` format is the standard binary file format in NumPy for
persisting a *single* arbitrary NumPy array on disk. The format stores all
of the shape and dtype information necessary to reconstruct the array
correctly even on another machine with a different architecture.
The format is designed to be as simple as possible while achieving
its limited goals.

The ``.npz`` format is the standard format for persisting *multiple* NumPy
arrays on disk. A ``.npz`` file is a zip file containing multiple ``.npy``
files, one for each array.

Capabilities
------------

- Can represent all NumPy arrays including nested record arrays and
  object arrays.

- Represents the data in its native binary form.

- Supports Fortran-contiguous arrays directly.

- Stores all of the necessary information to reconstruct the array
  including shape and dtype on a machine of a different
  architecture.  Both little-endian and big-endian arrays are
  supported, and a file with little-endian numbers will yield
  a little-endian array on any machine reading the file. The
  types are described in terms of their actual sizes. For example,
  if a machine with a 64-bit C "long int" writes out an array with
  "long ints", a reading machine with 32-bit C "long ints" will yield
  an array with 64-bit integers.

- Is straightforward to reverse engineer. Datasets often live longer than
  the programs that created them. A competent developer should be
  able to create a solution in his preferred programming language to
  read most ``.npy`` files that he has been given without much
  documentation.

- Allows memory-mapping of the data. See `open_memmep`.

- Can be read from a filelike stream object instead of an actual file.

- Stores object arrays, i.e. arrays containing elements that are arbitrary
  Python objects. Files with object arrays are not to be mmapable, but
  can be read and written to disk.

Limitations
-----------

- Arbitrary subclasses of numpy.ndarray are not completely preserved.
  Subclasses will be accepted for writing, but only the array data will
  be written out. A regular numpy.ndarray object will be created
  upon reading the file.

.. warning::

  Due to limitations in the interpretation of structured dtypes, dtypes
  with fields with empty names will have the names replaced by 'f0', 'f1',
  etc. Such arrays will not round-trip through the format entirely
  accurately. The data is intact; only the field names will differ. We are
  working on a fix for this. This fix will not require a change in the
  file format. The arrays with such structures can still be saved and
  restored, and the correct dtype may be restored by using the
  ``loadedarray.view(correct_dtype)`` method.

File extensions
---------------

We recommend using the ``.npy`` and ``.npz`` extensions for files saved
in this format. This is by no means a requirement; applications may wish
to use these file formats but use an extension specific to the
application. In the absence of an obvious alternative, however,
we suggest using ``.npy`` and ``.npz``.

Version numbering
-----------------

The version numbering of these formats is independent of NumPy version
numbering. If the format is upgraded, the code in `numpy.io` will still
be able to read and write Version 1.0 files.

Format Version 1.0
------------------

The first 6 bytes are a magic string: exactly ``\x93NUMPY``.

The next 1 byte is an unsigned byte: the major version number of the file
format, e.g. ``\x01``.

The next 1 byte is an unsigned byte: the minor version number of the file
format, e.g. ``\x00``. Note: the version of the file format is not tied
to the version of the numpy package.

The next 2 bytes form a little-endian unsigned short int: the length of
the header data HEADER_LEN.

The next HEADER_LEN bytes form the header data describing the array's
format. It is an ASCII string which contains a Python literal expression
of a dictionary. It is terminated by a newline (``\n``) and padded with
spaces (``\x20``) to make the total length of
``magic string + 4 + HEADER_LEN`` be evenly divisible by 16 for alignment
purposes.

The dictionary contains three keys:

    "descr" : dtype.descr
      An object that can be passed as an argument to the `numpy.dtype`
      constructor to create the array's dtype.
    "fortran_order" : bool
      Whether the array data is Fortran-contiguous or not. Since
      Fortran-contiguous arrays are a common form of non-C-contiguity,
      we allow them to be written directly to disk for efficiency.
    "shape" : tuple of int
      The shape of the array.

For repeatability and readability, the dictionary keys are sorted in
alphabetic order. This is for convenience only. A writer SHOULD implement
this if possible. A reader MUST NOT depend on this.

Following the header comes the array data. If the dtype contains Python
objects (i.e. ``dtype.hasobject is True``), then the data is a Python
pickle of the array. Otherwise the data is the contiguous (either C-
or Fortran-, depending on ``fortran_order``) bytes of the array.
Consumers can figure out the number of bytes by multiplying the number
of elements given by the shape (noting that ``shape=()`` means there is
1 element) by ``dtype.itemsize``.

Notes
-----
The ``.npy`` format, including reasons for creating it and a comparison of
alternatives, is described fully in the "npy-format" NEP.


    Get a serializable descriptor from the dtype.

    The .descr attribute of a dtype object cannot be round-tripped through
    the dtype() constructor. Simple types, like dtype('float32'), have
    a descr which looks like a record array with one field with '' as
    a name. The dtype() constructor interprets this as a request to give
    a default name.  Instead, we construct descriptor that can be passed to
    dtype().

    Parameters
    ----------
    dtype : dtype
        The dtype of the array that will be written to disk.

    Returns
    -------
    descr : object
        An object that can be passed to `numpy.dtype()` in order to
        replicate the input dtype.

     Write the header for an array using the 1.0 format.

    Parameters
    ----------
    fp : filelike object
    d : dict
        This has the appropriate entries for writing its string representation
        to the header of the file.
    shape is not valid: %r
    Write an array to an NPY file, including a header.

    If the array is neither C-contiguous nor Fortran-contiguous AND the
    file_like object is not a real file object, this function will have to
    copy data in memory.

    Parameters
    ----------
    fp : file_like object
        An open, writable file object, or similar object with a ``.write()``
        method.
    array : ndarray
        The array to write to disk.
    version : (int, int), optional
        The version number of the format.  Default: (1, 0)

    Raises
    ------
    ValueError
        If the array cannot be persisted.
    Various other errors
        If the array contains Python objects as part of its dtype, the
        process of pickling them may raise various errors if the objects
        are not picklable.

     Return the magic string for the given file format version.

    Parameters
    ----------
    major : int in [0, 255]
    minor : int in [0, 255]

    Returns
    -------
    magic : str

    Raises
    ------
    ValueError if the version cannot be formatted.
    header does not fit inside 65536 bytesarray header length       @{Gz?zG?q=
p?HzG?      @@NxqiszhwgtbhBHddmodmsorttmp_wzimagzrealkaiserslobj2sumvalunwraphamminghanningindexermindiffon_edgebartlettblackmanold_maskbin_indexflatcountpiecewiseph_correctinside_boundssorting_index_vectorize_callpositive_indices_get_ufunc_and_otypesnot_smaller_than_edge[   gT`g0fFVg!<gA`<g`g8g}<g*<gbe~g2h]'gE_V=gsk[=g&GCi=gfCg{~5g%t9QgO $=guo >g["d,->gmVX>gna>g+A>gRx?gIk?g	b?[   g4!\Tg}b3<grg^<g"P
g'&&KF5=gbLag$/=gjzg<t=gVg4T&>g0Kg5dMv;p>g"cg$>g'dogY(X?>gZY&+g|t(?gRBguZ?gI ^qga?g!Ng->?g-4pKgw?gWg*5N?[)   s   selects	   piecewises
   trim_zeross   copys   iterables
   percentiles   diffs   gradients   angles   unwraps   sort_complexs   disps   extracts   places	   vectorizes   asarray_chkfinites   averages	   histograms   histogramdds   bincounts   digitizes   covs   corrcoefs   msorts   medians   sincs   hammings   hannings   bartletts   blackmans   kaisers   trapzs   i0s
   add_newdocs   add_docstrings   meshgrids   deletes   inserts   appends   interps   add_newdoc_ufunc
    Return the gradient of an N-dimensional array.

    The gradient is computed using central differences in the interior
    and first differences at the boundaries. The returned gradient hence has
    the same shape as the input array.

    Parameters
    ----------
    f : array_like
      An N-dimensional array containing samples of a scalar function.
    `*varargs` : scalars
      0, 1, or N scalars specifying the sample distances in each direction,
      that is: `dx`, `dy`, `dz`, ... The default distance is 1.


    Returns
    -------
    gradient : ndarray
      N arrays of the same shape as `f` giving the derivative of `f` with
      respect to each dimension.

    Examples
    --------
    >>> x = np.array([1, 2, 4, 7, 11, 16], dtype=np.float)
    >>> np.gradient(x)
    array([ 1. ,  1.5,  2.5,  3.5,  4.5,  5. ])
    >>> np.gradient(x, 2)
    array([ 0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])

    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=np.float))
    [array([[ 2.,  2., -1.],
           [ 2.,  2., -1.]]),
    array([[ 1. ,  2.5,  4. ],
           [ 1. ,  1. ,  1. ]])]

    in the future the special handling of scalars will be removed from delete and raise an error
    Return correlation coefficients.

    Please refer to the documentation for `cov` for more detail.  The
    relationship between the correlation coefficient matrix, `P`, and the
    covariance matrix, `C`, is

    .. math:: P_{ij} = \frac{ C_{ij} } { \sqrt{ C_{ii} * C_{jj} } }

    The values of `P` are between -1 and 1, inclusive.

    Parameters
    ----------
    x : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `m` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        shape as `m`.
    rowvar : int, optional
        If `rowvar` is non-zero (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : int, optional
        Default normalization is by ``(N - 1)``, where ``N`` is the number of
        observations (unbiased estimate). If `bias` is 1, then
        normalization is by ``N``. These values can be overridden by using
        the keyword ``ddof`` in numpy versions >= 1.5.
    ddof : {None, int}, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.

    Returns
    -------
    out : ndarray
        The correlation coefficient matrix of the variables.

    See Also
    --------
    cov : Covariance matrix

    ddof must be integerValid values for `indexing` are 'xy' and 'ij'.Invalid otype specification
    Compute the multidimensional histogram of some data.

    Parameters
    ----------
    sample : array_like
        The data to be histogrammed. It must be an (N,D) array or data
        that can be converted to such. The rows of the resulting array
        are the coordinates of points in a D dimensional polytope.
    bins : sequence or int, optional
        The bin specification:

        * A sequence of arrays describing the bin edges along each dimension.
        * The number of bins for each dimension (nx, ny, ... =bins)
        * The number of bins for all dimensions (nx=ny=...=bins).

    range : sequence, optional
        A sequence of lower and upper bin edges to be used if the edges are
        not given explicitly in `bins`. Defaults to the minimum and maximum
        values along each dimension.
    normed : bool, optional
        If False, returns the number of samples in each bin. If True,
        returns the bin density ``bin_count / sample_count / bin_volume``.
    weights : array_like (N,), optional
        An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.
        Weights are normalized to 1 if normed is True. If normed is False,
        the values of the returned histogram are equal to the sum of the
        weights belonging to the samples falling into each bin.

    Returns
    -------
    H : ndarray
        The multidimensional histogram of sample x. See normed and weights
        for the different possible semantics.
    edges : list
        A list of D arrays describing the bin edges for each dimension.

    See Also
    --------
    histogram: 1-D histogram
    histogram2d: 2-D histogram

    Examples
    --------
    >>> r = np.random.randn(100,3)
    >>> H, edges = np.histogramdd(r, bins = (5, 8, 4))
    >>> H.shape, edges[0].size, edges[1].size, edges[2].size
    ((5, 8, 4), 6, 9, 5)

    
        Return arrays with the results of `pyfunc` broadcast (vectorized) over
        `args` and `kwargs` not in `excluded`.
        
    Return the elements of an array that satisfy some condition.

    This is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If
    `condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.

    Parameters
    ----------
    condition : array_like
        An array whose nonzero or True entries indicate the elements of `arr`
        to extract.
    arr : array_like
        Input array of the same size as `condition`.

    Returns
    -------
    extract : ndarray
        Rank 1 array of values from `arr` where `condition` is True.

    See Also
    --------
    take, put, copyto, compress

    Examples
    --------
    >>> arr = np.arange(12).reshape((3, 4))
    >>> arr
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11]])
    >>> condition = np.mod(arr, 3)==0
    >>> condition
    array([[ True, False, False,  True],
           [False, False,  True, False],
           [False,  True, False, False]], dtype=bool)
    >>> np.extract(condition, arr)
    array([0, 3, 6, 9])


    If `condition` is boolean:

    >>> arr[condition]
    array([0, 3, 6, 9])

    1D weights expected when shapes of a and weights differ.
    Integrate along the given axis using the composite trapezoidal rule.

    Integrate `y` (`x`) along given axis.

    Parameters
    ----------
    y : array_like
        Input array to integrate.
    x : array_like, optional
        If `x` is None, then spacing between all `y` elements is `dx`.
    dx : scalar, optional
        If `x` is None, spacing given by `dx` is assumed. Default is 1.
    axis : int, optional
        Specify the axis.

    Returns
    -------
    trapz : float
        Definite integral as approximated by trapezoidal rule.

    See Also
    --------
    sum, cumsum

    Notes
    -----
    Image [2]_ illustrates trapezoidal rule -- y-axis locations of points
    will be taken from `y` array, by default x-axis distances between
    points will be 1.0, alternatively they can be provided with `x` array
    or with `dx` scalar.  Return value will be equal to combined area under
    the red lines.


    References
    ----------
    .. [1] Wikipedia page: http://en.wikipedia.org/wiki/Trapezoidal_rule

    .. [2] Illustration image:
           http://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png

    Examples
    --------
    >>> np.trapz([1,2,3])
    4.0
    >>> np.trapz([1,2,3], x=[4,6,8])
    8.0
    >>> np.trapz([1,2,3], dx=2)
    8.0
    >>> a = np.arange(6).reshape(2, 3)
    >>> a
    array([[0, 1, 2],
           [3, 4, 5]])
    >>> np.trapz(a, axis=0)
    array([ 1.5,  2.5,  3.5])
    >>> np.trapz(a, axis=1)
    array([ 2.,  8.])

    index %i is out of bounds for axis %i with size %iin the future the special handling of scalars will be removed from insert and raise an errorweights should have the same shape as a.
    Calculate the n-th order discrete difference along given axis.

    The first order difference is given by ``out[n] = a[n+1] - a[n]`` along
    the given axis, higher order differences are calculated by using `diff`
    recursively.

    Parameters
    ----------
    a : array_like
        Input array
    n : int, optional
        The number of times values are differenced.
    axis : int, optional
        The axis along which the difference is taken, default is the last axis.

    Returns
    -------
    diff : ndarray
        The `n` order differences. The shape of the output is the same as `a`
        except along `axis` where the dimension is smaller by `n`.

    See Also
    --------
    gradient, ediff1d, cumsum

    Examples
    --------
    >>> x = np.array([1, 2, 4, 7, 0])
    >>> np.diff(x)
    array([ 1,  2,  3, -7])
    >>> np.diff(x, n=2)
    array([  1,   1, -10])

    >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])
    >>> np.diff(x)
    array([[2, 3, 4],
           [5, 1, 2]])
    >>> np.diff(x, axis=0)
    array([[-1,  2,  0, -2]])

    Vectorized call to `func` over positional `args`.
    Evaluate a piecewise-defined function.

    Given a set of conditions and corresponding functions, evaluate each
    function on the input data wherever its condition is true.

    Parameters
    ----------
    x : ndarray
        The input domain.
    condlist : list of bool arrays
        Each boolean array corresponds to a function in `funclist`.  Wherever
        `condlist[i]` is True, `funclist[i](x)` is used as the output value.

        Each boolean array in `condlist` selects a piece of `x`,
        and should therefore be of the same shape as `x`.

        The length of `condlist` must correspond to that of `funclist`.
        If one extra function is given, i.e. if
        ``len(funclist) - len(condlist) == 1``, then that extra function
        is the default value, used wherever all conditions are false.
    funclist : list of callables, f(x,*args,**kw), or scalars
        Each function is evaluated over `x` wherever its corresponding
        condition is True.  It should take an array as input and give an array
        or a scalar value as output.  If, instead of a callable,
        a scalar is provided then a constant function (``lambda x: scalar``) is
        assumed.
    args : tuple, optional
        Any further arguments given to `piecewise` are passed to the functions
        upon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then
        each function is called as ``f(x, 1, 'a')``.
    kw : dict, optional
        Keyword arguments used in calling `piecewise` are passed to the
        functions upon execution, i.e., if called
        ``piecewise(..., ..., lambda=1)``, then each function is called as
        ``f(x, lambda=1)``.

    Returns
    -------
    out : ndarray
        The output is the same shape and type as x and is found by
        calling the functions in `funclist` on the appropriate portions of `x`,
        as defined by the boolean arrays in `condlist`.  Portions not covered
        by any condition have undefined values.


    See Also
    --------
    choose, select, where

    Notes
    -----
    This is similar to choose or select, except that functions are
    evaluated on elements of `x` that satisfy the corresponding condition from
    `condlist`.

    The result is::

            |--
            |funclist[0](x[condlist[0]])
      out = |funclist[1](x[condlist[1]])
            |...
            |funclist[n2](x[condlist[n2]])
            |--

    Examples
    --------
    Define the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.

    >>> x = np.linspace(-2.5, 2.5, 6)
    >>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])
    array([-1., -1., -1.,  1.,  1.,  1.])

    Define the absolute value, which is ``-x`` for ``x <0`` and ``x`` for
    ``x >= 0``.

    >>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])
    array([ 2.5,  1.5,  0.5,  0.5,  1.5,  2.5])

    
    Convert the input to an array, checking for NaNs or Infs.

    Parameters
    ----------
    a : array_like
        Input data, in any form that can be converted to an array.  This
        includes lists, lists of tuples, tuples, tuples of tuples, tuples
        of lists and ndarrays.  Success requires no NaNs or Infs.
    dtype : data-type, optional
        By default, the data-type is inferred from the input data.
    order : {'C', 'F'}, optional
        Whether to use row-major ('C') or column-major ('FORTRAN') memory
        representation.  Defaults to 'C'.

    Returns
    -------
    out : ndarray
        Array interpretation of `a`.  No copy is performed if the input
        is already an ndarray.  If `a` is a subclass of ndarray, a base
        class ndarray is returned.

    Raises
    ------
    ValueError
        Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).

    See Also
    --------
    asarray : Create and array.
    asanyarray : Similar function which passes through subclasses.
    ascontiguousarray : Convert input to a contiguous array.
    asfarray : Convert input to a floating point ndarray.
    asfortranarray : Convert input to an ndarray with column-major
                     memory order.
    fromiter : Create an array from an iterator.
    fromfunction : Construct an array by executing a function on grid
                   positions.

    Examples
    --------
    Convert a list into an array.  If all elements are finite
    ``asarray_chkfinite`` is identical to ``asarray``.

    >>> a = [1, 2]
    >>> np.asarray_chkfinite(a, dtype=float)
    array([1., 2.])

    Raises ValueError if array_like contains Nans or Infs.

    >>> a = [1, 2, np.inf]
    >>> try:
    ...     np.asarray_chkfinite(a)
    ... except ValueError:
    ...     print 'ValueError'
    ...
    ValueError

    Axis must be specified when shapes of a and weights differ.The dimension of bins must be equal to the dimension of the sample x.in the future negative indices will not be ignored by `numpy.delete`.
    Compute the histogram of a set of data.

    Parameters
    ----------
    a : array_like
        Input data. The histogram is computed over the flattened array.
    bins : int or sequence of scalars, optional
        If `bins` is an int, it defines the number of equal-width
        bins in the given range (10, by default). If `bins` is a sequence,
        it defines the bin edges, including the rightmost edge, allowing
        for non-uniform bin widths.
    range : (float, float), optional
        The lower and upper range of the bins.  If not provided, range
        is simply ``(a.min(), a.max())``.  Values outside the range are
        ignored.
    normed : bool, optional
        This keyword is deprecated in Numpy 1.6 due to confusing/buggy
        behavior. It will be removed in Numpy 2.0. Use the density keyword
        instead.
        If False, the result will contain the number of samples
        in each bin.  If True, the result is the value of the
        probability *density* function at the bin, normalized such that
        the *integral* over the range is 1. Note that this latter behavior is
        known to be buggy with unequal bin widths; use `density` instead.
    weights : array_like, optional
        An array of weights, of the same shape as `a`.  Each value in `a`
        only contributes its associated weight towards the bin count
        (instead of 1).  If `normed` is True, the weights are normalized,
        so that the integral of the density over the range remains 1
    density : bool, optional
        If False, the result will contain the number of samples
        in each bin.  If True, the result is the value of the
        probability *density* function at the bin, normalized such that
        the *integral* over the range is 1. Note that the sum of the
        histogram values will not be equal to 1 unless bins of unity
        width are chosen; it is not a probability *mass* function.
        Overrides the `normed` keyword if given.

    Returns
    -------
    hist : array
        The values of the histogram. See `normed` and `weights` for a
        description of the possible semantics.
    bin_edges : array of dtype float
        Return the bin edges ``(length(hist)+1)``.


    See Also
    --------
    histogramdd, bincount, searchsorted, digitize

    Notes
    -----
    All but the last (righthand-most) bin is half-open.  In other words, if
    `bins` is::

      [1, 2, 3, 4]

    then the first bin is ``[1, 2)`` (including 1, but excluding 2) and the
    second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which *includes*
    4.

    Examples
    --------
    >>> np.histogram([1, 2, 1], bins=[0, 1, 2, 3])
    (array([0, 2, 1]), array([0, 1, 2, 3]))
    >>> np.histogram(np.arange(4), bins=np.arange(5), density=True)
    (array([ 0.25,  0.25,  0.25,  0.25]), array([0, 1, 2, 3, 4]))
    >>> np.histogram([[1, 2, 1], [1, 0, 1]], bins=[0,1,2,3])
    (array([1, 4, 1]), array([0, 1, 2, 3]))

    >>> a = np.arange(5)
    >>> hist, bin_edges = np.histogram(a, density=True)
    >>> hist
    array([ 0.5,  0. ,  0.5,  0. ,  0. ,  0.5,  0. ,  0.5,  0. ,  0.5])
    >>> hist.sum()
    2.4999999999999996
    >>> np.sum(hist*np.diff(bin_edges))
    1.0

    
    Return an array copy of the given object.

    Parameters
    ----------
    a : array_like
        Input data.
    order : {'C', 'F', 'A', 'K'}, optional
        Controls the memory layout of the copy. 'C' means C-order,
        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
        'C' otherwise. 'K' means match the layout of `a` as closely
        as possible. (Note that this function and :meth:ndarray.copy are very
        similar, but have different default values for their order=
        arguments.)

    Returns
    -------
    arr : ndarray
        Array interpretation of `a`.

    Notes
    -----
    This is equivalent to

    >>> np.array(a, copy=True)                              #doctest: +SKIP

    Examples
    --------
    Create an array x, with a reference y and a copy z:

    >>> x = np.array([1, 2, 3])
    >>> y = x
    >>> z = np.copy(x)

    Note that, when we modify x, y changes, but not z:

    >>> x[0] = 10
    >>> x[0] == y[0]
    True
    >>> x[0] == z[0]
    False

    
    Display a message on a device.

    Parameters
    ----------
    mesg : str
        Message to display.
    device : object
        Device to write message. If None, defaults to ``sys.stdout`` which is
        very similar to ``print``. `device` needs to have ``write()`` and
        ``flush()`` methods.
    linefeed : bool, optional
        Option whether to print a line feed or not. Defaults to True.

    Raises
    ------
    AttributeError
        If `device` does not have a ``write()`` or ``flush()`` method.

    Examples
    --------
    Besides ``sys.stdout``, a file-like object can also be used as it has
    both required methods:

    >>> from StringIO import StringIO
    >>> buf = StringIO()
    >>> np.disp('"Display" in a file', device=buf)
    >>> buf.getvalue()
    '"Display" in a file\n'

    /usr/lib/python2.7/dist-packages/numpy/lib/function_base.py`bins` should be a positive integer.
    Return a copy of an array sorted along the first axis.

    Parameters
    ----------
    a : array_like
        Array to be sorted.

    Returns
    -------
    sorted_array : ndarray
        Array of the same type and shape as `a`.

    See Also
    --------
    sort

    Notes
    -----
    ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.

    Invalid otype specified: %sElement at index %s in `bins` should be a positive integer.
    This function is deprecated.  Use numpy.lib.arraysetops.unique()
    instead.
    
    Estimate a covariance matrix, given data.

    Covariance indicates the level to which two variables vary together.
    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,
    then the covariance matrix element :math:`C_{ij}` is the covariance of
    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance
    of :math:`x_i`.

    Parameters
    ----------
    m : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `m` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        form as that of `m`.
    rowvar : int, optional
        If `rowvar` is non-zero (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : int, optional
        Default normalization is by ``(N - 1)``, where ``N`` is the number of
        observations given (unbiased estimate). If `bias` is 1, then
        normalization is by ``N``. These values can be overridden by using
        the keyword ``ddof`` in numpy versions >= 1.5.
    ddof : int, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.

    Returns
    -------
    out : ndarray
        The covariance matrix of the variables.

    See Also
    --------
    corrcoef : Normalized covariance matrix

    Examples
    --------
    Consider two variables, :math:`x_0` and :math:`x_1`, which
    correlate perfectly, but in opposite directions:

    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T
    >>> x
    array([[0, 1, 2],
           [2, 1, 0]])

    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance
    matrix shows this clearly:

    >>> np.cov(x)
    array([[ 1., -1.],
           [-1.,  1.]])

    Note that element :math:`C_{0,1}`, which shows the correlation between
    :math:`x_0` and :math:`x_1`, is negative.

    Further, note how `x` and `y` are combined:

    >>> x = [-2.1, -1,  4.3]
    >>> y = [3,  1.1,  0.12]
    >>> X = np.vstack((x,y))
    >>> print np.cov(X)
    [[ 11.71        -4.286     ]
     [ -4.286        2.14413333]]
    >>> print np.cov(x, y)
    [[ 11.71        -4.286     ]
     [ -4.286        2.14413333]]
    >>> print np.cov(x)
    11.71

    
    Compute the weighted average along the specified axis.

    Parameters
    ----------
    a : array_like
        Array containing data to be averaged. If `a` is not an array, a
        conversion is attempted.
    axis : int, optional
        Axis along which to average `a`. If `None`, averaging is done over
        the flattened array.
    weights : array_like, optional
        An array of weights associated with the values in `a`. Each value in
        `a` contributes to the average according to its associated weight.
        The weights array can either be 1-D (in which case its length must be
        the size of `a` along the given axis) or of the same shape as `a`.
        If `weights=None`, then all data in `a` are assumed to have a
        weight equal to one.
    returned : bool, optional
        Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
        is returned, otherwise only the average is returned.
        If `weights=None`, `sum_of_weights` is equivalent to the number of
        elements over which the average is taken.


    Returns
    -------
    average, [sum_of_weights] : {array_type, double}
        Return the average along the specified axis. When returned is `True`,
        return a tuple with the average as the first element and the sum
        of the weights as the second element. The return type is `Float`
        if `a` is of integer type, otherwise it is of the same type as `a`.
        `sum_of_weights` is of the same type as `average`.

    Raises
    ------
    ZeroDivisionError
        When all weights along axis are zero. See `numpy.ma.average` for a
        version robust to this type of error.
    TypeError
        When the length of 1D `weights` is not the same as the shape of `a`
        along axis.

    See Also
    --------
    mean

    ma.average : average for masked arrays -- useful if your data contains
                 "missing" values

    Examples
    --------
    >>> data = range(1,5)
    >>> data
    [1, 2, 3, 4]
    >>> np.average(data)
    2.5
    >>> np.average(range(1,11), weights=range(10,0,-1))
    4.0

    >>> data = np.arange(6).reshape((3,2))
    >>> data
    array([[0, 1],
           [2, 3],
           [4, 5]])
    >>> np.average(data, axis=1, weights=[1./4, 3./4])
    array([ 0.75,  2.75,  4.75])
    >>> np.average(data, weights=[1./4, 3./4])
    Traceback (most recent call last):
    ...
    TypeError: Axis must be specified when shapes of a and weights differ.

    index array argument obj to insert must be one dimensional or scalarpercentile must be either in the range [0,100]
    Return the Blackman window.

    The Blackman window is a taper formed by using the first three
    terms of a summation of cosines. It was designed to have close to the
    minimal leakage possible.  It is close to optimal, only slightly worse
    than a Kaiser window.

    Parameters
    ----------
    M : int
        Number of points in the output window. If zero or less, an empty
        array is returned.

    Returns
    -------
    out : ndarray
        The window, with the maximum value normalized to one (the value one
        appears only if the number of samples is odd).

    See Also
    --------
    bartlett, hamming, hanning, kaiser

    Notes
    -----
    The Blackman window is defined as

    .. math::  w(n) = 0.42 - 0.5 \cos(2\pi n/M) + 0.08 \cos(4\pi n/M)

    Most references to the Blackman window come from the signal processing
    literature, where it is used as one of many windowing functions for
    smoothing values.  It is also known as an apodization (which means
    "removing the foot", i.e. smoothing discontinuities at the beginning
    and end of the sampled signal) or tapering function. It is known as a
    "near optimal" tapering function, almost as good (by some measures)
    as the kaiser window.

    References
    ----------
    Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,
    Dover Publications, New York.

    Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.
    Upper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.

    Examples
    --------
    >>> np.blackman(12)
    array([ -1.38777878e-17,   3.26064346e-02,   1.59903635e-01,
             4.14397981e-01,   7.36045180e-01,   9.67046769e-01,
             9.67046769e-01,   7.36045180e-01,   4.14397981e-01,
             1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])


    Plot the window and the frequency response:

    >>> from numpy.fft import fft, fftshift
    >>> window = np.blackman(51)
    >>> plt.plot(window)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Blackman window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Sample")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    >>> plt.figure()
    <matplotlib.figure.Figure object at 0x...>
    >>> A = fft(window, 2048) / 25.5
    >>> mag = np.abs(fftshift(A))
    >>> freq = np.linspace(-0.5, 0.5, len(A))
    >>> response = 20 * np.log10(mag)
    >>> response = np.clip(response, -100, 100)
    >>> plt.plot(freq, response)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Frequency response of Blackman window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Magnitude [dB]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Normalized frequency [cycles per sample]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.axis('tight')
    (-0.5, 0.5, -100.0, ...)
    >>> plt.show()

    
    Append values to the end of an array.

    Parameters
    ----------
    arr : array_like
        Values are appended to a copy of this array.
    values : array_like
        These values are appended to a copy of `arr`.  It must be of the
        correct shape (the same shape as `arr`, excluding `axis`).  If
        `axis` is not specified, `values` can be any shape and will be
        flattened before use.
    axis : int, optional
        The axis along which `values` are appended.  If `axis` is not
        given, both `arr` and `values` are flattened before use.

    Returns
    -------
    append : ndarray
        A copy of `arr` with `values` appended to `axis`.  Note that
        `append` does not occur in-place: a new array is allocated and
        filled.  If `axis` is None, `out` is a flattened array.

    See Also
    --------
    insert : Insert elements into an array.
    delete : Delete elements from an array.

    Examples
    --------
    >>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])
    array([1, 2, 3, 4, 5, 6, 7, 8, 9])

    When `axis` is specified, `values` must have the correct shape.

    >>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)
    array([[1, 2, 3],
           [4, 5, 6],
           [7, 8, 9]])
    >>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)
    Traceback (most recent call last):
    ...
    ValueError: arrays must have same number of dimensions

    Weights sum to zero, can't be normalized
    Modified Bessel function of the first kind, order 0.

    Usually denoted :math:`I_0`.  This function does broadcast, but will *not*
    "up-cast" int dtype arguments unless accompanied by at least one float or
    complex dtype argument (see Raises below).

    Parameters
    ----------
    x : array_like, dtype float or complex
        Argument of the Bessel function.

    Returns
    -------
    out : ndarray, shape = x.shape, dtype = x.dtype
        The modified Bessel function evaluated at each of the elements of `x`.

    Raises
    ------
    TypeError: array cannot be safely cast to required type
        If argument consists exclusively of int dtypes.

    See Also
    --------
    scipy.special.iv, scipy.special.ive

    Notes
    -----
    We use the algorithm published by Clenshaw [1]_ and referenced by
    Abramowitz and Stegun [2]_, for which the function domain is
    partitioned into the two intervals [0,8] and (8,inf), and Chebyshev
    polynomial expansions are employed in each interval. Relative error on
    the domain [0,30] using IEEE arithmetic is documented [3]_ as having a
    peak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).

    References
    ----------
    .. [1] C. W. Clenshaw, "Chebyshev series for mathematical functions", in
           *National Physical Laboratory Mathematical Tables*, vol. 5, London:
           Her Majesty's Stationery Office, 1962.
    .. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical
           Functions*, 10th printing, New York: Dover, 1964, pp. 379.
           http://www.math.sfu.ca/~cbm/aands/page_379.htm
    .. [3] http://kobesearch.cpan.org/htdocs/Math-Cephes/Math/Cephes.html

    Examples
    --------
    >>> np.i0([0.])
    array(1.0)
    >>> np.i0([0., 1. + 2j])
    array([ 1.00000000+0.j        ,  0.18785373+0.64616944j])

    
            Found bin edge of size <= 0. Did you specify `bins` with
            non-monotonic sequence?
    Compute the qth percentile of the data along the specified axis.

    Returns the qth percentile of the array elements.

    Parameters
    ----------
    a : array_like
        Input array or object that can be converted to an array.
    q : float in range of [0,100] (or sequence of floats)
        Percentile to compute which must be between 0 and 100 inclusive.
    axis : int, optional
        Axis along which the percentiles are computed. The default (None)
        is to compute the median along a flattened version of the array.
    out : ndarray, optional
        Alternative output array in which to place the result. It must
        have the same shape and buffer length as the expected output,
        but the type (of the output) will be cast if necessary.
    overwrite_input : bool, optional
       If True, then allow use of memory of input array `a` for
       calculations. The input array will be modified by the call to
       median. This will save memory when you do not need to preserve
       the contents of the input array. Treat the input as undefined,
       but it will probably be fully or partially sorted.
       Default is False. Note that, if `overwrite_input` is True and the
       input is not already an array, an error will be raised.

    Returns
    -------
    percentile : scalar or ndarray
        If a single percentile `q` is given and axis=None a scalar is
        returned.  If multiple percentiles `q` are given an array holding
        the result is returned. The results are listed in the first axis.
        (If `out` is specified, in which case that array is returned
        instead).  If the input contains integers, or floats of smaller
        precision than 64, then the output data-type is float64. Otherwise,
        the output data-type is the same as that of the input.

    See Also
    --------
    mean, median

    Notes
    -----
    Given a vector V of length N, the q-th percentile of V is the q-th ranked
    value in a sorted copy of V.  The values and distances of the two
    nearest neighbors as well as the `interpolation` parameter will
    determine the percentile if the normalized ranking does not match q
    exactly. This function is the same as the median if ``q=50``, the same
    as the minimum if ``q=0``and the same as the maximum if ``q=100``.

    Examples
    --------
    >>> a = np.array([[10, 7, 4], [3, 2, 1]])
    >>> a
    array([[10,  7,  4],
           [ 3,  2,  1]])
    >>> np.percentile(a, 50)
    3.5
    >>> np.percentile(a, 50, axis=0)
    array([ 6.5,  4.5,  2.5])
    >>> np.percentile(a, 50, axis=1)
    array([ 7.,  2.])

    >>> m = np.percentile(a, 50, axis=0)
    >>> out = np.zeros_like(m)
    >>> np.percentile(a, 50, axis=0, out=m)
    array([ 6.5,  4.5,  2.5])
    >>> m
    array([ 6.5,  4.5,  2.5])

    >>> b = a.copy()
    >>> np.percentile(b, 50, axis=1, overwrite_input=True)
    array([ 7.,  2.])
    >>> assert not np.all(a==b)
    >>> b = a.copy()
    >>> np.percentile(b, 50, axis=None, overwrite_input=True)
    3.5

    
    Return the Kaiser window.

    The Kaiser window is a taper formed by using a Bessel function.

    Parameters
    ----------
    M : int
        Number of points in the output window. If zero or less, an
        empty array is returned.
    beta : float
        Shape parameter for window.

    Returns
    -------
    out : array
        The window, with the maximum value normalized to one (the value
        one appears only if the number of samples is odd).

    See Also
    --------
    bartlett, blackman, hamming, hanning

    Notes
    -----
    The Kaiser window is defined as

    .. math::  w(n) = I_0\left( \beta \sqrt{1-\frac{4n^2}{(M-1)^2}}
               \right)/I_0(\beta)

    with

    .. math:: \quad -\frac{M-1}{2} \leq n \leq \frac{M-1}{2},

    where :math:`I_0` is the modified zeroth-order Bessel function.

    The Kaiser was named for Jim Kaiser, who discovered a simple
    approximation to the DPSS window based on Bessel functions.  The Kaiser
    window is a very good approximation to the Digital Prolate Spheroidal
    Sequence, or Slepian window, which is the transform which maximizes the
    energy in the main lobe of the window relative to total energy.

    The Kaiser can approximate many other windows by varying the beta
    parameter.

    ====  =======================
    beta  Window shape
    ====  =======================
    0     Rectangular
    5     Similar to a Hamming
    6     Similar to a Hanning
    8.6   Similar to a Blackman
    ====  =======================

    A beta value of 14 is probably a good starting point. Note that as beta
    gets large, the window narrows, and so the number of samples needs to be
    large enough to sample the increasingly narrow spike, otherwise NaNs will
    get returned.

    Most references to the Kaiser window come from the signal processing
    literature, where it is used as one of many windowing functions for
    smoothing values.  It is also known as an apodization (which means
    "removing the foot", i.e. smoothing discontinuities at the beginning
    and end of the sampled signal) or tapering function.

    References
    ----------
    .. [1] J. F. Kaiser, "Digital Filters" - Ch 7 in "Systems analysis by
           digital computer", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.
           John Wiley and Sons, New York, (1966).
    .. [2] E.R. Kanasewich, "Time Sequence Analysis in Geophysics", The
           University of Alberta Press, 1975, pp. 177-178.
    .. [3] Wikipedia, "Window function",
           http://en.wikipedia.org/wiki/Window_function

    Examples
    --------
    >>> np.kaiser(12, 14)
    array([  7.72686684e-06,   3.46009194e-03,   4.65200189e-02,
             2.29737120e-01,   5.99885316e-01,   9.45674898e-01,
             9.45674898e-01,   5.99885316e-01,   2.29737120e-01,
             4.65200189e-02,   3.46009194e-03,   7.72686684e-06])


    Plot the window and the frequency response:

    >>> from numpy.fft import fft, fftshift
    >>> window = np.kaiser(51, 14)
    >>> plt.plot(window)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Kaiser window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Sample")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    >>> plt.figure()
    <matplotlib.figure.Figure object at 0x...>
    >>> A = fft(window, 2048) / 25.5
    >>> mag = np.abs(fftshift(A))
    >>> freq = np.linspace(-0.5, 0.5, len(A))
    >>> response = 20 * np.log10(mag)
    >>> response = np.clip(response, -100, 100)
    >>> plt.plot(freq, response)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Frequency response of Kaiser window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Magnitude [dB]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Normalized frequency [cycles per sample]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.axis('tight')
    (-0.5, 0.5, -100.0, ...)
    >>> plt.show()

    
    Return an array drawn from elements in choicelist, depending on conditions.

    Parameters
    ----------
    condlist : list of bool ndarrays
        The list of conditions which determine from which array in `choicelist`
        the output elements are taken. When multiple conditions are satisfied,
        the first one encountered in `condlist` is used.
    choicelist : list of ndarrays
        The list of arrays from which the output elements are taken. It has
        to be of the same length as `condlist`.
    default : scalar, optional
        The element inserted in `output` when all conditions evaluate to False.

    Returns
    -------
    output : ndarray
        The output at position m is the m-th element of the array in
        `choicelist` where the m-th element of the corresponding array in
        `condlist` is True.

    See Also
    --------
    where : Return elements from one of two arrays depending on condition.
    take, choose, compress, diag, diagonal

    Examples
    --------
    >>> x = np.arange(10)
    >>> condlist = [x<3, x>5]
    >>> choicelist = [x, x**2]
    >>> np.select(condlist, choicelist)
    array([ 0,  1,  2,  0,  0,  0, 36, 49, 64, 81])

    order must be non-negative but got meshgrid() takes 2 or more arguments (%d given)axis %d out of bounds (%d)
    vectorize(pyfunc, otypes='', doc=None, excluded=None, cache=False)

    Generalized function class.

    Define a vectorized function which takes a nested sequence
    of objects or numpy arrays as inputs and returns a
    numpy array as output. The vectorized function evaluates `pyfunc` over
    successive tuples of the input arrays like the python map function,
    except it uses the broadcasting rules of numpy.

    The data type of the output of `vectorized` is determined by calling
    the function with the first element of the input.  This can be avoided
    by specifying the `otypes` argument.

    Parameters
    ----------
    pyfunc : callable
        A python function or method.
    otypes : str or list of dtypes, optional
        The output data type. It must be specified as either a string of
        typecode characters or a list of data type specifiers. There should
        be one data type specifier for each output.
    doc : str, optional
        The docstring for the function. If `None`, the docstring will be the
        ``pyfunc.__doc__``.
    excluded : set, optional
        Set of strings or integers representing the positional or keyword
        arguments for which the function will not be vectorized.  These will be
        passed directly to `pyfunc` unmodified.

        .. versionadded:: 1.7.0

    cache : bool, optional
       If `True`, then cache the first function call that determines the number
       of outputs if `otypes` is not provided.

        .. versionadded:: 1.7.0

    Returns
    -------
    vectorized : callable
        Vectorized function.

    Examples
    --------
    >>> def myfunc(a, b):
    ...     "Return a-b if a>b, otherwise return a+b"
    ...     if a > b:
    ...         return a - b
    ...     else:
    ...         return a + b

    >>> vfunc = np.vectorize(myfunc)
    >>> vfunc([1, 2, 3, 4], 2)
    array([3, 4, 1, 2])

    The docstring is taken from the input function to `vectorize` unless it
    is specified

    >>> vfunc.__doc__
    'Return a-b if a>b, otherwise return a+b'
    >>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')
    >>> vfunc.__doc__
    'Vectorized `myfunc`'

    The output type is determined by evaluating the first element of the input,
    unless it is specified

    >>> out = vfunc([1, 2, 3, 4], 2)
    >>> type(out[0])
    <type 'numpy.int32'>
    >>> vfunc = np.vectorize(myfunc, otypes=[np.float])
    >>> out = vfunc([1, 2, 3, 4], 2)
    >>> type(out[0])
    <type 'numpy.float64'>

    The `excluded` argument can be used to prevent vectorizing over certain
    arguments.  This can be useful for array-like arguments of a fixed length
    such as the coefficients for a polynomial as in `polyval`:

    >>> def mypolyval(p, x):
    ...     _p = list(p)
    ...     res = _p.pop(0)
    ...     while _p:
    ...         res = res*x + _p.pop(0)
    ...     return res
    >>> vpolyval = np.vectorize(mypolyval, excluded=['p'])
    >>> vpolyval(p=[1, 2, 3], x=[0, 1])
    array([3, 6])

    Positional arguments may also be excluded by specifying their position:

    >>> vpolyval.excluded.add(0)
    >>> vpolyval([1, 2, 3], x=[0, 1])
    array([3, 6])

    Notes
    -----
    The `vectorize` function is provided primarily for convenience, not for
    performance. The implementation is essentially a for loop.

    If `otypes` is not specified, then a call to the function with the
    first argument will be used to determine the number of outputs.  The
    results of this call will be cached if `cache` is `True` to prevent
    calling the function twice.  However, to implement the cache, the
    original function must be wrapped which will slow down subsequent
    calls, so only do this if your function is expensive.

    The new keyword argument interface and `excluded` argument support
    further degrades performance.

    
    Return the Hanning window.

    The Hanning window is a taper formed by using a weighted cosine.

    Parameters
    ----------
    M : int
        Number of points in the output window. If zero or less, an
        empty array is returned.

    Returns
    -------
    out : ndarray, shape(M,)
        The window, with the maximum value normalized to one (the value
        one appears only if `M` is odd).

    See Also
    --------
    bartlett, blackman, hamming, kaiser

    Notes
    -----
    The Hanning window is defined as

    .. math::  w(n) = 0.5 - 0.5cos\left(\frac{2\pi{n}}{M-1}\right)
               \qquad 0 \leq n \leq M-1

    The Hanning was named for Julius van Hann, an Austrian meteorologist.
    It is also known as the Cosine Bell. Some authors prefer that it be
    called a Hann window, to help avoid confusion with the very similar
    Hamming window.

    Most references to the Hanning window come from the signal processing
    literature, where it is used as one of many windowing functions for
    smoothing values.  It is also known as an apodization (which means
    "removing the foot", i.e. smoothing discontinuities at the beginning
    and end of the sampled signal) or tapering function.

    References
    ----------
    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power
           spectra, Dover Publications, New York.
    .. [2] E.R. Kanasewich, "Time Sequence Analysis in Geophysics",
           The University of Alberta Press, 1975, pp. 106-108.
    .. [3] Wikipedia, "Window function",
           http://en.wikipedia.org/wiki/Window_function
    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,
           "Numerical Recipes", Cambridge University Press, 1986, page 425.

    Examples
    --------
    >>> np.hanning(12)
    array([ 0.        ,  0.07937323,  0.29229249,  0.57115742,  0.82743037,
            0.97974649,  0.97974649,  0.82743037,  0.57115742,  0.29229249,
            0.07937323,  0.        ])

    Plot the window and its frequency response:

    >>> from numpy.fft import fft, fftshift
    >>> window = np.hanning(51)
    >>> plt.plot(window)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Hann window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Sample")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    >>> plt.figure()
    <matplotlib.figure.Figure object at 0x...>
    >>> A = fft(window, 2048) / 25.5
    >>> mag = np.abs(fftshift(A))
    >>> freq = np.linspace(-0.5, 0.5, len(A))
    >>> response = 20 * np.log10(mag)
    >>> response = np.clip(response, -100, 100)
    >>> plt.plot(freq, response)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Frequency response of the Hann window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Magnitude [dB]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Normalized frequency [cycles per sample]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.axis('tight')
    (-0.5, 0.5, -100.0, ...)
    >>> plt.show()

    
    Unwrap by changing deltas between values to 2*pi complement.

    Unwrap radian phase `p` by changing absolute jumps greater than
    `discont` to their 2*pi complement along the given axis.

    Parameters
    ----------
    p : array_like
        Input array.
    discont : float, optional
        Maximum discontinuity between values, default is ``pi``.
    axis : int, optional
        Axis along which unwrap will operate, default is the last axis.

    Returns
    -------
    out : ndarray
        Output array.

    See Also
    --------
    rad2deg, deg2rad

    Notes
    -----
    If the discontinuity in `p` is smaller than ``pi``, but larger than
    `discont`, no unwrapping is done because taking the 2*pi complement
    would only make the discontinuity larger.

    Examples
    --------
    >>> phase = np.linspace(0, np.pi, num=5)
    >>> phase[3:] += np.pi
    >>> phase
    array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531])
    >>> np.unwrap(phase)
    array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ])

    
    Check whether or not an object can be iterated over.

    Parameters
    ----------
    y : object
      Input object.

    Returns
    -------
    b : {0, 1}
      Return 1 if the object has an iterator method or is a sequence,
      and 0 otherwise.


    Examples
    --------
    >>> np.iterable([1, 2, 3])
    1
    >>> np.iterable(2)
    0

    
    Return the Bartlett window.

    The Bartlett window is very similar to a triangular window, except
    that the end points are at zero.  It is often used in signal
    processing for tapering a signal, without generating too much
    ripple in the frequency domain.

    Parameters
    ----------
    M : int
        Number of points in the output window. If zero or less, an
        empty array is returned.

    Returns
    -------
    out : array
        The triangular window, with the maximum value normalized to one
        (the value one appears only if the number of samples is odd), with
        the first and last samples equal to zero.

    See Also
    --------
    blackman, hamming, hanning, kaiser

    Notes
    -----
    The Bartlett window is defined as

    .. math:: w(n) = \frac{2}{M-1} \left(
              \frac{M-1}{2} - \left|n - \frac{M-1}{2}\right|
              \right)

    Most references to the Bartlett window come from the signal
    processing literature, where it is used as one of many windowing
    functions for smoothing values.  Note that convolution with this
    window produces linear interpolation.  It is also known as an
    apodization (which means"removing the foot", i.e. smoothing
    discontinuities at the beginning and end of the sampled signal) or
    tapering function. The fourier transform of the Bartlett is the product
    of two sinc functions.
    Note the excellent discussion in Kanasewich.

    References
    ----------
    .. [1] M.S. Bartlett, "Periodogram Analysis and Continuous Spectra",
           Biometrika 37, 1-16, 1950.
    .. [2] E.R. Kanasewich, "Time Sequence Analysis in Geophysics",
           The University of Alberta Press, 1975, pp. 109-110.
    .. [3] A.V. Oppenheim and R.W. Schafer, "Discrete-Time Signal
           Processing", Prentice-Hall, 1999, pp. 468-471.
    .. [4] Wikipedia, "Window function",
           http://en.wikipedia.org/wiki/Window_function
    .. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,
           "Numerical Recipes", Cambridge University Press, 1986, page 429.


    Examples
    --------
    >>> np.bartlett(12)
    array([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273,
            0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,
            0.18181818,  0.        ])

    Plot the window and its frequency response (requires SciPy and matplotlib):

    >>> from numpy.fft import fft, fftshift
    >>> window = np.bartlett(51)
    >>> plt.plot(window)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Bartlett window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Sample")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    >>> plt.figure()
    <matplotlib.figure.Figure object at 0x...>
    >>> A = fft(window, 2048) / 25.5
    >>> mag = np.abs(fftshift(A))
    >>> freq = np.linspace(-0.5, 0.5, len(A))
    >>> response = 20 * np.log10(mag)
    >>> response = np.clip(response, -100, 100)
    >>> plt.plot(freq, response)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Frequency response of Bartlett window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Magnitude [dB]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Normalized frequency [cycles per sample]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.axis('tight')
    (-0.5, 0.5, -100.0, ...)
    >>> plt.show()

    
    One-dimensional linear interpolation.

    Returns the one-dimensional piecewise linear interpolant to a function
    with given values at discrete data-points.

    Parameters
    ----------
    x : array_like
        The x-coordinates of the interpolated values.

    xp : 1-D sequence of floats
        The x-coordinates of the data points, must be increasing.

    fp : 1-D sequence of floats
        The y-coordinates of the data points, same length as `xp`.

    left : float, optional
        Value to return for `x < xp[0]`, default is `fp[0]`.

    right : float, optional
        Value to return for `x > xp[-1]`, defaults is `fp[-1]`.

    Returns
    -------
    y : {float, ndarray}
        The interpolated values, same shape as `x`.

    Raises
    ------
    ValueError
        If `xp` and `fp` have different length

    Notes
    -----
    Does not check that the x-coordinate sequence `xp` is increasing.
    If `xp` is not increasing, the results are nonsense.
    A simple check for increasing is::

        np.all(np.diff(xp) > 0)


    Examples
    --------
    >>> xp = [1, 2, 3]
    >>> fp = [3, 2, 0]
    >>> np.interp(2.5, xp, fp)
    1.0
    >>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)
    array([ 3. ,  3. ,  2.5 ,  0.56,  0. ])
    >>> UNDEF = -99.0
    >>> np.interp(3.14, xp, fp, right=UNDEF)
    -99.0

    Plot an interpolant to the sine function:

    >>> x = np.linspace(0, 2*np.pi, 10)
    >>> y = np.sin(x)
    >>> xvals = np.linspace(0, 2*np.pi, 50)
    >>> yinterp = np.interp(xvals, x, y)
    >>> import matplotlib.pyplot as plt
    >>> plt.plot(x, y, 'o')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.plot(xvals, yinterp, '-x')
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.show()

    Length of weights not compatible with specified axis.
    Trim the leading and/or trailing zeros from a 1-D array or sequence.

    Parameters
    ----------
    filt : 1-D array or sequence
        Input array.
    trim : str, optional
        A string with 'f' representing trim from front and 'b' to trim from
        back. Default is 'fb', trim zeros from both front and back of the
        array.

    Returns
    -------
    trimmed : 1-D array or sequence
        The result of trimming the input. The input data type is preserved.

    Examples
    --------
    >>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))
    >>> np.trim_zeros(a)
    array([1, 2, 3, 0, 2, 1])

    >>> np.trim_zeros(a, 'b')
    array([0, 0, 0, 1, 2, 3, 0, 2, 1])

    The input data type is preserved, list/tuple in means list/tuple out.

    >>> np.trim_zeros([0, 1, 2, 0])
    [1, 2]

    axis %i is out of bounds for an array of dimension %iin the future insert will treat boolean arrays and array-likes as a boolean index instead of casting it to integerReturn (ufunc, otypes).in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integermax must be larger than min in range parameter.list of cases must be same length as list of conditions
    Return a new array with sub-arrays along an axis deleted. For a one
    dimensional array, this returns those entries not returned by
    `arr[obj]`.

    Parameters
    ----------
    arr : array_like
      Input array.
    obj : slice, int or array of ints
      Indicate which sub-arrays to remove.
    axis : int, optional
      The axis along which to delete the subarray defined by `obj`.
      If `axis` is None, `obj` is applied to the flattened array.

    Returns
    -------
    out : ndarray
        A copy of `arr` with the elements specified by `obj` removed. Note
        that `delete` does not occur in-place. If `axis` is None, `out` is
        a flattened array.

    See Also
    --------
    insert : Insert elements into an array.
    append : Append elements at the end of an array.

    Notes
    -----
    Often it is preferable to use a boolean mask. For example:
    
    >>> mask = np.ones(len(arr), dtype=bool)
    >>> mask[[0,2,4]] = False
    >>> result = arr[mask,...]

    Is equivalent to `np.delete(arr, [0,2,4], axis=0)`, but allows further
    use of `mask`.

    Examples
    --------
    >>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])
    >>> arr
    array([[ 1,  2,  3,  4],
           [ 5,  6,  7,  8],
           [ 9, 10, 11, 12]])
    >>> np.delete(arr, 1, 0)
    array([[ 1,  2,  3,  4],
           [ 9, 10, 11, 12]])

    >>> np.delete(arr, np.s_[::2], 1)
    array([[ 2,  4],
           [ 6,  8],
           [10, 12]])
    >>> np.delete(arr, [1,3,5], None)
    array([ 1,  3,  5,  7,  8,  9, 10, 11, 12])

    
    Return the sinc function.

    The sinc function is :math:`\sin(\pi x)/(\pi x)`.

    Parameters
    ----------
    x : ndarray
        Array (possibly multi-dimensional) of values for which to to
        calculate ``sinc(x)``.

    Returns
    -------
    out : ndarray
        ``sinc(x)``, which has the same shape as the input.

    Notes
    -----
    ``sinc(0)`` is the limit value 1.

    The name sinc is short for "sine cardinal" or "sinus cardinalis".

    The sinc function is used in various signal processing applications,
    including in anti-aliasing, in the construction of a Lanczos resampling
    filter, and in interpolation.

    For bandlimited interpolation of discrete-time signals, the ideal
    interpolation kernel is proportional to the sinc function.

    References
    ----------
    .. [1] Weisstein, Eric W. "Sinc Function." From MathWorld--A Wolfram Web
           Resource. http://mathworld.wolfram.com/SincFunction.html
    .. [2] Wikipedia, "Sinc function",
           http://en.wikipedia.org/wiki/Sinc_function

    Examples
    --------
    >>> x = np.linspace(-4, 4, 41)
    >>> np.sinc(x)
    array([ -3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02,
            -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,
             6.68206631e-02,   1.16434881e-01,   1.26137788e-01,
             8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,
            -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,
             3.89804309e-17,   2.33872321e-01,   5.04551152e-01,
             7.56826729e-01,   9.35489284e-01,   1.00000000e+00,
             9.35489284e-01,   7.56826729e-01,   5.04551152e-01,
             2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,
            -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,
            -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,
             1.16434881e-01,   6.68206631e-02,   3.89804309e-17,
            -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,
            -4.92362781e-02,  -3.89804309e-17])

    >>> plt.plot(x, np.sinc(x))
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Sinc Function")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("X")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    It works in 2-D as well:

    >>> x = np.linspace(-4, 4, 401)
    >>> xx = np.outer(x, x)
    >>> plt.imshow(np.sinc(xx))
    <matplotlib.image.AxesImage object at 0x...>

    
    Return the angle of the complex argument.

    Parameters
    ----------
    z : array_like
        A complex number or sequence of complex numbers.
    deg : bool, optional
        Return angle in degrees if True, radians if False (default).

    Returns
    -------
    angle : {ndarray, scalar}
        The counterclockwise angle from the positive real axis on
        the complex plane, with dtype as numpy.float64.

    See Also
    --------
    arctan2
    absolute



    Examples
    --------
    >>> np.angle([1.0, 1.0j, 1+1j])               # in radians
    array([ 0.        ,  1.57079633,  0.78539816])
    >>> np.angle(1+1j, deg=True)                  # in degrees
    45.0

    using a non-integer array as obj in insert will result in an error in the future
    Sort a complex array using the real part first, then the imaginary part.

    Parameters
    ----------
    a : array_like
        Input array

    Returns
    -------
    out : complex ndarray
        Always returns a sorted complex array.

    Examples
    --------
    >>> np.sort_complex([5, 3, 6, 2, 1])
    array([ 1.+0.j,  2.+0.j,  3.+0.j,  5.+0.j,  6.+0.j])

    >>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])
    array([ 1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])

    Adds documentation to obj which is in module place.

    If doc is a string add it to obj as a docstring

    If doc is a tuple, then the first element is interpreted as
       an attribute of obj and the second as the docstring
          (method, docstring)

    If doc is a list, then each element of the list should be a
       sequence of length two --> [(method1, docstring1),
       (method2, docstring2), ...]

    This routine never raises an error.

    This routine cannot modify read-only docstrings, as appear
    in new-style classes or built-in functions. Because this
    routine never raises an error the caller must check manually
    that the docstrings were changed.
       invalid number of argumentsInternal Shape Error
    Return coordinate matrices from two or more coordinate vectors.

    Make N-D coordinate arrays for vectorized evaluations of
    N-D scalar/vector fields over N-D grids, given
    one-dimensional coordinate arrays x1, x2,..., xn.

    Parameters
    ----------
    x1, x2,..., xn : array_like
        1-D arrays representing the coordinates of a grid.
    indexing : {'xy', 'ij'}, optional
        Cartesian ('xy', default) or matrix ('ij') indexing of output.
        See Notes for more details.
    sparse : bool, optional
         If True a sparse grid is returned in order to conserve memory.
         Default is False.
    copy : bool, optional
        If False, a view into the original arrays are returned in order to
        conserve memory.  Default is True.  Please note that
        ``sparse=False, copy=False`` will likely return non-contiguous
        arrays.  Furthermore, more than one element of a broadcast array
        may refer to a single memory location.  If you need to write to the
        arrays, make copies first.

    Returns
    -------
    X1, X2,..., XN : ndarray
        For vectors `x1`, `x2`,..., 'xn' with lengths ``Ni=len(xi)`` ,
        return ``(N1, N2, N3,...Nn)`` shaped arrays if indexing='ij'
        or ``(N2, N1, N3,...Nn)`` shaped arrays if indexing='xy'
        with the elements of `xi` repeated to fill the matrix along
        the first dimension for `x1`, the second for `x2` and so on.

    Notes
    -----
    This function supports both indexing conventions through the indexing
    keyword argument.  Giving the string 'ij' returns a meshgrid with
    matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.
    In the 2-D case with inputs of length M and N, the outputs are of shape
    (N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case
    with inputs of length M, N and P, outputs are of shape (N, M, P) for
    'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is
    illustrated by the following code snippet::

        xv, yv = meshgrid(x, y, sparse=False, indexing='ij')
        for i in range(nx):
            for j in range(ny):
                # treat xv[i,j], yv[i,j]

        xv, yv = meshgrid(x, y, sparse=False, indexing='xy')
        for i in range(nx):
            for j in range(ny):
                # treat xv[j,i], yv[j,i]

    In the 1-D and 0-D case, the indexing and sparse keywords have no
    effect.

    See Also
    --------
    index_tricks.mgrid : Construct a multi-dimensional "meshgrid"
                     using indexing notation.
    index_tricks.ogrid : Construct an open multi-dimensional "meshgrid"
                     using indexing notation.

    Examples
    --------
    >>> nx, ny = (3, 2)
    >>> x = np.linspace(0, 1, nx)
    >>> y = np.linspace(0, 1, ny)
    >>> xv, yv = meshgrid(x, y)
    >>> xv
    array([[ 0. ,  0.5,  1. ],
           [ 0. ,  0.5,  1. ]])
    >>> yv
    array([[ 0.,  0.,  0.],
           [ 1.,  1.,  1.]])
    >>> xv, yv = meshgrid(x, y, sparse=True)  # make sparse output arrays
    >>> xv
    array([[ 0. ,  0.5,  1. ]])
    >>> yv
    array([[ 0.],
           [ 1.]])

    `meshgrid` is very useful to evaluate functions on a grid.

    >>> x = np.arange(-5, 5, 0.1)
    >>> y = np.arange(-5, 5, 0.1)
    >>> xx, yy = meshgrid(x, y, sparse=True)
    >>> z = np.sin(xx**2 + yy**2) / (xx**2 + yy**2)
    >>> h = plt.contourf(x,y,z)

    bins must increase monotonically.using a non-integer array as obj in delete will result in an error in the future
    Insert values along the given axis before the given indices.

    Parameters
    ----------
    arr : array_like
        Input array.
    obj : int, slice or sequence of ints
        Object that defines the index or indices before which `values` is
        inserted.

        .. versionadded:: 1.8.0

        Support for multiple insertions when `obj` is a single scalar or a
        sequence with one element (similar to calling insert multiple
        times).
    values : array_like
        Values to insert into `arr`. If the type of `values` is different
        from that of `arr`, `values` is converted to the type of `arr`.
        `values` should be shaped so that ``arr[...,obj,...] = values``
        is legal.
    axis : int, optional
        Axis along which to insert `values`.  If `axis` is None then `arr`
        is flattened first.

    Returns
    -------
    out : ndarray
        A copy of `arr` with `values` inserted.  Note that `insert`
        does not occur in-place: a new array is returned. If
        `axis` is None, `out` is a flattened array.

    See Also
    --------
    append : Append elements at the end of an array.
    concatenate : Join a sequence of arrays together.
    delete : Delete elements from an array.

    Notes
    -----
    Note that for higher dimensional inserts `obj=0` behaves very different
    from `obj=[0]` just like `arr[:,0,:] = values` is different from
    `arr[:,[0],:] = values`.

    Examples
    --------
    >>> a = np.array([[1, 1], [2, 2], [3, 3]])
    >>> a
    array([[1, 1],
           [2, 2],
           [3, 3]])
    >>> np.insert(a, 1, 5)
    array([1, 5, 1, 2, 2, 3, 3])
    >>> np.insert(a, 1, 5, axis=1)
    array([[1, 5, 1],
           [2, 5, 2],
           [3, 5, 3]])

    Difference between sequence and scalars:
    >>> np.insert(a, [1], [[1],[2],[3]], axis=1)
    array([[1, 1, 1],
           [2, 2, 2],
           [3, 3, 3]])
    >>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),
    ...                np.insert(a, [1], [[1],[2],[3]], axis=1))
    True

    >>> b = a.flatten()
    >>> b
    array([1, 1, 2, 2, 3, 3])
    >>> np.insert(b, [2, 2], [5, 6])
    array([1, 1, 5, 6, 2, 2, 3, 3])

    >>> np.insert(b, slice(2, 4), [5, 6])
    array([1, 1, 5, 2, 6, 2, 3, 3])

    >>> np.insert(b, [2, 2], [7.13, False]) # type casting
    array([1, 1, 7, 0, 2, 2, 3, 3])

    >>> x = np.arange(8).reshape(2, 4)
    >>> idx = (1, 3)
    >>> np.insert(x, idx, 999, axis=1)
    array([[  0, 999,   1,   2, 999,   3],
           [  4, 999,   5,   6, 999,   7]])

    
    Compute the median along the specified axis.

    Returns the median of the array elements.

    Parameters
    ----------
    a : array_like
        Input array or object that can be converted to an array.
    axis : int, optional
        Axis along which the medians are computed. The default (axis=None)
        is to compute the median along a flattened version of the array.
    out : ndarray, optional
        Alternative output array in which to place the result. It must have
        the same shape and buffer length as the expected output, but the
        type (of the output) will be cast if necessary.
    overwrite_input : bool, optional
       If True, then allow use of memory of input array (a) for
       calculations. The input array will be modified by the call to
       median. This will save memory when you do not need to preserve the
       contents of the input array. Treat the input as undefined, but it
       will probably be fully or partially sorted. Default is False. Note
       that, if `overwrite_input` is True and the input is not already an
       ndarray, an error will be raised.

    Returns
    -------
    median : ndarray
        A new array holding the result (unless `out` is specified, in which
        case that array is returned instead).  If the input contains
        integers, or floats of smaller precision than 64, then the output
        data-type is float64.  Otherwise, the output data-type is the same
        as that of the input.

    See Also
    --------
    mean, percentile

    Notes
    -----
    Given a vector V of length N, the median of V is the middle value of
    a sorted copy of V, ``V_sorted`` - i.e., ``V_sorted[(N-1)/2]``, when N is
    odd.  When N is even, it is the average of the two middle values of
    ``V_sorted``.

    Examples
    --------
    >>> a = np.array([[10, 7, 4], [3, 2, 1]])
    >>> a
    array([[10,  7,  4],
           [ 3,  2,  1]])
    >>> np.median(a)
    3.5
    >>> np.median(a, axis=0)
    array([ 6.5,  4.5,  2.5])
    >>> np.median(a, axis=1)
    array([ 7.,  2.])
    >>> m = np.median(a, axis=0)
    >>> out = np.zeros_like(m)
    >>> np.median(a, axis=0, out=m)
    array([ 6.5,  4.5,  2.5])
    >>> m
    array([ 6.5,  4.5,  2.5])
    >>> b = a.copy()
    >>> np.median(b, axis=1, overwrite_input=True)
    array([ 7.,  2.])
    >>> assert not np.all(a==b)
    >>> b = a.copy()
    >>> np.median(b, axis=None, overwrite_input=True)
    3.5
    >>> assert not np.all(a==b)

    in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.function list and condition list must be the same
    Change elements of an array based on conditional and input values.

    Similar to ``np.copyto(arr, vals, where=mask)``, the difference is that
    `place` uses the first N elements of `vals`, where N is the number of
    True values in `mask`, while `copyto` uses the elements where `mask`
    is True.

    Note that `extract` does the exact opposite of `place`.

    Parameters
    ----------
    arr : array_like
        Array to put data into.
    mask : array_like
        Boolean mask array. Must have the same size as `a`.
    vals : 1-D sequence
        Values to put into `a`. Only the first N elements are used, where
        N is the number of True values in `mask`. If `vals` is smaller
        than N it will be repeated.

    See Also
    --------
    copyto, put, take, extract

    Examples
    --------
    >>> arr = np.arange(6).reshape(2, 3)
    >>> np.place(arr, arr>2, [44, 55])
    >>> arr
    array([[ 0,  1,  2],
           [44, 55, 44]])

    
    Return the Hamming window.

    The Hamming window is a taper formed by using a weighted cosine.

    Parameters
    ----------
    M : int
        Number of points in the output window. If zero or less, an
        empty array is returned.

    Returns
    -------
    out : ndarray
        The window, with the maximum value normalized to one (the value
        one appears only if the number of samples is odd).

    See Also
    --------
    bartlett, blackman, hanning, kaiser

    Notes
    -----
    The Hamming window is defined as

    .. math::  w(n) = 0.54 - 0.46cos\left(\frac{2\pi{n}}{M-1}\right)
               \qquad 0 \leq n \leq M-1

    The Hamming was named for R. W. Hamming, an associate of J. W. Tukey
    and is described in Blackman and Tukey. It was recommended for
    smoothing the truncated autocovariance function in the time domain.
    Most references to the Hamming window come from the signal processing
    literature, where it is used as one of many windowing functions for
    smoothing values.  It is also known as an apodization (which means
    "removing the foot", i.e. smoothing discontinuities at the beginning
    and end of the sampled signal) or tapering function.

    References
    ----------
    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power
           spectra, Dover Publications, New York.
    .. [2] E.R. Kanasewich, "Time Sequence Analysis in Geophysics", The
           University of Alberta Press, 1975, pp. 109-110.
    .. [3] Wikipedia, "Window function",
           http://en.wikipedia.org/wiki/Window_function
    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,
           "Numerical Recipes", Cambridge University Press, 1986, page 425.

    Examples
    --------
    >>> np.hamming(12)
    array([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594,
            0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,
            0.15302337,  0.08      ])

    Plot the window and the frequency response:

    >>> from numpy.fft import fft, fftshift
    >>> window = np.hamming(51)
    >>> plt.plot(window)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Hamming window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Amplitude")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Sample")
    <matplotlib.text.Text object at 0x...>
    >>> plt.show()

    >>> plt.figure()
    <matplotlib.figure.Figure object at 0x...>
    >>> A = fft(window, 2048) / 25.5
    >>> mag = np.abs(fftshift(A))
    >>> freq = np.linspace(-0.5, 0.5, len(A))
    >>> response = 20 * np.log10(mag)
    >>> response = np.clip(response, -100, 100)
    >>> plt.plot(freq, response)
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.title("Frequency response of Hamming window")
    <matplotlib.text.Text object at 0x...>
    >>> plt.ylabel("Magnitude [dB]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.xlabel("Normalized frequency [cycles per sample]")
    <matplotlib.text.Text object at 0x...>
    >>> plt.axis('tight')
    (-0.5, 0.5, -100.0, ...)
    >>> plt.show()

    (   t   samplet   binst   ranget   normedt   weightst   Nt   Dt   nbint   edgest   dedgest   Mt   smint   smaxt   it   Ncountt   mindifft   decimalt   not_smaller_than_edget   on_edget   histt   nit   xyt	   flatcountt   at   jt   coret   st   shape(   t   at   binst   ranget   normedt   weightst   densityt   mnt   mxt   mit   ntypet   nt   blockt   it   sat   zerot   tmp_at   tmp_wt   sorting_indext   swt   cwt	   bin_indext   dbkey0mymatndincrdefaxesoldndimindex_expfill_diagonaldiag_indices_fromunknown special directive
    Construct an open mesh from multiple sequences.

    This function takes N 1-D sequences and returns N outputs with N
    dimensions each, such that the shape is 1 in all but one dimension
    and the dimension with the non-unit shape value cycles through all
    N dimensions.

    Using `ix_` one can quickly construct index arrays that will index
    the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array
    ``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.

    Parameters
    ----------
    args : 1-D sequences

    Returns
    -------
    out : tuple of ndarrays
        N arrays with N dimensions each, with N the number of input
        sequences. Together these arrays form an open mesh.

    See Also
    --------
    ogrid, mgrid, meshgrid

    Examples
    --------
    >>> a = np.arange(10).reshape(2, 5)
    >>> a
    array([[0, 1, 2, 3, 4],
           [5, 6, 7, 8, 9]])
    >>> ixgrid = np.ix_([0,1], [2,4])
    >>> ixgrid
    (array([[0],
           [1]]), array([[2, 4]]))
    >>> ixgrid[0].shape, ixgrid[1].shape
    ((2, 1), (1, 2))
    >>> a[ixgrid]
    array([[2, 4],
           [7, 9]])

    
    An N-dimensional iterator object to index arrays.

    Given the shape of an array, an `ndindex` instance iterates over
    the N-dimensional index of the array. At each iteration a tuple
    of indices is returned, the last dimension is iterated over first.

    Parameters
    ----------
    `*args` : ints
      The size of each dimension of the array.

    See Also
    --------
    ndenumerate, flatiter

    Examples
    --------
    >>> for index in np.ndindex(3, 2, 1):
    ...     print index
    (0, 0, 0)
    (0, 1, 0)
    (1, 0, 0)
    (1, 1, 0)
    (2, 0, 0)
    (2, 1, 0)

    Cross index must be 1 dimensionalAll dimensions of input must be of equal length
    Return the indices to access the main diagonal of an n-dimensional array.

    See `diag_indices` for full details.

    Parameters
    ----------
    arr : array, at least 2-D

    See Also
    --------
    diag_indices

    Notes
    -----
    .. versionadded:: 1.4.0

    
        Standard iterator method, updates the index and returns the index tuple.

        Returns
        -------
        val : tuple of ints
            Returns a tuple containing the indices of the current iteration.

        /usr/lib/python2.7/dist-packages/numpy/lib/index_tricks.py
        Standard iterator method, returns the index tuple and array value.

        Returns
        -------
        coords : tuple of ints
            The indices of the current iteration.
        val : scalar
            The array element of the current iteration.

        
    A nicer way to build up index tuples for arrays.

    .. note::
       Use one of the two predefined instances `index_exp` or `s_`
       rather than directly using `IndexExpression`.

    For any index combination, including slicing and axis insertion,
    ``a[indices]`` is the same as ``a[np.index_exp[indices]]`` for any
    array `a`. However, ``np.index_exp[indices]`` can be used anywhere
    in Python code and returns a tuple of slice objects that can be
    used in the construction of complex index expressions.

    Parameters
    ----------
    maketuple : bool
        If True, always returns a tuple.

    See Also
    --------
    index_exp : Predefined instance that always returns a tuple:
       `index_exp = IndexExpression(maketuple=True)`.
    s_ : Predefined instance without tuple conversion:
       `s_ = IndexExpression(maketuple=False)`.

    Notes
    -----
    You can do all this with `slice()` plus a few special objects,
    but there's a lot to remember and this version is simpler because
    it uses the standard array indexing syntax.

    Examples
    --------
    >>> np.s_[2::2]
    slice(2, None, 2)
    >>> np.index_exp[2::2]
    (slice(2, None, 2),)

    >>> np.array([0, 1, 2, 3, 4])[np.s_[2::2]]
    array([2, 4])

    special directives must be the first entry.
    Translates slice objects to concatenation along the second axis.

    This is short-hand for ``np.r_['-1,2,0', index expression]``, which is
    useful because of its common occurrence. In particular, arrays will be
    stacked along their last axis after being upgraded to at least 2-D with
    1's post-pended to the shape (column vectors made out of 1-D arrays).

    For detailed documentation, see `r_`.

    Examples
    --------
    >>> np.c_[np.array([[1,2,3]]), 0, 0, np.array([[4,5,6]])]
    array([[1, 2, 3, 0, 0, 4, 5, 6]])

    
    Return the indices to access the main diagonal of an array.

    This returns a tuple of indices that can be used to access the main
    diagonal of an array `a` with ``a.ndim >= 2`` dimensions and shape
    (n, n, ..., n). For ``a.ndim = 2`` this is the usual diagonal, for
    ``a.ndim > 2`` this is the set of indices to access ``a[i, i, ..., i]``
    for ``i = [0..n-1]``.

    Parameters
    ----------
    n : int
      The size, along each dimension, of the arrays for which the returned
      indices can be used.

    ndim : int, optional
      The number of dimensions.

    See also
    --------
    diag_indices_from

    Notes
    -----
    .. versionadded:: 1.4.0

    Examples
    --------
    Create a set of indices to access the diagonal of a (4, 4) array:

    >>> di = np.diag_indices(4)
    >>> di
    (array([0, 1, 2, 3]), array([0, 1, 2, 3]))
    >>> a = np.arange(16).reshape(4, 4)
    >>> a
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])
    >>> a[di] = 100
    >>> a
    array([[100,   1,   2,   3],
           [  4, 100,   6,   7],
           [  8,   9, 100,  11],
           [ 12,  13,  14, 100]])

    Now, we create indices to manipulate a 3-D array:

    >>> d3 = np.diag_indices(2, 3)
    >>> d3
    (array([0, 1]), array([0, 1]), array([0, 1]))

    And use it to set the diagonal of an array of zeros to 1:

    >>> a = np.zeros((2, 2, 2), dtype=np.int)
    >>> a[d3] = 1
    >>> a
    array([[[1, 0],
            [0, 0]],
           [[0, 0],
            [0, 1]]])

    
    Construct a multi-dimensional "meshgrid".

    ``grid = nd_grid()`` creates an instance which will return a mesh-grid
    when indexed.  The dimension and number of the output arrays are equal
    to the number of indexing dimensions.  If the step length is not a
    complex number, then the stop is not inclusive.

    However, if the step length is a **complex number** (e.g. 5j), then the
    integer part of its magnitude is interpreted as specifying the
    number of points to create between the start and stop values, where
    the stop value **is inclusive**.

    If instantiated with an argument of ``sparse=True``, the mesh-grid is
    open (or not fleshed out) so that only one-dimension of each returned
    argument is greater than 1.

    Parameters
    ----------
    sparse : bool, optional
        Whether the grid is sparse or not. Default is False.

    Notes
    -----
    Two instances of `nd_grid` are made available in the NumPy namespace,
    `mgrid` and `ogrid`::

        mgrid = nd_grid(sparse=False)
        ogrid = nd_grid(sparse=True)

    Users should use these pre-defined instances instead of using `nd_grid`
    directly.

    Examples
    --------
    >>> mgrid = np.lib.index_tricks.nd_grid()
    >>> mgrid[0:5,0:5]
    array([[[0, 0, 0, 0, 0],
            [1, 1, 1, 1, 1],
            [2, 2, 2, 2, 2],
            [3, 3, 3, 3, 3],
            [4, 4, 4, 4, 4]],
           [[0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4],
            [0, 1, 2, 3, 4]]])
    >>> mgrid[-1:1:5j]
    array([-1. , -0.5,  0. ,  0.5,  1. ])

    >>> ogrid = np.lib.index_tricks.nd_grid(sparse=True)
    >>> ogrid[0:5,0:5]
    [array([[0],
            [1],
            [2],
            [3],
            [4]]), array([[0, 1, 2, 3, 4]])]

    
        Increment the multi-dimensional index by one.

        This method is for backward compatibility only: do not use.
        
    Multidimensional index iterator.

    Return an iterator yielding pairs of array coordinates and values.

    Parameters
    ----------
    a : ndarray
      Input array.

    See Also
    --------
    ndindex, flatiter

    Examples
    --------
    >>> a = np.array([[1, 2], [3, 4]])
    >>> for index, x in np.ndenumerate(a):
    ...     print index, x
    (0, 0) 1
    (0, 1) 2
    (1, 0) 3
    (1, 1) 4

    
    Translates slice objects to concatenation along the first axis.

    This is a simple way to build up arrays quickly. There are two use cases.

    1. If the index expression contains comma separated arrays, then stack
       them along their first axis.
    2. If the index expression contains slice notation or scalars then create
       a 1-D array with a range indicated by the slice notation.

    If slice notation is used, the syntax ``start:stop:step`` is equivalent
    to ``np.arange(start, stop, step)`` inside of the brackets. However, if
    ``step`` is an imaginary number (i.e. 100j) then its integer portion is
    interpreted as a number-of-points desired and the start and stop are
    inclusive. In other words ``start:stop:stepj`` is interpreted as
    ``np.linspace(start, stop, step, endpoint=1)`` inside of the brackets.
    After expansion of slice notation, all comma separated sequences are
    concatenated together.

    Optional character strings placed as the first element of the index
    expression can be used to change the output. The strings 'r' or 'c' result
    in matrix output. If the result is 1-D and 'r' is specified a 1 x N (row)
    matrix is produced. If the result is 1-D and 'c' is specified, then a N x 1
    (column) matrix is produced. If the result is 2-D then both provide the
    same matrix result.

    A string integer specifies which axis to stack multiple comma separated
    arrays along. A string of two comma-separated integers allows indication
    of the minimum number of dimensions to force each entry into as the
    second integer (the axis to concatenate along is still the first integer).

    A string with three comma-separated integers allows specification of the
    axis to concatenate along, the minimum number of dimensions to force the
    entries to, and which axis should contain the start of the arrays which
    are less than the specified number of dimensions. In other words the third
    integer allows you to specify where the 1's should be placed in the shape
    of the arrays that have their shapes upgraded. By default, they are placed
    in the front of the shape tuple. The third argument allows you to specify
    where the start of the array should be instead. Thus, a third argument of
    '0' would place the 1's at the end of the array shape. Negative integers
    specify where in the new shape tuple the last dimension of upgraded arrays
    should be placed, so the default is '-1'.

    Parameters
    ----------
    Not a function, so takes no parameters


    Returns
    -------
    A concatenated ndarray or matrix.

    See Also
    --------
    concatenate : Join a sequence of arrays together.
    c_ : Translates slice objects to concatenation along the second axis.

    Examples
    --------
    >>> np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]
    array([1, 2, 3, 0, 0, 4, 5, 6])
    >>> np.r_[-1:1:6j, [0]*3, 5, 6]
    array([-1. , -0.6, -0.2,  0.2,  0.6,  1. ,  0. ,  0. ,  0. ,  5. ,  6. ])

    String integers specify the axis to concatenate along or the minimum
    number of dimensions to force entries into.

    >>> a = np.array([[0, 1, 2], [3, 4, 5]])
    >>> np.r_['-1', a, a] # concatenate along last axis
    array([[0, 1, 2, 0, 1, 2],
           [3, 4, 5, 3, 4, 5]])
    >>> np.r_['0,2', [1,2,3], [4,5,6]] # concatenate along first axis, dim>=2
    array([[1, 2, 3],
           [4, 5, 6]])

    >>> np.r_['0,2,0', [1,2,3], [4,5,6]]
    array([[1],
           [2],
           [3],
           [4],
           [5],
           [6]])
    >>> np.r_['1,2,0', [1,2,3], [4,5,6]]
    array([[1, 4],
           [2, 5],
           [3, 6]])

    Using 'r' or 'c' as a first string argument creates a matrix.

    >>> np.r_['r',[1,2,3], [4,5,6]]
    matrix([[1, 2, 3, 4, 5, 6]])

    
    Translates slice objects to concatenation along an axis.

    For detailed documentation on usage, see `r_`.

    Fill the main diagonal of the given array of any dimensionality.

    For an array `a` with ``a.ndim > 2``, the diagonal is the list of
    locations with indices ``a[i, i, ..., i]`` all identical. This function
    modifies the input array in-place, it does not return a value.

    Parameters
    ----------
    a : array, at least 2-D.
      Array whose diagonal is to be filled, it gets modified in-place.

    val : scalar
      Value to be written on the diagonal, its type must be compatible with
      that of the array a.

    wrap : bool
      For tall matrices in NumPy version up to 1.6.2, the
      diagonal "wrapped" after N columns. You can have this behavior
      with this option. This affect only tall matrices.

    See also
    --------
    diag_indices, diag_indices_from

    Notes
    -----
    .. versionadded:: 1.4.0

    This functionality can be obtained via `diag_indices`, but internally
    this version uses a much faster implementation that never constructs the
    indices and uses simple slicing.

    Examples
    --------
    >>> a = np.zeros((3, 3), int)
    >>> np.fill_diagonal(a, 5)
    >>> a
    array([[5, 0, 0],
           [0, 5, 0],
           [0, 0, 5]])

    The same function can operate on a 4-D array:

    >>> a = np.zeros((3, 3, 3, 3), int)
    >>> np.fill_diagonal(a, 4)

    We only show a few blocks for clarity:

    >>> a[0, 0]
    array([[4, 0, 0],
           [0, 0, 0],
           [0, 0, 0]])
    >>> a[1, 1]
    array([[0, 0, 0],
           [0, 4, 0],
           [0, 0, 0]])
    >>> a[2, 2]
    array([[0, 0, 0],
           [0, 0, 0],
           [0, 0, 4]])

    # tall matrices no wrap
    >>> a = np.zeros((5, 3),int)
    >>> fill_diagonal(a, 4)
    array([[4, 0, 0],
           [0, 4, 0],
           [0, 0, 4],
           [0, 0, 0],
           [0, 0, 0]])

    # tall matrices wrap
    >>> a = np.zeros((5, 3),int)
    >>> fill_diagonal(a, 4)
    array([[4, 0, 0],
           [0, 4, 0],
           [0, 0, 4],
           [0, 0, 0],
           [4, 0, 0]])

    # wide matrices
    >>> a = np.zeros((3, 5),int)
    >>> fill_diagonal(a, 4)
    array([[4, 0, 0, 0, 0],
           [0, 4, 0, 0, 0],
           [0, 0, 4, 0, 0]])

    array must be at least 2-dinput array must be at least 2-d(   t   selft   keyt   trans1dt   ndmint   framet   mymatt   objst   scalarst
   arraytypest   scalartypest   kt   scalart   stept   startt   stopt   sizet   newobjt   key0t   vect   xt   tempobjt   k2t   defaxest   k1t   axest   final_dtypet   resnumpy.lib.info/usr/lib/python2.7/dist-packages/numpy/lib/info.py
Basic functions used by several sub-packages and
useful to have in the main name-space.

Type Handling
-------------
================ ===================
iscomplexobj     Test for complex object, scalar result
isrealobj        Test for real object, scalar result
iscomplex        Test for complex elements, array result
isreal           Test for real elements, array result
imag             Imaginary part
real             Real part
real_if_close    Turns complex number with tiny imaginary part to real
isneginf         Tests for negative infinity, array result
isposinf         Tests for positive infinity, array result
isnan            Tests for nans, array result
isinf            Tests for infinity, array result
isfinite         Tests for finite numbers, array result
isscalar         True if argument is a scalar
nan_to_num       Replaces NaN's with 0 and infinities with large numbers
cast             Dictionary of functions to force cast to each type
common_type      Determine the minimum common type code for a group
                 of arrays
mintypecode      Return minimal allowed common typecode.
================ ===================

Index Tricks
------------
================ ===================
mgrid            Method which allows easy construction of N-d
                 'mesh-grids'
``r_``           Append and construct arrays: turns slice objects into
                 ranges and concatenates them, for 2d arrays appends rows.
index_exp        Konrad Hinsen's index_expression class instance which
                 can be useful for building complicated slicing syntax.
================ ===================

Useful Functions
----------------
================ ===================
select           Extension of where to multiple conditions and choices
extract          Extract 1d array from flattened array according to mask
insert           Insert 1d array of values into Nd array according to mask
linspace         Evenly spaced samples in linear space
logspace         Evenly spaced samples in logarithmic space
fix              Round x to nearest integer towards zero
mod              Modulo mod(x,y) = x % y except keeps sign of y
amax             Array maximum along axis
amin             Array minimum along axis
ptp              Array max-min along axis
cumsum           Cumulative sum along axis
prod             Product of elements along axis
cumprod          Cumluative product along axis
diff             Discrete differences along axis
angle            Returns angle of complex argument
unwrap           Unwrap phase along given axis (1-d algorithm)
sort_complex     Sort a complex-array (based on real, then imaginary)
trim_zeros       Trim the leading and trailing zeros from 1D array.
vectorize        A class that wraps a Python function taking scalar
                 arguments into a generalized function which can handle
                 arrays of arguments using the broadcast rules of
                 numerix Python.
================ ===================

Shape Manipulation
------------------
================ ===================
squeeze          Return a with length-one dimensions removed.
atleast_1d       Force arrays to be > 1D
atleast_2d       Force arrays to be > 2D
atleast_3d       Force arrays to be > 3D
vstack           Stack arrays vertically (row on row)
hstack           Stack arrays horizontally (column on column)
column_stack     Stack 1D arrays as columns into 2D array
dstack           Stack arrays depthwise (along third dimension)
split            Divide array into a list of sub-arrays
hsplit           Split into columns
vsplit           Split into rows
dsplit           Split along third dimension
================ ===================

Matrix (2D Array) Manipulations
-------------------------------
================ ===================
fliplr           2D array with columns flipped
flipud           2D array with rows flipped
rot90            Rotate a 2D array a multiple of 90 degrees
eye              Return a 2D array with ones down a given diagonal
diag             Construct a 2D array from a vector, or return a given
                 diagonal from a 2D array.
mat              Construct a Matrix
bmat             Build a Matrix from blocks
================ ===================

Polynomials
-----------
================ ===================
poly1d           A one-dimensional polynomial class
poly             Return polynomial coefficients from roots
roots            Find roots of polynomial given coefficients
polyint          Integrate polynomial
polyder          Differentiate polynomial
polyadd          Add polynomials
polysub          Substract polynomials
polymul          Multiply polynomials
polydiv          Divide polynomials
polyval          Evaluate polynomial at given argument
================ ===================

Import Tricks
-------------
================ ===================
ppimport         Postpone module import until trying to use it
ppimport_attr    Postpone module import until trying to use its attribute
ppresolve        Import postponed module and return it.
================ ===================

Machine Arithmetics
-------------------
================ ===================
machar_single    Single precision floating point arithmetic parameters
machar_double    Double precision floating point arithmetic parameters
================ ===================

Threading Tricks
----------------
================ ===================
ParallelExec     Execute commands in parallel thread.
================ ===================

1D Array Set Operations
-----------------------
Set operations for 1D numeric arrays based on sort() function.

================ ===================
ediff1d          Array difference (auxiliary function).
unique           Unique elements of an array.
intersect1d      Intersection of 1D arrays with unique elements.
setxor1d         Set exclusive-or of 1D arrays with unique elements.
in1d             Test whether elements in a 1D array are also present in
                 another array.
union1d          Union of 1D arrays with unique elements.
setdiff1d        Set difference of 1D arrays with unique elements.
================ ===================

isbadis_newnansumnanargmaxnanargmin
    Return the indices of the maximum values in the specified axis ignoring
    NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the
    results cannot be trusted if a slice contains only NaNs and -Infs.


    Parameters
    ----------
    a : array_like
        Input data.
    axis : int, optional
        Axis along which to operate.  By default flattened input is used.

    Returns
    -------
    index_array : ndarray
        An array of indices or a single index value.

    See Also
    --------
    argmax, nanargmin

    Examples
    --------
    >>> a = np.array([[np.nan, 4], [2, 3]])
    >>> np.argmax(a)
    0
    >>> np.nanargmax(a)
    1
    >>> np.nanargmax(a, axis=0)
    array([1, 0])
    >>> np.nanargmax(a, axis=1)
    array([1, 1])

    Degrees of freedom <= 0 for slice.If a is inexact, then dtype must be inexact
    Return the indices of the minimum values in the specified axis ignoring
    NaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results
    cannot be trusted if a slice contains only NaNs and Infs.

    Parameters
    ----------
    a : array_like
        Input data.
    axis : int, optional
        Axis along which to operate.  By default flattened input is used.

    Returns
    -------
    index_array : ndarray
        An array of indices or a single index value.

    See Also
    --------
    argmin, nanargmax

    Examples
    --------
    >>> a = np.array([[np.nan, 4], [2, 3]])
    >>> np.argmin(a)
    0
    >>> np.nanargmin(a)
    2
    >>> np.nanargmin(a, axis=0)
    array([1, 1])
    >>> np.nanargmin(a, axis=1)
    array([1, 0])

    numpy.lib.nanfunctions
Functions that ignore NaN.

Functions
---------

- `nanmin` -- minimum non-NaN value
- `nanmax` -- maximum non-NaN value
- `nanargmin` -- index of minimum non-NaN value
- `nanargmax` -- index of maximum non-NaN value
- `nansum` -- sum of non-NaN values
- `nanmean` -- mean of non-NaN values
- `nanvar` -- variance of non-NaN values
- `nanstd` -- standard deviation of non-NaN values


    Compute the variance along the specified axis, while ignoring NaNs.

    Returns the variance of the array elements, a measure of the spread of
    a distribution.  The variance is computed for the flattened array by
    default, otherwise over the specified axis.

    For all-NaN slices or slices with zero degrees of freedom, NaN is
    returned and a `RuntimeWarning` is raised.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        Array containing numbers whose variance is desired.  If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the variance is computed.  The default is to compute
        the variance of the flattened array.
    dtype : data-type, optional
        Type to use in computing the variance.  For arrays of integer type
        the default is `float32`; for arrays of float types it is the same as
        the array type.
    out : ndarray, optional
        Alternate output array in which to place the result.  It must have
        the same shape as the expected output, but the type is cast if
        necessary.
    ddof : int, optional
        "Delta Degrees of Freedom": the divisor used in the calculation is
        ``N - ddof``, where ``N`` represents the number of non-NaN
        elements. By default `ddof` is zero.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    variance : ndarray, see dtype parameter above
        If `out` is None, return a new array containing the variance,
        otherwise return a reference to the output array. If ddof is >= the
        number of non-NaN elements in a slice or the slice contains only
        NaNs, then the result for that slice is NaN.

    See Also
    --------
    std : Standard deviation
    mean : Average
    var : Variance while not ignoring NaNs
    nanstd, nanmean
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    The variance is the average of the squared deviations from the mean,
    i.e.,  ``var = mean(abs(x - x.mean())**2)``.

    The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
    If, however, `ddof` is specified, the divisor ``N - ddof`` is used
    instead.  In standard statistical practice, ``ddof=1`` provides an
    unbiased estimator of the variance of a hypothetical infinite
    population.  ``ddof=0`` provides a maximum likelihood estimate of the
    variance for normally distributed variables.

    Note that for complex numbers, the absolute value is taken before
    squaring, so that the result is always real and nonnegative.

    For floating-point input, the variance is computed using the same
    precision the input has.  Depending on the input data, this can cause
    the results to be inaccurate, especially for `float32` (see example
    below).  Specifying a higher-accuracy accumulator using the ``dtype``
    keyword can alleviate this issue.

    Examples
    --------
    >>> a = np.array([[1, np.nan], [3, 4]])
    >>> np.var(a)
    1.5555555555555554
    >>> np.nanvar(a, axis=0)
    array([ 1.,  0.])
    >>> np.nanvar(a, axis=1)
    array([ 0.,  0.25])

    
    Return the sum of array elements over a given axis treating Not a
    Numbers (NaNs) as zero.

    FutureWarning: In Numpy versions <= 1.8 Nan is returned for slices that
    are all-NaN or empty. In later versions zero will be returned.

    Parameters
    ----------
    a : array_like
        Array containing numbers whose sum is desired. If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the sum is computed. The default is to compute the
        sum of the flattened array.
    dtype : data-type, optional
        The type of the returned array and of the accumulator in which the
        elements are summed.  By default, the dtype of `a` is used.  An
        exception is when `a` has an integer type with less precision than
        the platform (u)intp. In that case, the default will be either
        (u)int32 or (u)int64 depending on whether the platform is 32 or 64
        bits. For inexact inputs, dtype must be inexact.

        .. versionadded:: 1.8.0
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``. If provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.  See
        `doc.ufuncs` for details. The casting of NaN to integer can yield
        unexpected results.

        .. versionadded:: 1.8.0
    keepdims : bool, optional
        If True, the axes which are reduced are left in the result as
        dimensions with size one. With this option, the result will
        broadcast correctly against the original `arr`.

        .. versionadded:: 1.8.0

    Returns
    -------
    y : ndarray or numpy scalar

    See Also
    --------
    numpy.sum : Sum across array propagating NaNs.
    isnan : Show which elements are NaN.
    isfinite: Show which elements are not NaN or +/-inf.

    Notes
    -----
    If both positive and negative infinity are present, the sum will be Not
    A Number (NaN).

    Numpy integer arithmetic is modular. If the size of a sum exceeds the
    size of an integer accumulator, its value will wrap around and the
    result will be incorrect. Specifying ``dtype=double`` can alleviate
    that problem.

    Examples
    --------
    >>> np.nansum(1)
    1
    >>> np.nansum([1])
    1
    >>> np.nansum([1, np.nan])
    1.0
    >>> a = np.array([[1, 1], [1, np.nan]])
    >>> np.nansum(a)
    3.0
    >>> np.nansum(a, axis=0)
    array([ 2.,  1.])
    >>> np.nansum([1, np.nan, np.inf])
    inf
    >>> np.nansum([1, np.nan, np.NINF])
    -inf
    >>> np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present
    nan

    /usr/lib/python2.7/dist-packages/numpy/lib/nanfunctions.pyIn Numpy 1.9 the sum along empty slices will be zero.
    Compute the arithmetic mean along the specified axis, ignoring NaNs.

    Returns the average of the array elements.  The average is taken over
    the flattened array by default, otherwise over the specified axis.
    `float64` intermediate and return values are used for integer inputs.

    For all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        Array containing numbers whose mean is desired. If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the means are computed. The default is to compute
        the mean of the flattened array.
    dtype : data-type, optional
        Type to use in computing the mean.  For integer inputs, the default
        is `float64`; for inexact inputs, it is the same as the input
        dtype.
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``; if provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.  See
        `doc.ufuncs` for details.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left in the
        result as dimensions with size one. With this option, the result
        will broadcast correctly against the original `arr`.

    Returns
    -------
    m : ndarray, see dtype parameter above
        If `out=None`, returns a new array containing the mean values,
        otherwise a reference to the output array is returned. Nan is
        returned for slices that contain only NaNs.

    See Also
    --------
    average : Weighted average
    mean : Arithmetic mean taken while not ignoring NaNs
    var, nanvar

    Notes
    -----
    The arithmetic mean is the sum of the non-NaN elements along the axis
    divided by the number of non-NaN elements.

    Note that for floating-point input, the mean is computed using the same
    precision the input has.  Depending on the input data, this can cause
    the results to be inaccurate, especially for `float32`.  Specifying a
    higher-precision accumulator using the `dtype` keyword can alleviate
    this issue.

    Examples
    --------
    >>> a = np.array([[1, np.nan], [3, 4]])
    >>> np.nanmean(a)
    2.6666666666666665
    >>> np.nanmean(a, axis=0)
    array([ 2.,  4.])
    >>> np.nanmean(a, axis=1)
    array([ 1.,  3.5])

    
    Compute the standard deviation along the specified axis, while
    ignoring NaNs.

    Returns the standard deviation, a measure of the spread of a
    distribution, of the non-NaN array elements. The standard deviation is
    computed for the flattened array by default, otherwise over the
    specified axis.

    For all-NaN slices or slices with zero degrees of freedom, NaN is
    returned and a `RuntimeWarning` is raised.

    .. versionadded:: 1.8.0

    Parameters
    ----------
    a : array_like
        Calculate the standard deviation of the non-NaN values.
    axis : int, optional
        Axis along which the standard deviation is computed. The default is
        to compute the standard deviation of the flattened array.
    dtype : dtype, optional
        Type to use in computing the standard deviation. For arrays of
        integer type the default is float64, for arrays of float types it
        is the same as the array type.
    out : ndarray, optional
        Alternative output array in which to place the result. It must have
        the same shape as the expected output but the type (of the
        calculated values) will be cast if necessary.
    ddof : int, optional
        Means Delta Degrees of Freedom.  The divisor used in calculations
        is ``N - ddof``, where ``N`` represents the number of non-NaN
        elements.  By default `ddof` is zero.
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left
        in the result as dimensions with size one. With this option,
        the result will broadcast correctly against the original `arr`.

    Returns
    -------
    standard_deviation : ndarray, see dtype parameter above.
        If `out` is None, return a new array containing the standard
        deviation, otherwise return a reference to the output array. If
        ddof is >= the number of non-NaN elements in a slice or the slice
        contains only NaNs, then the result for that slice is NaN.

    See Also
    --------
    var, mean, std
    nanvar, nanmean
    numpy.doc.ufuncs : Section "Output arguments"

    Notes
    -----
    The standard deviation is the square root of the average of the squared
    deviations from the mean: ``std = sqrt(mean(abs(x - x.mean())**2))``.

    The average squared deviation is normally calculated as
    ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is
    specified, the divisor ``N - ddof`` is used instead. In standard
    statistical practice, ``ddof=1`` provides an unbiased estimator of the
    variance of the infinite population. ``ddof=0`` provides a maximum
    likelihood estimate of the variance for normally distributed variables.
    The standard deviation computed in this function is the square root of
    the estimated variance, so even with ``ddof=1``, it will not be an
    unbiased estimate of the standard deviation per se.

    Note that, for complex numbers, `std` takes the absolute value before
    squaring, so that the result is always real and nonnegative.

    For floating-point input, the *std* is computed using the same
    precision the input has. Depending on the input data, this can cause
    the results to be inaccurate, especially for float32 (see example
    below).  Specifying a higher-accuracy accumulator using the `dtype`
    keyword can alleviate this issue.

    Examples
    --------
    >>> a = np.array([[1, np.nan], [3, 4]])
    >>> np.nanstd(a)
    1.247219128924647
    >>> np.nanstd(a, axis=0)
    array([ 1.,  0.])
    >>> np.nanstd(a, axis=1)
    array([ 0.,  0.5])

    
    Return the maximum of an array or maximum along an axis, ignoring any
    NaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is
    raised and NaN is returned for that slice.

    Parameters
    ----------
    a : array_like
        Array containing numbers whose maximum is desired. If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the maximum is computed. The default is to compute
        the maximum of the flattened array.
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``; if provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.  See
        `doc.ufuncs` for details.

        .. versionadded:: 1.8.0
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left in the
        result as dimensions with size one. With this option, the result
        will broadcast correctly against the original `a`.

        .. versionadded:: 1.8.0

    Returns
    -------
    nanmax : ndarray
        An array with the same shape as `a`, with the specified axis removed.
        If `a` is a 0-d array, or if axis is None, an ndarray scalar is
        returned.  The same dtype as `a` is returned.

    See Also
    --------
    nanmin :
        The minimum value of an array along a given axis, ignoring any NaNs.
    amax :
        The maximum value of an array along a given axis, propagating any NaNs.
    fmax :
        Element-wise maximum of two arrays, ignoring any NaNs.
    maximum :
        Element-wise maximum of two arrays, propagating any NaNs.
    isnan :
        Shows which elements are Not a Number (NaN).
    isfinite:
        Shows which elements are neither NaN nor infinity.

    amin, fmin, minimum

    Notes
    -----
    Numpy uses the IEEE Standard for Binary Floating-Point for Arithmetic
    (IEEE 754). This means that Not a Number is not equivalent to infinity.
    Positive infinity is treated as a very large number and negative
    infinity is treated as a very small (i.e. negative) number.

    If the input has a integer type the function is equivalent to np.max.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, np.nan]])
    >>> np.nanmax(a)
    3.0
    >>> np.nanmax(a, axis=0)
    array([ 3.,  2.])
    >>> np.nanmax(a, axis=1)
    array([ 2.,  3.])

    When positive infinity and negative infinity are present:

    >>> np.nanmax([1, 2, np.nan, np.NINF])
    2.0
    >>> np.nanmax([1, 2, np.nan, np.inf])
    inf

    If a is inexact, then out must be inexact
    If `a` is of inexact type, make a copy of `a`, replace NaNs with
    the `val` value, and return the copy together with a boolean mask
    marking the locations where NaNs were present. If `a` is not of
    inexact type, do nothing and return `a` together with a mask of None.

    Parameters
    ----------
    a : array-like
        Input array.
    val : float
        NaN values are set to val before doing the operation.

    Returns
    -------
    y : ndarray
        If `a` is of inexact type, return a copy of `a` with the NaNs
        replaced by the fill value, otherwise return `a`.
    mask: {bool, None}
        If `a` is of inexact type, return a boolean mask marking locations of
        NaNs, otherwise return None.

    All-NaN axis encountered
    Replace values in `a` with NaN where `mask` is True.  This differs from
    copyto in that it will deal with the case where `a` is a numpy scalar.

    Parameters
    ----------
    a : ndarray or numpy scalar
        Array or numpy scalar some of whose values are to be replaced
        by val.
    val : numpy scalar
        Value used a replacement.
    mask : ndarray, scalar
        Boolean array. Where True the corresponding element of `a` is
        replaced by `val`. Broadcasts.

    Returns
    -------
    res : ndarray, scalar
        Array with elements replaced or scalar `val`.

    
    Return minimum of an array or minimum along an axis, ignoring any NaNs.
    When all-NaN slices are encountered a ``RuntimeWarning`` is raised and
    Nan is returned for that slice.

    Parameters
    ----------
    a : array_like
        Array containing numbers whose minimum is desired. If `a` is not an
        array, a conversion is attempted.
    axis : int, optional
        Axis along which the minimum is computed. The default is to compute
        the minimum of the flattened array.
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``; if provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.  See
        `doc.ufuncs` for details.

        .. versionadded:: 1.8.0
    keepdims : bool, optional
        If this is set to True, the axes which are reduced are left in the
        result as dimensions with size one. With this option, the result
        will broadcast correctly against the original `a`.

        .. versionadded:: 1.8.0

    Returns
    -------
    nanmin : ndarray
        An array with the same shape as `a`, with the specified axis
        removed.  If `a` is a 0-d array, or if axis is None, an ndarray
        scalar is returned.  The same dtype as `a` is returned.

    See Also
    --------
    nanmax :
        The maximum value of an array along a given axis, ignoring any NaNs.
    amin :
        The minimum value of an array along a given axis, propagating any NaNs.
    fmin :
        Element-wise minimum of two arrays, ignoring any NaNs.
    minimum :
        Element-wise minimum of two arrays, propagating any NaNs.
    isnan :
        Shows which elements are Not a Number (NaN).
    isfinite:
        Shows which elements are neither NaN nor infinity.

    amax, fmax, maximum

    Notes
    -----
    Numpy uses the IEEE Standard for Binary Floating-Point for Arithmetic
    (IEEE 754). This means that Not a Number is not equivalent to infinity.
    Positive infinity is treated as a very large number and negative
    infinity is treated as a very small (i.e. negative) number.

    If the input has a integer type the function is equivalent to np.min.

    Examples
    --------
    >>> a = np.array([[1, 2], [3, np.nan]])
    >>> np.nanmin(a)
    1.0
    >>> np.nanmin(a, axis=0)
    array([ 1.,  2.])
    >>> np.nanmin(a, axis=1)
    array([ 1.,  3.])

    When positive infinity and negative infinity are present:

    >>> np.nanmin([1, 2, np.nan, np.inf])
    1.0
    >>> np.nanmin([1, 2, np.nan, np.NINF])
    -inf

    All-NaN slice encountered
    Compute a/b ignoring invalid results. If `a` is an array the division
    is done in place. If `a` is a scalar, then its type is preserved in the
    output. If out is None, then then a is used instead so that the
    division is in place. Note that this is only called with `a` an inexact
    type.

    Parameters
    ----------
    a : {ndarray, numpy scalar}
        Numerator. Expected to be of inexact type but not checked.
    b : {ndarray, numpy scalar}
        Denominator.
    out : ndarray, optional
        Alternate output array in which to place the result.  The default
        is ``None``; if provided, it must have the same shape as the
        expected output, but the type will be cast if necessary.

    Returns
    -------
    ret : {ndarray, numpy scalar}
        The return value is a/b. If `a` was an ndarray the division is done
        in place. If `a` is a numpy scalar, the division preserves its type.

    zipitarcnamerowmasksfromregexmafromtxtndfromtxtallowZip64miss_charsrecfromcsvrecfromtxt_ZIP_PREFIXfuture_builtinssavez_compressednbinvalid_skipped-numpy.npy(occurred line #%i for value '%s')Return an iterator over the files in the archive.PKUse this factory to produce the class so that we can do a lazy
    import on gzip.

    |S%iConverter #%i is locked and cannot be upgraded: 
    NpzFile(fid)

    A dictionary-like object with lazy-loading of files in the zipped
    archive provided on construction.

    `NpzFile` is used to load files in the NumPy ``.npz`` data archive
    format. It assumes that files in the archive have a ".npy" extension,
    other files are ignored.

    The arrays and file strings are lazily loaded on either
    getitem access using ``obj['key']`` or attribute lookup using
    ``obj.f.key``. A list of all files (without ".npy" extensions) can
    be obtained with ``obj.files`` and the ZipFile object itself using
    ``obj.zip``.

    Attributes
    ----------
    files : list of str
        List of all files in the archive with a ".npy" extension.
    zip : ZipFile instance
        The ZipFile object initialized with the zipped archive.
    f : BagObj instance
        An object on which attribute can be performed as an alternative
        to getitem access on the `NpzFile` instance itself.

    Parameters
    ----------
    fid : file or str
        The zipped archive to open. This is either a file-like object
        or a string containing the path to the archive.
    own_fid : bool, optional
        Whether NpzFile should close the file handle.
        Requires that `fid` is a file-like object.

    Examples
    --------
    >>> from tempfile import TemporaryFile
    >>> outfile = TemporaryFile()
    >>> x = np.arange(10)
    >>> y = np.sin(x)
    >>> np.savez(outfile, x=x, y=y)
    >>> outfile.seek(0)

    >>> npz = np.load(outfile)
    >>> isinstance(npz, np.lib.io.NpzFile)
    True
    >>> npz.files
    ['y', 'x']
    >>> npz['x']  # getitem access
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
    >>> npz.f.x  # attribute lookup
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

     (%s+%sj)%s is not a file in the archiveFailed to interpret file %s as a pickleChop off comments, strip, and split at delimiter.
    Load data from a text file.

    Each row in the text file must have the same number of values.

    Parameters
    ----------
    fname : file or str
        File, filename, or generator to read.  If the filename extension is
        ``.gz`` or ``.bz2``, the file is first decompressed. Note that
        generators should return byte strings for Python 3k.
    dtype : data-type, optional
        Data-type of the resulting array; default: float.  If this is a
        record data-type, the resulting array will be 1-dimensional, and
        each row will be interpreted as an element of the array.  In this
        case, the number of columns used must match the number of fields in
        the data-type.
    comments : str, optional
        The character used to indicate the start of a comment;
        default: '#'.
    delimiter : str, optional
        The string used to separate values.  By default, this is any
        whitespace.
    converters : dict, optional
        A dictionary mapping column number to a function that will convert
        that column to a float.  E.g., if column 0 is a date string:
        ``converters = {0: datestr2num}``.  Converters can also be used to
        provide a default value for missing data (but see also `genfromtxt`):
        ``converters = {3: lambda s: float(s.strip() or 0)}``.  Default: None.
    skiprows : int, optional
        Skip the first `skiprows` lines; default: 0.
    usecols : sequence, optional
        Which columns to read, with 0 being the first.  For example,
        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.
        The default, None, results in all columns being read.
    unpack : bool, optional
        If True, the returned array is transposed, so that arguments may be
        unpacked using ``x, y, z = loadtxt(...)``.  When used with a record
        data-type, arrays are returned for each field.  Default is False.
    ndmin : int, optional
        The returned array will have at least `ndmin` dimensions.
        Otherwise mono-dimensional axes will be squeezed.
        Legal values: 0 (default), 1 or 2.

        .. versionadded:: 1.6.0

    Returns
    -------
    out : ndarray
        Data read from the text file.

    See Also
    --------
    load, fromstring, fromregex
    genfromtxt : Load data with missing values handled as specified.
    scipy.io.loadmat : reads MATLAB data files

    Notes
    -----
    This function aims to be a fast reader for simply formatted files.  The
    `genfromtxt` function provides more sophisticated handling of, e.g.,
    lines with missing values.

    Examples
    --------
    >>> from StringIO import StringIO   # StringIO behaves like a file object
    >>> c = StringIO("0 1\n2 3")
    >>> np.loadtxt(c)
    array([[ 0.,  1.],
           [ 2.,  3.]])

    >>> d = StringIO("M 21 72\nF 35 58")
    >>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),
    ...                      'formats': ('S1', 'i4', 'f4')})
    array([('M', 21, 72.0), ('F', 35, 58.0)],
          dtype=[('gender', '|S1'), ('age', '<i4'), ('weight', '<f4')])

    >>> c = StringIO("1,0,2\n3,0,4")
    >>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)
    >>> x
    array([ 1.,  3.])
    >>> y
    array([ 2.,  4.])

    
    Load ASCII data stored in a file and return it as a single array.

    Parameters
    ----------
    fname, kwargs : For a description of input parameters, see `genfromtxt`.

    See Also
    --------
    numpy.genfromtxt : generic function.

    genfromtxt: Empty input file: "%s"%.18e
    Load ASCII data stored in a text file and return a masked array.

    Parameters
    ----------
    fname, kwargs : For a description of input parameters, see `genfromtxt`.

    See Also
    --------
    numpy.genfromtxt : generic function to load ASCII data.

    
    Save an array to a text file.

    Parameters
    ----------
    fname : filename or file handle
        If the filename ends in ``.gz``, the file is automatically saved in
        compressed gzip format.  `loadtxt` understands gzipped files
        transparently.
    X : array_like
        Data to be saved to a text file.
    fmt : str or sequence of strs, optional
        A single format (%10.5f), a sequence of formats, or a
        multi-format string, e.g. 'Iteration %d -- %10.5f', in which
        case `delimiter` is ignored. For complex `X`, the legal options
        for `fmt` are:
            a) a single specifier, `fmt='%.4e'`, resulting in numbers formatted
                like `' (%s+%sj)' % (fmt, fmt)`
            b) a full string specifying every real and imaginary part, e.g.
                `' %.4e %+.4j %.4e %+.4j %.4e %+.4j'` for 3 columns
            c) a list of specifiers, one per column - in this case, the real
                and imaginary part must have separate specifiers,
                e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns
    delimiter : str, optional
        Character separating columns.
    newline : str, optional
        .. versionadded:: 1.5.0
    header : str, optional
        String that will be written at the beginning of the file.

        .. versionadded:: 1.7.0
    footer : str, optional
        String that will be written at the end of the file.

        .. versionadded:: 1.7.0
    comments : str, optional
        String that will be prepended to the ``header`` and ``footer`` strings,
        to mark them as comments. Default: '# ',  as expected by e.g.
        ``numpy.loadtxt``.

        .. versionadded:: 1.7.0

        Character separating lines.

    See Also
    --------
    save : Save an array to a binary file in NumPy ``.npy`` format
    savez : Save several arrays into a ``.npz`` compressed archive

    Notes
    -----
    Further explanation of the `fmt` parameter
    (``%[flag]width[.precision]specifier``):

    flags:
        ``-`` : left justify

        ``+`` : Forces to preceed result with + or -.

        ``0`` : Left pad the number with zeros instead of space (see width).

    width:
        Minimum number of characters to be printed. The value is not truncated
        if it has more characters.

    precision:
        - For integer specifiers (eg. ``d,i,o,x``), the minimum number of
          digits.
        - For ``e, E`` and ``f`` specifiers, the number of digits to print
          after the decimal point.
        - For ``g`` and ``G``, the maximum number of significant digits.
        - For ``s``, the maximum number of characters.

    specifiers:
        ``c`` : character

        ``d`` or ``i`` : signed decimal integer

        ``e`` or ``E`` : scientific notation with ``e`` or ``E``.

        ``f`` : decimal floating point

        ``g,G`` : use the shorter of ``e,E`` or ``f``

        ``o`` : signed octal

        ``s`` : string of characters

        ``u`` : unsigned decimal integer

        ``x,X`` : unsigned hexadecimal integer

    This explanation of ``fmt`` is not complete, for an exhaustive
    specification see [1]_.

    References
    ----------
    .. [1] `Format Specification Mini-Language
           <http://docs.python.org/library/string.html#
           format-specification-mini-language>`_, Python Documentation.

    Examples
    --------
    >>> x = y = z = np.arange(0.0,5.0,1.0)
    >>> np.savetxt('test.out', x, delimiter=',')   # X is an array
    >>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays
    >>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation

    Return files in the archive with a ".npy" extension.The use of `skiprows` is deprecated, it will be removed in numpy 2.0.
Please use `skip_header` instead.
    Load data from a text file, with missing values handled as specified.

    Each line past the first `skip_header` lines is split at the `delimiter`
    character, and characters following the `comments` character are discarded.

    Parameters
    ----------
    fname : file or str
        File, filename, or generator to read.  If the filename extension is
        `.gz` or `.bz2`, the file is first decompressed. Note that
        generators must return byte strings in Python 3k.
    dtype : dtype, optional
        Data type of the resulting array.
        If None, the dtypes will be determined by the contents of each
        column, individually.
    comments : str, optional
        The character used to indicate the start of a comment.
        All the characters occurring on a line after a comment are discarded
    delimiter : str, int, or sequence, optional
        The string used to separate values.  By default, any consecutive
        whitespaces act as delimiter.  An integer or sequence of integers
        can also be provided as width(s) of each field.
    skip_header : int, optional
        The numbers of lines to skip at the beginning of the file.
    skip_footer : int, optional
        The numbers of lines to skip at the end of the file
    converters : variable, optional
        The set of functions that convert the data of a column to a value.
        The converters can also be used to provide a default value
        for missing data: ``converters = {3: lambda s: float(s or 0)}``.
    missing_values : variable, optional
        The set of strings corresponding to missing data.
    filling_values : variable, optional
        The set of values to be used as default when the data are missing.
    usecols : sequence, optional
        Which columns to read, with 0 being the first.  For example,
        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.
    names : {None, True, str, sequence}, optional
        If `names` is True, the field names are read from the first valid line
        after the first `skip_header` lines.
        If `names` is a sequence or a single-string of comma-separated names,
        the names will be used to define the field names in a structured dtype.
        If `names` is None, the names of the dtype fields will be used, if any.
    excludelist : sequence, optional
        A list of names to exclude. This list is appended to the default list
        ['return','file','print']. Excluded names are appended an underscore:
        for example, `file` would become `file_`.
    deletechars : str, optional
        A string combining invalid characters that must be deleted from the
        names.
    defaultfmt : str, optional
        A format used to define default field names, such as "f%i" or "f_%02i".
    autostrip : bool, optional
        Whether to automatically strip white spaces from the variables.
    replace_space : char, optional
        Character(s) used in replacement of white spaces in the variables
        names. By default, use a '_'.
    case_sensitive : {True, False, 'upper', 'lower'}, optional
        If True, field names are case sensitive.
        If False or 'upper', field names are converted to upper case.
        If 'lower', field names are converted to lower case.
    unpack : bool, optional
        If True, the returned array is transposed, so that arguments may be
        unpacked using ``x, y, z = loadtxt(...)``
    usemask : bool, optional
        If True, return a masked array.
        If False, return a regular array.
    invalid_raise : bool, optional
        If True, an exception is raised if an inconsistency is detected in the
        number of columns.
        If False, a warning is emitted and the offending lines are skipped.

    Returns
    -------
    out : ndarray
        Data read from the text file. If `usemask` is True, this is a
        masked array.

    See Also
    --------
    numpy.loadtxt : equivalent function when no data is missing.

    Notes
    -----
    * When spaces are used as delimiters, or when no delimiter has been given
      as input, there should not be any missing data between two fields.
    * When the variables are named (either by a flexible dtype or with `names`,
      there must not be any header in the file (else a ValueError
      exception is raised).
    * Individual values are not stripped of spaces by default.
      When using a custom converter, make sure the function does remove spaces.

    References
    ----------
    .. [1] Numpy User Guide, section `I/O with Numpy
           <http://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.

    Examples
    ---------
    >>> from StringIO import StringIO
    >>> import numpy as np

    Comma delimited file with mixed dtype

    >>> s = StringIO("1,1.3,abcde")
    >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),
    ... ('mystring','S5')], delimiter=",")
    >>> data
    array((1, 1.3, 'abcde'),
          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])

    Using dtype = None

    >>> s.seek(0) # needed for StringIO example only
    >>> data = np.genfromtxt(s, dtype=None,
    ... names = ['myint','myfloat','mystring'], delimiter=",")
    >>> data
    array((1, 1.3, 'abcde'),
          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])

    Specifying dtype and names

    >>> s.seek(0)
    >>> data = np.genfromtxt(s, dtype="i8,f8,S5",
    ... names=['myint','myfloat','mystring'], delimiter=",")
    >>> data
    array((1, 1.3, 'abcde'),
          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])

    An example with fixed-width columns

    >>> s = StringIO("11.3abcde")
    >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],
    ...     delimiter=[1,3,5])
    >>> data
    array((1, 1.3, 'abcde'),
          dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', '|S5')])

    
    Save several arrays into a single file in compressed ``.npz`` format.

    If keyword arguments are given, then filenames are taken from the keywords.
    If arguments are passed in with no keywords, then stored file names are
    arr_0, arr_1, etc.

    Parameters
    ----------
    file : str
        File name of .npz file.
    args : Arguments
        Function arguments.
    kwds : Keyword arguments
        Keywords.

    See Also
    --------
    numpy.savez : Save several arrays into an uncompressed ``.npz`` file format
    numpy.load : Load the files created by savez_compressed.

    
        Close the file.

        invalid fmt: %r
    BagObj(obj)

    Convert attribute look-ups to getitems on the object passed in.

    Parameters
    ----------
    obj : class instance
        Object on which attribute look-up is performed.

    Examples
    --------
    >>> from numpy.lib.npyio import BagObj as BO
    >>> class BagDemo(object):
    ...     def __getitem__(self, key): # An instance of BagObj(BagDemo)
    ...                                 # will call this method when any
    ...                                 # attribute look-up is required
    ...         result = "Doesn't matter what you want, "
    ...         return result + "you're gonna get this"
    ...
    >>> demo_obj = BagDemo()
    >>> bagobj = BO(demo_obj)
    >>> bagobj.hello_there
    "Doesn't matter what you want, you're gonna get this"
    >>> bagobj.I_can_be_anything
    "Doesn't matter what you want, you're gonna get this"

    fname must be a string, file handle, or generatorSome errors were detected !
    Load ASCII data from a file and return it in a record array.

    If ``usemask=False`` a standard `recarray` is returned,
    if ``usemask=True`` a MaskedRecords array is returned.

    Parameters
    ----------
    fname, kwargs : For a description of input parameters, see `genfromtxt`.

    See Also
    --------
    numpy.genfromtxt : generic function

    Notes
    -----
    By default, `dtype` is None, which means that the data-type of the output
    array will be determined from the data.

    fmt has wrong number of %% formats:  %s
    Construct an array from a text file, using regular expression parsing.

    The returned array is always a structured array, and is constructed from
    all matches of the regular expression in the file. Groups in the regular
    expression are converted to fields of the structured array.

    Parameters
    ----------
    file : str or file
        File name or file object to read.
    regexp : str or regexp
        Regular expression used to parse the file.
        Groups in the regular expression correspond to fields in the dtype.
    dtype : dtype or list of dtypes
        Dtype for the structured array.

    Returns
    -------
    output : ndarray
        The output array, containing the part of the content of `file` that
        was matched by `regexp`. `output` is always a structured array.

    Raises
    ------
    TypeError
        When `dtype` is not a valid dtype for a structured array.

    See Also
    --------
    fromstring, loadtxt

    Notes
    -----
    Dtypes for structured arrays can be specified in several forms, but all
    forms specify at least the data type and field name. For details see
    `doc.structured_arrays`.

    Examples
    --------
    >>> f = open('test.dat', 'w')
    >>> f.write("1312 foo\n1534  bar\n444   qux")
    >>> f.close()

    >>> regexp = r"(\d+)\s+(...)"  # match [digits, whitespace, anything]
    >>> output = np.fromregex('test.dat', regexp,
    ...                       [('num', np.int64), ('key', 'S3')])
    >>> output
    array([(1312L, 'foo'), (1534L, 'bar'), (444L, 'qux')],
          dtype=[('num', '<i8'), ('key', '|S3')])
    >>> output['num']
    array([1312, 1534,  444], dtype=int64)

    loadtxt: Empty input file: "%s"
    Load an array(s) or pickled objects from .npy, .npz, or pickled files.

    Parameters
    ----------
    file : file-like object or string
        The file to read. Compressed files with the filename extension
        ``.gz`` are acceptable. File-like objects must support the
        ``seek()`` and ``read()`` methods. Pickled files require that the
        file-like object support the ``readline()`` method as well.
    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional
        If not None, then memory-map the file, using the given mode (see
        `numpy.memmap` for a detailed description of the modes).  A
        memory-mapped array is kept on disk. However, it can be accessed
        and sliced like any ndarray.  Memory mapping is especially useful
        for accessing small fragments of large files without reading the
        entire file into memory.

    Returns
    -------
    result : array, tuple, dict, etc.
        Data stored in the file. For ``.npz`` files, the returned instance
        of NpzFile class must be closed to avoid leaking file descriptors.

    Raises
    ------
    IOError
        If the input file does not exist or cannot be read.

    See Also
    --------
    save, savez, savez_compressed, loadtxt
    memmap : Create a memory-map to an array stored in a file on disk.

    Notes
    -----
    - If the file contains pickle data, then whatever object is stored
      in the pickle is returned.
    - If the file is a ``.npy`` file, then a single array is returned.
    - If the file is a ``.npz`` file, then a dictionary-like object is
      returned, containing ``{filename: array}`` key-value pairs, one for
      each file in the archive.
    - If the file is a ``.npz`` file, the returned value supports the
      context manager protocol in a similar fashion to the open function::

        with load('foo.npz') as data:
            a = data['a']

      The underlying file descriptor is closed when exiting the 'with'
      block.

    Examples
    --------
    Store data to disk, and load it again:

    >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))
    >>> np.load('/tmp/123.npy')
    array([[1, 2, 3],
           [4, 5, 6]])

    Store compressed data to disk, and load it again:

    >>> a=np.array([[1, 2, 3], [4, 5, 6]])
    >>> b=np.array([1, 2])
    >>> np.savez('/tmp/123.npz', a=a, b=b)
    >>> data = np.load('/tmp/123.npz')
    >>> data['a']
    array([[1, 2, 3],
           [4, 5, 6]])
    >>> data['b']
    array([1, 2])
    >>> data.close()

    Mem-map the stored array, and then access the second row
    directly from disk:

    >>> X = np.load('/tmp/123.npy', mmap_mode='r')
    >>> X[1, :]
    memmap([4, 5, 6])

    Pack items into nested lists based on re-packing info.
        Return a list of tuples, with each tuple (filename, array in file).

        
    Load ASCII data stored in a comma-separated file.

    The returned array is a record array (if ``usemask=False``, see
    `recarray`) or a masked record array (if ``usemask=True``,
    see `ma.mrecords.MaskedRecords`).

    Parameters
    ----------
    fname, kwargs : For a description of input parameters, see `genfromtxt`.

    See Also
    --------
    numpy.genfromtxt : generic function to load ASCII data.

    Cannot use un-named variables and keyword %sfmt has wrong shape.  %s    Line #%%i (got %%i columns instead of %i)fname mustbe a string, filehandle, or generator. (got %s instead)/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyNested fields involving objects are not supported...
    Save an array to a binary file in NumPy ``.npy`` format.

    Parameters
    ----------
    file : file or str
        File or filename to which the data is saved.  If file is a file-object,
        then the filename is unchanged.  If file is a string, a ``.npy``
        extension will be appended to the file name if it does not already
        have one.
    arr : array_like
        Array data to be saved.

    See Also
    --------
    savez : Save several arrays into a ``.npz`` archive
    savetxt, load

    Notes
    -----
    For a description of the ``.npy`` format, see `format`.

    Examples
    --------
    >>> from tempfile import TemporaryFile
    >>> outfile = TemporaryFile()

    >>> x = np.arange(10)
    >>> np.save(outfile, x)

    >>> outfile.seek(0) # Only needed here to simulate closing & reopening file
    >>> np.load(outfile)
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

    Illegal value of ndmin keyword: %sUnpack a structured data-type, and produce re-packing info.Generator that returns tuples (filename, array in file).arr_%dThe input argument 'converter' should be a valid dictionary (got '%s' instead)The use of `missing` is deprecated, it will be removed in Numpy 2.0.
Please use `missing_values` instead.
    Save several arrays into a single file in uncompressed ``.npz`` format.

    If arguments are passed in with no keywords, the corresponding variable
    names, in the .npz file, are 'arr_0', 'arr_1', etc. If keyword arguments
    are given, the corresponding variable names, in the ``.npz`` file will
    match the keyword names.

    Parameters
    ----------
    file : str or file
        Either the file name (string) or an open file (file-like object)
        where the data will be saved. If file is a string, the ``.npz``
        extension will be appended to the file name if it is not already there.
    args : Arguments, optional
        Arrays to save to the file. Since it is not possible for Python to
        know the names of the arrays outside `savez`, the arrays will be saved
        with names "arr_0", "arr_1", and so on. These arguments can be any
        expression.
    kwds : Keyword arguments, optional
        Arrays to save to the file. Arrays will be saved in the file with the
        keyword names.

    Returns
    -------
    None

    See Also
    --------
    save : Save a single array to a binary file in NumPy format.
    savetxt : Save an array to a file as plain text.
    savez_compressed : Save several arrays into a compressed .npz file format

    Notes
    -----
    The ``.npz`` file format is a zipped archive of files named after the
    variables they contain.  The archive is not compressed and each file
    in the archive contains one variable in ``.npy`` format. For a
    description of the ``.npy`` format, see `format`.

    When opening the saved ``.npz`` file with `load` a `NpzFile` object is
    returned. This is a dictionary-like object which can be queried for
    its list of arrays (with the ``.files`` attribute), and for the arrays
    themselves.

    Examples
    --------
    >>> from tempfile import TemporaryFile
    >>> outfile = TemporaryFile()
    >>> x = np.arange(10)
    >>> y = np.sin(x)

    Using `savez` with \*args, the arrays are saved with default names.

    >>> np.savez(outfile, x, y)
    >>> outfile.seek(0) # Only needed here to simulate closing & reopening file
    >>> npzfile = np.load(outfile)
    >>> npzfile.files
    ['arr_1', 'arr_0']
    >>> npzfile['arr_0']
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

    Using `savez` with \**kwds, the arrays are saved with the keyword names.

    >>> outfile = TemporaryFile()
    >>> np.savez(outfile, x=x, y=y)
    >>> outfile.seek(0)
    >>> npzfile = np.load(outfile)
    >>> npzfile.files
    ['y', 'x']
    >>> npzfile['x']
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

    Illegal argument(   t   fnamet   dtypet   commentst	   delimitert   skiprowst   skip_headert   skip_footert
   converterst   missingt   missing_valuest   filling_valuest   usecolst   namest   excludelistt   deletecharst   replace_spacet	   autostript   case_sensitivet
   defaultfmtt   unpackt   usemaskt   looset   invalid_raise(\   t   fnamet   dtypet   commentst	   delimitert   skiprowst   skip_headert   skip_footert
   converterst   missingt   missing_valuest   filling_valuest   usecolst   namest   excludelistt   deletecharst   replace_spacet	   autostript   case_sensitivet
   defaultfmtt   unpackt   usemaskt   looset   invalid_raiset   MaskedArrayt   make_mask_descrt   user_converterst   errmsgt   own_fhdt   fhdt
   split_linet   validate_namest   it   first_valuest
   first_linet   fvalt   _t   nbcolst   currentt   descrt   user_missing_valuest   keyt   valt   misst   valuet   entryt
   user_valuet   valuest   user_filling_valuest   nt   fillt
   dtype_flatt   zipitt   dtt	   uc_updatet   convt   testing_valuet
   miss_charst   rowst   append_to_rowst   maskst   append_to_maskst   invalidt   append_to_invalidt   linet   nbvaluest   vt   mt	   convertert   _mt   current_columnt   jt	   nbinvalidt   nbrowst   templatet   nbinvalid_skippedt   nbt   _rt   datat   column_typest	   strcolidxt   ct   baset   ddtypet   mdtypet   outputt
   outputmaskt   tt   rowmaskst   ishomogeneoust   ttypet   namet   mval(   t   fnamet   dtypet   commentst	   delimitert
   converterst   skiprowst   usecolst   unpackt   ndmint   user_converterst   fownt   fht   bz2t   Xt   flatten_dtypet
   pack_itemst
   split_linet   defconvt   it
   first_valst
   first_linet   Nt   dtype_typest   packingt   dtt   convt   linet   valst   valt   itemst   field+=__pos__neg_rootspos_rootstrailing_zeros
    Find the coefficients of a polynomial with the given sequence of roots.

    Returns the coefficients of the polynomial whose leading coefficient
    is one for the given sequence of zeros (multiple roots must be included
    in the sequence as many times as their multiplicity; see Examples).
    A square matrix (or array, which will be treated as a matrix) can also
    be given, in which case the coefficients of the characteristic polynomial
    of the matrix are returned.

    Parameters
    ----------
    seq_of_zeros : array_like, shape (N,) or (N, N)
        A sequence of polynomial roots, or a square array or matrix object.

    Returns
    -------
    c : ndarray
        1D array of polynomial coefficients from highest to lowest degree:

        ``c[0] * x**(N) + c[1] * x**(N-1) + ... + c[N-1] * x + c[N]``
        where c[0] always equals 1.

    Raises
    ------
    ValueError
        If input is the wrong shape (the input must be a 1-D or square
        2-D array).

    See Also
    --------
    polyval : Evaluate a polynomial at a point.
    roots : Return the roots of a polynomial.
    polyfit : Least squares polynomial fit.
    poly1d : A one-dimensional polynomial class.

    Notes
    -----
    Specifying the roots of a polynomial still leaves one degree of
    freedom, typically represented by an undetermined leading
    coefficient. [1]_ In the case of this function, that coefficient -
    the first one in the returned array - is always taken as one. (If
    for some reason you have one other point, the only automatic way
    presently to leverage that information is to use ``polyfit``.)

    The characteristic polynomial, :math:`p_a(t)`, of an `n`-by-`n`
    matrix **A** is given by

        :math:`p_a(t) = \mathrm{det}(t\, \mathbf{I} - \mathbf{A})`,

    where **I** is the `n`-by-`n` identity matrix. [2]_

    References
    ----------
    .. [1] M. Sullivan and M. Sullivan, III, "Algebra and Trignometry,
       Enhanced With Graphing Utilities," Prentice-Hall, pg. 318, 1996.

    .. [2] G. Strang, "Linear Algebra and Its Applications, 2nd Edition,"
       Academic Press, pg. 182, 1980.

    Examples
    --------
    Given a sequence of a polynomial's zeros:

    >>> np.poly((0, 0, 0)) # Multiple root example
    array([1, 0, 0, 0])

    The line above represents z**3 + 0*z**2 + 0*z + 0.

    >>> np.poly((-1./2, 0, 1./2))
    array([ 1.  ,  0.  , -0.25,  0.  ])

    The line above represents z**3 - z/4

    >>> np.poly((np.random.random(1.)[0], 0, np.random.random(1.)[0]))
    array([ 1.        , -0.77086955,  0.08618131,  0.        ]) #random

    Given a square array object:

    >>> P = np.array([[0, 1./3], [-1./2, 0]])
    >>> np.poly(P)
    array([ 1.        ,  0.        ,  0.16666667])

    Or a square matrix object:

    >>> np.poly(np.matrix(P))
    array([ 1.        ,  0.        ,  0.16666667])

    Note how in all cases the leading coefficient is always 1.

    k must be a scalar or a rank-1 array of length 1 or >m.
    Find the product of two polynomials.

    Finds the polynomial resulting from the multiplication of the two input
    polynomials. Each input must be either a poly1d object or a 1D sequence
    of polynomial coefficients, from highest to lowest degree.

    Parameters
    ----------
    a1, a2 : array_like or poly1d object
        Input polynomials.

    Returns
    -------
    out : ndarray or poly1d object
        The polynomial resulting from the multiplication of the inputs. If
        either inputs is a poly1d object, then the output is also a poly1d
        object. Otherwise, it is a 1D array of polynomial coefficients from
        highest to lowest degree.

    See Also
    --------
    poly1d : A one-dimensional polynomial class.
    poly, polyadd, polyder, polydiv, polyfit, polyint, polysub,
    polyval

    Examples
    --------
    >>> np.polymul([1, 2, 3], [9, 5, 1])
    array([ 9, 23, 38, 17,  3])

    Using poly1d objects:

    >>> p1 = np.poly1d([1, 2, 3])
    >>> p2 = np.poly1d([9, 5, 1])
    >>> print p1
       2
    1 x + 2 x + 3
    >>> print p2
       2
    9 x + 5 x + 1
    >>> print np.polymul(p1, p2)
       4      3      2
    9 x + 23 x + 38 x + 17 x + 3

    Order of integral must be positive (see polyder)
    Difference (subtraction) of two polynomials.

    Given two polynomials `a1` and `a2`, returns ``a1 - a2``.
    `a1` and `a2` can be either array_like sequences of the polynomials'
    coefficients (including coefficients equal to zero), or `poly1d` objects.

    Parameters
    ----------
    a1, a2 : array_like or poly1d
        Minuend and subtrahend polynomials, respectively.

    Returns
    -------
    out : ndarray or poly1d
        Array or `poly1d` object of the difference polynomial's coefficients.

    See Also
    --------
    polyval, polydiv, polymul, polyadd

    Examples
    --------
    .. math:: (2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)

    >>> np.polysub([2, 10, -2], [3, 10, -4])
    array([-1,  0,  2])

    
        Return a derivative of this polynomial.

        Refer to `polyder` for full documentation.

        See Also
        --------
        polyder : equivalent function

        
Functions to operate on polynomials.


        Return an antiderivative (indefinite integral) of this polynomial.

        Refer to `polyint` for full documentation.

        See Also
        --------
        polyint : equivalent function

        '%s' has no attribute '%s'
    Issued by `polyfit` when the Vandermonde matrix is rank deficient.

    For more information, a way to suppress the warning, and an example of
    `RankWarning` being issued, see `polyfit`.

    poly1d(%s)numpy.lib.polynomialPower to non-negative integers only.Attributes cannot be changed this way.Does not support negative powers.[*][*]([0-9]*)%s %s**%d
    Evaluate a polynomial at specific values.

    If `p` is of length N, this function returns the value:

        ``p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]``

    If `x` is a sequence, then `p(x)` is returned for each element of `x`.
    If `x` is another polynomial then the composite polynomial `p(x(t))`
    is returned.

    Parameters
    ----------
    p : array_like or poly1d object
       1D array of polynomial coefficients (including coefficients equal
       to zero) from highest degree to the constant term, or an
       instance of poly1d.
    x : array_like or poly1d object
       A number, a 1D array of numbers, or an instance of poly1d, "at"
       which to evaluate `p`.

    Returns
    -------
    values : ndarray or poly1d
       If `x` is a poly1d instance, the result is the composition of the two
       polynomials, i.e., `x` is "substituted" in `p` and the simplified
       result is returned. In addition, the type of `x` - array_like or
       poly1d - governs the type of the output: `x` array_like => `values`
       array_like, `x` a poly1d object => `values` is also.

    See Also
    --------
    poly1d: A polynomial class.

    Notes
    -----
    Horner's scheme [1]_ is used to evaluate the polynomial. Even so,
    for polynomials of high degree the values may be inaccurate due to
    rounding errors. Use carefully.

    References
    ----------
    .. [1] I. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng.
       trans. Ed.), *Handbook of Mathematics*, New York, Van Nostrand
       Reinhold Co., 1985, pg. 720.

    Examples
    --------
    >>> np.polyval([3,0,1], 5)  # 3 * 5**2 + 0 * 5**1 + 1
    76
    >>> np.polyval([3,0,1], np.poly1d(5))
    poly1d([ 76.])
    >>> np.polyval(np.poly1d([3,0,1]), 5)
    76
    >>> np.polyval(np.poly1d([3,0,1]), np.poly1d(5))
    poly1d([ 76.])

    
    Return the derivative of the specified order of a polynomial.

    Parameters
    ----------
    p : poly1d or sequence
        Polynomial to differentiate.
        A sequence is interpreted as polynomial coefficients, see `poly1d`.
    m : int, optional
        Order of differentiation (default: 1)

    Returns
    -------
    der : poly1d
        A new polynomial representing the derivative.

    See Also
    --------
    polyint : Anti-derivative of a polynomial.
    poly1d : Class for one-dimensional polynomials.

    Examples
    --------
    The derivative of the polynomial :math:`x^3 + x^2 + x^1 + 1` is:

    >>> p = np.poly1d([1,1,1,1])
    >>> p2 = np.polyder(p)
    >>> p2
    poly1d([3, 2, 1])

    which evaluates to:

    >>> p2(2.)
    17.0

    We can verify this, approximating the derivative with
    ``(f(x + h) - f(x))/h``:

    >>> (p(2. + 0.001) - p(2.)) / 0.001
    17.007000999997857

    The fourth-order derivative of a 3rd-order polynomial is zero:

    >>> np.polyder(p, 2)
    poly1d([6, 2])
    >>> np.polyder(p, 3)
    poly1d([6])
    >>> np.polyder(p, 4)
    poly1d([ 0.])

    
    Least squares polynomial fit.

    Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`
    to points `(x, y)`. Returns a vector of coefficients `p` that minimises
    the squared error.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting polynomial
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than this
        relative to the largest singular value will be ignored. The default
        value is len(x)*eps, where eps is the relative precision of the float
        type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is
        False (the default) just the coefficients are returned, when True
        diagnostic information from the singular value decomposition is also
        returned.
    w : array_like, shape (M,), optional
        weights to apply to the y-coordinates of the sample points.
    cov : bool, optional
        Return the estimate and the covariance matrix of the estimate
        If full is True, then cov is not returned.

    Returns
    -------
    p : ndarray, shape (M,) or (M, K)
        Polynomial coefficients, highest power first.
        If `y` was 2-D, the coefficients for `k`-th data set are in ``p[:,k]``.

    residuals, rank, singular_values, rcond : present only if `full` = True
        Residuals of the least-squares fit, the effective rank of the scaled
        Vandermonde coefficient matrix, its singular values, and the specified
        value of `rcond`. For more details, see `linalg.lstsq`.

    V : ndaray, shape (M,M) or (M,M,K) : present only if `full` = False and `cov`=True
        The covariance matrix of the polynomial coefficient estimates.  The diagonal
        of this matrix are the variance estimates for each coefficient.  If y is a 2-d
        array, then the covariance matrix for the `k`-th data set are in ``V[:,:,k]``


    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.

        The warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', np.RankWarning)

    See Also
    --------
    polyval : Computes polynomial values.
    linalg.lstsq : Computes a least-squares fit.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution minimizes the squared error

    .. math ::
        E = \sum_{j=0}^k |p(x_j) - y_j|^2

    in the equations::

        x[0]**n * p[n] + ... + x[0] * p[1] + p[0] = y[0]
        x[1]**n * p[n] + ... + x[1] * p[1] + p[0] = y[1]
        ...
        x[k]**n * p[n] + ... + x[k] * p[1] + p[0] = y[k]

    The coefficient matrix of the coefficients `p` is a Vandermonde matrix.

    `polyfit` issues a `RankWarning` when the least-squares fit is badly
    conditioned. This implies that the best fit is not well-defined due
    to numerical error. The results may be improved by lowering the polynomial
    degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter
    can also be set to a value smaller than its default, but the resulting
    fit may be spurious: including contributions from the small singular
    values can add numerical noise to the result.

    Note that fitting polynomial coefficients is inherently badly conditioned
    when the degree of the polynomial is large or the interval of sample points
    is badly centered. The quality of the fit should always be checked in these
    cases. When polynomial fits are not satisfactory, splines may be a good
    alternative.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting
    .. [2] Wikipedia, "Polynomial interpolation",
           http://en.wikipedia.org/wiki/Polynomial_interpolation

    Examples
    --------
    >>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])
    >>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])
    >>> z = np.polyfit(x, y, 3)
    >>> z
    array([ 0.08703704, -0.81349206,  1.69312169, -0.03968254])

    It is convenient to use `poly1d` objects for dealing with polynomials:

    >>> p = np.poly1d(z)
    >>> p(0.5)
    0.6143849206349179
    >>> p(3.5)
    -0.34732142857143039
    >>> p(10)
    22.579365079365115

    High-order polynomials may oscillate wildly:

    >>> p30 = np.poly1d(np.polyfit(x, y, 30))
    /... RankWarning: Polyfit may be poorly conditioned...
    >>> p30(4)
    -0.80000000000000204
    >>> p30(5)
    -0.99999999999999445
    >>> p30(4.5)
    -0.10547061179440398

    Illustration:

    >>> import matplotlib.pyplot as plt
    >>> xp = np.linspace(-2, 6, 100)
    >>> plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')
    [<matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>]
    >>> plt.ylim(-2,2)
    (-2, 2)
    >>> plt.show()

    input must be 1d or square 2d array.Order of derivative must be positive (see polyint)
    Find the sum of two polynomials.

    Returns the polynomial resulting from the sum of two input polynomials.
    Each input must be either a poly1d object or a 1D sequence of polynomial
    coefficients, from highest to lowest degree.

    Parameters
    ----------
    a1, a2 : array_like or poly1d object
        Input polynomials.

    Returns
    -------
    out : ndarray or poly1d object
        The sum of the inputs. If either input is a poly1d object, then the
        output is also a poly1d object. Otherwise, it is a 1D array of
        polynomial coefficients from highest to lowest degree.

    See Also
    --------
    poly1d : A one-dimensional polynomial class.
    poly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval

    Examples
    --------
    >>> np.polyadd([1, 2], [9, 5, 4])
    array([9, 6, 6])

    Using poly1d objects:

    >>> p1 = np.poly1d([1, 2])
    >>> p2 = np.poly1d([9, 5, 4])
    >>> print p1
    1 x + 2
    >>> print p2
       2
    9 x + 5 x + 4
    >>> print np.polyadd(p1, p2)
       2
    9 x + 6 x + 6

    
    Return the roots of a polynomial with coefficients given in p.

    The values in the rank-1 array `p` are coefficients of a polynomial.
    If the length of `p` is n+1 then the polynomial is described by::

      p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]

    Parameters
    ----------
    p : array_like
        Rank-1 array of polynomial coefficients.

    Returns
    -------
    out : ndarray
        An array containing the complex roots of the polynomial.

    Raises
    ------
    ValueError
        When `p` cannot be converted to a rank-1 array.

    See also
    --------
    poly : Find the coefficients of a polynomial with a given sequence
           of roots.
    polyval : Evaluate a polynomial at a point.
    polyfit : Least squares polynomial fit.
    poly1d : A one-dimensional polynomial class.

    Notes
    -----
    The algorithm relies on computing the eigenvalues of the
    companion matrix [1]_.

    References
    ----------
    .. [1] R. A. Horn & C. R. Johnson, *Matrix Analysis*.  Cambridge, UK:
        Cambridge University Press, 1999, pp. 146-7.

    Examples
    --------
    >>> coeff = [3.2, 2, 1]
    >>> np.roots(coeff)
    array([-0.3125+0.46351241j, -0.3125-0.46351241j])

    %.4gPolynomial must be 1d only.(%s + %sj)/usr/lib/python2.7/dist-packages/numpy/lib/polynomial.pyInput must be a rank-1 array.
    A one-dimensional polynomial class.

    A convenience class, used to encapsulate "natural" operations on
    polynomials so that said operations may take on their customary
    form in code (see Examples).

    Parameters
    ----------
    c_or_r : array_like
        The polynomial's coefficients, in decreasing powers, or if
        the value of the second parameter is True, the polynomial's
        roots (values where the polynomial evaluates to 0).  For example,
        ``poly1d([1, 2, 3])`` returns an object that represents
        :math:`x^2 + 2x + 3`, whereas ``poly1d([1, 2, 3], True)`` returns
        one that represents :math:`(x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6`.
    r : bool, optional
        If True, `c_or_r` specifies the polynomial's roots; the default
        is False.
    variable : str, optional
        Changes the variable used when printing `p` from `x` to `variable`
        (see Examples).

    Examples
    --------
    Construct the polynomial :math:`x^2 + 2x + 3`:

    >>> p = np.poly1d([1, 2, 3])
    >>> print np.poly1d(p)
       2
    1 x + 2 x + 3

    Evaluate the polynomial at :math:`x = 0.5`:

    >>> p(0.5)
    4.25

    Find the roots:

    >>> p.r
    array([-1.+1.41421356j, -1.-1.41421356j])
    >>> p(p.r)
    array([ -4.44089210e-16+0.j,  -4.44089210e-16+0.j])

    These numbers in the previous line represent (0, 0) to machine precision

    Show the coefficients:

    >>> p.c
    array([1, 2, 3])

    Display the order (the leading zero-coefficients are removed):

    >>> p.order
    2

    Show the coefficient of the k-th power in the polynomial
    (which is equivalent to ``p.c[-(i+1)]``):

    >>> p[1]
    2

    Polynomials can be added, subtracted, multiplied, and divided
    (returns quotient and remainder):

    >>> p * p
    poly1d([ 1,  4, 10, 12,  9])

    >>> (p**3 + 4) / p
    (poly1d([  1.,   4.,  10.,  12.,   9.]), poly1d([ 4.]))

    ``asarray(p)`` gives the coefficient array, so polynomials can be
    used in all functions that accept arrays:

    >>> p**2 # square of polynomial
    poly1d([ 1,  4, 10, 12,  9])

    >>> np.square(p) # square of individual coefficients
    array([1, 4, 9])

    The variable used in the string representation of `p` can be modified,
    using the `variable` parameter:

    >>> p = np.poly1d([1,2,3], variable='z')
    >>> print p
       2
    1 z + 2 z + 3

    Construct a polynomial from its roots:

    >>> np.poly1d([1, 2], True)
    poly1d([ 1, -3,  2])

    This is the same polynomial as obtained by:

    >>> np.poly1d([1, -1]) * np.poly1d([1, -2])
    poly1d([ 1, -3,  2])

    
    Return an antiderivative (indefinite integral) of a polynomial.

    The returned order `m` antiderivative `P` of polynomial `p` satisfies
    :math:`\frac{d^m}{dx^m}P(x) = p(x)` and is defined up to `m - 1`
    integration constants `k`. The constants determine the low-order
    polynomial part

    .. math:: \frac{k_{m-1}}{0!} x^0 + \ldots + \frac{k_0}{(m-1)!}x^{m-1}

    of `P` so that :math:`P^{(j)}(0) = k_{m-j-1}`.

    Parameters
    ----------
    p : {array_like, poly1d}
        Polynomial to differentiate.
        A sequence is interpreted as polynomial coefficients, see `poly1d`.
    m : int, optional
        Order of the antiderivative. (Default: 1)
    k : {None, list of `m` scalars, scalar}, optional
        Integration constants. They are given in the order of integration:
        those corresponding to highest-order terms come first.

        If ``None`` (default), all constants are assumed to be zero.
        If `m = 1`, a single scalar can be given instead of a list.

    See Also
    --------
    polyder : derivative of a polynomial
    poly1d.integ : equivalent method

    Examples
    --------
    The defining property of the antiderivative:

    >>> p = np.poly1d([1,1,1])
    >>> P = np.polyint(p)
    >>> P
    poly1d([ 0.33333333,  0.5       ,  1.        ,  0.        ])
    >>> np.polyder(P) == p
    True

    The integration constants default to zero, but can be specified:

    >>> P = np.polyint(p, 3)
    >>> P(0)
    0.0
    >>> np.polyder(P)(0)
    0.0
    >>> np.polyder(P, 2)(0)
    0.0
    >>> P = np.polyint(p, 3, k=[6,5,3])
    >>> P
    poly1d([ 0.01666667,  0.04166667,  0.16666667,  3. ,  5. ,  3. ])

    Note that 3 = 6 / 2!, and that the constants are given in the order of
    integrations. Constant of the highest-order polynomial term comes first:

    >>> np.polyder(P, 2)(0)
    6.0
    >>> np.polyder(P, 1)(0)
    5.0
    >>> P(0)
    3.0

    
    Returns the quotient and remainder of polynomial division.

    The input arrays are the coefficients (including any coefficients
    equal to zero) of the "numerator" (dividend) and "denominator"
    (divisor) polynomials, respectively.

    Parameters
    ----------
    u : array_like or poly1d
        Dividend polynomial's coefficients.

    v : array_like or poly1d
        Divisor polynomial's coefficients.

    Returns
    -------
    q : ndarray
        Coefficients, including those equal to zero, of the quotient.
    r : ndarray
        Coefficients, including those equal to zero, of the remainder.

    See Also
    --------
    poly, polyadd, polyder, polydiv, polyfit, polyint, polymul, polysub,
    polyval

    Notes
    -----
    Both `u` and `v` must be 0-d or 1-d (ndim = 0 or 1), but `u.ndim` need
    not equal `v.ndim`. In other words, all four possible combinations -
    ``u.ndim = v.ndim = 0``, ``u.ndim = v.ndim = 1``,
    ``u.ndim = 1, v.ndim = 0``, and ``u.ndim = 0, v.ndim = 1`` - work.

    Examples
    --------
    .. math:: \frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25

    >>> x = np.array([3.0, 5.0, 2.0])
    >>> y = np.array([2.0, 1.0])
    >>> np.polydiv(x, y)
    (array([ 1.5 ,  1.75]), array([ 0.25]))

    _ln2logn
    Compute the inverse cosine of x.

    Return the "principal value" (for a description of this, see
    `numpy.arccos`) of the inverse cosine of `x`. For real `x` such that
    `abs(x) <= 1`, this is a real number in the closed interval
    :math:`[0, \pi]`.  Otherwise, the complex principle value is returned.

    Parameters
    ----------
    x : array_like or scalar
       The value(s) whose arccos is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The inverse cosine(s) of the `x` value(s). If `x` was a scalar, so
       is `out`, otherwise an array object is returned.

    See Also
    --------
    numpy.arccos

    Notes
    -----
    For an arccos() that returns ``NAN`` when real `x` is not in the
    interval ``[-1,1]``, use `numpy.arccos`.

    Examples
    --------
    >>> np.set_printoptions(precision=4)

    >>> np.emath.arccos(1) # a scalar is returned
    0.0

    >>> np.emath.arccos([1,2])
    array([ 0.-0.j   ,  0.+1.317j])

    Convert its input `arr` to a complex array.

    The input is returned as a complex array of the smallest type that will fit
    the original data: types like single, byte, short, etc. become csingle,
    while others become cdouble.

    A copy of the input is always made.

    Parameters
    ----------
    arr : array

    Returns
    -------
    array
        An array with the same input data as the input but in complex form.

    Examples
    --------

    First, consider an input of type short:

    >>> a = np.array([1,2,3],np.short)

    >>> ac = np.lib.scimath._tocomplex(a); ac
    array([ 1.+0.j,  2.+0.j,  3.+0.j], dtype=complex64)

    >>> ac.dtype
    dtype('complex64')

    If the input is of type double, the output is correspondingly of the
    complex double type as well:

    >>> b = np.array([1,2,3],np.double)

    >>> bc = np.lib.scimath._tocomplex(b); bc
    array([ 1.+0.j,  2.+0.j,  3.+0.j])

    >>> bc.dtype
    dtype('complex128')

    Note that even if the input was complex to begin with, a copy is still
    made, since the astype() method always copies:

    >>> c = np.array([1,2,3],np.csingle)

    >>> cc = np.lib.scimath._tocomplex(c); cc
    array([ 1.+0.j,  2.+0.j,  3.+0.j], dtype=complex64)

    >>> c *= 2; c
    array([ 2.+0.j,  4.+0.j,  6.+0.j], dtype=complex64)

    >>> cc
    array([ 1.+0.j,  2.+0.j,  3.+0.j], dtype=complex64)
    Convert `x` to double if it has real, negative components.

    Otherwise, output is just the array version of the input (via asarray).

    Parameters
    ----------
    x : array_like

    Returns
    -------
    array

    Examples
    --------
    >>> np.lib.scimath._fix_int_lt_zero([1,2])
    array([1, 2])

    >>> np.lib.scimath._fix_int_lt_zero([-1,2])
    array([-1.,  2.])
    Convert `x` to complex if it has real components x_i with abs(x_i)>1.

    Otherwise, output is just the array version of the input (via asarray).

    Parameters
    ----------
    x : array_like

    Returns
    -------
    array

    Examples
    --------
    >>> np.lib.scimath._fix_real_abs_gt_1([0,1])
    array([0, 1])

    >>> np.lib.scimath._fix_real_abs_gt_1([0,2])
    array([ 0.+0.j,  2.+0.j])
    
    Return x to the power p, (x**p).

    If `x` contains negative values, the output is converted to the
    complex domain.

    Parameters
    ----------
    x : array_like
        The input value(s).
    p : array_like of ints
        The power(s) to which `x` is raised. If `x` contains multiple values,
        `p` has to either be a scalar, or contain the same number of values
        as `x`. In the latter case, the result is
        ``x[0]**p[0], x[1]**p[1], ...``.

    Returns
    -------
    out : ndarray or scalar
        The result of ``x**p``. If `x` and `p` are scalars, so is `out`,
        otherwise an array is returned.

    See Also
    --------
    numpy.power

    Examples
    --------
    >>> np.set_printoptions(precision=4)

    >>> np.lib.scimath.power([2, 4], 2)
    array([ 4, 16])
    >>> np.lib.scimath.power([2, 4], -2)
    array([ 0.25  ,  0.0625])
    >>> np.lib.scimath.power([-2, 4], 2)
    array([  4.+0.j,  16.+0.j])

    Convert `x` to complex if it has real, negative components.

    Otherwise, output is just the array version of the input (via asarray).

    Parameters
    ----------
    x : array_like

    Returns
    -------
    array

    Examples
    --------
    >>> np.lib.scimath._fix_real_lt_zero([1,2])
    array([1, 2])

    >>> np.lib.scimath._fix_real_lt_zero([-1,2])
    array([-1.+0.j,  2.+0.j])
    
    Take log base n of x.

    If `x` contains negative inputs, the answer is computed and returned in the
    complex domain.

    Parameters
    ----------
    n : int
       The base in which the log is taken.
    x : array_like
       The value(s) whose log base `n` is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The log base `n` of the `x` value(s). If `x` was a scalar, so is
       `out`, otherwise an array is returned.

    Examples
    --------
    >>> np.set_printoptions(precision=4)

    >>> np.lib.scimath.logn(2, [4, 8])
    array([ 2.,  3.])
    >>> np.lib.scimath.logn(2, [-4, -8, 8])
    array([ 2.+4.5324j,  3.+4.5324j,  3.+0.j    ])

    
    Compute the natural logarithm of `x`.

    Return the "principal value" (for a description of this, see `numpy.log`)
    of :math:`log_e(x)`. For real `x > 0`, this is a real number (``log(0)``
    returns ``-inf`` and ``log(np.inf)`` returns ``inf``). Otherwise, the
    complex principle value is returned.

    Parameters
    ----------
    x : array_like
       The value(s) whose log is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The log of the `x` value(s). If `x` was a scalar, so is `out`,
       otherwise an array is returned.

    See Also
    --------
    numpy.log

    Notes
    -----
    For a log() that returns ``NAN`` when real `x < 0`, use `numpy.log`
    (note, however, that otherwise `numpy.log` and this `log` are identical,
    i.e., both return ``-inf`` for `x = 0`, ``inf`` for `x = inf`, and,
    notably, the complex principle value if ``x.imag != 0``).

    Examples
    --------
    >>> np.emath.log(np.exp(1))
    1.0

    Negative arguments are handled "correctly" (recall that
    ``exp(log(x)) == x`` does *not* hold for real ``x < 0``):

    >>> np.emath.log(-np.exp(1)) == (1 + np.pi * 1j)
    True

    
    Compute the logarithm base 10 of `x`.

    Return the "principal value" (for a description of this, see
    `numpy.log10`) of :math:`log_{10}(x)`. For real `x > 0`, this
    is a real number (``log10(0)`` returns ``-inf`` and ``log10(np.inf)``
    returns ``inf``). Otherwise, the complex principle value is returned.

    Parameters
    ----------
    x : array_like or scalar
       The value(s) whose log base 10 is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The log base 10 of the `x` value(s). If `x` was a scalar, so is `out`,
       otherwise an array object is returned.

    See Also
    --------
    numpy.log10

    Notes
    -----
    For a log10() that returns ``NAN`` when real `x < 0`, use `numpy.log10`
    (note, however, that otherwise `numpy.log10` and this `log10` are
    identical, i.e., both return ``-inf`` for `x = 0`, ``inf`` for `x = inf`,
    and, notably, the complex principle value if ``x.imag != 0``).

    Examples
    --------

    (We set the printing precision so the example can be auto-tested)

    >>> np.set_printoptions(precision=4)

    >>> np.emath.log10(10**1)
    1.0

    >>> np.emath.log10([-10**1, -10**2, 10**2])
    array([ 1.+1.3644j,  2.+1.3644j,  2.+0.j    ])

    
    Compute the square root of x.

    For negative input elements, a complex value is returned
    (unlike `numpy.sqrt` which returns NaN).

    Parameters
    ----------
    x : array_like
       The input value(s).

    Returns
    -------
    out : ndarray or scalar
       The square root of `x`. If `x` was a scalar, so is `out`,
       otherwise an array is returned.

    See Also
    --------
    numpy.sqrt

    Examples
    --------
    For real, non-negative inputs this works just like `numpy.sqrt`:

    >>> np.lib.scimath.sqrt(1)
    1.0
    >>> np.lib.scimath.sqrt([1, 4])
    array([ 1.,  2.])

    But it automatically handles negative inputs:

    >>> np.lib.scimath.sqrt(-1)
    (0.0+1.0j)
    >>> np.lib.scimath.sqrt([-1,4])
    array([ 0.+1.j,  2.+0.j])

    
    Compute the logarithm base 2 of `x`.

    Return the "principal value" (for a description of this, see
    `numpy.log2`) of :math:`log_2(x)`. For real `x > 0`, this is
    a real number (``log2(0)`` returns ``-inf`` and ``log2(np.inf)`` returns
    ``inf``). Otherwise, the complex principle value is returned.

    Parameters
    ----------
    x : array_like
       The value(s) whose log base 2 is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The log base 2 of the `x` value(s). If `x` was a scalar, so is `out`,
       otherwise an array is returned.

    See Also
    --------
    numpy.log2

    Notes
    -----
    For a log2() that returns ``NAN`` when real `x < 0`, use `numpy.log2`
    (note, however, that otherwise `numpy.log2` and this `log2` are
    identical, i.e., both return ``-inf`` for `x = 0`, ``inf`` for `x = inf`,
    and, notably, the complex principle value if ``x.imag != 0``).

    Examples
    --------
    We set the printing precision so the example can be auto-tested:

    >>> np.set_printoptions(precision=4)

    >>> np.emath.log2(8)
    3.0
    >>> np.emath.log2([-4, -8, 8])
    array([ 2.+4.5324j,  3.+4.5324j,  3.+0.j    ])

    
Wrapper functions to more user-friendly calling of certain math functions
whose output data-type is different than the input data-type in certain
domains of the input.

For example, for functions like `log` with branch cuts, the versions in this
module provide the mathematically valid answers in the complex plane::

  >>> import math
  >>> from numpy.lib import scimath
  >>> scimath.log(-math.exp(1)) == (1+1j*math.pi)
  True

Similarly, `sqrt`, other base logarithms, `power` and trig functions are
correctly handled.  See their respective docstrings for specific examples.

/usr/lib/python2.7/dist-packages/numpy/lib/scimath.py
    Compute the inverse sine of x.

    Return the "principal value" (for a description of this, see
    `numpy.arcsin`) of the inverse sine of `x`. For real `x` such that
    `abs(x) <= 1`, this is a real number in the closed interval
    :math:`[-\pi/2, \pi/2]`.  Otherwise, the complex principle value is
    returned.

    Parameters
    ----------
    x : array_like or scalar
       The value(s) whose arcsin is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The inverse sine(s) of the `x` value(s). If `x` was a scalar, so
       is `out`, otherwise an array object is returned.

    See Also
    --------
    numpy.arcsin

    Notes
    -----
    For an arcsin() that returns ``NAN`` when real `x` is not in the
    interval ``[-1,1]``, use `numpy.arcsin`.

    Examples
    --------
    >>> np.set_printoptions(precision=4)

    >>> np.emath.arcsin(0)
    0.0

    >>> np.emath.arcsin([0,1])
    array([ 0.    ,  1.5708])

    
    Compute the inverse hyperbolic tangent of `x`.

    Return the "principal value" (for a description of this, see
    `numpy.arctanh`) of `arctanh(x)`. For real `x` such that
    `abs(x) < 1`, this is a real number.  If `abs(x) > 1`, or if `x` is
    complex, the result is complex. Finally, `x = 1` returns``inf`` and
    `x=-1` returns ``-inf``.

    Parameters
    ----------
    x : array_like
       The value(s) whose arctanh is (are) required.

    Returns
    -------
    out : ndarray or scalar
       The inverse hyperbolic tangent(s) of the `x` value(s). If `x` was
       a scalar so is `out`, otherwise an array is returned.


    See Also
    --------
    numpy.arctanh

    Notes
    -----
    For an arctanh() that returns ``NAN`` when real `x` is not in the
    interval ``(-1,1)``, use `numpy.arctanh` (this latter, however, does
    return +/-inf for `x = +/-1`).

    Examples
    --------
    >>> np.set_printoptions(precision=4)

    >>> np.emath.arctanh(np.matrix(np.eye(2)))
    array([[ Inf,   0.],
           [  0.,  Inf]])
    >>> np.emath.arctanh([1j])
    array([ 0.+0.7854j])

    dim_outsection_sizesnumber sections must be larger than 0.vsplit only works on arrays of 3 or more dimensions
    Kronecker product of two arrays.

    Computes the Kronecker product, a composite array made of blocks of the
    second array scaled by the first.

    Parameters
    ----------
    a, b : array_like

    Returns
    -------
    out : ndarray

    See Also
    --------
    outer : The outer product

    Notes
    -----
    The function assumes that the number of dimenensions of `a` and `b`
    are the same, if necessary prepending the smallest with ones.
    If `a.shape = (r0,r1,..,rN)` and `b.shape = (s0,s1,...,sN)`,
    the Kronecker product has shape `(r0*s0, r1*s1, ..., rN*SN)`.
    The elements are products of elements from `a` and `b`, organized
    explicitly by::

        kron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]

    where::

        kt = it * st + jt,  t = 0,...,N

    In the common 2-D case (N=1), the block structure can be visualized::

        [[ a[0,0]*b,   a[0,1]*b,  ... , a[0,-1]*b  ],
         [  ...                              ...   ],
         [ a[-1,0]*b,  a[-1,1]*b, ... , a[-1,-1]*b ]]


    Examples
    --------
    >>> np.kron([1,10,100], [5,6,7])
    array([  5,   6,   7,  50,  60,  70, 500, 600, 700])
    >>> np.kron([5,6,7], [1,10,100])
    array([  5,  50, 500,   6,  60, 600,   7,  70, 700])

    >>> np.kron(np.eye(2), np.ones((2,2)))
    array([[ 1.,  1.,  0.,  0.],
           [ 1.,  1.,  0.,  0.],
           [ 0.,  0.,  1.,  1.],
           [ 0.,  0.,  1.,  1.]])

    >>> a = np.arange(100).reshape((2,5,2,5))
    >>> b = np.arange(24).reshape((2,3,4))
    >>> c = np.kron(a,b)
    >>> c.shape
    (2, 10, 6, 20)
    >>> I = (1,3,0,2)
    >>> J = (0,2,1)
    >>> J1 = (0,) + J             # extend to ndim=4
    >>> S1 = (1,) + b.shape
    >>> K = tuple(np.array(I) * np.array(S1) + np.array(J1))
    >>> c[K] == a[I]*b[J]
    True

    
    Split an array into multiple sub-arrays horizontally (column-wise).

    Please refer to the `split` documentation.  `hsplit` is equivalent
    to `split` with ``axis=1``, the array is always split along the second
    axis regardless of the array dimension.

    See Also
    --------
    split : Split an array into multiple sub-arrays of equal size.

    Examples
    --------
    >>> x = np.arange(16.0).reshape(4, 4)
    >>> x
    array([[  0.,   1.,   2.,   3.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.],
           [ 12.,  13.,  14.,  15.]])
    >>> np.hsplit(x, 2)
    [array([[  0.,   1.],
           [  4.,   5.],
           [  8.,   9.],
           [ 12.,  13.]]),
     array([[  2.,   3.],
           [  6.,   7.],
           [ 10.,  11.],
           [ 14.,  15.]])]
    >>> np.hsplit(x, np.array([3, 6]))
    [array([[  0.,   1.,   2.],
           [  4.,   5.,   6.],
           [  8.,   9.,  10.],
           [ 12.,  13.,  14.]]),
     array([[  3.],
           [  7.],
           [ 11.],
           [ 15.]]),
     array([], dtype=float64)]

    With a higher dimensional array the split is still along the second axis.

    >>> x = np.arange(8.0).reshape(2, 2, 2)
    >>> x
    array([[[ 0.,  1.],
            [ 2.,  3.]],
           [[ 4.,  5.],
            [ 6.,  7.]]])
    >>> np.hsplit(x, 2)
    [array([[[ 0.,  1.]],
           [[ 4.,  5.]]]),
     array([[[ 2.,  3.]],
           [[ 6.,  7.]]])]

    
    Split an array into multiple sub-arrays.

    Parameters
    ----------
    ary : ndarray
        Array to be divided into sub-arrays.
    indices_or_sections : int or 1-D array
        If `indices_or_sections` is an integer, N, the array will be divided
        into N equal arrays along `axis`.  If such a split is not possible,
        an error is raised.

        If `indices_or_sections` is a 1-D array of sorted integers, the entries
        indicate where along `axis` the array is split.  For example,
        ``[2, 3]`` would, for ``axis=0``, result in

          - ary[:2]
          - ary[2:3]
          - ary[3:]

        If an index exceeds the dimension of the array along `axis`,
        an empty sub-array is returned correspondingly.
    axis : int, optional
        The axis along which to split, default is 0.

    Returns
    -------
    sub-arrays : list of ndarrays
        A list of sub-arrays.

    Raises
    ------
    ValueError
        If `indices_or_sections` is given as an integer, but
        a split does not result in equal division.

    See Also
    --------
    array_split : Split an array into multiple sub-arrays of equal or
                  near-equal size.  Does not raise an exception if
                  an equal division cannot be made.
    hsplit : Split array into multiple sub-arrays horizontally (column-wise).
    vsplit : Split array into multiple sub-arrays vertically (row wise).
    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).
    concatenate : Join arrays together.
    hstack : Stack arrays in sequence horizontally (column wise).
    vstack : Stack arrays in sequence vertically (row wise).
    dstack : Stack arrays in sequence depth wise (along third dimension).

    Examples
    --------
    >>> x = np.arange(9.0)
    >>> np.split(x, 3)
    [array([ 0.,  1.,  2.]), array([ 3.,  4.,  5.]), array([ 6.,  7.,  8.])]

    >>> x = np.arange(8.0)
    >>> np.split(x, [3, 5, 6, 10])
    [array([ 0.,  1.,  2.]),
     array([ 3.,  4.]),
     array([ 5.]),
     array([ 6.,  7.]),
     array([], dtype=float64)]

    array split does not result in an equal division/usr/lib/python2.7/dist-packages/numpy/lib/shape_base.pyvsplit only works on arrays of 2 or more dimensions
    Split an array into multiple sub-arrays vertically (row-wise).

    Please refer to the ``split`` documentation.  ``vsplit`` is equivalent
    to ``split`` with `axis=0` (default), the array is always split along the
    first axis regardless of the array dimension.

    See Also
    --------
    split : Split an array into multiple sub-arrays of equal size.

    Examples
    --------
    >>> x = np.arange(16.0).reshape(4, 4)
    >>> x
    array([[  0.,   1.,   2.,   3.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.],
           [ 12.,  13.,  14.,  15.]])
    >>> np.vsplit(x, 2)
    [array([[ 0.,  1.,  2.,  3.],
           [ 4.,  5.,  6.,  7.]]),
     array([[  8.,   9.,  10.,  11.],
           [ 12.,  13.,  14.,  15.]])]
    >>> np.vsplit(x, np.array([3, 6]))
    [array([[  0.,   1.,   2.,   3.],
           [  4.,   5.,   6.,   7.],
           [  8.,   9.,  10.,  11.]]),
     array([[ 12.,  13.,  14.,  15.]]),
     array([], dtype=float64)]

    With a higher dimensional array the split is still along the first axis.

    >>> x = np.arange(8.0).reshape(2, 2, 2)
    >>> x
    array([[[ 0.,  1.],
            [ 2.,  3.]],
           [[ 4.,  5.],
            [ 6.,  7.]]])
    >>> np.vsplit(x, 2)
    [array([[[ 0.,  1.],
            [ 2.,  3.]]]),
     array([[[ 4.,  5.],
            [ 6.,  7.]]])]

    numpy.lib.shape_base
    Stack 1-D arrays as columns into a 2-D array.

    Take a sequence of 1-D arrays and stack them as columns
    to make a single 2-D array. 2-D arrays are stacked as-is,
    just like with `hstack`.  1-D arrays are turned into 2-D columns
    first.

    Parameters
    ----------
    tup : sequence of 1-D or 2-D arrays.
        Arrays to stack. All of them must have the same first dimension.

    Returns
    -------
    stacked : 2-D array
        The array formed by stacking the given arrays.

    See Also
    --------
    hstack, vstack, concatenate

    Notes
    -----
    This function is equivalent to ``np.vstack(tup).T``.

    Examples
    --------
    >>> a = np.array((1,2,3))
    >>> b = np.array((2,3,4))
    >>> np.column_stack((a,b))
    array([[1, 2],
           [2, 3],
           [3, 4]])

    
    Stack arrays in sequence depth wise (along third axis).

    Takes a sequence of arrays and stack them along the third axis
    to make a single array. Rebuilds arrays divided by `dsplit`.
    This is a simple way to stack 2D arrays (images) into a single
    3D array for processing.

    Parameters
    ----------
    tup : sequence of arrays
        Arrays to stack. All of them must have the same shape along all
        but the third axis.

    Returns
    -------
    stacked : ndarray
        The array formed by stacking the given arrays.

    See Also
    --------
    vstack : Stack along first axis.
    hstack : Stack along second axis.
    concatenate : Join arrays.
    dsplit : Split array along third axis.

    Notes
    -----
    Equivalent to ``np.concatenate(tup, axis=2)``.

    Examples
    --------
    >>> a = np.array((1,2,3))
    >>> b = np.array((2,3,4))
    >>> np.dstack((a,b))
    array([[[1, 2],
            [2, 3],
            [3, 4]]])

    >>> a = np.array([[1],[2],[3]])
    >>> b = np.array([[2],[3],[4]])
    >>> np.dstack((a,b))
    array([[[1, 2]],
           [[2, 3]],
           [[3, 4]]])

    Find the wrapper for the array with the highest priority.

    In case of ties, leftmost wins. If no wrapper is found, return None
    
    Expand the shape of an array.

    Insert a new axis, corresponding to a given position in the array shape.

    Parameters
    ----------
    a : array_like
        Input array.
    axis : int
        Position (amongst axes) where new axis is to be inserted.

    Returns
    -------
    res : ndarray
        Output array. The number of dimensions is one greater than that of
        the input array.

    See Also
    --------
    doc.indexing, atleast_1d, atleast_2d, atleast_3d

    Examples
    --------
    >>> x = np.array([1,2])
    >>> x.shape
    (2,)

    The following is equivalent to ``x[np.newaxis,:]`` or ``x[np.newaxis]``:

    >>> y = np.expand_dims(x, axis=0)
    >>> y
    array([[1, 2]])
    >>> y.shape
    (1, 2)

    >>> y = np.expand_dims(x, axis=1)  # Equivalent to x[:,newaxis]
    >>> y
    array([[1],
           [2]])
    >>> y.shape
    (2, 1)

    Note that some examples may use ``None`` instead of ``np.newaxis``.  These
    are the same objects:

    >>> np.newaxis is None
    True

    hsplit only works on arrays of 1 or more dimensionsfunction is not returning an array of the correct shape
    Apply a function to 1-D slices along the given axis.

    Execute `func1d(a, *args)` where `func1d` operates on 1-D arrays and `a`
    is a 1-D slice of `arr` along `axis`.

    Parameters
    ----------
    func1d : function
        This function should accept 1-D arrays. It is applied to 1-D
        slices of `arr` along the specified axis.
    axis : integer
        Axis along which `arr` is sliced.
    arr : ndarray
        Input array.
    args : any
        Additional arguments to `func1d`.

    Returns
    -------
    apply_along_axis : ndarray
        The output array. The shape of `outarr` is identical to the shape of
        `arr`, except along the `axis` dimension, where the length of `outarr`
        is equal to the size of the return value of `func1d`.  If `func1d`
        returns a scalar `outarr` will have one fewer dimensions than `arr`.

    See Also
    --------
    apply_over_axes : Apply a function repeatedly over multiple axes.

    Examples
    --------
    >>> def my_func(a):
    ...     """Average first and last element of a 1-D array"""
    ...     return (a[0] + a[-1]) * 0.5
    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])
    >>> np.apply_along_axis(my_func, 0, b)
    array([ 4.,  5.,  6.])
    >>> np.apply_along_axis(my_func, 1, b)
    array([ 2.,  5.,  8.])

    For a function that doesn't return a scalar, the number of dimensions in
    `outarr` is the same as `arr`.

    >>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])
    >>> np.apply_along_axis(sorted, 1, b)
    array([[1, 7, 8],
           [3, 4, 9],
           [2, 5, 6]])

    
    Apply a function repeatedly over multiple axes.

    `func` is called as `res = func(a, axis)`, where `axis` is the first
    element of `axes`.  The result `res` of the function call must have
    either the same dimensions as `a` or one less dimension.  If `res`
    has one less dimension than `a`, a dimension is inserted before
    `axis`.  The call to `func` is then repeated for each axis in `axes`,
    with `res` as the first argument.

    Parameters
    ----------
    func : function
        This function must take two arguments, `func(a, axis)`.
    a : array_like
        Input array.
    axes : array_like
        Axes over which `func` is applied; the elements must be integers.

    Returns
    -------
    apply_over_axis : ndarray
        The output array.  The number of dimensions is the same as `a`,
        but the shape can be different.  This depends on whether `func`
        changes the shape of its output with respect to its input.

    See Also
    --------
    apply_along_axis :
        Apply a function to 1-D slices of an array along the given axis.

    Examples
    --------
    >>> a = np.arange(24).reshape(2,3,4)
    >>> a
    array([[[ 0,  1,  2,  3],
            [ 4,  5,  6,  7],
            [ 8,  9, 10, 11]],
           [[12, 13, 14, 15],
            [16, 17, 18, 19],
            [20, 21, 22, 23]]])

    Sum over axes 0 and 2. The result has same number of dimensions
    as the original array:

    >>> np.apply_over_axes(np.sum, a, [0,2])
    array([[[ 60],
            [ 92],
            [124]]])

    
    Split an array into multiple sub-arrays.

    Please refer to the ``split`` documentation.  The only difference
    between these functions is that ``array_split`` allows
    `indices_or_sections` to be an integer that does *not* equally
    divide the axis.

    See Also
    --------
    split : Split array into multiple sub-arrays of equal size.

    Examples
    --------
    >>> x = np.arange(8.0)
    >>> np.array_split(x, 3)
        [array([ 0.,  1.,  2.]), array([ 3.,  4.,  5.]), array([ 6.,  7.])]

    
    Split array into multiple sub-arrays along the 3rd axis (depth).

    Please refer to the `split` documentation.  `dsplit` is equivalent
    to `split` with ``axis=2``, the array is always split along the third
    axis provided the array dimension is greater than or equal to 3.

    See Also
    --------
    split : Split an array into multiple sub-arrays of equal size.

    Examples
    --------
    >>> x = np.arange(16.0).reshape(2, 2, 4)
    >>> x
    array([[[  0.,   1.,   2.,   3.],
            [  4.,   5.,   6.,   7.]],
           [[  8.,   9.,  10.,  11.],
            [ 12.,  13.,  14.,  15.]]])
    >>> np.dsplit(x, 2)
    [array([[[  0.,   1.],
            [  4.,   5.]],
           [[  8.,   9.],
            [ 12.,  13.]]]),
     array([[[  2.,   3.],
            [  6.,   7.]],
           [[ 10.,  11.],
            [ 14.,  15.]]])]
    >>> np.dsplit(x, np.array([3, 6]))
    [array([[[  0.,   1.,   2.],
            [  4.,   5.,   6.]],
           [[  8.,   9.,  10.],
            [ 12.,  13.,  14.]]]),
     array([[[  3.],
            [  7.]],
           [[ 11.],
            [ 15.]]]),
     array([], dtype=float64)]

    
    Construct an array by repeating A the number of times given by reps.

    If `reps` has length ``d``, the result will have dimension of
    ``max(d, A.ndim)``.

    If ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new
    axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,
    or shape (1, 1, 3) for 3-D replication. If this is not the desired
    behavior, promote `A` to d-dimensions manually before calling this
    function.

    If ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.
    Thus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as
    (1, 1, 2, 2).

    Parameters
    ----------
    A : array_like
        The input array.
    reps : array_like
        The number of repetitions of `A` along each axis.

    Returns
    -------
    c : ndarray
        The tiled output array.

    See Also
    --------
    repeat : Repeat elements of an array.

    Examples
    --------
    >>> a = np.array([0, 1, 2])
    >>> np.tile(a, 2)
    array([0, 1, 2, 0, 1, 2])
    >>> np.tile(a, (2, 2))
    array([[0, 1, 2, 0, 1, 2],
           [0, 1, 2, 0, 1, 2]])
    >>> np.tile(a, (2, 1, 2))
    array([[[0, 1, 2, 0, 1, 2]],
           [[0, 1, 2, 0, 1, 2]]])

    >>> b = np.array([[1, 2], [3, 4]])
    >>> np.tile(b, 2)
    array([[1, 2, 1, 2],
           [3, 4, 3, 4]])
    >>> np.tile(b, (2, 1))
    array([[1, 2],
           [3, 4],
           [1, 2],
           [3, 4]])

     Dummy object that just exists to hang __array_interface__ dictionaries
    and possibly keep alive a reference to a base array.
     Make an ndarray from the given array with the given shape and strides.
    
    Broadcast any number of arrays against each other.

    Parameters
    ----------
    `*args` : array_likes
        The arrays to broadcast.

    Returns
    -------
    broadcasted : list of arrays
        These arrays are views on the original arrays.  They are typically
        not contiguous.  Furthermore, more than one element of a
        broadcasted array may refer to a single memory location.  If you
        need to write to the arrays, make copies first.

    Examples
    --------
    >>> x = np.array([[1,2,3]])
    >>> y = np.array([[1],[2],[3]])
    >>> np.broadcast_arrays(x, y)
    [array([[1, 2, 3],
           [1, 2, 3],
           [1, 2, 3]]), array([[1, 1, 1],
           [2, 2, 2],
           [3, 3, 3]])]

    Here is a useful idiom for getting contiguous copies instead of
    non-contiguous views.

    >>> [np.array(a) for a in np.broadcast_arrays(x, y)]
    [array([[1, 2, 3],
           [1, 2, 3],
           [1, 2, 3]]), array([[1, 1, 1],
           [2, 2, 2],
           [3, 3, 3]])]

    /usr/lib/python2.7/dist-packages/numpy/lib/stride_tricks.py
Utilities that manipulate strides to achieve desirable effects.

An explanation of strides can be found in the "ndarray.rst" file in the
NumPy reference guide.

shape mismatch: two or more arrays have incompatible dimensions on axis %r.tril_indices_fromtriu_indices_from
    Flip array in the up/down direction.

    Flip the entries in each column in the up/down direction.
    Rows are preserved, but appear in a different order than before.

    Parameters
    ----------
    m : array_like
        Input array.

    Returns
    -------
    out : array_like
        A view of `m` with the rows reversed.  Since a view is
        returned, this operation is :math:`\mathcal O(1)`.

    See Also
    --------
    fliplr : Flip array in the left/right direction.
    rot90 : Rotate array counterclockwise.

    Notes
    -----
    Equivalent to ``A[::-1,...]``.
    Does not require the array to be two-dimensional.

    Examples
    --------
    >>> A = np.diag([1.0, 2, 3])
    >>> A
    array([[ 1.,  0.,  0.],
           [ 0.,  2.,  0.],
           [ 0.,  0.,  3.]])
    >>> np.flipud(A)
    array([[ 0.,  0.,  3.],
           [ 0.,  2.,  0.],
           [ 1.,  0.,  0.]])

    >>> A = np.random.randn(2,3,5)
    >>> np.all(np.flipud(A)==A[::-1,...])
    True

    >>> np.flipud([1,2])
    array([2, 1])

    
    Compute the bi-dimensional histogram of two data samples.

    Parameters
    ----------
    x : array_like, shape (N,)
        An array containing the x coordinates of the points to be
        histogrammed.
    y : array_like, shape (N,)
        An array containing the y coordinates of the points to be
        histogrammed.
    bins : int or [int, int] or array_like or [array, array], optional
        The bin specification:

          * If int, the number of bins for the two dimensions (nx=ny=bins).
          * If [int, int], the number of bins in each dimension (nx, ny = bins).
          * If array_like, the bin edges for the two dimensions
            (x_edges=y_edges=bins).
          * If [array, array], the bin edges in each dimension
            (x_edges, y_edges = bins).

    range : array_like, shape(2,2), optional
        The leftmost and rightmost edges of the bins along each dimension
        (if not specified explicitly in the `bins` parameters):
        ``[[xmin, xmax], [ymin, ymax]]``. All values outside of this range
        will be considered outliers and not tallied in the histogram.
    normed : bool, optional
        If False, returns the number of samples in each bin. If True,
        returns the bin density ``bin_count / sample_count / bin_area``.
    weights : array_like, shape(N,), optional
        An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.
        Weights are normalized to 1 if `normed` is True. If `normed` is
        False, the values of the returned histogram are equal to the sum of
        the weights belonging to the samples falling into each bin.

    Returns
    -------
    H : ndarray, shape(nx, ny)
        The bi-dimensional histogram of samples `x` and `y`. Values in `x`
        are histogrammed along the first dimension and values in `y` are
        histogrammed along the second dimension.
    xedges : ndarray, shape(nx,)
        The bin edges along the first dimension.
    yedges : ndarray, shape(ny,)
        The bin edges along the second dimension.

    See Also
    --------
    histogram : 1D histogram
    histogramdd : Multidimensional histogram

    Notes
    -----
    When `normed` is True, then the returned histogram is the sample
    density, defined such that the sum over bins of the product
    ``bin_value * bin_area`` is 1.

    Please note that the histogram does not follow the Cartesian convention
    where `x` values are on the abscissa and `y` values on the ordinate
    axis.  Rather, `x` is histogrammed along the first dimension of the
    array (vertical), and `y` along the second dimension of the array
    (horizontal).  This ensures compatibility with `histogramdd`.

    Examples
    --------
    >>> import matplotlib as mpl
    >>> import matplotlib.pyplot as plt

    Construct a 2D-histogram with variable bin width. First define the bin
    edges:

    >>> xedges = [0, 1, 1.5, 3, 5]
    >>> yedges = [0, 2, 3, 4, 6]

    Next we create a histogram H with random bin content:

    >>> x = np.random.normal(3, 1, 100)
    >>> y = np.random.normal(1, 1, 100)
    >>> H, xedges, yedges = np.histogram2d(y, x, bins=(xedges, yedges))

    Or we fill the histogram H with a determined bin content:

    >>> H = np.ones((4, 4)).cumsum().reshape(4, 4)
    >>> print H[::-1]  # This shows the bin content in the order as plotted
    [[ 13.  14.  15.  16.]
     [  9.  10.  11.  12.]
     [  5.   6.   7.   8.]
     [  1.   2.   3.   4.]]

    Imshow can only do an equidistant representation of bins:

    >>> fig = plt.figure(figsize=(7, 3))
    >>> ax = fig.add_subplot(131)
    >>> ax.set_title('imshow:
equidistant')
    >>> im = plt.imshow(H, interpolation='nearest', origin='low',
                    extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])

    pcolormesh can displaying exact bin edges:

    >>> ax = fig.add_subplot(132)
    >>> ax.set_title('pcolormesh:
exact bin edges')
    >>> X, Y = np.meshgrid(xedges, yedges)
    >>> ax.pcolormesh(X, Y, H)
    >>> ax.set_aspect('equal')

    NonUniformImage displays exact bin edges with interpolation:

    >>> ax = fig.add_subplot(133)
    >>> ax.set_title('NonUniformImage:
interpolated')
    >>> im = mpl.image.NonUniformImage(ax, interpolation='bilinear')
    >>> xcenters = xedges[:-1] + 0.5 * (xedges[1:] - xedges[:-1])
    >>> ycenters = yedges[:-1] + 0.5 * (yedges[1:] - yedges[:-1])
    >>> im.set_data(xcenters, ycenters, H)
    >>> ax.images.append(im)
    >>> ax.set_xlim(xedges[0], xedges[-1])
    >>> ax.set_ylim(yedges[0], yedges[-1])
    >>> ax.set_aspect('equal')
    >>> plt.show()

    
    Flip array in the left/right direction.

    Flip the entries in each row in the left/right direction.
    Columns are preserved, but appear in a different order than before.

    Parameters
    ----------
    m : array_like
        Input array.

    Returns
    -------
    f : ndarray
        A view of `m` with the columns reversed.  Since a view
        is returned, this operation is :math:`\mathcal O(1)`.

    See Also
    --------
    flipud : Flip array in the up/down direction.
    rot90 : Rotate array counterclockwise.

    Notes
    -----
    Equivalent to A[:,::-1]. Does not require the array to be
    two-dimensional.

    Examples
    --------
    >>> A = np.diag([1.,2.,3.])
    >>> A
    array([[ 1.,  0.,  0.],
           [ 0.,  2.,  0.],
           [ 0.,  0.,  3.]])
    >>> np.fliplr(A)
    array([[ 0.,  0.,  1.],
           [ 0.,  2.,  0.],
           [ 3.,  0.,  0.]])

    >>> A = np.random.randn(2,3,5)
    >>> np.all(np.fliplr(A)==A[:,::-1,...])
    True

    
    Return the indices for the lower-triangle of arr.

    See `tril_indices` for full details.

    Parameters
    ----------
    arr : array_like
        The indices will be valid for square arrays whose dimensions are
        the same as arr.
    k : int, optional
        Diagonal offset (see `tril` for details).

    See Also
    --------
    tril_indices, tril

    Notes
    -----
    .. versionadded:: 1.4.0

    
    Extract a diagonal or construct a diagonal array.

    See the more detailed documentation for ``numpy.diagonal`` if you use this
    function to extract a diagonal and wish to write to the resulting array;
    whether it returns a copy or a view depends on what version of numpy you
    are using.

    Parameters
    ----------
    v : array_like
        If `v` is a 2-D array, return a copy of its `k`-th diagonal.
        If `v` is a 1-D array, return a 2-D array with `v` on the `k`-th
        diagonal.
    k : int, optional
        Diagonal in question. The default is 0. Use `k>0` for diagonals
        above the main diagonal, and `k<0` for diagonals below the main
        diagonal.

    Returns
    -------
    out : ndarray
        The extracted diagonal or constructed diagonal array.

    See Also
    --------
    diagonal : Return specified diagonals.
    diagflat : Create a 2-D array with the flattened input as a diagonal.
    trace : Sum along diagonals.
    triu : Upper triangle of an array.
    tril : Lower triange of an array.

    Examples
    --------
    >>> x = np.arange(9).reshape((3,3))
    >>> x
    array([[0, 1, 2],
           [3, 4, 5],
           [6, 7, 8]])

    >>> np.diag(x)
    array([0, 4, 8])
    >>> np.diag(x, k=1)
    array([1, 5])
    >>> np.diag(x, k=-1)
    array([3, 7])

    >>> np.diag(np.diag(x))
    array([[0, 0, 0],
           [0, 4, 0],
           [0, 0, 8]])

    Input must >= 2-d.
    Generate a Van der Monde matrix.

    The columns of the output matrix are decreasing powers of the input
    vector.  Specifically, the `i`-th output column is the input vector
    raised element-wise to the power of ``N - i - 1``.  Such a matrix with
    a geometric progression in each row is named for Alexandre-Theophile
    Vandermonde.

    Parameters
    ----------
    x : array_like
        1-D input array.
    N : int, optional
        Order of (number of columns in) the output.  If `N` is not specified,
        a square array is returned (``N = len(x)``).

    Returns
    -------
    out : ndarray
        Van der Monde matrix of order `N`.  The first column is ``x^(N-1)``,
        the second ``x^(N-2)`` and so forth.

    Examples
    --------
    >>> x = np.array([1, 2, 3, 5])
    >>> N = 3
    >>> np.vander(x, N)
    array([[ 1,  1,  1],
           [ 4,  2,  1],
           [ 9,  3,  1],
           [25,  5,  1]])

    >>> np.column_stack([x**(N-1-i) for i in range(N)])
    array([[ 1,  1,  1],
           [ 4,  2,  1],
           [ 9,  3,  1],
           [25,  5,  1]])

    >>> x = np.array([1, 2, 3, 5])
    >>> np.vander(x)
    array([[  1,   1,   1,   1],
           [  8,   4,   2,   1],
           [ 27,   9,   3,   1],
           [125,  25,   5,   1]])

    The determinant of a square Vandermonde matrix is the product
    of the differences between the values of the input vector:

    >>> np.linalg.det(np.vander(x))
    48.000000000000043
    >>> (5-3)*(5-2)*(5-1)*(3-2)*(3-1)*(2-1)
    48

    
    Return a 2-D array with ones on the diagonal and zeros elsewhere.

    Parameters
    ----------
    N : int
      Number of rows in the output.
    M : int, optional
      Number of columns in the output. If None, defaults to `N`.
    k : int, optional
      Index of the diagonal: 0 (the default) refers to the main diagonal,
      a positive value refers to an upper diagonal, and a negative value
      to a lower diagonal.
    dtype : data-type, optional
      Data-type of the returned array.

    Returns
    -------
    I : ndarray of shape (N,M)
      An array where all elements are equal to zero, except for the `k`-th
      diagonal, whose values are equal to one.

    See Also
    --------
    identity : (almost) equivalent function
    diag : diagonal 2-D array from a 1-D array specified by the user.

    Examples
    --------
    >>> np.eye(2, dtype=int)
    array([[1, 0],
           [0, 1]])
    >>> np.eye(3, k=1)
    array([[ 0.,  1.,  0.],
           [ 0.,  0.,  1.],
           [ 0.,  0.,  0.]])

    input array must be 2-d and squareInput must be 1- or 2-d.
    Lower triangle of an array.

    Return a copy of an array with elements above the `k`-th diagonal zeroed.

    Parameters
    ----------
    m : array_like, shape (M, N)
        Input array.
    k : int, optional
        Diagonal above which to zero elements.  `k = 0` (the default) is the
        main diagonal, `k < 0` is below it and `k > 0` is above.

    Returns
    -------
    tril : ndarray, shape (M, N)
        Lower triangle of `m`, of same shape and data-type as `m`.

    See Also
    --------
    triu : same thing, only for the upper triangle

    Examples
    --------
    >>> np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)
    array([[ 0,  0,  0],
           [ 4,  0,  0],
           [ 7,  8,  0],
           [10, 11, 12]])

    Input must be >= 1-d.
    Return the indices for the upper-triangle of a (N, N) array.

    See `triu_indices` for full details.

    Parameters
    ----------
    arr : ndarray, shape(N, N)
        The indices will be valid for square arrays.
    k : int, optional
        Diagonal offset (see `triu` for details).

    Returns
    -------
    triu_indices_from : tuple, shape(2) of ndarray, shape(N)
        Indices for the upper-triangle of `arr`.

    See Also
    --------
    triu_indices, triu

    Notes
    -----
    .. versionadded:: 1.4.0

    
    Upper triangle of an array.

    Return a copy of a matrix with the elements below the `k`-th diagonal
    zeroed.

    Please refer to the documentation for `tril` for further details.

    See Also
    --------
    tril : lower triangle of an array

    Examples
    --------
    >>> np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)
    array([[ 1,  2,  3],
           [ 4,  5,  6],
           [ 0,  8,  9],
           [ 0,  0, 12]])

    
    Return the indices to access (n, n) arrays, given a masking function.

    Assume `mask_func` is a function that, for a square array a of size
    ``(n, n)`` with a possible offset argument `k`, when called as
    ``mask_func(a, k)`` returns a new array with zeros in certain locations
    (functions like `triu` or `tril` do precisely this). Then this function
    returns the indices where the non-zero values would be located.

    Parameters
    ----------
    n : int
        The returned indices will be valid to access arrays of shape (n, n).
    mask_func : callable
        A function whose call signature is similar to that of `triu`, `tril`.
        That is, ``mask_func(x, k)`` returns a boolean array, shaped like `x`.
        `k` is an optional argument to the function.
    k : scalar
        An optional argument which is passed through to `mask_func`. Functions
        like `triu`, `tril` take a second argument that is interpreted as an
        offset.

    Returns
    -------
    indices : tuple of arrays.
        The `n` arrays of indices corresponding to the locations where
        ``mask_func(np.ones((n, n)), k)`` is True.

    See Also
    --------
    triu, tril, triu_indices, tril_indices

    Notes
    -----
    .. versionadded:: 1.4.0

    Examples
    --------
    These are the indices that would allow you to access the upper triangular
    part of any 3x3 array:

    >>> iu = np.mask_indices(3, np.triu)

    For example, if `a` is a 3x3 array:

    >>> a = np.arange(9).reshape(3, 3)
    >>> a
    array([[0, 1, 2],
           [3, 4, 5],
           [6, 7, 8]])
    >>> a[iu]
    array([0, 1, 2, 4, 5, 8])

    An offset can be passed also to the masking function.  This gets us the
    indices starting on the first diagonal right of the main one:

    >>> iu1 = np.mask_indices(3, np.triu, 1)

    with which we now extract only three elements:

    >>> a[iu1]
    array([1, 2, 5])

    
    Rotate an array by 90 degrees in the counter-clockwise direction.

    The first two dimensions are rotated; therefore, the array must be at
    least 2-D.

    Parameters
    ----------
    m : array_like
        Array of two or more dimensions.
    k : integer
        Number of times the array is rotated by 90 degrees.

    Returns
    -------
    y : ndarray
        Rotated array.

    See Also
    --------
    fliplr : Flip an array horizontally.
    flipud : Flip an array vertically.

    Examples
    --------
    >>> m = np.array([[1,2],[3,4]], int)
    >>> m
    array([[1, 2],
           [3, 4]])
    >>> np.rot90(m)
    array([[2, 4],
           [1, 3]])
    >>> np.rot90(m, 2)
    array([[4, 3],
           [2, 1]])

    Input must be >= 2-d.
    Return the indices for the upper-triangle of an (n, n) array.

    Parameters
    ----------
    n : int
        The size of the arrays for which the returned indices will
        be valid.
    k : int, optional
        Diagonal offset (see `triu` for details).

    Returns
    -------
    inds : tuple, shape(2) of ndarrays, shape(`n`)
        The indices for the triangle. The returned tuple contains two arrays,
        each with the indices along one dimension of the array.  Can be used
        to slice a ndarray of shape(`n`, `n`).

    See also
    --------
    tril_indices : similar function, for lower-triangular.
    mask_indices : generic function accepting an arbitrary mask function.
    triu, tril

    Notes
    -----
    .. versionadded:: 1.4.0

    Examples
    --------
    Compute two different sets of indices to access 4x4 arrays, one for the
    upper triangular part starting at the main diagonal, and one starting two
    diagonals further right:

    >>> iu1 = np.triu_indices(4)
    >>> iu2 = np.triu_indices(4, 2)

    Here is how they can be used with a sample array:

    >>> a = np.arange(16).reshape(4, 4)
    >>> a
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])

    Both for indexing:

    >>> a[iu1]
    array([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 15])

    And for assigning values:

    >>> a[iu1] = -1
    >>> a
    array([[-1, -1, -1, -1],
           [ 4, -1, -1, -1],
           [ 8,  9, -1, -1],
           [12, 13, 14, -1]])

    These cover only a small part of the whole array (two diagonals right
    of the main one):

    >>> a[iu2] = -10
    >>> a
    array([[ -1,  -1, -10, -10],
           [  4,  -1,  -1, -10],
           [  8,   9,  -1,  -1],
           [ 12,  13,  14,  -1]])

    
    Return the indices for the lower-triangle of an (n, n) array.

    Parameters
    ----------
    n : int
        The row dimension of the square arrays for which the returned
        indices will be valid.
    k : int, optional
        Diagonal offset (see `tril` for details).

    Returns
    -------
    inds : tuple of arrays
        The indices for the triangle. The returned tuple contains two arrays,
        each with the indices along one dimension of the array.

    See also
    --------
    triu_indices : similar function, for upper-triangular.
    mask_indices : generic function accepting an arbitrary mask function.
    tril, triu

    Notes
    -----
    .. versionadded:: 1.4.0

    Examples
    --------
    Compute two different sets of indices to access 4x4 arrays, one for the
    lower triangular part starting at the main diagonal, and one starting two
    diagonals further right:

    >>> il1 = np.tril_indices(4)
    >>> il2 = np.tril_indices(4, 2)

    Here is how they can be used with a sample array:

    >>> a = np.arange(16).reshape(4, 4)
    >>> a
    array([[ 0,  1,  2,  3],
           [ 4,  5,  6,  7],
           [ 8,  9, 10, 11],
           [12, 13, 14, 15]])

    Both for indexing:

    >>> a[il1]
    array([ 0,  4,  5,  8,  9, 10, 12, 13, 14, 15])

    And for assigning values:

    >>> a[il1] = -1
    >>> a
    array([[-1,  1,  2,  3],
           [-1, -1,  6,  7],
           [-1, -1, -1, 11],
           [-1, -1, -1, -1]])

    These cover almost the whole array (two diagonals right of the main one):

    >>> a[il2] = -10
    >>> a
    array([[-10, -10, -10,   3],
           [-10, -10, -10, -10],
           [-10, -10, -10, -10],
           [-10, -10, -10, -10]])

    
    Create a two-dimensional array with the flattened input as a diagonal.

    Parameters
    ----------
    v : array_like
        Input data, which is flattened and set as the `k`-th
        diagonal of the output.
    k : int, optional
        Diagonal to set; 0, the default, corresponds to the "main" diagonal,
        a positive (negative) `k` giving the number of the diagonal above
        (below) the main.

    Returns
    -------
    out : ndarray
        The 2-D output array.

    See Also
    --------
    diag : MATLAB work-alike for 1-D and 2-D arrays.
    diagonal : Return specified diagonals.
    trace : Sum along diagonals.

    Examples
    --------
    >>> np.diagflat([[1,2], [3,4]])
    array([[1, 0, 0, 0],
           [0, 2, 0, 0],
           [0, 0, 3, 0],
           [0, 0, 0, 4]])

    >>> np.diagflat([1,2], 1)
    array([[0, 1, 0],
           [0, 0, 2],
           [0, 0, 0]])

    
    An array with ones at and below the given diagonal and zeros elsewhere.

    Parameters
    ----------
    N : int
        Number of rows in the array.
    M : int, optional
        Number of columns in the array.
        By default, `M` is taken equal to `N`.
    k : int, optional
        The sub-diagonal at and below which the array is filled.
        `k` = 0 is the main diagonal, while `k` < 0 is below it,
        and `k` > 0 is above.  The default is 0.
    dtype : dtype, optional
        Data type of the returned array.  The default is float.

    Returns
    -------
    tri : ndarray of shape (N, M)
        Array with its lower triangle filled with ones and zero elsewhere;
        in other words ``T[i,j] == 1`` for ``i <= j + k``, 0 otherwise.

    Examples
    --------
    >>> np.tri(3, 5, 2, dtype=int)
    array([[1, 1, 1, 0, 0],
           [1, 1, 1, 1, 0],
           [1, 1, 1, 1, 1]])

    >>> np.tri(3, 5, -1)
    array([[ 0.,  0.,  0.,  0.,  0.],
           [ 1.,  0.,  0.,  0.,  0.],
           [ 1.,  1.,  0.,  0.,  0.]])

    /usr/lib/python2.7/dist-packages/numpy/lib/twodim_base.py Basic functions for manipulating 2d arrays

GDFgdf{s   S1s	   charactert   ?s   boolt   Bs   unsigned chart   Ds   complex double precisiont   Gs   complex long double precisiont   Fs   complex single precisiont   Is   unsigned integert   Hs   unsigned shortt   Ls   unsigned long integert   Os   objectt   Qs   unsigned long long integert   Ss   stringt   Us   unicodet   Vs   voidt   bs   signed chart   ds   double precisiont   gs   long precisiont   fs   single precisiont   is   integert   hs   shortt   ls   long integert   qs   long long integer0/usr/lib/python2.7/dist-packages/numpy/lib/type_check.pycan't get common type for non-numeric array
    Return the real part of the elements of the array.

    Parameters
    ----------
    val : array_like
        Input array.

    Returns
    -------
    out : ndarray
        Output array. If `val` is real, the type of `val` is used for the
        output.  If `val` has complex elements, the returned type is float.

    See Also
    --------
    real_if_close, imag, angle

    Examples
    --------
    >>> a = np.array([1+2j, 3+4j, 5+6j])
    >>> a.real
    array([ 1.,  3.,  5.])
    >>> a.real = 9
    >>> a
    array([ 9.+2.j,  9.+4.j,  9.+6.j])
    >>> a.real = np.array([9, 8, 7])
    >>> a
    array([ 9.+2.j,  8.+4.j,  7.+6.j])

    Automatically adapted for numpy Sep 19, 2005 by convertcode.py


    If complex input returns a real array if complex parts are close to zero.

    "Close to zero" is defined as `tol` * (machine epsilon of the type for
    `a`).

    Parameters
    ----------
    a : array_like
        Input array.
    tol : float
        Tolerance in machine epsilons for the complex part of the elements
        in the array.

    Returns
    -------
    out : ndarray
        If `a` is real, the type of `a` is used for the output.  If `a`
        has complex elements, the returned type is float.

    See Also
    --------
    real, imag, angle

    Notes
    -----
    Machine epsilon varies from machine to machine and between data types
    but Python floats on most platforms have a machine epsilon equal to
    2.2204460492503131e-16.  You can use 'np.finfo(np.float).eps' to print
    out the machine epsilon for floats.

    Examples
    --------
    >>> np.finfo(np.float).eps
    2.2204460492503131e-16

    >>> np.real_if_close([2.1 + 4e-14j], tol=1000)
    array([ 2.1])
    >>> np.real_if_close([2.1 + 4e-13j], tol=1000)
    array([ 2.1 +4.00000000e-13j])

    
    Replace nan with zero and inf with finite numbers.

    Returns an array or scalar replacing Not a Number (NaN) with zero,
    (positive) infinity with a very large number and negative infinity
    with a very small (or negative) number.

    Parameters
    ----------
    x : array_like
        Input data.

    Returns
    -------
    out : ndarray, float
        Array with the same shape as `x` and dtype of the element in `x`  with
        the greatest precision. NaN is replaced by zero, and infinity
        (-infinity) is replaced by the largest (smallest or most negative)
        floating point value that fits in the output dtype. All finite numbers
        are upcast to the output dtype (default float64).

    See Also
    --------
    isinf : Shows which elements are negative or negative infinity.
    isneginf : Shows which elements are negative infinity.
    isposinf : Shows which elements are positive infinity.
    isnan : Shows which elements are Not a Number (NaN).
    isfinite : Shows which elements are finite (not NaN, not infinity)

    Notes
    -----
    Numpy uses the IEEE Standard for Binary Floating-Point for Arithmetic
    (IEEE 754). This means that Not a Number is not equivalent to infinity.


    Examples
    --------
    >>> np.set_printoptions(precision=8)
    >>> x = np.array([np.inf, -np.inf, np.nan, -128, 128])
    >>> np.nan_to_num(x)
    array([  1.79769313e+308,  -1.79769313e+308,   0.00000000e+000,
            -1.28000000e+002,   1.28000000e+002])

    
    Returns a bool array, where True if input element is real.

    If element has complex type with zero complex part, the return value
    for that element is True.

    Parameters
    ----------
    x : array_like
        Input array.

    Returns
    -------
    out : ndarray, bool
        Boolean array of same shape as `x`.

    See Also
    --------
    iscomplex
    isrealobj : Return True if x is not a complex type.

    Examples
    --------
    >>> np.isreal([1+1j, 1+0j, 4.5, 3, 2, 2j])
    array([False,  True,  True,  True,  True, False], dtype=bool)

    
    Return an array converted to a float type.

    Parameters
    ----------
    a : array_like
        The input array.
    dtype : str or dtype object, optional
        Float type code to coerce input array `a`.  If `dtype` is one of the
        'int' dtypes, it is replaced with float64.

    Returns
    -------
    out : ndarray
        The input `a` as a float ndarray.

    Examples
    --------
    >>> np.asfarray([2, 3])
    array([ 2.,  3.])
    >>> np.asfarray([2, 3], dtype='float')
    array([ 2.,  3.])
    >>> np.asfarray([2, 3], dtype='int8')
    array([ 2.,  3.])

    
    Return a scalar type which is common to the input arrays.

    The return type will always be an inexact (i.e. floating point) scalar
    type, even if all the arrays are integer arrays. If one of the inputs is
    an integer array, the minimum precision type that is returned is a
    64-bit floating point dtype.

    All input arrays can be safely cast to the returned dtype without loss
    of information.

    Parameters
    ----------
    array1, array2, ... : ndarrays
        Input arrays.

    Returns
    -------
    out : data type code
        Data type code.

    See Also
    --------
    dtype, mintypecode

    Examples
    --------
    >>> np.common_type(np.arange(2, dtype=np.float32))
    <type 'numpy.float32'>
    >>> np.common_type(np.arange(2, dtype=np.float32), np.arange(2))
    <type 'numpy.float64'>
    >>> np.common_type(np.arange(4), np.array([45, 6.j]), np.array([45.0]))
    <type 'numpy.complex128'>

    
    Check for a complex type or an array of complex numbers.

    The type of the input is checked, not the value. Even if the input
    has an imaginary part equal to zero, `iscomplexobj` evaluates to True.

    Parameters
    ----------
    x : any
        The input can be of any type and shape.

    Returns
    -------
    iscomplexobj : bool
        The return value, True if `x` is of a complex type or has at least
        one complex element.

    See Also
    --------
    isrealobj, iscomplex

    Examples
    --------
    >>> np.iscomplexobj(1)
    False
    >>> np.iscomplexobj(1+0j)
    True
    >>> np.iscomplexobj([3, 1+0j, True])
    True

    
    Return a description for the given data type code.

    Parameters
    ----------
    char : str
        Data type code.

    Returns
    -------
    out : str
        Description of the input data type code.

    See Also
    --------
    dtype, typecodes

    Examples
    --------
    >>> typechars = ['S1', '?', 'B', 'D', 'G', 'F', 'I', 'H', 'L', 'O', 'Q',
    ...              'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q']
    >>> for typechar in typechars:
    ...     print typechar, ' : ', np.typename(typechar)
    ...
    S1  :  character
    ?  :  bool
    B  :  unsigned char
    D  :  complex double precision
    G  :  complex long double precision
    F  :  complex single precision
    I  :  unsigned integer
    H  :  unsigned short
    L  :  unsigned long integer
    O  :  object
    Q  :  unsigned long long integer
    S  :  string
    U  :  unicode
    V  :  void
    b  :  signed char
    d  :  double precision
    g  :  long precision
    f  :  single precision
    i  :  integer
    h  :  short
    l  :  long integer
    q  :  long long integer

    
    Return True if x is a not complex type or an array of complex numbers.

    The type of the input is checked, not the value. So even if the input
    has an imaginary part equal to zero, `isrealobj` evaluates to False
    if the data type is complex.

    Parameters
    ----------
    x : any
        The input can be of any type and shape.

    Returns
    -------
    y : bool
        The return value, False if `x` is of a complex type.

    See Also
    --------
    iscomplexobj, isreal

    Examples
    --------
    >>> np.isrealobj(1)
    True
    >>> np.isrealobj(1+0j)
    False
    >>> np.isrealobj([3, 1+0j, True])
    False

    
    Return the character for the minimum-size type to which given types can
    be safely cast.

    The returned type character must represent the smallest size dtype such
    that an array of the returned type can handle the data from an array of
    all types in `typechars` (or if `typechars` is an array, then its
    dtype.char).

    Parameters
    ----------
    typechars : list of str or array_like
        If a list of strings, each string should represent a dtype.
        If array_like, the character representation of the array dtype is used.
    typeset : str or list of str, optional
        The set of characters that the returned character is chosen from.
        The default set is 'GDFgdf'.
    default : str, optional
        The default character, this is returned if none of the characters in
        `typechars` matches a character in `typeset`.

    Returns
    -------
    typechar : str
        The character representing the minimum-size type that was found.

    See Also
    --------
    dtype, sctype2char, maximum_sctype

    Examples
    --------
    >>> np.mintypecode(['d', 'f', 'S'])
    'd'
    >>> x = np.array([1.1, 2-3.j])
    >>> np.mintypecode(x)
    'D'

    >>> np.mintypecode('abceh', default='G')
    'G'

    
    Returns a bool array, where True if input element is complex.

    What is tested is whether the input has a non-zero imaginary part, not if
    the input type is complex.

    Parameters
    ----------
    x : array_like
        Input array.

    Returns
    -------
    out : ndarray of bools
        Output array.

    See Also
    --------
    isreal
    iscomplexobj : Return True if x is a complex type or an array of complex
                   numbers.

    Examples
    --------
    >>> np.iscomplex([1+1j, 1+0j, 4.5, 3, 2, 2j])
    array([ True, False, False, False, False,  True], dtype=bool)

    
    Return the imaginary part of the elements of the array.

    Parameters
    ----------
    val : array_like
        Input array.

    Returns
    -------
    out : ndarray
        Output array. If `val` is real, the type of `val` is used for the
        output.  If `val` has complex elements, the returned type is float.

    See Also
    --------
    real, angle, real_if_close

    Examples
    --------
    >>> a = np.array([1+2j, 3+4j, 5+6j])
    >>> a.imag
    array([ 2.,  4.,  6.])
    >>> a.imag = np.array([8, 10, 12])
    >>> a
    array([ 1. +8.j,  3.+10.j,  5.+12.j])

    GDFgdfQqLlIiHhBb?
    Convert an array of size 1 to its scalar equivalent.

    Parameters
    ----------
    a : ndarray
        Input array of size 1.

    Returns
    -------
    out : scalar
        Scalar representation of `a`. The output data type is the same type
        returned by the input's `item` method.

    Examples
    --------
    >>> np.asscalar(np.array([24]))
    24

    /usr/lib/python2.7/dist-packages/numpy/lib/ufunclike.py
    Test element-wise for negative infinity, return result as bool array.

    Parameters
    ----------
    x : array_like
        The input array.
    y : array_like, optional
        A boolean array with the same shape and type as `x` to store the
        result.

    Returns
    -------
    y : ndarray
        A boolean array with the same dimensions as the input.
        If second argument is not supplied then a numpy boolean array is
        returned with values True where the corresponding element of the
        input is negative infinity and values False where the element of
        the input is not negative infinity.

        If a second argument is supplied the result is stored there. If the
        type of that array is a numeric type the result is represented as
        zeros and ones, if the type is boolean then as False and True. The
        return value `y` is then a reference to that array.

    See Also
    --------
    isinf, isposinf, isnan, isfinite

    Notes
    -----
    Numpy uses the IEEE Standard for Binary Floating-Point for Arithmetic
    (IEEE 754).

    Errors result if the second argument is also supplied when x is a scalar
    input, or if first and second arguments have different shapes.

    Examples
    --------
    >>> np.isneginf(np.NINF)
    array(True, dtype=bool)
    >>> np.isneginf(np.inf)
    array(False, dtype=bool)
    >>> np.isneginf(np.PINF)
    array(False, dtype=bool)
    >>> np.isneginf([-np.inf, 0., np.inf])
    array([ True, False, False], dtype=bool)

    >>> x = np.array([-np.inf, 0., np.inf])
    >>> y = np.array([2, 2, 2])
    >>> np.isneginf(x, y)
    array([1, 0, 0])
    >>> y
    array([1, 0, 0])

    
Module of functions that are like ufuncs in acting on arrays and optionally
storing results in an output array.


    Test element-wise for positive infinity, return result as bool array.

    Parameters
    ----------
    x : array_like
        The input array.
    y : array_like, optional
        A boolean array with the same shape as `x` to store the result.

    Returns
    -------
    y : ndarray
        A boolean array with the same dimensions as the input.
        If second argument is not supplied then a boolean array is returned
        with values True where the corresponding element of the input is
        positive infinity and values False where the element of the input is
        not positive infinity.

        If a second argument is supplied the result is stored there. If the
        type of that array is a numeric type the result is represented as zeros
        and ones, if the type is boolean then as False and True.
        The return value `y` is then a reference to that array.

    See Also
    --------
    isinf, isneginf, isfinite, isnan

    Notes
    -----
    Numpy uses the IEEE Standard for Binary Floating-Point for Arithmetic
    (IEEE 754).

    Errors result if the second argument is also supplied when `x` is a
    scalar input, or if first and second arguments have different shapes.

    Examples
    --------
    >>> np.isposinf(np.PINF)
    array(True, dtype=bool)
    >>> np.isposinf(np.inf)
    array(True, dtype=bool)
    >>> np.isposinf(np.NINF)
    array(False, dtype=bool)
    >>> np.isposinf([-np.inf, 0., np.inf])
    array([False, False,  True], dtype=bool)

    >>> x = np.array([-np.inf, 0., np.inf])
    >>> y = np.array([2, 2, 2])
    >>> np.isposinf(x, y)
    array([0, 0, 1])
    >>> y
    array([0, 0, 1])

    numpy.lib.ufunclike
    Round to nearest integer towards zero.

    Round an array of floats element-wise to nearest integer towards zero.
    The rounded values are returned as floats.

    Parameters
    ----------
    x : array_like
        An array of floats to be rounded
    y : ndarray, optional
        Output array

    Returns
    -------
    out : ndarray of floats
        The array of rounded numbers

    See Also
    --------
    trunc, floor, ceil
    around : Round to given number of decimals

    Examples
    --------
    >>> np.fix(3.14)
    3.0
    >>> np.fix(3)
    3.0
    >>> np.fix([2.1, 2.9, -2.1, -2.9])
    array([ 2.,  2., -2., -2.])

    idvUAddUSubeltspagerprvala_dataaddstrargstrbytestrmoddictnamestrthis_pythisobjastridesgetpagershapestrsplitdocvisitNumvisitStrvisitDictvisitListvisitNameallmethodsold_stderrold_stdoutvisitBytesvisitConstvisitTuplebyte_boundsInstanceTypevisitUnaryOpgetChildNodesvisitUnaryAddvisitUnarySub_ppimport_attrrelevance_valuevisitExpression_ppimport_modulevisitNameConstant_ppimport_importerdeprecate_with_docget_numarray_include`%s` is deprecated, use `%s` instead!  %s  --  %sNot available for this object.Instance of class: Unsupported source construct: %s
        Decorator call.  Refer to ``decorate``.

        
    Return the directory that contains the NumPy \*.h header files.

    Extension modules that need to compile against NumPy should use this
    function to locate the appropriate include directory.

    Notes
    -----
    When using ``distutils``, for example in ``setup.py``.
    ::

        import numpy as np
        ...
        Extension('extension_name', ...
                include_dirs=[np.get_include()])
        ...

    
    Returns pointers to the end-points of an array.

    Parameters
    ----------
    a : ndarray
        Input array. It must conform to the Python-side of the array interface.

    Returns
    -------
    (low, high) : tuple of 2 integers
        The first integer is the first byte of the array, the second integer is
        just past the last byte of the array.  If `a` is not contiguous it
        will not use every byte between the (`low`, `high`) values.

    Examples
    --------
    >>> I = np.eye(2, dtype='f'); I.dtype
    dtype('float32')
    >>> low, high = np.byte_bounds(I)
    >>> high - low == I.size*I.itemsize
    True
    >>> I = np.eye(2, dtype='G'); I.dtype
    dtype('complex192')
    >>> low, high = np.byte_bounds(I)
    >>> high - low == I.size*I.itemsize
    True

    
    Print or write to a file the source code for a Numpy object.

    The source code is only returned for objects written in Python. Many
    functions and classes are defined in C and will therefore not return
    useful information.

    Parameters
    ----------
    object : numpy object
        Input object. This can be any object (function, class, module, ...).
    output : file object, optional
        If `output` not supplied then source code is printed to screen
        (sys.stdout).  File object must be created with either write 'w' or
        append 'a' modes.

    See Also
    --------
    lookfor, info

    Examples
    --------
    >>> np.source(np.interp)                        #doctest: +SKIP
    In file: /usr/lib/python2.6/dist-packages/numpy/lib/function_base.py
    def interp(x, xp, fp, left=None, right=None):
        """.... (full docstring printed)"""
        if isinstance(x, (float, int, number)):
            return compiled_interp([x], xp, fp, left, right).item()
        else:
            return compiled_interp(x, xp, fp, left, right)

    The source code is only returned for objects written in Python.

    >>> np.source(np.array)                         #doctest: +SKIP
    Not available for this object.

    

Methods:
%s %s %s %s %s %s %s[a-z0-9_]+\(.*[,=].*\)
    Get help information for a function, class, or module.

    Parameters
    ----------
    object : object or str, optional
        Input object or name to get information about. If `object` is a
        numpy object, its docstring is given. If it is a string, available
        modules are searched for matching objects.
        If None, information about `info` itself is returned.
    maxwidth : int, optional
        Printing width.
    output : file like object, optional
        File like object that the output is written to, default is ``stdout``.
        The object has to be opened in 'w' or 'a' mode.
    toplevel : str, optional
        Start search at this level.

    See Also
    --------
    source, lookfor

    Notes
    -----
    When used interactively with an object, ``np.info(obj)`` is equivalent to
    ``help(obj)`` on the Python prompt or ``obj?`` on the IPython prompt.

    Examples
    --------
    >>> np.info(np.polyval) # doctest: +SKIP
       polyval(p, x)
         Evaluate the polynomial p at x.
         ...

    When using a string for `object` it is possible to get multiple results.

    >>> np.info('fft') # doctest: +SKIP
         *** Found in numpy ***
    Core FFT routines
    ...
         *** Found in numpy.fft ***
     fft(a, n=None, axis=-1)
    ...
         *** Repeat reference found in numpy.fft.fftpack ***
         *** Total of 3 references found. ***

    Nothing found.
     *** Total of %d references found. ***Name %s Shape %s Bytes %s TypeUnknown unary op: %r`arrayrange` is deprecated, use `arange` instead!
    Do a keyword search on docstrings.

    A list of of objects that matched the search is displayed,
    sorted by relevance. All given keywords need to be found in the
    docstring for it to be returned as a result, but the order does
    not matter.

    Parameters
    ----------
    what : str
        String containing words to look for.
    module : str or list, optional
        Name of module(s) whose docstrings to go through.
    import_modules : bool, optional
        Whether to import sub-modules in packages. Default is True.
    regenerate : bool, optional
        Whether to re-generate the docstring cache. Default is False.
    output : file-like, optional
        File-like object to write the output to. If omitted, use a pager.

    See Also
    --------
    source, info

    Notes
    -----
    Relevance is determined only roughly, by checking if the keywords occur
    in the function name, at the start of a docstring, etc.

    Examples
    --------
    >>> np.lookfor('binary representation')
    Search results for 'binary representation'
    ------------------------------------------
    numpy.binary_repr
        Return the binary representation of the input number as a string.
    numpy.core.setup_common.long_double_representation
        Given a binary dump as given by GNU od -b, look for long double
    numpy.base_repr
        Return a string representation of a number in the given base system.
    ...

    
    Object to evaluate constant string expressions.

    This includes strings with lists, dicts and tuples using the abstract
    syntax tree created by ``compiler.parse``.

    For an example of usage, see `safe_eval`.

    See Also
    --------
    safe_eval

    
    Return the directory that contains the numarray \*.h header files.

    Extension modules that need to compile against numarray should use this
    function to locate the appropriate include directory.

    Parameters
    ----------
    type : any, optional
        If `type` is not None, the location of the NumPy headers is returned
        as well.

    Returns
    -------
    dirs : str or list of str
        If `type` is None, `dirs` is a string containing the path to the
        numarray headers.
        If `type` is not None, `dirs` is a list of strings with first the
        path(s) to the numarray headers, followed by the path to the NumPy
        headers.

    Notes
    -----
    Useful when using ``distutils``, for example in ``setup.py``.
    ::

        import numpy as np
        ...
        Extension('extension_name', ...
                include_dirs=[np.get_numarray_include()])
        ...

    
Upper bound on total bytes  =       %d
    Issues a DeprecationWarning, adds warning to `old_name`'s
    docstring, rebinds ``old_name.__name__`` and returns the new
    function object.

    This function may also be used as a decorator.

    Parameters
    ----------
    func : function
        The function to be deprecated.
    old_name : str, optional
        The name of the function to be deprecated. Default is None, in which
        case the name of `func` is used.
    new_name : str, optional
        The new name for the function. Default is None, in which case
        the deprecation message is that `old_name` is deprecated. If given,
        the deprecation message is that `old_name` is deprecated and `new_name`
        should be used instead.
    message : str, optional
        Additional explanation of the deprecation.  Displayed in the docstring
        after the warning.

    Returns
    -------
    old_func : function
        The deprecated function.

    Examples
    --------
    Note that ``olduint`` returns a value after printing Deprecation Warning:

    >>> olduint = np.deprecate(np.uint)
    >>> olduint(6)
    /usr/lib/python2.5/site-packages/numpy/lib/utils.py:114:
    DeprecationWarning: uint32 is deprecated
      warnings.warn(str1, DeprecationWarning)
    6

    
    Decorator class to deprecate old functions.

    Refer to `deprecate` for details.

    See Also
    --------
    deprecate

    
    Generate docstring cache for given module.

    Parameters
    ----------
    module : str, None, module
        Module for which to generate docstring cache
    import_modules : bool
        Whether to import sub-modules in packages.
    regenerate : bool
        Re-generate the docstring cache

    Returns
    -------
    cache : dict {obj_full_name: (docstring, kind, index), ...}
        Docstring cache for the module, either cached one (regenerate=False)
        or newly generated.

    
     *** Repeat reference found in %s ***      *** Found in %s ***
    Protected string evaluation.

    Evaluate a string containing a Python literal expression without
    allowing the execution of arbitrary non-literal code.

    Parameters
    ----------
    source : str
        The string to evaluate.

    Returns
    -------
    obj : object
       The result of evaluating `source`.

    Raises
    ------
    SyntaxError
        If the code has invalid Python syntax, or if it contains non-literal
        code.

    Examples
    --------
    >>> np.safe_eval('1')
    1
    >>> np.safe_eval('[1, 2, 3]')
    [1, 2, 3]
    >>> np.safe_eval('{"foo": ("bar", 10.0)}')
    {'foo': ('bar', 10.0)}

    >>> np.safe_eval('import os')
    Traceback (most recent call last):
      ...
    SyntaxError: invalid syntax

    >>> np.safe_eval('open("/home/user/.ssh/id_dsa").read()')
    Traceback (most recent call last):
      ...
    SyntaxError: Unsupported source construct: compiler.ast.CallFunc

    Help for %s not found.In file: %s

    Print the Numpy arrays in the given dictionary.

    If there is no dictionary passed in or `vardict` is None then returns
    Numpy arrays in the globals() dictionary (all Numpy arrays in the
    namespace).

    Parameters
    ----------
    vardict : dict, optional
        A dictionary possibly containing ndarrays.  Default is globals().

    Returns
    -------
    out : None
        Returns 'None'.

    Notes
    -----
    Prints out the name, shape, bytes and type of all of the ndarrays present
    in `vardict`.

    Examples
    --------
    >>> a = np.arange(10)
    >>> b = np.ones(20)
    >>> np.who()
    Name            Shape            Bytes            Type
    ===========================================================
    a               10               40               int32
    b               20               160              float64
    Upper bound on total bytes  =       200

    >>> d = {'x': np.arange(2.0), 'y': np.arange(3.0), 'txt': 'Some str',
    ... 'idx':5}
    >>> np.who(d)
    Name            Shape            Bytes            Type
    ===========================================================
    y               3                24               float64
    x               2                16               float64
    Upper bound on total bytes  =       40

    `%s` is deprecated!%s
    %sUnknown name: %sSearch results for '%s'/usr/lib/python2.7/dist-packages/numpy/lib/utils.py(   t   whatt   modulet   import_modulest
   regeneratet   outputt   pydoct   cachet   foundt   whatst   namet	   docstringt   kindt   indext   okt   doct   wt   kind_relevancet	   relevancet   relevance_valuet   st	   help_textt   ixt   linet   doclinest	   first_doct   pager(   t   objectt   maxwidtht   outputt   toplevelt   pydoct   inspectt   nnt   numfoundt   objlistt   namestrt   objt   namet	   argumentst   argstrt   arglistt   doc1t   methodst   metht   thisobjt   methstrt   othert   doc(   t   modulet   import_modulest
   regeneratet   inspectt   StringIOt   cachet   modt   seent   indext   stackt   namet   itemt   kindt   _allt   ptht   mod_patht   this_pyt   init_pyt	   to_importt   base_exct
   old_stdoutt
   old_stderrt   nt   vt	   item_namet   mod_namet   doc(   t   vardictt   framet   stat   cachet   namet   vart   idvt   namestrt   originalt   shapestrt   bytestrt   maxnamet   maxshapet   maxbytet
   totalbytest   kt   valt   sp1t   sp2t   sp3t   prval
Core Linear Algebra Tools
=========================

=============== ==========================================================
Linear algebra basics
==========================================================================
norm            Vector or matrix norm
inv             Inverse of a square matrix
solve           Solve a linear system of equations
det             Determinant of a square matrix
slogdet         Logarithm of the determinant of a square matrix
lstsq           Solve linear least-squares problem
pinv            Pseudo-inverse (Moore-Penrose) calculated using a singular
                value decomposition
matrix_power    Integer power of a square matrix
=============== ==========================================================

=============== ==========================================================
Eigenvalues and decompositions
==========================================================================
eig             Eigenvalues and vectors of a square matrix
eigh            Eigenvalues and eigenvectors of a Hermitian matrix
eigvals         Eigenvalues of a square matrix
eigvalsh        Eigenvalues of a Hermitian matrix
qr              QR decomposition of a matrix
svd             Singular value decomposition of a matrix
cholesky        Cholesky decomposition of a matrix
=============== ==========================================================

=============== ==========================================================
Tensor operations
==========================================================================
tensorsolve     Solve a linear tensor equation
tensorinv       Calculate an inverse of a tensor
=============== ==========================================================

=============== ==========================================================
Exceptions
==========================================================================
LinAlgError     Indicates a failed linear algebra operation
=============== ==========================================================

/usr/lib/python2.7/dist-packages/numpy/linalg/__init__.pynumpy.linalg.info/usr/lib/python2.7/dist-packages/numpy/linalg/info.pyCore Linear Algebra Tools
-------------------------
Linear algebra basics:

- norm            Vector or matrix norm
- inv             Inverse of a square matrix
- solve           Solve a linear system of equations
- det             Determinant of a square matrix
- lstsq           Solve linear least-squares problem
- pinv            Pseudo-inverse (Moore-Penrose) calculated using a singular
                  value decomposition
- matrix_power    Integer power of a square matrix

Eigenvalues and decompositions:

- eig             Eigenvalues and vectors of a square matrix
- eigh            Eigenvalues and eigenvectors of a Hermitian matrix
- eigvals         Eigenvalues of a square matrix
- eigvalsh        Eigenvalues of a Hermitian matrix
- qr              QR decomposition of a matrix
- svd             Singular value decomposition of a matrix
- cholesky        Cholesky decomposition of a matrix

Tensor operations:

- tensorsolve     Solve a linear tensor equation
- tensorinv       Calculate an inverse of a tensor

Exceptions:

- LinAlgError     Indicates a failed linear algebra operation

ainvnlvlsvd_ma_realdgelsddgeqrfdorgqrlrworksolve1zgelsdzgeqrfeigh_loeigh_upsvd_m_fsvd_m_ssvd_n_fsvd_n_sbstar_realcholesky_loeigvalsh_loeigvalsh_upmatrix_rankroutine_name_convertarraylapack_routine_assertSquareness[   s   matrix_powers   solves   tensorsolves	   tensorinvs   invs   choleskys   eigvalss   eigvalshs   pinvs   slogdets   dets   svds   eigs   eighs   lstsqs   norms   qrs   conds   matrix_ranks   LinAlgError
    Return the eigenvalues and eigenvectors of a Hermitian or symmetric matrix.

    Returns two objects, a 1-D array containing the eigenvalues of `a`, and
    a 2-D square array or matrix (depending on the input type) of the
    corresponding eigenvectors (in columns).

    Parameters
    ----------
    A : (..., M, M) array
        Hermitian/Symmetric matrices whose eigenvalues and
        eigenvectors are to be computed.
    UPLO : {'L', 'U'}, optional
        Specifies whether the calculation is done with the lower triangular
        part of `a` ('L', default) or the upper triangular part ('U').

    Returns
    -------
    w : (..., M) ndarray
        The eigenvalues, not necessarily ordered.
    v : {(..., M, M) ndarray, (..., M, M) matrix}
        The column ``v[:, i]`` is the normalized eigenvector corresponding
        to the eigenvalue ``w[i]``.  Will return a matrix object if `a` is
        a matrix object.

    Raises
    ------
    LinAlgError
        If the eigenvalue computation does not converge.

    See Also
    --------
    eigvalsh : eigenvalues of symmetric or Hermitian arrays.
    eig : eigenvalues and right eigenvectors for non-symmetric arrays.
    eigvals : eigenvalues of non-symmetric arrays.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The eigenvalues/eigenvectors are computed using LAPACK routines _ssyevd,
    _heevd

    The eigenvalues of real symmetric or complex Hermitian matrices are
    always real. [1]_ The array `v` of (column) eigenvectors is unitary
    and `a`, `w`, and `v` satisfy the equations
    ``dot(a, v[:, i]) = w[i] * v[:, i]``.

    References
    ----------
    .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
           FL, Academic Press, Inc., 1980, pg. 222.

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> a = np.array([[1, -2j], [2j, 5]])
    >>> a
    array([[ 1.+0.j,  0.-2.j],
           [ 0.+2.j,  5.+0.j]])
    >>> w, v = LA.eigh(a)
    >>> w; v
    array([ 0.17157288,  5.82842712])
    array([[-0.92387953+0.j        , -0.38268343+0.j        ],
           [ 0.00000000+0.38268343j,  0.00000000-0.92387953j]])

    >>> np.dot(a, v[:, 0]) - w[0] * v[:, 0] # verify 1st e-val/vec pair
    array([2.77555756e-17 + 0.j, 0. + 1.38777878e-16j])
    >>> np.dot(a, v[:, 1]) - w[1] * v[:, 1] # verify 2nd e-val/vec pair
    array([ 0.+0.j,  0.+0.j])

    >>> A = np.matrix(a) # what happens if input is a matrix object
    >>> A
    matrix([[ 1.+0.j,  0.-2.j],
            [ 0.+2.j,  5.+0.j]])
    >>> w, v = LA.eigh(A)
    >>> w; v
    array([ 0.17157288,  5.82842712])
    matrix([[-0.92387953+0.j        , -0.38268343+0.j        ],
            [ 0.00000000+0.38268343j,  0.00000000-0.92387953j]])

    For backward compatibility let mode default.
    Solve a linear matrix equation, or system of linear scalar equations.

    Computes the "exact" solution, `x`, of the well-determined, i.e., full
    rank, linear matrix equation `ax = b`.

    Parameters
    ----------
    a : (..., M, M) array_like
        Coefficient matrix.
    b : {(..., M,), (..., M, K)}, array_like
        Ordinate or "dependent variable" values.

    Returns
    -------
    x : {(..., M,), (..., M, K)} ndarray
        Solution to the system a x = b.  Returned shape is identical to `b`.

    Raises
    ------
    LinAlgError
        If `a` is singular or not square.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The solutions are computed using LAPACK routine _gesv

    `a` must be square and of full-rank, i.e., all rows (or, equivalently,
    columns) must be linearly independent; if either is not true, use
    `lstsq` for the least-squares best "solution" of the
    system/equation.

    References
    ----------
    .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
           FL, Academic Press, Inc., 1980, pg. 22.

    Examples
    --------
    Solve the system of equations ``3 * x0 + x1 = 9`` and ``x0 + 2 * x1 = 8``:

    >>> a = np.array([[3,1], [1,2]])
    >>> b = np.array([9,8])
    >>> x = np.linalg.solve(a, b)
    >>> x
    array([ 2.,  3.])

    Check that the solution is correct:

    >>> np.allclose(np.dot(a, x), b)
    True

    
    Cholesky decomposition.

    Return the Cholesky decomposition, `L * L.H`, of the square matrix `a`,
    where `L` is lower-triangular and .H is the conjugate transpose operator
    (which is the ordinary transpose if `a` is real-valued).  `a` must be
    Hermitian (symmetric if real-valued) and positive-definite.  Only `L` is
    actually returned.

    Parameters
    ----------
    a : (..., M, M) array_like
        Hermitian (symmetric if all elements are real), positive-definite
        input matrix.

    Returns
    -------
    L : (..., M, M) array_like
        Upper or lower-triangular Cholesky factor of `a`.  Returns a
        matrix object if `a` is a matrix object.

    Raises
    ------
    LinAlgError
       If the decomposition fails, for example, if `a` is not
       positive-definite.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The Cholesky decomposition is often used as a fast way of solving

    .. math:: A \mathbf{x} = \mathbf{b}

    (when `A` is both Hermitian/symmetric and positive-definite).

    First, we solve for :math:`\mathbf{y}` in

    .. math:: L \mathbf{y} = \mathbf{b},

    and then for :math:`\mathbf{x}` in

    .. math:: L.H \mathbf{x} = \mathbf{y}.

    Examples
    --------
    >>> A = np.array([[1,-2j],[2j,5]])
    >>> A
    array([[ 1.+0.j,  0.-2.j],
           [ 0.+2.j,  5.+0.j]])
    >>> L = np.linalg.cholesky(A)
    >>> L
    array([[ 1.+0.j,  0.+0.j],
           [ 0.+2.j,  1.+0.j]])
    >>> np.dot(L, L.T.conj()) # verify that L * L.H = A
    array([[ 1.+0.j,  0.-2.j],
           [ 0.+2.j,  5.+0.j]])
    >>> A = [[1,-2j],[2j,5]] # what happens if A is only array_like?
    >>> np.linalg.cholesky(A) # an ndarray object is returned
    array([[ 1.+0.j,  0.+0.j],
           [ 0.+2.j,  1.+0.j]])
    >>> # But a matrix object is returned if A is a matrix object
    >>> LA.cholesky(np.matrix(A))
    matrix([[ 1.+0.j,  0.+0.j],
            [ 0.+2.j,  1.+0.j]])

    
    Generic Python-exception-derived object raised by linalg functions.

    General purpose exception class, derived from Python's exception.Exception
    class, programmatically raised in linalg functions when a Linear
    Algebra-related condition would prevent further correct execution of the
    function.

    Parameters
    ----------
    None

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> LA.inv(np.zeros((2,2)))
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "...linalg.py", line 350,
        in inv return wrap(solve(a, identity(a.shape[0], dtype=a.dtype)))
      File "...linalg.py", line 249,
        in solve
        raise LinAlgError('Singular matrix')
    numpy.linalg.LinAlgError: Singular matrix

    UPLO argument must be 'L' or 'U'Lite version of scipy.linalg.

Notes
-----
This module is a lite version of the linalg.py module in SciPy which
contains high-level Python interface to the LAPACK library.  The lite
version only accesses the following LAPACK functions: dgesv, zgesv,
dgeev, zgeev, dgesdd, zgesdd, dgelsd, zgelsd, dsyevd, zheevd, dgetrf,
zgetrf, dpotrf, zpotrf, dgeqrf, zgeqrf, zungqr, dorgqr.
Duplicate axes given.Eigenvalues did not converge
    Return matrix rank of array using SVD method

    Rank of the array is the number of SVD singular values of the array that are
    greater than `tol`.

    Parameters
    ----------
    M : {(M,), (M, N)} array_like
        array of <=2 dimensions
    tol : {None, float}, optional
       threshold below which SVD values are considered zero. If `tol` is
       None, and ``S`` is an array with singular values for `M`, and
       ``eps`` is the epsilon value for datatype of ``S``, then `tol` is
       set to ``S.max() * max(M.shape) * eps``.

    Notes
    -----
    The default threshold to detect rank deficiency is a test on the magnitude
    of the singular values of `M`.  By default, we identify singular values less
    than ``S.max() * max(M.shape) * eps`` as indicating rank deficiency (with
    the symbols defined above). This is the algorithm MATLAB uses [1].  It also
    appears in *Numerical recipes* in the discussion of SVD solutions for linear
    least squares [2].

    This default threshold is designed to detect rank deficiency accounting for
    the numerical errors of the SVD computation.  Imagine that there is a column
    in `M` that is an exact (in floating point) linear combination of other
    columns in `M`. Computing the SVD on `M` will not produce a singular value
    exactly equal to 0 in general: any difference of the smallest SVD value from
    0 will be caused by numerical imprecision in the calculation of the SVD.
    Our threshold for small SVD values takes this numerical imprecision into
    account, and the default threshold will detect such numerical rank
    deficiency.  The threshold may declare a matrix `M` rank deficient even if
    the linear combination of some columns of `M` is not exactly equal to
    another column of `M` but only numerically very close to another column of
    `M`.

    We chose our default threshold because it is in wide use.  Other thresholds
    are possible.  For example, elsewhere in the 2007 edition of *Numerical
    recipes* there is an alternative threshold of ``S.max() *
    np.finfo(M.dtype).eps / 2. * np.sqrt(m + n + 1.)``. The authors describe
    this threshold as being based on "expected roundoff error" (p 71).

    The thresholds above deal with floating point roundoff error in the
    calculation of the SVD.  However, you may have more information about the
    sources of error in `M` that would make you consider other tolerance values
    to detect *effective* rank deficiency.  The most useful measure of the
    tolerance depends on the operations you intend to use on your matrix.  For
    example, if your data come from uncertain measurements with uncertainties
    greater than floating point epsilon, choosing a tolerance near that
    uncertainty may be preferable.  The tolerance may be absolute if the
    uncertainties are absolute rather than relative.

    References
    ----------
    .. [1] MATLAB reference documention, "Rank"
           http://www.mathworks.com/help/techdoc/ref/rank.html
    .. [2] W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery,
           "Numerical Recipes (3rd edition)", Cambridge University Press, 2007,
           page 795.

    Examples
    --------
    >>> from numpy.linalg import matrix_rank
    >>> matrix_rank(np.eye(4)) # Full rank matrix
    4
    >>> I=np.eye(4); I[-1,-1] = 0. # rank deficient matrix
    >>> matrix_rank(I)
    3
    >>> matrix_rank(np.ones((4,))) # 1 dimension - rank 1 unless all 0
    1
    >>> matrix_rank(np.zeros((4,)))
    0
    D->DdThe 'economic' option is deprecated.Incompatible dimensionsd->ddCast the type t to either double or cdouble.numpy.linalg.linalgArrays cannot be empty
    Compute the condition number of a matrix.

    This function is capable of returning the condition number using
    one of seven different norms, depending on the value of `p` (see
    Parameters below).

    Parameters
    ----------
    x : (M, N) array_like
        The matrix whose condition number is sought.
    p : {None, 1, -1, 2, -2, inf, -inf, 'fro'}, optional
        Order of the norm:

        =====  ============================
        p      norm for matrices
        =====  ============================
        None   2-norm, computed directly using the ``SVD``
        'fro'  Frobenius norm
        inf    max(sum(abs(x), axis=1))
        -inf   min(sum(abs(x), axis=1))
        1      max(sum(abs(x), axis=0))
        -1     min(sum(abs(x), axis=0))
        2      2-norm (largest sing. value)
        -2     smallest singular value
        =====  ============================

        inf means the numpy.inf object, and the Frobenius norm is
        the root-of-sum-of-squares norm.

    Returns
    -------
    c : {float, inf}
        The condition number of the matrix. May be infinite.

    See Also
    --------
    numpy.linalg.norm

    Notes
    -----
    The condition number of `x` is defined as the norm of `x` times the
    norm of the inverse of `x` [1]_; the norm can be the usual L2-norm
    (root-of-sum-of-squares) or one of a number of other matrix norms.

    References
    ----------
    .. [1] G. Strang, *Linear Algebra and Its Applications*, Orlando, FL,
           Academic Press, Inc., 1980, pg. 285.

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> a = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])
    >>> a
    array([[ 1,  0, -1],
           [ 0,  1,  0],
           [ 1,  0,  1]])
    >>> LA.cond(a)
    1.4142135623730951
    >>> LA.cond(a, 'fro')
    3.1622776601683795
    >>> LA.cond(a, np.inf)
    2.0
    >>> LA.cond(a, -np.inf)
    1.0
    >>> LA.cond(a, 1)
    2.0
    >>> LA.cond(a, -1)
    1.0
    >>> LA.cond(a, 2)
    1.4142135623730951
    >>> LA.cond(a, -2)
    0.70710678118654746
    >>> min(LA.svd(a, compute_uv=0))*min(LA.svd(LA.inv(a), compute_uv=0))
    0.70710678118654746

    Invalid norm order for matrices.Last 2 dimensions of the array must be squareInvalid ind argument.
    Compute the (Moore-Penrose) pseudo-inverse of a matrix.

    Calculate the generalized inverse of a matrix using its
    singular-value decomposition (SVD) and including all
    *large* singular values.

    Parameters
    ----------
    a : (M, N) array_like
      Matrix to be pseudo-inverted.
    rcond : float
      Cutoff for small singular values.
      Singular values smaller (in modulus) than
      `rcond` * largest_singular_value (again, in modulus)
      are set to zero.

    Returns
    -------
    B : (N, M) ndarray
      The pseudo-inverse of `a`. If `a` is a `matrix` instance, then so
      is `B`.

    Raises
    ------
    LinAlgError
      If the SVD computation does not converge.

    Notes
    -----
    The pseudo-inverse of a matrix A, denoted :math:`A^+`, is
    defined as: "the matrix that 'solves' [the least-squares problem]
    :math:`Ax = b`," i.e., if :math:`\bar{x}` is said solution, then
    :math:`A^+` is that matrix such that :math:`\bar{x} = A^+b`.

    It can be shown that if :math:`Q_1 \Sigma Q_2^T = A` is the singular
    value decomposition of A, then
    :math:`A^+ = Q_2 \Sigma^+ Q_1^T`, where :math:`Q_{1,2}` are
    orthogonal matrices, :math:`\Sigma` is a diagonal matrix consisting
    of A's so-called singular values, (followed, typically, by
    zeros), and then :math:`\Sigma^+` is simply the diagonal matrix
    consisting of the reciprocals of A's singular values
    (again, followed by zeros). [1]_

    References
    ----------
    .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
           FL, Academic Press, Inc., 1980, pp. 139-142.

    Examples
    --------
    The following example checks that ``a * a+ * a == a`` and
    ``a+ * a * a+ == a+``:

    >>> a = np.random.randn(9, 6)
    >>> B = np.linalg.pinv(a)
    >>> np.allclose(a, np.dot(a, np.dot(B, a)))
    True
    >>> np.allclose(B, np.dot(B, np.dot(a, B)))
    True

    Invalid axis %r for an array with shape %r
    Solve the tensor equation ``a x = b`` for x.

    It is assumed that all indices of `x` are summed over in the product,
    together with the rightmost indices of `a`, as is done in, for example,
    ``tensordot(a, x, axes=len(b.shape))``.

    Parameters
    ----------
    a : array_like
        Coefficient tensor, of shape ``b.shape + Q``. `Q`, a tuple, equals
        the shape of that sub-tensor of `a` consisting of the appropriate
        number of its rightmost indices, and must be such that
       ``prod(Q) == prod(b.shape)`` (in which sense `a` is said to be
       'square').
    b : array_like
        Right-hand tensor, which can be of any shape.
    axes : tuple of ints, optional
        Axes in `a` to reorder to the right, before inversion.
        If None (default), no reordering is done.

    Returns
    -------
    x : ndarray, shape Q

    Raises
    ------
    LinAlgError
        If `a` is singular or not 'square' (in the above sense).

    See Also
    --------
    tensordot, tensorinv, einsum

    Examples
    --------
    >>> a = np.eye(2*3*4)
    >>> a.shape = (2*3, 4, 2, 3, 4)
    >>> b = np.random.randn(2*3, 4)
    >>> x = np.linalg.tensorsolve(a, b)
    >>> x.shape
    (2, 3, 4)
    >>> np.allclose(np.tensordot(a, x, axes=3), b)
    True

    
    Return the least-squares solution to a linear matrix equation.

    Solves the equation `a x = b` by computing a vector `x` that
    minimizes the Euclidean 2-norm `|| b - a x ||^2`.  The equation may
    be under-, well-, or over- determined (i.e., the number of
    linearly independent rows of `a` can be less than, equal to, or
    greater than its number of linearly independent columns).  If `a`
    is square and of full rank, then `x` (but for round-off error) is
    the "exact" solution of the equation.

    Parameters
    ----------
    a : (M, N) array_like
        "Coefficient" matrix.
    b : {(M,), (M, K)} array_like
        Ordinate or "dependent variable" values. If `b` is two-dimensional,
        the least-squares solution is calculated for each of the `K` columns
        of `b`.
    rcond : float, optional
        Cut-off ratio for small singular values of `a`.
        Singular values are set to zero if they are smaller than `rcond`
        times the largest singular value of `a`.

    Returns
    -------
    x : {(N,), (N, K)} ndarray
        Least-squares solution. If `b` is two-dimensional,
        the solutions are in the `K` columns of `x`.
    residuals : {(), (1,), (K,)} ndarray
        Sums of residuals; squared Euclidean 2-norm for each column in
        ``b - a*x``.
        If the rank of `a` is < N or > M, this is an empty array.
        If `b` is 1-dimensional, this is a (1,) shape array.
        Otherwise the shape is (K,).
    rank : int
        Rank of matrix `a`.
    s : (min(M, N),) ndarray
        Singular values of `a`.

    Raises
    ------
    LinAlgError
        If computation does not converge.

    Notes
    -----
    If `b` is a matrix, then all array results are returned as matrices.

    Examples
    --------
    Fit a line, ``y = mx + c``, through some noisy data-points:

    >>> x = np.array([0, 1, 2, 3])
    >>> y = np.array([-1, 0.2, 0.9, 2.1])

    By examining the coefficients, we see that the line should have a
    gradient of roughly 1 and cut the y-axis at, more or less, -1.

    We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``
    and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:

    >>> A = np.vstack([x, np.ones(len(x))]).T
    >>> A
    array([[ 0.,  1.],
           [ 1.,  1.],
           [ 2.,  1.],
           [ 3.,  1.]])

    >>> m, c = np.linalg.lstsq(A, y)[0]
    >>> print m, c
    1.0 -0.95

    Plot the data along with the fitted line:

    >>> import matplotlib.pyplot as plt
    >>> plt.plot(x, y, 'o', label='Original data', markersize=10)
    >>> plt.plot(x, m*x + c, 'r', label='Fitted line')
    >>> plt.legend()
    >>> plt.show()

    D->DD%d-dimensional array given. Array must be two-dimensionalarray type %s is unsupported in linalgd->dddMatrix is not positive definite
    Singular Value Decomposition.

    Factors the matrix `a` as ``u * np.diag(s) * v``, where `u` and `v`
    are unitary and `s` is a 1-d array of `a`'s singular values.

    Parameters
    ----------
    a : (..., M, N) array_like
        A real or complex matrix of shape (`M`, `N`) .
    full_matrices : bool, optional
        If True (default), `u` and `v` have the shapes (`M`, `M`) and
        (`N`, `N`), respectively.  Otherwise, the shapes are (`M`, `K`)
        and (`K`, `N`), respectively, where `K` = min(`M`, `N`).
    compute_uv : bool, optional
        Whether or not to compute `u` and `v` in addition to `s`.  True
        by default.

    Returns
    -------
    u : { (..., M, M), (..., M, K) } array
        Unitary matrices. The actual shape depends on the value of
        ``full_matrices``. Only returned when ``compute_uv`` is True.
    s : (..., K) array
        The singular values for every matrix, sorted in descending order.
    v : { (..., N, N), (..., K, N) } array
        Unitary matrices. The actual shape depends on the value of
        ``full_matrices``. Only returned when ``compute_uv`` is True.

    Raises
    ------
    LinAlgError
        If SVD computation does not converge.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The decomposition is performed using LAPACK routine _gesdd

    The SVD is commonly written as ``a = U S V.H``.  The `v` returned
    by this function is ``V.H`` and ``u = U``.

    If ``U`` is a unitary matrix, it means that it
    satisfies ``U.H = inv(U)``.

    The rows of `v` are the eigenvectors of ``a.H a``. The columns
    of `u` are the eigenvectors of ``a a.H``.  For row ``i`` in
    `v` and column ``i`` in `u`, the corresponding eigenvalue is
    ``s[i]**2``.

    If `a` is a `matrix` object (as opposed to an `ndarray`), then so
    are all the return values.

    Examples
    --------
    >>> a = np.random.randn(9, 6) + 1j*np.random.randn(9, 6)

    Reconstruction based on full SVD:

    >>> U, s, V = np.linalg.svd(a, full_matrices=True)
    >>> U.shape, V.shape, s.shape
    ((9, 9), (6, 6), (6,))
    >>> S = np.zeros((9, 6), dtype=complex)
    >>> S[:6, :6] = np.diag(s)
    >>> np.allclose(a, np.dot(U, np.dot(S, V)))
    True

    Reconstruction based on reduced SVD:

    >>> U, s, V = np.linalg.svd(a, full_matrices=False)
    >>> U.shape, V.shape, s.shape
    ((9, 6), (6, 6), (6,))
    >>> S = np.diag(s)
    >>> np.allclose(a, np.dot(U, np.dot(S, V)))
    True

    D->d
    Compute the sign and (natural) logarithm of the determinant of an array.

    If an array has a very small or very large determinant, than a call to
    `det` may overflow or underflow. This routine is more robust against such
    issues, because it computes the logarithm of the determinant rather than
    the determinant itself.

    Parameters
    ----------
    a : (..., M, M) array_like
        Input array, has to be a square 2-D array.

    Returns
    -------
    sign : (...) array_like
        A number representing the sign of the determinant. For a real matrix,
        this is 1, 0, or -1. For a complex matrix, this is a complex number
        with absolute value 1 (i.e., it is on the unit circle), or else 0.
    logdet : (...) array_like
        The natural log of the absolute value of the determinant.

    If the determinant is zero, then `sign` will be 0 and `logdet` will be
    -Inf. In all cases, the determinant is equal to ``sign * np.exp(logdet)``.

    See Also
    --------
    det

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The determinant is computed via LU factorization using the LAPACK
    routine z/dgetrf.

    .. versionadded:: 1.6.0.

    Examples
    --------
    The determinant of a 2-D array ``[[a, b], [c, d]]`` is ``ad - bc``:

    >>> a = np.array([[1, 2], [3, 4]])
    >>> (sign, logdet) = np.linalg.slogdet(a)
    >>> (sign, logdet)
    (-1, 0.69314718055994529)
    >>> sign * np.exp(logdet)
    -2.0

    Computing log-determinants for a stack of matrices:

    >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])
    >>> a.shape
    (3, 2, 2)
    >>> sign, logdet = np.linalg.slogdet(a)
    >>> (sign, logdet)
    (array([-1., -1., -1.]), array([ 0.69314718,  1.09861229,  2.07944154]))
    >>> sign * np.exp(logdet)
    array([-2., -3., -8.])

    This routine succeeds where ordinary `det` does not:

    >>> np.linalg.det(np.eye(500) * 0.1)
    0.0
    >>> np.linalg.slogdet(np.eye(500) * 0.1)
    (1, -1151.2925464970228)

    
    Compute the qr factorization of a matrix.

    Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is
    upper-triangular.

    Parameters
    ----------
    a : array_like, shape (M, N)
        Matrix to be factored.
    mode : {'reduced', 'complete', 'r', 'raw', 'full', 'economic'}, optional
        If K = min(M, N), then

        'reduced'  : returns q, r with dimensions (M, K), (K, N) (default)
        'complete' : returns q, r with dimensions (M, M), (M, N)
        'r'        : returns r only with dimensions (K, N)
        'raw'      : returns h, tau with dimensions (N, M), (K,)
        'full'     : alias of 'reduced', deprecated
        'economic' : returns h from 'raw', deprecated.

        The options 'reduced', 'complete, and 'raw' are new in numpy 1.8,
        see the notes for more information. The default is 'reduced' and to
        maintain backward compatibility with earlier versions of numpy both
        it and the old default 'full' can be omitted. Note that array h
        returned in 'raw' mode is transposed for calling Fortran. The
        'economic' mode is deprecated.  The modes 'full' and 'economic' may
        be passed using only the first letter for backwards compatibility,
        but all others must be spelled out. See the Notes for more
        explanation.


    Returns
    -------
    q : ndarray of float or complex, optional
        A matrix with orthonormal columns. When mode = 'complete' the
        result is an orthogonal/unitary matrix depending on whether or not
        a is real/complex. The determinant may be either +/- 1 in that
        case.
    r : ndarray of float or complex, optional
        The upper-triangular matrix.
    (h, tau) : ndarrays of np.double or np.cdouble, optional
        The array h contains the Householder reflectors that generate q
        along with r. The tau array contains scaling factors for the
        reflectors. In the deprecated  'economic' mode only h is returned.

    Raises
    ------
    LinAlgError
        If factoring fails.

    Notes
    -----
    This is an interface to the LAPACK routines dgeqrf, zgeqrf,
    dorgqr, and zungqr.

    For more information on the qr factorization, see for example:
    http://en.wikipedia.org/wiki/QR_factorization

    Subclasses of `ndarray` are preserved except for the 'raw' mode. So if
    `a` is of type `matrix`, all the return values will be matrices too.

    New 'reduced', 'complete', and 'raw' options for mode were added in
    Numpy 1.8 and the old option 'full' was made an alias of 'reduced'.  In
    addition the options 'full' and 'economic' were deprecated.  Because
    'full' was the previous default and 'reduced' is the new default,
    backward compatibility can be maintained by letting `mode` default.
    The 'raw' option was added so that LAPACK routines that can multiply
    arrays by q using the Householder reflectors can be used. Note that in
    this case the returned arrays are of type np.double or np.cdouble and
    the h array is transposed to be FORTRAN compatible.  No routines using
    the 'raw' return are currently exposed by numpy, but some are available
    in lapack_lite and just await the necessary work.

    Examples
    --------
    >>> a = np.random.randn(9, 6)
    >>> q, r = np.linalg.qr(a)
    >>> np.allclose(a, np.dot(q, r))  # a does equal qr
    True
    >>> r2 = np.linalg.qr(a, mode='r')
    >>> r3 = np.linalg.qr(a, mode='economic')
    >>> np.allclose(r, r2)  # mode='r' returns the same r as mode='full'
    True
    >>> # But only triu parts are guaranteed equal when mode='economic'
    >>> np.allclose(r, np.triu(r3[:6,:6], k=0))
    True

    Example illustrating a common use of `qr`: solving of least squares
    problems

    What are the least-squares-best `m` and `y0` in ``y = y0 + mx`` for
    the following data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points
    and you'll see that it should be y0 = 0, m = 1.)  The answer is provided
    by solving the over-determined matrix equation ``Ax = b``, where::

      A = array([[0, 1], [1, 1], [1, 1], [2, 1]])
      x = array([[y0], [m]])
      b = array([[1], [0], [2], [1]])

    If A = qr such that q is orthonormal (which is always possible via
    Gram-Schmidt), then ``x = inv(r) * (q.T) * b``.  (In numpy practice,
    however, we simply use `lstsq`.)

    >>> A = np.array([[0, 1], [1, 1], [1, 1], [2, 1]])
    >>> A
    array([[0, 1],
           [1, 1],
           [1, 1],
           [2, 1]])
    >>> b = np.array([1, 0, 2, 1])
    >>> q, r = LA.qr(A)
    >>> p = np.dot(q.T, b)
    >>> np.dot(LA.inv(r), p)
    array([  1.1e-16,   1.0e+00])

    Invalid norm order for vectors.Array must be squareArray must not contain infs or NaNsD->DdDImproper number of dimensions to norm.D->dDarray should have 2 or fewer dimensionsUnrecognized mode '%s'%s returns %d
    Compute the (multiplicative) inverse of a matrix.

    Given a square matrix `a`, return the matrix `ainv` satisfying
    ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.

    Parameters
    ----------
    a : (..., M, M) array_like
        Matrix to be inverted.

    Returns
    -------
    ainv : (..., M, M) ndarray or matrix
        (Multiplicative) inverse of the matrix `a`.

    Raises
    ------
    LinAlgError
        If `a` is not square or inversion fails.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    Examples
    --------
    >>> from numpy.linalg import inv
    >>> a = np.array([[1., 2.], [3., 4.]])
    >>> ainv = inv(a)
    >>> np.allclose(np.dot(a, ainv), np.eye(2))
    True
    >>> np.allclose(np.dot(ainv, a), np.eye(2))
    True

    If a is a matrix object, then the return value is a matrix as well:

    >>> ainv = inv(np.matrix(a))
    >>> ainv
    matrix([[-2. ,  1. ],
            [ 1.5, -0.5]])

    Inverses of several matrices can be computed at once:

    >>> a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])
    >>> inv(a)
    array([[[-2. ,  1. ],
            [ 1.5, -0.5]],
           [[-5. ,  2. ],
            [ 3. , -1. ]]])

    /usr/lib/python2.7/dist-packages/numpy/linalg/linalg.pyd->DCompute the extreme singular values of the 2-D matrices in `x`.

    This is a private utility function used by numpy.linalg.norm().

    Parameters
    ----------
    x : ndarray
    row_axis, col_axis : int
        The axes of `x` that hold the 2-D matrices.
    op : callable
        This should be either numpy.amin or numpy.amax.

    Returns
    -------
    result : float or ndarray
        If `x` is 2-D, the return values is a float.
        Otherwise, it is an array with ``x.ndim - 2`` dimensions.
        The return values are either the minimum or maximum of the
        singular values of the matrices, depending on whether `op`
        is `numpy.amin` or `numpy.amax`.

    
    Compute the 'inverse' of an N-dimensional array.

    The result is an inverse for `a` relative to the tensordot operation
    ``tensordot(a, b, ind)``, i. e., up to floating-point accuracy,
    ``tensordot(tensorinv(a), a, ind)`` is the "identity" tensor for the
    tensordot operation.

    Parameters
    ----------
    a : array_like
        Tensor to 'invert'. Its shape must be 'square', i. e.,
        ``prod(a.shape[:ind]) == prod(a.shape[ind:])``.
    ind : int, optional
        Number of first indices that are involved in the inverse sum.
        Must be a positive integer, default is 2.

    Returns
    -------
    b : ndarray
        `a`'s tensordot inverse, shape ``a.shape[:ind] + a.shape[ind:]``.

    Raises
    ------
    LinAlgError
        If `a` is singular or not 'square' (in the above sense).

    See Also
    --------
    tensordot, tensorsolve

    Examples
    --------
    >>> a = np.eye(4*6)
    >>> a.shape = (4, 6, 8, 3)
    >>> ainv = np.linalg.tensorinv(a, ind=2)
    >>> ainv.shape
    (8, 3, 4, 6)
    >>> b = np.random.randn(4, 6)
    >>> np.allclose(np.tensordot(ainv, b), np.linalg.tensorsolve(a, b))
    True

    >>> a = np.eye(4*6)
    >>> a.shape = (24, 8, 3)
    >>> ainv = np.linalg.tensorinv(a, ind=1)
    >>> ainv.shape
    (8, 3, 24)
    >>> b = np.random.randn(24)
    >>> np.allclose(np.tensordot(ainv, b, 1), np.linalg.tensorsolve(a, b))
    True

    
    Matrix or vector norm.

    This function is able to return one of seven different matrix norms,
    or one of an infinite number of vector norms (described below), depending
    on the value of the ``ord`` parameter.

    Parameters
    ----------
    x : array_like
        Input array.  If `axis` is None, `x` must be 1-D or 2-D.
    ord : {non-zero int, inf, -inf, 'fro'}, optional
        Order of the norm (see table under ``Notes``). inf means numpy's
        `inf` object.
    axis : {int, 2-tuple of ints, None}, optional
        If `axis` is an integer, it specifies the axis of `x` along which to
        compute the vector norms.  If `axis` is a 2-tuple, it specifies the
        axes that hold 2-D matrices, and the matrix norms of these matrices
        are computed.  If `axis` is None then either a vector norm (when `x`
        is 1-D) or a matrix norm (when `x` is 2-D) is returned.

    Returns
    -------
    n : float or ndarray
        Norm of the matrix or vector(s).

    Notes
    -----
    For values of ``ord <= 0``, the result is, strictly speaking, not a
    mathematical 'norm', but it may still be useful for various numerical
    purposes.

    The following norms can be calculated:

    =====  ============================  ==========================
    ord    norm for matrices             norm for vectors
    =====  ============================  ==========================
    None   Frobenius norm                2-norm
    'fro'  Frobenius norm                --
    inf    max(sum(abs(x), axis=1))      max(abs(x))
    -inf   min(sum(abs(x), axis=1))      min(abs(x))
    0      --                            sum(x != 0)
    1      max(sum(abs(x), axis=0))      as below
    -1     min(sum(abs(x), axis=0))      as below
    2      2-norm (largest sing. value)  as below
    -2     smallest singular value       as below
    other  --                            sum(abs(x)**ord)**(1./ord)
    =====  ============================  ==========================

    The Frobenius norm is given by [1]_:

        :math:`||A||_F = [\sum_{i,j} abs(a_{i,j})^2]^{1/2}`

    References
    ----------
    .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,
           Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> a = np.arange(9) - 4
    >>> a
    array([-4, -3, -2, -1,  0,  1,  2,  3,  4])
    >>> b = a.reshape((3, 3))
    >>> b
    array([[-4, -3, -2],
           [-1,  0,  1],
           [ 2,  3,  4]])

    >>> LA.norm(a)
    7.745966692414834
    >>> LA.norm(b)
    7.745966692414834
    >>> LA.norm(b, 'fro')
    7.745966692414834
    >>> LA.norm(a, np.inf)
    4
    >>> LA.norm(b, np.inf)
    9
    >>> LA.norm(a, -np.inf)
    0
    >>> LA.norm(b, -np.inf)
    2

    >>> LA.norm(a, 1)
    20
    >>> LA.norm(b, 1)
    7
    >>> LA.norm(a, -1)
    -4.6566128774142013e-010
    >>> LA.norm(b, -1)
    6
    >>> LA.norm(a, 2)
    7.745966692414834
    >>> LA.norm(b, 2)
    7.3484692283495345

    >>> LA.norm(a, -2)
    nan
    >>> LA.norm(b, -2)
    1.8570331885190563e-016
    >>> LA.norm(a, 3)
    5.8480354764257312
    >>> LA.norm(a, -3)
    nan

    Using the `axis` argument to compute vector norms:

    >>> c = np.array([[ 1, 2, 3],
    ...               [-1, 1, 4]])
    >>> LA.norm(c, axis=0)
    array([ 1.41421356,  2.23606798,  5.        ])
    >>> LA.norm(c, axis=1)
    array([ 3.74165739,  4.24264069])
    >>> LA.norm(c, ord=1, axis=1)
    array([6, 6])

    Using the `axis` argument to compute matrix norms:

    >>> m = np.arange(8).reshape(2,2,2)
    >>> LA.norm(m, axis=(1,2))
    array([  3.74165739,  11.22497216])
    >>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])
    (3.7416573867739413, 11.224972160321824)

    
    Compute the eigenvalues of a general matrix.

    Main difference between `eigvals` and `eig`: the eigenvectors aren't
    returned.

    Parameters
    ----------
    a : (..., M, M) array_like
        A complex- or real-valued matrix whose eigenvalues will be computed.

    Returns
    -------
    w : (..., M,) ndarray
        The eigenvalues, each repeated according to its multiplicity.
        They are not necessarily ordered, nor are they necessarily
        real for real matrices.

    Raises
    ------
    LinAlgError
        If the eigenvalue computation does not converge.

    See Also
    --------
    eig : eigenvalues and right eigenvectors of general arrays
    eigvalsh : eigenvalues of symmetric or Hermitian arrays.
    eigh : eigenvalues and eigenvectors of symmetric/Hermitian arrays.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    This is implemented using the _geev LAPACK routines which compute
    the eigenvalues and eigenvectors of general square arrays.

    Examples
    --------
    Illustration, using the fact that the eigenvalues of a diagonal matrix
    are its diagonal elements, that multiplying a matrix on the left
    by an orthogonal matrix, `Q`, and on the right by `Q.T` (the transpose
    of `Q`), preserves the eigenvalues of the "middle" matrix.  In other words,
    if `Q` is orthogonal, then ``Q * A * Q.T`` has the same eigenvalues as
    ``A``:

    >>> from numpy import linalg as LA
    >>> x = np.random.random()
    >>> Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])
    >>> LA.norm(Q[0, :]), LA.norm(Q[1, :]), np.dot(Q[0, :],Q[1, :])
    (1.0, 1.0, 0.0)

    Now multiply a diagonal matrix by Q on one side and by Q.T on the other:

    >>> D = np.diag((-1,1))
    >>> LA.eigvals(D)
    array([-1.,  1.])
    >>> A = np.dot(Q, D)
    >>> A = np.dot(A, Q.T)
    >>> LA.eigvals(A)
    array([ 1., -1.])

    d->DDThe 'full' option is deprecated in favor of 'reduced'.

    Compute the eigenvalues of a Hermitian or real symmetric matrix.

    Main difference from eigh: the eigenvectors are not computed.

    Parameters
    ----------
    a : (..., M, M) array_like
        A complex- or real-valued matrix whose eigenvalues are to be
        computed.
    UPLO : {'L', 'U'}, optional
        Same as `lower`, with 'L' for lower and 'U' for upper triangular.
        Deprecated.

    Returns
    -------
    w : (..., M,) ndarray
        The eigenvalues, not necessarily ordered, each repeated according to
        its multiplicity.

    Raises
    ------
    LinAlgError
        If the eigenvalue computation does not converge.

    See Also
    --------
    eigh : eigenvalues and eigenvectors of symmetric/Hermitian arrays.
    eigvals : eigenvalues of general real or complex arrays.
    eig : eigenvalues and right eigenvectors of general real or complex
          arrays.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The eigenvalues are computed using LAPACK routines _ssyevd, _heevd

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> a = np.array([[1, -2j], [2j, 5]])
    >>> LA.eigvalsh(a)
    array([ 0.17157288+0.j,  5.82842712+0.j])

    
    Compute the eigenvalues and right eigenvectors of a square array.

    Parameters
    ----------
    a : (..., M, M) array
        Matrices for which the eigenvalues and right eigenvectors will
        be computed

    Returns
    -------
    w : (..., M) array
        The eigenvalues, each repeated according to its multiplicity.
        The eigenvalues are not necessarily ordered. The resulting
        array will be always be of complex type. When `a` is real
        the resulting eigenvalues will be real (0 imaginary part) or
        occur in conjugate pairs

    v : (..., M, M) array
        The normalized (unit "length") eigenvectors, such that the
        column ``v[:,i]`` is the eigenvector corresponding to the
        eigenvalue ``w[i]``.

    Raises
    ------
    LinAlgError
        If the eigenvalue computation does not converge.

    See Also
    --------
    eigvalsh : eigenvalues of a symmetric or Hermitian (conjugate symmetric)
       array.

    eigvals : eigenvalues of a non-symmetric array.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    This is implemented using the _geev LAPACK routines which compute
    the eigenvalues and eigenvectors of general square arrays.

    The number `w` is an eigenvalue of `a` if there exists a vector
    `v` such that ``dot(a,v) = w * v``. Thus, the arrays `a`, `w`, and
    `v` satisfy the equations ``dot(a[:,:], v[:,i]) = w[i] * v[:,i]``
    for :math:`i \in \{0,...,M-1\}`.

    The array `v` of eigenvectors may not be of maximum rank, that is, some
    of the columns may be linearly dependent, although round-off error may
    obscure that fact. If the eigenvalues are all different, then theoretically
    the eigenvectors are linearly independent. Likewise, the (complex-valued)
    matrix of eigenvectors `v` is unitary if the matrix `a` is normal, i.e.,
    if ``dot(a, a.H) = dot(a.H, a)``, where `a.H` denotes the conjugate
    transpose of `a`.

    Finally, it is emphasized that `v` consists of the *right* (as in
    right-hand side) eigenvectors of `a`.  A vector `y` satisfying
    ``dot(y.T, a) = z * y.T`` for some number `z` is called a *left*
    eigenvector of `a`, and, in general, the left and right eigenvectors
    of a matrix are not necessarily the (perhaps conjugate) transposes
    of each other.

    References
    ----------
    G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL,
    Academic Press, Inc., 1980, Various pp.

    Examples
    --------
    >>> from numpy import linalg as LA

    (Almost) trivial example with real e-values and e-vectors.

    >>> w, v = LA.eig(np.diag((1, 2, 3)))
    >>> w; v
    array([ 1.,  2.,  3.])
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])

    Real matrix possessing complex e-values and e-vectors; note that the
    e-values are complex conjugates of each other.

    >>> w, v = LA.eig(np.array([[1, -1], [1, 1]]))
    >>> w; v
    array([ 1. + 1.j,  1. - 1.j])
    array([[ 0.70710678+0.j        ,  0.70710678+0.j        ],
           [ 0.00000000-0.70710678j,  0.00000000+0.70710678j]])

    Complex-valued matrix with real e-values (but complex-valued e-vectors);
    note that a.conj().T = a, i.e., a is Hermitian.

    >>> a = np.array([[1, 1j], [-1j, 1]])
    >>> w, v = LA.eig(a)
    >>> w; v
    array([  2.00000000e+00+0.j,   5.98651912e-36+0.j]) # i.e., {2, 0}
    array([[ 0.00000000+0.70710678j,  0.70710678+0.j        ],
           [ 0.70710678+0.j        ,  0.00000000+0.70710678j]])

    Be careful about round-off error!

    >>> a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]])
    >>> # Theor. e-values are 1 +/- 1e-9
    >>> w, v = LA.eig(a)
    >>> w; v
    array([ 1.,  1.])
    array([[ 1.,  0.],
           [ 0.,  1.]])

    
    Compute the determinant of an array.

    Parameters
    ----------
    a : (..., M, M) array_like
        Input array to compute determinants for.

    Returns
    -------
    det : (...) array_like
        Determinant of `a`.

    See Also
    --------
    slogdet : Another way to representing the determinant, more suitable
      for large matrices where underflow/overflow may occur.

    Notes
    -----
    Broadcasting rules apply, see the `numpy.linalg` documentation for
    details.

    The determinant is computed via LU factorization using the LAPACK
    routine z/dgetrf.

    Examples
    --------
    The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:

    >>> a = np.array([[1, 2], [3, 4]])
    >>> np.linalg.det(a)
    -2.0

    Computing determinants for a stack of matrices:

    >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])
    >>> a.shape
    (2, 2, 2
    >>> np.linalg.det(a)
    array([-2., -3., -8.])

    %d-dimensional array given. Array must be at least two-dimensional($   t   arrayt   asarrayt   zerost   emptyt
   empty_liket	   transposet   intct   singlet   doublet   csinglet   cdoublet   inexactt   complexfloatingt   newaxist   ravelt   allt   Inft   dott   addt   multiplyt   sqrtt   maximumt   fastCopyAndTransposet   sumt   isfinitet   sizet   finfot   errstatet	   geterrobjt
   longdoublet   rollaxist   amint   amaxt   productt   abst	   broadcast(   t   at   bt   rcondt   matht   _t   wrapt   is_1dt   mt   nt   n_rhst   ldbt   tt   result_tt   result_real_tt   real_tt   bstart   st   nlvlt   iworkt   lapack_routinet   lworkt   rworkt   workt   resultst   a_realt
   bstar_realt   lrworkt   residst   xt   st/usr/lib/python2.7/dist-packages/numpy/ma
=============
Masked Arrays
=============

Arrays sometimes contain invalid or missing data.  When doing operations
on such arrays, we wish to suppress invalid values, which is the purpose masked
arrays fulfill (an example of typical use is given below).

For example, examine the following array:

>>> x = np.array([2, 1, 3, np.nan, 5, 2, 3, np.nan])

When we try to calculate the mean of the data, the result is undetermined:

>>> np.mean(x)
nan

The mean is calculated using roughly ``np.sum(x)/len(x)``, but since
any number added to ``NaN`` [1]_ produces ``NaN``, this doesn't work.  Enter
masked arrays:

>>> m = np.ma.masked_array(x, np.isnan(x))
>>> m
masked_array(data = [2.0 1.0 3.0 -- 5.0 2.0 3.0 --],
      mask = [False False False  True False False False  True],
      fill_value=1e+20)

Here, we construct a masked array that suppress all ``NaN`` values.  We
may now proceed to calculate the mean of the other values:

>>> np.mean(m)
2.6666666666666665

.. [1] Not-a-Number, a floating point value that is the result of an
       invalid operation.

/usr/lib/python2.7/dist-packages/numpy/ma/__init__.py@xDSVUelmisMAmabsxnewafuncidx_lkargsmindxodatarndimc__builtin__
complex
GDx@G        R.cdtypeodtyperdtypetoflexz8__int___onmaskobjtype_enabledallequalcurrent1dataiterfromflexget_reallong_flxlong_stdmaskitertmp_datatmp_mask__float___basedict_flatmask_get_data_get_flat_get_mask_set_flat_set_maskanomaliesis_maskedmin_valueshort_flxshort_stdtorecordsrecordmasksharedmaskcurrenttypefix_invalidmasked_lessmaskindicesset_displayshrink_mask__floordiv____setslice___defaultmaskcurrentdescr?__ifloordiv____rfloordiv__masked_insidemasked_objectmasked_valuesmasked_greatermasked_invalidmasked_outside_get_recordmask_set_recordmaskfill_value_func_defaulthardmaskmasked_not_equalcommon_fill_valuemasked_less_equalmasked_greater_equalmasked_%(name)s(data =
 %(data)s,
       %(nlen)s mask =
 %(mask)s,
 %(nlen)s fill_value = %(fill)s)
masked_%(name)s(data =
 %(data)s,
       %(nlen)s mask =
 %(mask)s,
%(nlen)s  fill_value = %(fill)s,
      %(nlen)s dtype = %(dtype)s)
masked_%(name)s(data = %(data)s,
%(nlen)s        mask = %(mask)s,
%(nlen)s  fill_value = %(fill)s,
%(nlen)s       dtype = %(dtype)s)
masked_%(name)s(data = %(data)s,
       %(nlen)s mask = %(mask)s,
%(nlen)s  fill_value = %(fill)s)
[   s   MAErrors	   MaskErrors   MaskTypes   MaskedArrays   bool_s   abss   absolutes   adds   alls   allcloses   allequals   alltrues   amaxs   amins   angles   anoms	   anomaliess   anys   aranges   arccoss   arccoshs   arcsins   arcsinhs   arctans   arctan2s   arctanhs   argmaxs   argmins   argsorts   arounds   arrays   asarrays
   asanyarrays   bitwise_ands
   bitwise_ors   bitwise_xors   ceils   chooses   clips   common_fill_values   compresss
   compresseds   concatenates	   conjugates   copys   coss   coshs   counts   cumprods   cumsums   default_fill_values   diags   diagonals   diffs   divides   dumps   dumpss   emptys
   empty_likes   equals   exps   expand_dimss   fabss   flatten_masks   fmods   filleds   floors   floor_divides   fix_invalids   flatten_structured_arrays
   frombuffers   fromflexs   fromfunctions   getdatas   getmasks   getmaskarrays   greaters   greater_equals   harden_masks   hypots   identitys   idss   indicess   inners   innerproducts   isMAs   isMaskedArrays   is_masks	   is_maskeds   isarrays
   left_shifts   lesss
   less_equals   loads   loadss   logs   log2s   log10s   logical_ands   logical_nots
   logical_ors   logical_xors	   make_masks   make_mask_descrs   make_mask_nones   mask_ors   maskeds   masked_arrays   masked_equals   masked_greaters   masked_greater_equals   masked_insides   masked_invalids   masked_lesss   masked_less_equals   masked_not_equals   masked_objects   masked_outsides   masked_print_options   masked_singletons   masked_valuess   masked_wheres   maxs   maximums   maximum_fill_values   means   mins   minimums   minimum_fill_values   mods   multiplys   mvoids   negatives   nomasks   nonzeros	   not_equals   oness   outers   outerproducts   powers   prods   products   ptps   puts   putmasks   ranks   ravels	   remainders   repeats   reshapes   resizes   right_shifts   round_s   rounds   set_fill_values   shapes   sins   sinhs   sizes   sometrues   sorts   soften_masks   sqrts   squeezes   stds   subtracts   sums   swapaxess   takes   tans   tanhs   traces	   transposes   true_divides   vars   wheres   zeros
        Check if any of the elements of `a` are true.

        Performs a logical_or over the given axis and returns the result.
        Masked values are considered as False during computation.

        Parameters
        ----------
        axis : {None, integer}
            Axis to perform the operation over.
            If None, perform over flattened array and return a scalar.
        out : {None, array}, optional
            Array into which the result can be placed. Its type is preserved
            and it must be of the right shape to hold the output.

        See Also
        --------
        any : equivalent function

        
    Mask using floating point equality.

    Return a MaskedArray, masked where the data in array `x` are approximately
    equal to `value`, i.e. where the following condition is True

    (abs(x - value) <= atol+rtol*abs(value))

    The fill_value is set to `value` and the mask is set to ``nomask`` if
    possible.  For integers, consider using ``masked_equal``.

    Parameters
    ----------
    x : array_like
        Array to mask.
    value : float
        Masking value.
    rtol : float, optional
        Tolerance parameter.
    atol : float, optional
        Tolerance parameter (1e-8).
    copy : bool, optional
        Whether to return a copy of `x`.
    shrink : bool, optional
        Whether to collapse a mask full of False to ``nomask``.

    Returns
    -------
    result : MaskedArray
        The result of masking `x` where approximately equal to `value`.

    See Also
    --------
    masked_where : Mask where a condition is met.
    masked_equal : Mask where equal to a given value (integers).

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = np.array([1, 1.1, 2, 1.1, 3])
    >>> ma.masked_values(x, 1.1)
    masked_array(data = [1.0 -- 2.0 -- 3.0],
          mask = [False  True False  True False],
          fill_value=1.1)

    Note that `mask` is set to ``nomask`` if possible.

    >>> ma.masked_values(x, 1.5)
    masked_array(data = [ 1.   1.1  2.   1.1  3. ],
          mask = False,
          fill_value=1.5)

    For integers, the fill value will be different in general to the
    result of ``masked_equal``.

    >>> x = np.arange(5)
    >>> x
    array([0, 1, 2, 3, 4])
    >>> ma.masked_values(x, 2)
    masked_array(data = [0 1 -- 3 4],
          mask = [False False  True False False],
          fill_value=2)
    >>> ma.masked_equal(x, 2)
    masked_array(data = [0 1 -- 3 4],
          mask = [False False  True False False],
          fill_value=999999)

    
    Generic class for maximum/minimum functions.

    .. note::
      This is the base class for `_maximum_operation` and
      `_minimum_operation`.

    
        Return the data portion of the masked array as a hierarchical Python list.

        Data items are converted to the nearest compatible Python type.
        Masked values are converted to `fill_value`. If `fill_value` is None,
        the corresponding entries in the output list will be ``None``.

        Parameters
        ----------
        fill_value : scalar, optional
            The value to use for invalid entries. Default is None.

        Returns
        -------
        result : list
            The Python list representation of the masked array.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3], [4,5,6], [7,8,9]], mask=[0] + [1,0]*4)
        >>> x.tolist()
        [[1, None, 3], [None, 5, None], [7, None, 9]]
        >>> x.tolist(-999)
        [[1, -999, 3], [-999, 5, -999], [7, -999, 9]]

        True divide self by other in-place.
    Flat iterator object to iterate over masked arrays.

    A `MaskedIterator` iterator is returned by ``x.flat`` for any masked array
    `x`. It allows iterating over the array as if it were a 1-D array,
    either in a for-loop or by calling its `next` method.

    Iteration is done in C-contiguous style, with the last index varying the
    fastest. The iterator can also be indexed using basic slicing or
    advanced indexing.

    See Also
    --------
    MaskedArray.flat : Return a flat iterator over an array.
    MaskedArray.flatten : Returns a flattened copy of an array.

    Notes
    -----
    `MaskedIterator` is not exported by the `ma` module. Instead of
    instantiating a `MaskedIterator` directly, use `MaskedArray.flat`.

    Examples
    --------
    >>> x = np.ma.array(arange(6).reshape(2, 3))
    >>> fl = x.flat
    >>> type(fl)
    <class 'numpy.ma.core.MaskedIterator'>
    >>> for item in fl:
    ...     print item
    ...
    0
    1
    2
    3
    4
    5

    Extracting more than a single element b indexing the `MaskedIterator`
    returns a masked array:

    >>> fl[2:4]
    masked_array(data = [2 3],
                 mask = False,
           fill_value = 999999)

    
        Return the addresses of the data and mask areas.

        Parameters
        ----------
        None

        Examples
        --------
        >>> x = np.ma.array([1, 2, 3], mask=[0, 1, 1])
        >>> x.ids()
        (166670640, 166659832)

        If the array has no mask, the address of `nomask` is returned. This address
        is typically not close to the data in memory:

        >>> x = np.ma.array([1, 2, 3])
        >>> x.ids()
        (166691080, 3083169284L)

        Class for mask related errors.
    Return the filling value of a, if any.  Otherwise, returns the
    default filling value for that type.

    Unsuitable type for calculating minimum.
    Return the common filling value of two masked arrays, if any.

    If ``a.fill_value == b.fill_value``, return the fill value,
    otherwise return None.

    Parameters
    ----------
    a, b : MaskedArray
        The masked arrays for which to compare fill values.

    Returns
    -------
    fill_value : scalar or None
        The common fill value, or None.

    Examples
    --------
    >>> x = np.ma.array([0, 1.], fill_value=3)
    >>> y = np.ma.array([0, 1.], fill_value=3)
    >>> np.ma.common_fill_value(x, y)
    3.0

    Inconsistant shape between the condition and the input (got %s and %s)DomainGreater(v)(x) = true where x <= v
        Save a masked array to a file in binary format.

        .. warning::
          This function is not implemented yet.

        Raises
        ------
        NotImplementedError
            When `tofile` is called.

        Multiply other by self, and return a new masked array.Return the mask of the records.
    A record is masked when all the fields are masked.

        
    Extract a diagonal or construct a diagonal array.

    This function is the equivalent of `numpy.diag` that takes masked
    values into account, see `numpy.diag` for details.

    See Also
    --------
    numpy.diag : Equivalent function for ndarrays.

    
        Return the cumulative sum of the elements along the given axis.
        The cumulative sum is calculated over the flattened array by
        default, otherwise over the specified axis.

        Masked values are set to 0 internally during the computation.
        However, their position is saved, and the result will be masked at
        the same locations.

        Parameters
        ----------
        axis : {None, -1, int}, optional
            Axis along which the sum is computed. The default (`axis` = None) is to
            compute over the flattened array. `axis` may be negative, in which case
            it counts from the   last to the first axis.
        dtype : {None, dtype}, optional
            Type of the returned array and of the accumulator in which the
            elements are summed.  If `dtype` is not specified, it defaults
            to the dtype of `a`, unless `a` has an integer dtype with a
            precision less than that of the default platform integer.  In
            that case, the default platform integer is used.
        out : ndarray, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output
            but the type will be cast if necessary.

        Returns
        -------
        cumsum : ndarray.
            A new array holding the result is returned unless ``out`` is
            specified, in which case a reference to ``out`` is returned.

        Notes
        -----
        The mask is lost if `out` is not a valid :class:`MaskedArray` !

        Arithmetic is modular when using integer types, and no error is
        raised on overflow.

        Examples
        --------
        >>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0])
        >>> print marr.cumsum()
        [0 1 3 -- -- -- 9 16 24 33]

        
        Return the indices of unmasked elements that are not zero.

        Returns a tuple of arrays, one for each dimension, containing the
        indices of the non-zero elements in that dimension. The corresponding
        non-zero values can be obtained with::

            a[a.nonzero()]

        To group the indices by element, rather than dimension, use
        instead::

            np.transpose(a.nonzero())

        The result of this is always a 2d array, with a row for each non-zero
        element.

        Parameters
        ----------
        None

        Returns
        -------
        tuple_of_arrays : tuple
            Indices of elements that are non-zero.

        See Also
        --------
        numpy.nonzero :
            Function operating on ndarrays.
        flatnonzero :
            Return indices that are non-zero in the flattened version of the input
            array.
        ndarray.nonzero :
            Equivalent ndarray method.
        count_nonzero :
            Counts the number of non-zero elements in the input array.

        Examples
        --------
        >>> import numpy.ma as ma
        >>> x = ma.array(np.eye(3))
        >>> x
        masked_array(data =
         [[ 1.  0.  0.]
         [ 0.  1.  0.]
         [ 0.  0.  1.]],
              mask =
         False,
              fill_value=1e+20)
        >>> x.nonzero()
        (array([0, 1, 2]), array([0, 1, 2]))

        Masked elements are ignored.

        >>> x[1, 1] = ma.masked
        >>> x
        masked_array(data =
         [[1.0 0.0 0.0]
         [0.0 -- 0.0]
         [0.0 0.0 1.0]],
              mask =
         [[False False False]
         [False  True False]
         [False False False]],
              fill_value=1e+20)
        >>> x.nonzero()
        (array([0, 2]), array([0, 2]))

        Indices can also be grouped by element.

        >>> np.transpose(x.nonzero())
        array([[0, 0],
               [2, 2]])

        A common use for ``nonzero`` is to find the indices of an array, where
        a condition is True.  Given an array `a`, the condition `a` > 3 is a
        boolean array and since False is interpreted as 0, ma.nonzero(a > 3)
        yields the indices of the `a` where the condition is true.

        >>> a = ma.array([[1,2,3],[4,5,6],[7,8,9]])
        >>> a > 3
        masked_array(data =
         [[False False False]
         [ True  True  True]
         [ True  True  True]],
              mask =
         False,
              fill_value=999999)
        >>> ma.nonzero(a > 3)
        (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))

        The ``nonzero`` method of the condition array can also be called.

        >>> (a > 3).nonzero()
        (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))

        
        Return `a` where condition is ``True``.

        If condition is a `MaskedArray`, missing values are considered
        as ``False``.

        Parameters
        ----------
        condition : var
            Boolean 1-d array selecting which entries to return. If len(condition)
            is less than the size of a along the axis, then output is truncated
            to length of condition array.
        axis : {None, int}, optional
            Axis along which the operation must be performed.
        out : {None, ndarray}, optional
            Alternative output array in which to place the result. It must have
            the same shape as the expected output but the type will be cast if
            necessary.

        Returns
        -------
        result : MaskedArray
            A :class:`MaskedArray` object.

        Notes
        -----
        Please note the difference with :meth:`compressed` !
        The output of :meth:`compress` has a mask, the output of
        :meth:`compressed` does not.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]
        >>> x.compress([1, 0, 1])
        masked_array(data = [1 3],
              mask = [False False],
              fill_value=999999)

        >>> x.compress([1, 0, 1], axis=1)
        masked_array(data =
         [[1 3]
         [-- --]
         [7 9]],
              mask =
         [[False False]
         [ True  True]
         [False False]],
              fill_value=999999)

        
        Return array of indices to the minimum values along the given axis.

        Parameters
        ----------
        axis : {None, integer}
            If None, the index is into the flattened array, otherwise along
            the specified axis
        fill_value : {var}, optional
            Value used to fill in the masked values.  If None, the output of
            minimum_fill_value(self._data) is used instead.
        out : {None, array}, optional
            Array into which the result can be placed. Its type is preserved
            and it must be of the right shape to hold the output.

        Returns
        -------
        {ndarray, scalar}
            If multi-dimension input, returns a new ndarray of indices to the
            minimum values along the given axis.  Otherwise, returns a scalar
            of index to the minimum values along the given axis.

        Examples
        --------
        >>> x = np.ma.array(arange(4), mask=[1,1,0,0])
        >>> x.shape = (2,2)
        >>> print x
        [[-- --]
         [2 3]]
        >>> print x.argmin(axis=0, fill_value=-1)
        [0 0]
        >>> print x.argmin(axis=0, fill_value=9)
        [1 1]

        
        Count the non-masked elements of the array along the given axis.

        Parameters
        ----------
        axis : int, optional
            Axis along which to count the non-masked elements. If `axis` is
            `None`, all non-masked elements are counted.

        Returns
        -------
        result : int or ndarray
            If `axis` is `None`, an integer count is returned. When `axis` is
            not `None`, an array with shape determined by the lengths of the
            remaining axes, is returned.

        See Also
        --------
        count_masked : Count masked elements in array or along a given axis.

        Examples
        --------
        >>> import numpy.ma as ma
        >>> a = ma.arange(6).reshape((2, 3))
        >>> a[1, :] = ma.masked
        >>> a
        masked_array(data =
         [[0 1 2]
         [-- -- --]],
                     mask =
         [[False False False]
         [ True  True  True]],
               fill_value = 999999)
        >>> a.count()
        3

        When the `axis` keyword is specified an array of appropriate size is
        returned.

        >>> a.count(axis=0)
        array([1, 1, 1])
        >>> a.count(axis=1)
        array([3, 0])

        
    Mask an array where equal to a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x == value).  For floating point arrays,
    consider using ``masked_values(x, value)``.

    See Also
    --------
    masked_where : Mask where a condition is met.
    masked_values : Mask using floating point equality.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_equal(a, 2)
    masked_array(data = [0 1 -- 3],
          mask = [False False  True False],
          fill_value=999999)

    A masked array does not own its data and therefore cannot be resized.
Use the numpy.ma.resize function instead.Create the masked_print_option object.
        Copy the mask and set the sharedmask flag to False.

        Whether the mask is shared between masked arrays can be seen from
        the `sharedmask` property. `unshare_mask` ensures the mask is not shared.
        A copy of the mask is only made if it was shared.

        See Also
        --------
        sharedmask

        Add other to self, and return a new masked array.
    An array class with possibly masked values.

    Masked values of True exclude the corresponding element from any
    computation.

    Construction::

      x = MaskedArray(data, mask=nomask, dtype=None,
                      copy=False, subok=True, ndmin=0, fill_value=None,
                      keep_mask=True, hard_mask=None, shrink=True)

    Parameters
    ----------
    data : array_like
        Input data.
    mask : sequence, optional
        Mask. Must be convertible to an array of booleans with the same
        shape as `data`. True indicates a masked (i.e. invalid) data.
    dtype : dtype, optional
        Data type of the output.
        If `dtype` is None, the type of the data argument (``data.dtype``)
        is used. If `dtype` is not None and different from ``data.dtype``,
        a copy is performed.
    copy : bool, optional
        Whether to copy the input data (True), or to use a reference instead.
        Default is False.
    subok : bool, optional
        Whether to return a subclass of `MaskedArray` if possible (True) or a
        plain `MaskedArray`. Default is True.
    ndmin : int, optional
        Minimum number of dimensions. Default is 0.
    fill_value : scalar, optional
        Value used to fill in the masked values when necessary.
        If None, a default based on the data-type is used.
    keep_mask : bool, optional
        Whether to combine `mask` with the mask of the input data, if any
        (True), or to use only `mask` for the output (False). Default is True.
    hard_mask : bool, optional
        Whether to use a hard mask or not. With a hard mask, masked values
        cannot be unmasked. Default is False.
    shrink : bool, optional
        Whether to force compression of an empty mask. Default is True.

    maskedarray version of the numpy function.
    Return input with invalid data masked and replaced by a fill value.

    Invalid data means values of `nan`, `inf`, etc.

    Parameters
    ----------
    a : array_like
        Input array, a (subclass of) ndarray.
    copy : bool, optional
        Whether to use a copy of `a` (True) or to fix `a` in place (False).
        Default is True.
    fill_value : scalar, optional
        Value used for fixing invalid data. Default is None, in which case
        the ``a.fill_value`` is used.

    Returns
    -------
    b : MaskedArray
        The input array with invalid entries fixed.

    Notes
    -----
    A copy is performed by default.

    Examples
    --------
    >>> x = np.ma.array([1., -1, np.nan, np.inf], mask=[1] + [0]*3)
    >>> x
    masked_array(data = [-- -1.0 nan inf],
                 mask = [ True False False False],
           fill_value = 1e+20)
    >>> np.ma.fix_invalid(x)
    masked_array(data = [-- -1.0 -- --],
                 mask = [ True False  True  True],
           fill_value = 1e+20)

    >>> fixed = np.ma.fix_invalid(x)
    >>> fixed.data
    array([  1.00000000e+00,  -1.00000000e+00,   1.00000000e+20,
             1.00000000e+20])
    >>> x.data
    array([  1.,  -1.,  NaN,  Inf])

    
    Return a masked array with elements from x or y, depending on condition.

    Returns a masked array, shaped like condition, where the elements
    are from `x` when `condition` is True, and from `y` otherwise.
    If neither `x` nor `y` are given, the function returns a tuple of
    indices where `condition` is True (the result of
    ``condition.nonzero()``).

    Parameters
    ----------
    condition : array_like, bool
        The condition to meet. For each True element, yield the corresponding
        element from `x`, otherwise from `y`.
    x, y : array_like, optional
        Values from which to choose. `x` and `y` need to have the same shape
        as condition, or be broadcast-able to that shape.

    Returns
    -------
    out : MaskedArray or tuple of ndarrays
        The resulting masked array if `x` and `y` were given, otherwise
        the result of ``condition.nonzero()``.

    See Also
    --------
    numpy.where : Equivalent function in the top-level NumPy module.

    Examples
    --------
    >>> x = np.ma.array(np.arange(9.).reshape(3, 3), mask=[[0, 1, 0],
    ...                                                    [1, 0, 1],
    ...                                                    [0, 1, 0]])
    >>> print x
    [[0.0 -- 2.0]
     [-- 4.0 --]
     [6.0 -- 8.0]]
    >>> np.ma.where(x > 5)    # return the indices where x > 5
    (array([2, 2]), array([0, 2]))

    >>> print np.ma.where(x > 5, x, -3.1416)
    [[-3.1416 -- -3.1416]
     [-- -3.1416 --]
     [6.0 -- 8.0]]

    Function version of the eponymous method.Add other to self in-place.Display the string to print for masked values.String representation.

        
    Check if all of the elements of `a` are true.

    Performs a :func:`logical_and` over the given axis and returns the result.
    Masked values are considered as True during computation.
    For convenience, the output array is masked where ALL the values along the
    current axis are masked: if the output would have been a scalar and that
    all the values are masked, then the output is `masked`.

    Parameters
    ----------
    axis : {None, integer}
        Axis to perform the operation over.
        If None, perform over flattened array.
    out : {None, array}, optional
        Array into which the result can be placed. Its type is preserved
        and it must be of the right shape to hold the output.

    See Also
    --------
    all : equivalent function

    Examples
    --------
    >>> np.ma.array([1,2,3]).all()
    True
    >>> a = np.ma.array([1,2,3], mask=True)
    >>> (a.all() is np.ma.masked)
    True

        
    Return the youngest subclass of MaskedArray from a list of (masked) arrays.
    In case of siblings, the first listed takes over.

    
    Construct a dtype description list from a given dtype.

    Returns a new dtype object, with the type of all fields in `ndtype` to a
    boolean type. Field names are not altered.

    Parameters
    ----------
    ndtype : dtype
        The dtype to convert.

    Returns
    -------
    result : dtype
        A dtype that looks like `ndtype`, the type of all fields is boolean.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> dtype = np.dtype({'names':['foo', 'bar'],
                          'formats':[np.float32, np.int]})
    >>> dtype
    dtype([('foo', '<f4'), ('bar', '<i4')])
    >>> ma.make_mask_descr(dtype)
    dtype([('foo', '|b1'), ('bar', '|b1')])
    >>> ma.make_mask_descr(np.float32)
    <type 'numpy.bool_'>

    Reduce `target` along the given `axis`.
    Return True if m is a valid, standard mask.

    This function does not check the contents of the input, only that the
    type is MaskType. In particular, this function returns False if the
    mask has a flexible dtype.

    Parameters
    ----------
    m : array_like
        Array to test.

    Returns
    -------
    result : bool
        True if `m.dtype.type` is MaskType, False otherwise.

    See Also
    --------
    isMaskedArray : Test whether input is an instance of MaskedArray.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> m = ma.masked_equal([0, 1, 0, 2, 3], 0)
    >>> m
    masked_array(data = [-- 1 -- 2 3],
          mask = [ True False  True False False],
          fill_value=999999)
    >>> ma.is_mask(m)
    False
    >>> ma.is_mask(m.mask)
    True

    Input must be an ndarray (or have similar attributes)
    for it to be considered a valid mask.

    >>> m = [False, True, False]
    >>> ma.is_mask(m)
    False
    >>> m = np.array([False, True, False])
    >>> m
    array([False,  True, False], dtype=bool)
    >>> ma.is_mask(m)
    True

    Arrays with complex dtypes don't return True.

    >>> dtype = np.dtype({'names':['monty', 'pithon'],
                          'formats':[np.bool, np.bool]})
    >>> dtype
    dtype([('monty', '|b1'), ('pithon', '|b1')])
    >>> m = np.array([(True, False), (False, True), (True, False)],
                     dtype=dtype)
    >>> m
    array([(True, False), (False, True), (True, False)],
          dtype=[('monty', '|b1'), ('pithon', '|b1')])
    >>> ma.is_mask(m)
    False

    Share status of the mask (read-only).DomainGreater(v)(x) is True where x <= v.abfunc(fillx, filly) must be defined.
           abfunc(x, filly) = x for all x to enable reduce.
        
    Get the signature from obj
    Define a domain for safe division.DomainGreaterEqual(v)(x) is True where x < v.
    Define functions from existing MaskedArray methods.

    Parameters
    ----------
    methodname : str
        Name of the method to transform.

    Imaginary part.
        Return the filling value of the masked array.

        Returns
        -------
        fill_value : scalar
            The filling value.

        Examples
        --------
        >>> for dt in [np.int32, np.int64, np.float64, np.complex128]:
        ...     np.ma.array([0, 1], dtype=dt).get_fill_value()
        ...
        999999
        999999
        1e+20
        (1e+20+0j)

        >>> x = np.ma.array([0, 1.], fill_value=-np.inf)
        >>> x.get_fill_value()
        -inf

        
    Wrapper around ``cPickle.load`` which accepts either a file-like object
    or a filename.

    Parameters
    ----------
    F : str or file
        The file or file name to load.

    See Also
    --------
    dump : Pickle an array

    Notes
    -----
    This is different from `numpy.load`, which does not use cPickle but loads
    the NumPy binary .npy format.

    Execute the call behavior.
        Return a copy of self, with masked values filled with a given value.

        Parameters
        ----------
        fill_value : scalar, optional
            The value to use for invalid entries (None by default).
            If None, the `fill_value` attribute of the array is used instead.

        Returns
        -------
        filled_array : ndarray
            A copy of ``self`` with invalid entries replaced by *fill_value*
            (be it the function argument or the attribute of ``self``.

        Notes
        -----
        The result is **not** a MaskedArray!

        Examples
        --------
        >>> x = np.ma.array([1,2,3,4,5], mask=[0,0,1,0,1], fill_value=-999)
        >>> x.filled()
        array([1, 2, -999, 4, -999])
        >>> type(x.filled())
        <type 'numpy.ndarray'>

        Subclassing is preserved. This means that if the data part of the masked
        array is a matrix, `filled` returns a matrix:

        >>> x = np.ma.array(np.matrix([[1, 2], [3, 4]]), mask=[[0, 1], [1, 0]])
        >>> x.filled()
        matrix([[     1, 999999],
                [999999,      4]])

        
    Flatten a structured array.

    The data type of the output is chosen such that it can represent all of the
    (nested) fields.

    Parameters
    ----------
    a : structured array

    Returns
    -------
    output : masked array or ndarray
        A flattened masked array if the input is a masked array, otherwise a
        standard ndarray.

    Examples
    --------
    >>> ndtype = [('a', int), ('b', float)]
    >>> a = np.array([(1, 1), (2, 2)], dtype=ndtype)
    >>> flatten_structured_array(a)
    array([[1., 1.],
           [2., 2.]])

    Return the function applied to the outer product of a and b.
        Returns a copy of the MaskedArray cast to given newtype.

        Returns
        -------
        output : MaskedArray
            A copy of self cast to input newtype.
            The returned record shape matches self.shape.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3.1],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1.0 -- 3.1]
         [-- 5.0 --]
         [7.0 -- 9.0]]
        >>> print x.astype(int32)
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]

        
    Returns element-wise base array raised to power from second array.

    This is the masked array version of `numpy.power`. For details see
    `numpy.power`.

    See Also
    --------
    numpy.power

    Notes
    -----
    The *out* argument to `numpy.power` is not supported, `third` has to be
    None.

    Is the use of the display value enabled?x.__getslice__(i, j) <==> x[i:j]

        Return the slice described by (i, j).  The use of negative
        indices is not supported.

        
    Returns a completely flattened version of the mask, where nested fields
    are collapsed.

    Parameters
    ----------
    mask : array_like
        Input array, which will be interpreted as booleans.

    Returns
    -------
    flattened_mask : ndarray of bools
        The flattened input.

    Examples
    --------
    >>> mask = np.array([0, 0, 1], dtype=np.bool)
    >>> flatten_mask(mask)
    array([False, False,  True], dtype=bool)

    >>> mask = np.array([(0, 0), (0, 1)], dtype=[('a', bool), ('b', bool)])
    >>> flatten_mask(mask)
    array([False, False, False,  True], dtype=bool)

    >>> mdtype = [('a', bool), ('b', [('ba', bool), ('bb', bool)])]
    >>> mask = np.array([(0, (0, 0)), (0, (0, 1))], dtype=mdtype)
    >>> flatten_mask(mask)
    array([False, False, False, False, False,  True], dtype=bool)

    
        Return a view of the MaskedArray data

        Parameters
        ----------
        dtype : data-type or ndarray sub-class, optional
            Data-type descriptor of the returned view, e.g., float32 or int16.
            The default, None, results in the view having the same data-type
            as `a`. As with ``ndarray.view``, dtype can also be specified as
            an ndarray sub-class, which then specifies the type of the
            returned object (this is equivalent to setting the ``type``
            parameter).
        type : Python type, optional
            Type of the returned view, e.g., ndarray or matrix.  Again, the
            default None results in type preservation.

        Notes
        -----

        ``a.view()`` is used two different ways:

        ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view
        of the array's memory with a different data-type.  This can cause a
        reinterpretation of the bytes of memory.

        ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just
        returns an instance of `ndarray_subclass` that looks at the same array
        (same shape, dtype, etc.)  This does not cause a reinterpretation of the
        memory.

        If `fill_value` is not specified, but `dtype` is specified (and is not
        an ndarray sub-class), the `fill_value` of the MaskedArray will be
        reset. If neither `fill_value` nor `dtype` are specified (or if
        `dtype` is an ndarray sub-class), then the fill value is preserved.
        Finally, if `fill_value` is specified, but `dtype` is not, the fill
        value is set to the specified value.

        For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of
        bytes per entry than the previous dtype (for example, converting a
        regular array to a structured array), then the behavior of the view
        cannot be predicted just from the superficial appearance of ``a`` (shown
        by ``print(a)``). It also depends on exactly how ``a`` is stored in
        memory. Therefore if ``a`` is C-ordered versus fortran-ordered, versus
        defined as a slice or transpose, etc., the view may give different
        results.
        Return the doc of the function (from the doc of the method).Masked values are replaced by 0.Define a valid interval for the `tan` function, so that:

    ``domain_tan(eps) = True`` where ``abs(cos(x)) < eps``

    
    Use an index array to construct a new array from a set of choices.

    Given an array of integers and a set of n choice arrays, this method
    will create a new array that merges each of the choice arrays.  Where a
    value in `a` is i, the new array will have the value that choices[i]
    contains in the same place.

    Parameters
    ----------
    a : ndarray of ints
        This array must contain integers in ``[0, n-1]``, where n is the
        number of choices.
    choices : sequence of arrays
        Choice arrays. The index array and all of the choices should be
        broadcastable to the same shape.
    out : array, optional
        If provided, the result will be inserted into this array. It should
        be of the appropriate shape and `dtype`.
    mode : {'raise', 'wrap', 'clip'}, optional
        Specifies how out-of-bounds indices will behave.

        * 'raise' : raise an error
        * 'wrap' : wrap around
        * 'clip' : clip to the range

    Returns
    -------
    merged_array : array

    See Also
    --------
    choose : equivalent function

    Examples
    --------
    >>> choice = np.array([[1,1,1], [2,2,2], [3,3,3]])
    >>> a = np.array([2, 1, 0])
    >>> np.ma.choose(a, choice)
    masked_array(data = [3 2 1],
          mask = False,
          fill_value=999999)

    
    Set storage-indexed locations to corresponding values.

    This function is equivalent to `MaskedArray.put`, see that method
    for details.

    See Also
    --------
    MaskedArray.put

    
    Mask the array `x` where the data are exactly equal to value.

    This function is similar to `masked_values`, but only suitable
    for object arrays: for floating point, use `masked_values` instead.

    Parameters
    ----------
    x : array_like
        Array to mask
    value : object
        Comparison value
    copy : {True, False}, optional
        Whether to return a copy of `x`.
    shrink : {True, False}, optional
        Whether to collapse a mask full of False to nomask

    Returns
    -------
    result : MaskedArray
        The result of masking `x` where equal to `value`.

    See Also
    --------
    masked_where : Mask where a condition is met.
    masked_equal : Mask where equal to a given value (integers).
    masked_values : Mask using floating point equality.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> food = np.array(['green_eggs', 'ham'], dtype=object)
    >>> # don't eat spoiled food
    >>> eat = ma.masked_object(food, 'green_eggs')
    >>> print eat
    [-- ham]
    >>> # plain ol` ham is boring
    >>> fresh_food = np.array(['cheese', 'ham', 'pineapple'], dtype=object)
    >>> eat = ma.masked_object(fresh_food, 'green_eggs')
    >>> print eat
    [cheese ham pineapple]

    Note that `mask` is set to ``nomask`` if possible.

    >>> eat
    masked_array(data = [cheese ham pineapple],
          mask = False,
          fill_value=?)

    
    Changes elements of an array based on conditional and input values.

    This is the masked array version of `numpy.putmask`, for details see
    `numpy.putmask`.

    See Also
    --------
    numpy.putmask

    Notes
    -----
    Using a masked array as `values` will **not** transform a `ndarray` into
    a `MaskedArray`.

    
        Return a copy with masked fields filled with a given value.

        Parameters
        ----------
        fill_value : scalar, optional
            The value to use for invalid entries (None by default).
            If None, the `fill_value` attribute is used instead.

        Returns
        -------
        filled_void
            A `np.void` object

        See Also
        --------
        MaskedArray.filled

    
    Mask an array where a condition is met.

    Return `a` as an array masked where `condition` is True.
    Any masked values of `a` or `condition` are also masked in the output.

    Parameters
    ----------
    condition : array_like
        Masking condition.  When `condition` tests floating point values for
        equality, consider using ``masked_values`` instead.
    a : array_like
        Array to mask.
    copy : bool
        If True (default) make a copy of `a` in the result.  If False modify
        `a` in place and return a view.

    Returns
    -------
    result : MaskedArray
        The result of masking `a` where `condition` is True.

    See Also
    --------
    masked_values : Mask using floating point equality.
    masked_equal : Mask where equal to a given value.
    masked_not_equal : Mask where `not` equal to a given value.
    masked_less_equal : Mask where less than or equal to a given value.
    masked_greater_equal : Mask where greater than or equal to a given value.
    masked_less : Mask where less than a given value.
    masked_greater : Mask where greater than a given value.
    masked_inside : Mask inside a given interval.
    masked_outside : Mask outside a given interval.
    masked_invalid : Mask invalid values (NaNs or infs).

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_where(a <= 2, a)
    masked_array(data = [-- -- -- 3],
          mask = [ True  True  True False],
          fill_value=999999)

    Mask array `b` conditional on `a`.

    >>> b = ['a', 'b', 'c', 'd']
    >>> ma.masked_where(a == 2, b)
    masked_array(data = [a b -- d],
          mask = [False False  True False],
          fill_value=N/A)

    Effect of the `copy` argument.

    >>> c = ma.masked_where(a <= 2, a)
    >>> c
    masked_array(data = [-- -- -- 3],
          mask = [ True  True  True False],
          fill_value=999999)
    >>> c[0] = 99
    >>> c
    masked_array(data = [99 -- -- 3],
          mask = [False  True  True False],
          fill_value=999999)
    >>> a
    array([0, 1, 2, 3])
    >>> c = ma.masked_where(a <= 2, a, copy=False)
    >>> c[0] = 99
    >>> c
    masked_array(data = [99 -- -- 3],
          mask = [False  True  True False],
          fill_value=999999)
    >>> a
    array([99,  1,  2,  3])

    When `condition` or `a` contain masked values.

    >>> a = np.arange(4)
    >>> a = ma.masked_where(a == 2, a)
    >>> a
    masked_array(data = [0 1 -- 3],
          mask = [False False  True False],
          fill_value=999999)
    >>> b = np.arange(4)
    >>> b = ma.masked_where(b == 0, b)
    >>> b
    masked_array(data = [-- 1 2 3],
          mask = [ True False False False],
          fill_value=999999)
    >>> ma.masked_where(a == 3, b)
    masked_array(data = [-- 1 -- --],
          mask = [ True False  True  True],
          fill_value=999999)

        %s
%sa.ptp(axis=None) =  a.max(axis)-a.min(axis)
    Return the default fill value for the argument object.

    The default filling value depends on the datatype of the input
    array or the type of the input scalar:

       ========  ========
       datatype  default
       ========  ========
       bool      True
       int       999999
       float     1.e20
       complex   1.e20+0j
       object    '?'
       string    'N/A'
       ========  ========


    Parameters
    ----------
    obj : ndarray, dtype or scalar
        The array data-type or scalar for which the default fill value
        is returned.

    Returns
    -------
    fill_value : scalar
        The default fill value.

    Examples
    --------
    >>> np.ma.default_fill_value(1)
    999999
    >>> np.ma.default_fill_value(np.array([1.1, 2., np.pi]))
    1e+20
    >>>  np.ma.default_fill_value(np.dtype(complex))
    (1e+20+0j)

    
    Expand the shape of an array.

    Expands the shape of the array by including a new axis before the one
    specified by the `axis` parameter. This function behaves the same as
    `numpy.expand_dims` but preserves masked elements.

    See Also
    --------
    numpy.expand_dims : Equivalent function in top-level NumPy module.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = ma.array([1, 2, 4])
    >>> x[1] = ma.masked
    >>> x
    masked_array(data = [1 -- 4],
                 mask = [False  True False],
           fill_value = 999999)
    >>> np.expand_dims(x, axis=0)
    array([[1, 2, 4]])
    >>> ma.expand_dims(x, axis=0)
    masked_array(data =
     [[1 -- 4]],
                 mask =
     [[False  True False]],
           fill_value = 999999)

    The same result can be achieved using slicing syntax with `np.newaxis`.

    >>> x[np.newaxis, :]
    masked_array(data =
     [[1 -- 4]],
                 mask =
     [[False  True False]],
           fill_value = 999999)

    
    Return the minimum along a given axis.

    Parameters
    ----------
    axis : {None, int}, optional
        Axis along which to operate.  By default, ``axis`` is None and the
        flattened input is used.
    out : array_like, optional
        Alternative output array in which to place the result.  Must be of
        the same shape and buffer length as the expected output.
    fill_value : {var}, optional
        Value used to fill in the masked values.
        If None, use the output of `minimum_fill_value`.

    Returns
    -------
    amin : array_like
        New array holding the result.
        If ``out`` was specified, ``out`` is returned.

    See Also
    --------
    minimum_fill_value
        Returns the minimum filling value for a given datatype.

        Returns the mask, True if ``masked``, False if ``nomask``.Generates a flattened version of the sequence.do a|=b on each field of a, recursivelyMultiply self by other in-place.
    Pickle a masked array to a file.

    This is a wrapper around ``cPickle.dump``.

    Parameters
    ----------
    a : MaskedArray
        The array to be pickled.
    F : str or file-like object
        The file to pickle `a` to. If a string, the full path to the file.

    
        Return the real part of the masked array.

        The returned array is a view on the real part of the `MaskedArray`
        whose `get_real` method is called.

        Parameters
        ----------
        None

        Returns
        -------
        result : MaskedArray
            The real part of the masked array.

        See Also
        --------
        get_imag, real, imag

        Examples
        --------
        >>> x = np.ma.array([1+1.j, -2j, 3.45+1.6j], mask=[False, True, False])
        >>> x.get_real()
        masked_array(data = [1.0 -- 3.45],
                     mask = [False  True False],
               fill_value = 1e+20)

        Masked data information would be lost in one or more location.Reduce target along the given axis.Set the mask.

        Return the function applied to the outer product of a and b.

        Set the enabling shrink to `shrink`.
        Returns array of indices of the maximum values along the given axis.
        Masked values are treated as if they had the value fill_value.

        Parameters
        ----------
        axis : {None, integer}
            If None, the index is into the flattened array, otherwise along
            the specified axis
        fill_value : {var}, optional
            Value used to fill in the masked values.  If None, the output of
            maximum_fill_value(self._data) is used instead.
        out : {None, array}, optional
            Array into which the result can be placed. Its type is preserved
            and it must be of the right shape to hold the output.

        Returns
        -------
        index_array : {integer_array}

        Examples
        --------
        >>> a = np.arange(6).reshape(2,3)
        >>> a.argmax()
        5
        >>> a.argmax(0)
        array([1, 1, 1])
        >>> a.argmax(1)
        array([2, 2])

        
    Set the filling value of a, if a is a masked array.

    This function changes the fill value of the masked array `a` in place.
    If `a` is not a masked array, the function returns silently, without
    doing anything.

    Parameters
    ----------
    a : array_like
        Input array.
    fill_value : dtype
        Filling value. A consistency test is performed to make sure
        the value is compatible with the dtype of `a`.

    Returns
    -------
    None
        Nothing returned by this function.

    See Also
    --------
    maximum_fill_value : Return the default fill value for a dtype.
    MaskedArray.fill_value : Return current fill value.
    MaskedArray.set_fill_value : Equivalent method.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(5)
    >>> a
    array([0, 1, 2, 3, 4])
    >>> a = ma.masked_where(a < 3, a)
    >>> a
    masked_array(data = [-- -- -- 3 4],
          mask = [ True  True  True False False],
          fill_value=999999)
    >>> ma.set_fill_value(a, -999)
    >>> a
    masked_array(data = [-- -- -- 3 4],
          mask = [ True  True  True False False],
          fill_value=-999)

    Nothing happens if `a` is not a masked array.

    >>> a = range(5)
    >>> a
    [0, 1, 2, 3, 4]
    >>> ma.set_fill_value(a, 100)
    >>> a
    [0, 1, 2, 3, 4]
    >>> a = np.arange(5)
    >>> a
    array([0, 1, 2, 3, 4])
    >>> ma.set_fill_value(a, 100)
    >>> a
    array([0, 1, 2, 3, 4])

    Raise self to the power other, in place.Defines an iterator for mvoiddomain_check_interval(a,b)(x) = true where x < a or y > b
        Return the maximum along a given axis.

        Parameters
        ----------
        axis : {None, int}, optional
            Axis along which to operate.  By default, ``axis`` is None and the
            flattened input is used.
        out : array_like, optional
            Alternative output array in which to place the result.  Must
            be of the same shape and buffer length as the expected output.
        fill_value : {var}, optional
            Value used to fill in the masked values.
            If None, use the output of maximum_fill_value().

        Returns
        -------
        amax : array_like
            New array holding the result.
            If ``out`` was specified, ``out`` is returned.

        See Also
        --------
        maximum_fill_value
            Returns the maximum filling value for a given datatype.

        
    Return a boolean mask of the given shape, filled with False.

    This function returns a boolean ndarray with all entries False, that can
    be used in common mask manipulations. If a complex dtype is specified, the
    type of each field is converted to a boolean type.

    Parameters
    ----------
    newshape : tuple
        A tuple indicating the shape of the mask.
    dtype : {None, dtype}, optional
        If None, use a MaskType instance. Otherwise, use a new datatype with
        the same fields as `dtype`, converted to boolean types.

    Returns
    -------
    result : ndarray
        An ndarray of appropriate shape and dtype, filled with False.

    See Also
    --------
    make_mask : Create a boolean mask from an array.
    make_mask_descr : Construct a dtype description list from a given dtype.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> ma.make_mask_none((3,))
    array([False, False, False], dtype=bool)

    Defining a more complex dtype.

    >>> dtype = np.dtype({'names':['foo', 'bar'],
                          'formats':[np.float32, np.int]})
    >>> dtype
    dtype([('foo', '<f4'), ('bar', '<i4')])
    >>> ma.make_mask_none((3,), dtype=dtype)
    array([(False, False), (False, False), (False, False)],
          dtype=[('foo', '|b1'), ('bar', '|b1')])

    
    Define binary operations that have a domain, like divide.

    They have no reduce, outer or accumulate.

    Parameters
    ----------
    mbfunc : function
        The function for which to define a masked version. Made available
        as ``_DomainedBinaryOperation.f``.
    domain : class instance
        Default domain for the function. Should be one of the ``_Domain*``
        classes.
    fillx : scalar, optional
        Filling value for the first argument, default is 0.
    filly : scalar, optional
        Filling value for the second argument, default is 0.

    
    Handle the string used to represent missing data in a masked array.

    
    Mask an array where less than or equal to a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x <= value).

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_less_equal(a, 2)
    masked_array(data = [-- -- -- 3],
          mask = [ True  True  True False],
          fill_value=999999)

    
    Private function validating the given `fill_value` for the given dtype.

    If fill_value is None, it is set to the default corresponding to the dtype
    if this latter is standard (no fields). If the datatype is flexible (named
    fields), fill_value is set to a tuple whose elements are the default fill
    values corresponding to each field.

    If fill_value is not None, its value is forced to the given dtype.

    Warning: converting a masked element to nan.
        Return the next value, or raise StopIteration.

        Examples
        --------
        >>> x = np.ma.array([3, 2], mask=[0, 1])
        >>> fl = x.flat
        >>> fl.next()
        3
        >>> fl.next()
        masked_array(data = --,
                     mask = True,
               fill_value = 1e+20)
        >>> fl.next()
        Traceback (most recent call last):
          File "<stdin>", line 1, in <module>
          File "/home/ralf/python/numpy/numpy/ma/core.py", line 2243, in next
            d = self.dataiter.next()
        StopIteration

        Masked version of 
        Return the imaginary part of the masked array.

        The returned array is a view on the imaginary part of the `MaskedArray`
        whose `get_imag` method is called.

        Parameters
        ----------
        None

        Returns
        -------
        result : MaskedArray
            The imaginary part of the masked array.

        See Also
        --------
        get_real, real, imag

        Examples
        --------
        >>> x = np.ma.array([1+1.j, -2j, 3.45+1.6j], mask=[False, True, False])
        >>> x.get_imag()
        masked_array(data = [1.0 -- 1.6],
                     mask = [False  True False],
               fill_value = 1e+20)

        
    Load a pickle from the current string.

    The result of ``cPickle.loads(strg)`` is returned.

    Parameters
    ----------
    strg : str
        The string to load.

    See Also
    --------
    dumps : Return a string corresponding to the pickling of a masked array.

    
    Create a new masked array from scratch.

    Notes
    -----
    A masked array can also be created by taking a .view(MaskedArray).

        
    Define a wrapper for basic array methods.

    Upon call, returns a masked array, where the new ``_data`` array is
    the output of the corresponding method called on the original
    ``_data``.

    If `onmask` is True, the new mask is the output of the method called
    on the initial mask. Otherwise, the new mask is just a reference
    to the initial mask.

    Attributes
    ----------
    _onmask : bool
        Holds the `onmask` parameter.
    obj : object
        The object calling `_arraymethod`.

    Parameters
    ----------
    funcname : str
        Name of the function to apply on data.
    onmask : bool
        Whether the mask must be processed also (True) or left
        alone (False). Default is True. Make available as `_onmask`
        attribute.

    
        Return (maximum - minimum) along the the given dimension
        (i.e. peak-to-peak value).

        Parameters
        ----------
        axis : {None, int}, optional
            Axis along which to find the peaks.  If None (default) the
            flattened array is used.
        out : {None, array_like}, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output
            but the type will be cast if necessary.
        fill_value : {var}, optional
            Value used to fill in the masked values.

        Returns
        -------
        ptp : ndarray.
            A new array holding the result, unless ``out`` was
            specified, in which case a reference to ``out`` is returned.

        Cannot alter the masked element.
    Return the mask of the records.
    A record is masked when all the fields are masked.

        
    Return a new masked array with the specified size and shape.

    This is the masked equivalent of the `numpy.resize` function. The new
    array is filled with repeated copies of `x` (in the order that the
    data are stored in memory). If `x` is masked, the new array will be
    masked, and the new mask will be a repetition of the old one.

    See Also
    --------
    numpy.resize : Equivalent function in the top level NumPy module.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = ma.array([[1, 2] ,[3, 4]])
    >>> a[0, 1] = ma.masked
    >>> a
    masked_array(data =
     [[1 --]
     [3 4]],
                 mask =
     [[False  True]
     [False False]],
           fill_value = 999999)
    >>> np.resize(a, (3, 3))
    array([[1, 2, 3],
           [4, 1, 2],
           [3, 4, 1]])
    >>> ma.resize(a, (3, 3))
    masked_array(data =
     [[1 -- 3]
     [4 1 --]
     [3 4 1]],
                 mask =
     [[False  True False]
     [False False  True]
     [False False False]],
           fill_value = 999999)

    A MaskedArray is always returned, regardless of the input type.

    >>> a = np.array([[1, 2] ,[3, 4]])
    >>> ma.resize(a, (3, 3))
    masked_array(data =
     [[1 2 3]
     [4 1 2]
     [3 4 1]],
                 mask =
     False,
           fill_value = 999999)

    
    Fake a 'void' object to use for masked array with structured dtypes.
    
    Mask an array inside a given interval.

    Shortcut to ``masked_where``, where `condition` is True for `x` inside
    the interval [v1,v2] (v1 <= x <= v2).  The boundaries `v1` and `v2`
    can be given in either order.

    See Also
    --------
    masked_where : Mask where a condition is met.

    Notes
    -----
    The array `x` is prefilled with its filling value.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = [0.31, 1.2, 0.01, 0.2, -0.4, -1.1]
    >>> ma.masked_inside(x, -0.3, 0.3)
    masked_array(data = [0.31 1.2 -- -- -0.4 -1.1],
          mask = [False False  True  True False False],
          fill_value=1e+20)

    The order of `v1` and `v2` doesn't matter.

    >>> ma.masked_inside(x, 0.3, -0.3)
    masked_array(data = [0.31 1.2 -- -- -0.4 -1.1],
          mask = [False False  True  True False False],
          fill_value=1e+20)

    Convert to int.
        Return the sum of the array elements over the given axis.
        Masked elements are set to 0 internally.

        Parameters
        ----------
        axis : {None, -1, int}, optional
            Axis along which the sum is computed. The default
            (`axis` = None) is to compute over the flattened array.
        dtype : {None, dtype}, optional
            Determines the type of the returned array and of the accumulator
            where the elements are summed. If dtype has the value None and
            the type of a is an integer type of precision less than the default
            platform integer, then the default platform integer precision is
            used.  Otherwise, the dtype is the same as that of a.
        out :  {None, ndarray}, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output
            but the type will be cast if necessary.

        Returns
        -------
        sum_along_axis : MaskedArray or scalar
            An array with the same shape as self, with the specified
            axis removed.   If self is a 0-d array, or if `axis` is None, a scalar
            is returned.  If an output array is specified, a reference to
            `out` is returned.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]
        >>> print x.sum()
        25
        >>> print x.sum(axis=1)
        [4 5 16]
        >>> print x.sum(axis=0)
        [8 5 12]
        >>> print type(x.sum(axis=0, dtype=np.int64)[0])
        <type 'numpy.int64'>

        
        (this docstring should be overwritten)
        
    Mask an array where greater than or equal to a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x >= value).

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_greater_equal(a, 2)
    masked_array(data = [0 1 -- --],
          mask = [False False  True  True],
          fill_value=999999)

    maximum(a, b) or maximum(a)
           In one argument case returns the scalar maximum.
        
    Return all the non-masked data as a 1-D array.

    This function is equivalent to calling the "compressed" method of a
    `MaskedArray`, see `MaskedArray.compressed` for details.

    See Also
    --------
    MaskedArray.compressed
        Equivalent method.

    Private function allowing recursion in make_descr.
        Return an ndarray of indices that sort the array along the
        specified axis.  Masked values are filled beforehand to
        `fill_value`.

        Parameters
        ----------
        axis : int, optional
            Axis along which to sort.  The default is -1 (last axis).
            If None, the flattened array is used.
        fill_value : var, optional
            Value used to fill the array before sorting.
            The default is the `fill_value` attribute of the input array.
        kind : {'quicksort', 'mergesort', 'heapsort'}, optional
            Sorting algorithm.
        order : list, optional
            When `a` is an array with fields defined, this argument specifies
            which fields to compare first, second, etc.  Not all fields need be
            specified.

        Returns
        -------
        index_array : ndarray, int
            Array of indices that sort `a` along the specified axis.
            In other words, ``a[index_array]`` yields a sorted `a`.

        See Also
        --------
        sort : Describes sorting algorithms used.
        lexsort : Indirect stable sort with multiple keys.
        ndarray.sort : Inplace sort.

        Notes
        -----
        See `sort` for notes on the different sorting algorithms.

        Examples
        --------
        >>> a = np.ma.array([3,2,1], mask=[False, False, True])
        >>> a
        masked_array(data = [3 2 --],
                     mask = [False False  True],
               fill_value = 999999)
        >>> a.argsort()
        array([1, 0, 2])

        Divide other into self, and return a new masked array.
        Return the product of the array elements over the given axis.
        Masked elements are set to 1 internally for computation.

        Parameters
        ----------
        axis : {None, int}, optional
            Axis over which the product is taken. If None is used, then the
            product is over all the array elements.
        dtype : {None, dtype}, optional
            Determines the type of the returned array and of the accumulator
            where the elements are multiplied. If ``dtype`` has the value ``None``
            and the type of a is an integer type of precision less than the default
            platform integer, then the default platform integer precision is
            used.  Otherwise, the dtype is the same as that of a.
        out : {None, array}, optional
            Alternative output array in which to place the result. It must have
            the same shape as the expected output but the type will be cast if
            necessary.

        Returns
        -------
        product_along_axis : {array, scalar}, see dtype parameter above.
            Returns an array whose shape is the same as a with the specified
            axis removed. Returns a 0d array when a is 1d or axis=None.
            Returns a reference to the specified output array if specified.

        See Also
        --------
        prod : equivalent function

        Notes
        -----
        Arithmetic is modular when using integer types, and no error is raised
        on overflow.

        Examples
        --------
        >>> np.prod([1.,2.])
        2.0
        >>> np.prod([1.,2.], dtype=np.int32)
        2
        >>> np.prod([[1.,2.],[3.,4.]])
        24.0
        >>> np.prod([[1.,2.],[3.,4.]], axis=1)
        array([  2.,  12.])

        Copies some attributes of obj to self.
        
    Convert the input to a masked array of the given data-type.

    No copy is performed if the input is already an `ndarray`. If `a` is
    a subclass of `MaskedArray`, a base class `MaskedArray` is returned.

    Parameters
    ----------
    a : array_like
        Input data, in any form that can be converted to a masked array. This
        includes lists, lists of tuples, tuples, tuples of tuples, tuples
        of lists, ndarrays and masked arrays.
    dtype : dtype, optional
        By default, the data-type is inferred from the input data.
    order : {'C', 'F'}, optional
        Whether to use row-major ('C') or column-major ('FORTRAN') memory
        representation.  Default is 'C'.

    Returns
    -------
    out : MaskedArray
        Masked array interpretation of `a`.

    See Also
    --------
    asanyarray : Similar to `asarray`, but conserves subclasses.

    Examples
    --------
    >>> x = np.arange(10.).reshape(2, 5)
    >>> x
    array([[ 0.,  1.,  2.,  3.,  4.],
           [ 5.,  6.,  7.,  8.,  9.]])
    >>> np.ma.asarray(x)
    masked_array(data =
     [[ 0.  1.  2.  3.  4.]
     [ 5.  6.  7.  8.  9.]],
                 mask =
     False,
           fill_value = 1e+20)
    >>> type(np.ma.asarray(x))
    <class 'numpy.ma.core.MaskedArray'>

    Finalizes the masked array.
        
        Special hook for ufuncs.
        Wraps the numpy array and sets the mask according to context.
        
        Compute the anomalies (deviations from the arithmetic mean)
        along the given axis.

        Returns an array of anomalies, with the same shape as the input and
        where the arithmetic mean is computed along the given axis.

        Parameters
        ----------
        axis : int, optional
            Axis over which the anomalies are taken.
            The default is to use the mean of the flattened array as reference.
        dtype : dtype, optional
            Type to use in computing the variance. For arrays of integer type
             the default is float32; for arrays of float types it is the same as
             the array type.

        See Also
        --------
        mean : Compute the mean of the array.

        Examples
        --------
        >>> a = np.ma.array([1,2,3])
        >>> a.anom()
        masked_array(data = [-1.  0.  1.],
                     mask = False,
               fill_value = 1e+20)

        Set a flattened version of self to value.Masked version of %s. [Invalid values are masked]
    Mask an array where `not` equal to a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x != value).

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_not_equal(a, 2)
    masked_array(data = [-- -- 2 --],
          mask = [ True  True False  True],
          fill_value=999999)

    
        .. warning::

            This method does nothing, except raise a ValueError exception. A
            masked array does not own its data and therefore cannot safely be
            resized in place. Use the `numpy.ma.resize` function instead.

        This method is difficult to implement safely and may be deprecated in
        future releases of NumPy.

        Executes the call behavior.Not implemented yet, sorry...
    Mask an array where greater than a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x > value).

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_greater(a, 2)
    masked_array(data = [0 1 2 --],
          mask = [False False False  True],
          fill_value=999999)

    Incompatible dtypes '%s'<>'%s'
    Combine two masks with the ``logical_or`` operator.

    The result may be a view on `m1` or `m2` if the other is `nomask`
    (i.e. False).

    Parameters
    ----------
    m1, m2 : array_like
        Input masks.
    copy : bool, optional
        If copy is False and one of the inputs is `nomask`, return a view
        of the other input mask. Defaults to False.
    shrink : bool, optional
        Whether to shrink the output to `nomask` if all its values are
        False. Defaults to True.

    Returns
    -------
    mask : output mask
        The result masks values that are masked in either `m1` or `m2`.

    Raises
    ------
    ValueError
        If `m1` and `m2` have different flexible dtypes.

    Examples
    --------
    >>> m1 = np.ma.make_mask([0, 1, 1, 0])
    >>> m2 = np.ma.make_mask([1, 0, 0, 0])
    >>> np.ma.mask_or(m1, m2)
    array([ True,  True,  True, False], dtype=bool)

    
        Give a new shape to the array without changing its data.

        Returns a masked array containing the same data, but with a new shape.
        The result is a view on the original array; if this is not possible, a
        ValueError is raised.

        Parameters
        ----------
        shape : int or tuple of ints
            The new shape should be compatible with the original shape. If an
            integer is supplied, then the result will be a 1-D array of that
            length.
        order : {'C', 'F'}, optional
            Determines whether the array data should be viewed as in C
            (row-major) or FORTRAN (column-major) order.

        Returns
        -------
        reshaped_array : array
            A new view on the array.

        See Also
        --------
        reshape : Equivalent function in the masked array module.
        numpy.ndarray.reshape : Equivalent method on ndarray object.
        numpy.reshape : Equivalent function in the NumPy module.

        Notes
        -----
        The reshaping operation cannot guarantee that a copy will not be made,
        to modify the shape in place, use ``a.shape = s``

        Examples
        --------
        >>> x = np.ma.array([[1,2],[3,4]], mask=[1,0,0,1])
        >>> print x
        [[-- 2]
         [3 --]]
        >>> x = x.reshape((4,1))
        >>> print x
        [[--]
         [2]
         [3]
         [--]]

        Check whether other equals self elementwiseCheck whether other doesn't equal self elementwise
        Set storage-indexed locations to corresponding values.

        Sets self._data.flat[n] = values[n] for each n in indices.
        If `values` is shorter than `indices` then it will repeat.
        If `values` has some masked values, the initial mask is updated
        in consequence, else the corresponding values are unmasked.

        Parameters
        ----------
        indices : 1-D array_like
            Target indices, interpreted as integers.
        values : array_like
            Values to place in self._data copy at target indices.
        mode : {'raise', 'wrap', 'clip'}, optional
            Specifies how out-of-bounds indices will behave.
            'raise' : raise an error.
            'wrap' : wrap around.
            'clip' : clip to the range.

        Notes
        -----
        `values` can be a scalar or length 1 array.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]
        >>> x.put([0,4,8],[10,20,30])
        >>> print x
        [[10 -- 3]
         [-- 20 --]
         [7 -- 30]]

        >>> x.put(4,999)
        >>> print x
        [[10 -- 3]
         [-- 999 --]
         [7 -- 30]]

        Get the index...
    Recursively fill `a` with `fill_value`.
    Private function
    
    Return the mask of a masked array, or full boolean array of False.

    Return the mask of `arr` as an ndarray if `arr` is a `MaskedArray` and
    the mask is not `nomask`, else return a full boolean array of False of
    the same shape as `arr`.

    Parameters
    ----------
    arr : array_like
        Input `MaskedArray` for which the mask is required.

    See Also
    --------
    getmask : Return the mask of a masked array, or nomask.
    getdata : Return the data of a masked array as an ndarray.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = ma.masked_equal([[1,2],[3,4]], 2)
    >>> a
    masked_array(data =
     [[1 --]
     [3 4]],
          mask =
     [[False  True]
     [False False]],
          fill_value=999999)
    >>> ma.getmaskarray(a)
    array([[False,  True],
           [False, False]], dtype=bool)

    Result when mask == ``nomask``

    >>> b = ma.masked_array([[1,2],[3,4]])
    >>> b
    masked_array(data =
     [[1 2]
     [3 4]],
          mask =
     False,
          fill_value=999999)
    >>> >ma.getmaskarray(b)
    array([[False, False],
           [False, False]], dtype=bool)

    Either both or neither x and y should be given.
    Determine whether input has masked values.

    Accepts any object as input, but always returns False unless the
    input is a MaskedArray containing masked values.

    Parameters
    ----------
    x : array_like
        Array to check for masked values.

    Returns
    -------
    result : bool
        True if `x` is a MaskedArray with masked values, False otherwise.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = ma.masked_equal([0, 1, 0, 2, 3], 0)
    >>> x
    masked_array(data = [-- 1 -- 2 3],
          mask = [ True False  True False False],
          fill_value=999999)
    >>> ma.is_masked(x)
    True
    >>> x = ma.masked_equal([0, 1, 0, 2, 3], 42)
    >>> x
    masked_array(data = [0 1 0 2 3],
          mask = False,
          fill_value=999999)
    >>> ma.is_masked(x)
    False

    Always returns False if `x` isn't a MaskedArray.

    >>> x = [False, True, False]
    >>> ma.is_masked(x)
    False
    >>> x = 'a string'
    >>> ma.is_masked(x)
    False

    
    Convert the input to a masked array, conserving subclasses.

    If `a` is a subclass of `MaskedArray`, its class is conserved.
    No copy is performed if the input is already an `ndarray`.

    Parameters
    ----------
    a : array_like
        Input data, in any form that can be converted to an array.
    dtype : dtype, optional
        By default, the data-type is inferred from the input data.
    order : {'C', 'F'}, optional
        Whether to use row-major ('C') or column-major ('FORTRAN') memory
        representation.  Default is 'C'.

    Returns
    -------
    out : MaskedArray
        MaskedArray interpretation of `a`.

    See Also
    --------
    asarray : Similar to `asanyarray`, but does not conserve subclass.

    Examples
    --------
    >>> x = np.arange(10.).reshape(2, 5)
    >>> x
    array([[ 0.,  1.,  2.,  3.,  4.],
           [ 5.,  6.,  7.,  8.,  9.]])
    >>> np.ma.asanyarray(x)
    masked_array(data =
     [[ 0.  1.  2.  3.  4.]
     [ 5.  6.  7.  8.  9.]],
                 mask =
     False,
           fill_value = 1e+20)
    >>> type(np.ma.asanyarray(x))
    <class 'numpy.ma.core.MaskedArray'>

    
    Permute the dimensions of an array.

    This function is exactly equivalent to `numpy.transpose`.

    See Also
    --------
    numpy.transpose : Equivalent function in top-level NumPy module.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = ma.arange(4).reshape((2,2))
    >>> x[1, 1] = ma.masked
    >>>> x
    masked_array(data =
     [[0 1]
     [2 --]],
                 mask =
     [[False False]
     [False  True]],
           fill_value = 999999)
    >>> ma.transpose(x)
    masked_array(data =
     [[0 2]
     [1 --]],
                 mask =
     [[False False]
     [False  True]],
           fill_value = 999999)

    x.__getitem__(y) <==> x[y]

        Return the item described by i, as a masked array.

        Check whether there are masked values along the given axis
    Return a copy of a, rounded to 'decimals' places.

    When 'decimals' is negative, it specifies the number of positions
    to the left of the decimal point.  The real and imaginary parts of
    complex numbers are rounded separately. Nothing is done if the
    array is not of float type and 'decimals' is greater than or equal
    to 0.

    Parameters
    ----------
    decimals : int
        Number of decimals to round to. May be negative.
    out : array_like
        Existing array to use for output.
        If not given, returns a default copy of a.

    Notes
    -----
    If out is given and does not have a mask attribute, the mask of a
    is lost!

    
    Puts printoptions in result where mask is True.
    Private function allowing for recursion
    
        Return the cumulative product of the elements along the given axis.
        The cumulative product is taken over the flattened array by
        default, otherwise over the specified axis.

        Masked values are set to 1 internally during the computation.
        However, their position is saved, and the result will be masked at
        the same locations.

        Parameters
        ----------
        axis : {None, -1, int}, optional
            Axis along which the product is computed. The default
            (`axis` = None) is to compute over the flattened array.
        dtype : {None, dtype}, optional
            Determines the type of the returned array and of the accumulator
            where the elements are multiplied. If ``dtype`` has the value ``None``
            and the type of ``a`` is an integer type of precision less than the
            default platform integer, then the default platform integer precision
            is used.  Otherwise, the dtype is the same as that of ``a``.
        out : ndarray, optional
            Alternative output array in which to place the result. It must
            have the same shape and buffer length as the expected output
            but the type will be cast if necessary.

        Returns
        -------
        cumprod : ndarray
            A new array holding the result is returned unless out is specified,
            in which case a reference to out is returned.

        Notes
        -----
        The mask is lost if `out` is not a valid MaskedArray !

        Arithmetic is modular when using integer types, and no error is
        raised on overflow.

        
    Returns an array containing the same data with a new shape.

    Refer to `MaskedArray.reshape` for full documentation.

    See Also
    --------
    MaskedArray.reshape : equivalent function

    M8[us]
        Returns the average of the array elements.

        Masked entries are ignored.
        The average is taken over the flattened array by default, otherwise over
        the specified axis. Refer to `numpy.mean` for the full documentation.

        Parameters
        ----------
        a : array_like
            Array containing numbers whose mean is desired. If `a` is not an
            array, a conversion is attempted.
        axis : int, optional
            Axis along which the means are computed. The default is to compute
            the mean of the flattened array.
        dtype : dtype, optional
            Type to use in computing the mean. For integer inputs, the default
            is float64; for floating point, inputs it is the same as the input
            dtype.
        out : ndarray, optional
            Alternative output array in which to place the result. It must have
            the same shape as the expected output but the type will be cast if
            necessary.

        Returns
        -------
        mean : ndarray, see dtype parameter above
            If `out=None`, returns a new array containing the mean values,
            otherwise a reference to the output array is returned.

        See Also
        --------
        numpy.ma.mean : Equivalent function.
        numpy.mean : Equivalent function on non-masked arrays.
        numpy.ma.average: Weighted average.

        Examples
        --------
        >>> a = np.ma.array([1,2,3], mask=[False, False, True])
        >>> a
        masked_array(data = [1 2 --],
                     mask = [False False  True],
               fill_value = 999999)
        >>> a.mean()
        1.5

        
    Sort the array, in-place

    Parameters
    ----------
    a : array_like
        Array to be sorted.
    axis : int, optional
        Axis along which to sort. If None, the array is flattened before
        sorting. The default is -1, which sorts along the last axis.
    kind : {'quicksort', 'mergesort', 'heapsort'}, optional
        Sorting algorithm. Default is 'quicksort'.
    order : list, optional
        When `a` is a structured array, this argument specifies which fields
        to compare first, second, and so on.  This list does not need to
        include all of the fields.
    endwith : {True, False}, optional
        Whether missing values (if any) should be forced in the upper indices
        (at the end of the array) (True) or lower indices (at the beginning).
    fill_value : {var}, optional
        Value used internally for the masked values.
        If ``fill_value`` is not None, it supersedes ``endwith``.

    Returns
    -------
    sorted_array : ndarray
        Array of the same type and shape as `a`.

    See Also
    --------
    ndarray.sort : Method to sort an array in-place.
    argsort : Indirect sort.
    lexsort : Indirect stable sort on multiple keys.
    searchsorted : Find elements in a sorted array.

    Notes
    -----
    See ``sort`` for notes on the different sorting algorithms.

    Examples
    --------
    >>> a = ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0])
    >>> # Default
    >>> a.sort()
    >>> print a
    [1 3 5 -- --]

    >>> a = ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0])
    >>> # Put missing values in the front
    >>> a.sort(endwith=False)
    >>> print a
    [-- -- 1 3 5]

    >>> a = ma.array([1, 2, 5, 4, 3],mask=[0, 1, 0, 1, 0])
    >>> # fill_value takes over endwith
    >>> a.sort(endwith=False, fill_value=3)
    >>> print a
    [1 -- -- 3 5]

        x.__setitem__(i, y) <==> x[i]=y

        Set item described by index. If value is masked, masks those
        locations.

        Not yet implemented. SorryAccumulate `target` along `axis` after filling with y fill
        value.

        
        Return an array rounded a to the given number of decimals.

        Refer to `numpy.around` for full documentation.

        See Also
        --------
        numpy.around : equivalent function

        
        Returns a 1D version of self, as a view.

        Returns
        -------
        MaskedArray
            Output view is of shape ``(self.size,)`` (or
            ``(np.ma.product(self.shape),)``).

        Examples
        --------
        >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]
        >>> print x.ravel()
        [1 -- 3 -- 5 -- 7 -- 9]

        
    Transforms the mvoid object into a tuple.

    Masked fields are replaced by None.

    Returns
    -------
    returned_tuple
        Tuple of fields
        
        Return all the non-masked data as a 1-D array.

        Returns
        -------
        data : ndarray
            A new `ndarray` holding the non-masked data is returned.

        Notes
        -----
        The result is **not** a MaskedArray!

        Examples
        --------
        >>> x = np.ma.array(np.arange(5), mask=[0]*2 + [1]*3)
        >>> x.compressed()
        array([0, 1])
        >>> type(x.compressed())
        <type 'numpy.ndarray'>

        Object to calculate maxima
    Build a masked array from a suitable flexible-type array.

    The input array has to have a data-type with ``_data`` and ``_mask``
    fields. This type of array is output by `MaskedArray.toflex`.

    Parameters
    ----------
    fxarray : ndarray
        The structured input array, containing ``_data`` and ``_mask``
        fields. If present, other fields are discarded.

    Returns
    -------
    result : MaskedArray
        The constructed masked array.

    See Also
    --------
    MaskedArray.toflex : Build a flexible-type array from a masked array.

    Examples
    --------
    >>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[0] + [1, 0] * 4)
    >>> rec = x.toflex()
    >>> rec
    array([[(0, False), (1, True), (2, False)],
           [(3, True), (4, False), (5, True)],
           [(6, False), (7, True), (8, False)]],
          dtype=[('_data', '<i4'), ('_mask', '|b1')])
    >>> x2 = np.ma.fromflex(rec)
    >>> x2
    masked_array(data =
     [[0 -- 2]
     [-- 4 --]
     [6 -- 8]],
                 mask =
     [[False  True False]
     [ True False  True]
     [False  True False]],
           fill_value = 999999)

    Extra fields can be present in the structured array but are discarded:

    >>> dt = [('_data', '<i4'), ('_mask', '|b1'), ('field3', '<f4')]
    >>> rec2 = np.zeros((2, 2), dtype=dt)
    >>> rec2
    array([[(0, False, 0.0), (0, False, 0.0)],
           [(0, False, 0.0), (0, False, 0.0)]],
          dtype=[('_data', '<i4'), ('_mask', '|b1'), ('field3', '<f4')])
    >>> y = np.ma.fromflex(rec2)
    >>> y
    masked_array(data =
     [[0 0]
     [0 0]],
                 mask =
     [[False False]
     [False False]],
           fill_value = 999999)

    
    Mask an array outside a given interval.

    Shortcut to ``masked_where``, where `condition` is True for `x` outside
    the interval [v1,v2] (x < v1)|(x > v2).
    The boundaries `v1` and `v2` can be given in either order.

    See Also
    --------
    masked_where : Mask where a condition is met.

    Notes
    -----
    The array `x` is prefilled with its filling value.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> x = [0.31, 1.2, 0.01, 0.2, -0.4, -1.1]
    >>> ma.masked_outside(x, -0.3, 0.3)
    masked_array(data = [-- -- 0.01 0.2 -- --],
          mask = [ True  True False False  True  True],
          fill_value=1e+20)

    The order of `v1` and `v2` doesn't matter.

    >>> ma.masked_outside(x, 0.3, -0.3)
    masked_array(data = [-- -- 0.01 0.2 -- --],
          mask = [ True  True False False  True  True],
          fill_value=1e+20)

    
    Return True if all entries of a and b are equal, using
    fill_value as a truth value where either or both are masked.

    Parameters
    ----------
    a, b : array_like
        Input arrays to compare.
    fill_value : bool, optional
        Whether masked values in a or b are considered equal (True) or not
        (False).

    Returns
    -------
    y : bool
        Returns True if the two arrays are equal within the given
        tolerance, False otherwise. If either array contains NaN,
        then False is returned.

    See Also
    --------
    all, any
    numpy.ma.allclose

    Examples
    --------
    >>> a = ma.array([1e10, 1e-7, 42.0], mask=[0, 0, 1])
    >>> a
    masked_array(data = [10000000000.0 1e-07 --],
          mask = [False False  True],
          fill_value=1e+20)

    >>> b = array([1e10, 1e-7, -42.0])
    >>> b
    array([  1.00000000e+10,   1.00000000e-07,  -4.20000000e+01])
    >>> ma.allequal(a, b, fill_value=False)
    False
    >>> ma.allequal(a, b)
    True

    Return a flat iterator.x.__setslice__(i, j, value) <==> x[i:j]=value

    Set the slice (i,j) of a to value. If value is masked, mask
    those locations.

        
    Shift the bits of an integer to the left.

    This is the masked array version of `numpy.left_shift`, for details
    see that function.

    See Also
    --------
    numpy.left_shift

    Unsuitable type for calculating maximum.
    Returns the inner product of a and b for arrays of floating point types.

    Like the generic NumPy equivalent the product sum is over the last dimension
    of a and b.

    Notes
    -----
    The first argument is not conjugated.

    Cannot convert masked element to a Python int.
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.

    
    Mask an array where invalid values occur (NaNs or infs).

    This function is a shortcut to ``masked_where``, with
    `condition` = ~(np.isfinite(a)). Any pre-existing mask is conserved.
    Only applies to arrays with a dtype where NaNs or infs make sense
    (i.e. floating point types), but accepts any array_like object.

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(5, dtype=np.float)
    >>> a[2] = np.NaN
    >>> a[3] = np.PINF
    >>> a
    array([  0.,   1.,  NaN,  Inf,   4.])
    >>> ma.masked_invalid(a)
    masked_array(data = [0.0 1.0 -- -- 4.0],
          mask = [False False  True  True False],
          fill_value=1e+20)

    Class for masked array related errors.Set the string to print for masked values.Override of MaskedArray's __reduce__.
        
        Reduce a mask to nomask when possible.

        Parameters
        ----------
        None

        Returns
        -------
        None

        Examples
        --------
        >>> x = np.ma.array([[1,2 ], [3, 4]], mask=[0]*4)
        >>> x.mask
        array([[False, False],
               [False, False]], dtype=bool)
        >>> x.shrink_mask()
        >>> x.mask
        False

        
    Defines masked version of unary operations, where invalid values are
    pre-masked.

    Parameters
    ----------
    mufunc : callable
        The function for which to define a masked version. Made available
        as ``_MaskedUnaryOperation.f``.
    fill : scalar, optional
        Filling value, default is 0.
    domain : class instance
        Domain for the function. Should be one of the ``_Domain*``
        classes. Default is None.

    Class of the underlying data (read-only).
    Return the minimum value that can be represented by the dtype of an object.

    This function is useful for calculating a fill value suitable for
    taking the maximum of an array with a given dtype.

    Parameters
    ----------
    obj : {ndarray, dtype}
        An object that can be queried for it's numeric type.

    Returns
    -------
    val : scalar
        The minimum representable value.

    Raises
    ------
    TypeError
        If `obj` isn't a suitable numeric type.

    See Also
    --------
    minimum_fill_value : The inverse function.
    set_fill_value : Set the filling value of a masked array.
    MaskedArray.fill_value : Return current fill value.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.int8()
    >>> ma.maximum_fill_value(a)
    -128
    >>> a = np.int32()
    >>> ma.maximum_fill_value(a)
    -2147483648

    An array of numeric data can also be passed.

    >>> a = np.array([1, 2, 3], dtype=np.int8)
    >>> ma.maximum_fill_value(a)
    -128
    >>> a = np.array([1, 2, 3], dtype=np.float32)
    >>> ma.maximum_fill_value(a)
    -inf

    
    Return the data of a masked array as an ndarray.

    Return the data of `a` (if any) as an ndarray if `a` is a ``MaskedArray``,
    else return `a` as a ndarray or subclass (depending on `subok`) if not.

    Parameters
    ----------
    a : array_like
        Input ``MaskedArray``, alternatively a ndarray or a subclass thereof.
    subok : bool
        Whether to force the output to be a `pure` ndarray (False) or to
        return a subclass of ndarray if appropriate (True, default).

    See Also
    --------
    getmask : Return the mask of a masked array, or nomask.
    getmaskarray : Return the mask of a masked array, or full array of False.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = ma.masked_equal([[1,2],[3,4]], 2)
    >>> a
    masked_array(data =
     [[1 --]
     [3 4]],
          mask =
     [[False  True]
     [False False]],
          fill_value=999999)
    >>> ma.getdata(a)
    array([[1, 2],
           [3, 4]])

    Equivalently use the ``MaskedArray`` `data` attribute.

    >>> a.data
    array([[1, 2],
           [3, 4]])

    Returns the filled array, or True if masked.Return the current mask.

        
    Define masked version of binary operations, where invalid
    values are pre-masked.

    Parameters
    ----------
    mbfunc : function
        The function for which to define a masked version. Made available
        as ``_MaskedBinaryOperation.f``.
    domain : class instance
        Default domain for the function. Should be one of the ``_Domain*``
        classes. Default is None.
    fillx : scalar, optional
        Filling value for the first argument, default is 0.
    filly : scalar, optional
        Filling value for the second argument, default is 0.

    Object to calculate minima
    Concatenate a sequence of arrays along the given axis.

    Parameters
    ----------
    arrays : sequence of array_like
        The arrays must have the same shape, except in the dimension
        corresponding to `axis` (the first, by default).
    axis : int, optional
        The axis along which the arrays will be joined. Default is 0.

    Returns
    -------
    result : MaskedArray
        The concatenated array with any masked entries preserved.

    See Also
    --------
    numpy.concatenate : Equivalent function in the top-level NumPy module.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = ma.arange(3)
    >>> a[1] = ma.masked
    >>> b = ma.arange(2, 5)
    >>> a
    masked_array(data = [0 -- 2],
                 mask = [False  True False],
           fill_value = 999999)
    >>> b
    masked_array(data = [2 3 4],
                 mask = False,
           fill_value = 999999)
    >>> ma.concatenate([a, b])
    masked_array(data = [0 -- 2 2 3 4],
                 mask = [False  True False False False False],
           fill_value = 999999)

    Return the current data, as a view of the original
        underlying data.

        3-argument power not supported.Divide self by other in-place.
    Adds a Notes section to an existing docstring.
    M8[D]Floor divide self by other in-place.
        Set the filling value of the masked array.

        Parameters
        ----------
        value : scalar, optional
            The new filling value. Default is None, in which case a default
            based on the data type is used.

        See Also
        --------
        ma.set_fill_value : Equivalent function.

        Examples
        --------
        >>> x = np.ma.array([0, 1.], fill_value=-np.inf)
        >>> x.fill_value
        -inf
        >>> x.set_fill_value(np.pi)
        >>> x.fill_value
        3.1415926535897931

        Reset to default:

        >>> x.set_fill_value()
        >>> x.fill_value
        1e+20

        
    Return a string corresponding to the pickling of a masked array.

    This is a wrapper around ``cPickle.dumps``.

    Parameters
    ----------
    a : MaskedArray
        The array for which the string representation of the pickle is
        returned.

    
        Return the array minimum along the specified axis.

        Parameters
        ----------
        axis : int, optional
            The axis along which to find the minima. Default is None, in which case
            the minimum value in the whole array is returned.

        Returns
        -------
        min : scalar or MaskedArray
            If `axis` is None, the result is a scalar. Otherwise, if `axis` is
            given and the array is at least 2-D, the result is a masked array with
            dimension one smaller than the array on which `mini` is called.

        Examples
        --------
        >>> x = np.ma.array(np.arange(6), mask=[0 ,1, 0, 0, 0 ,1]).reshape(3, 2)
        >>> print x
        [[0 --]
         [2 3]
         [4 --]]
        >>> x.mini()
        0
        >>> x.mini(axis=0)
        masked_array(data = [0 3],
                     mask = [False False],
               fill_value = 999999)
        >>> print x.mini(axis=1)
        [0 2 4]

        
    %s

    Notes
    -----
    %s
    
    Shift the bits of an integer to the right.

    This is the masked array version of `numpy.right_shift`, for details
    see that function.

    See Also
    --------
    numpy.right_shift

    DomainGreaterEqual(v)(x) = true where x < vLiteral string representation.

        /usr/lib/python2.7/dist-packages/numpy/ma/core.py
    Return the maximum value that can be represented by the dtype of an object.

    This function is useful for calculating a fill value suitable for
    taking the minimum of an array with a given dtype.

    Parameters
    ----------
    obj : ndarray or dtype
        An object that can be queried for it's numeric type.

    Returns
    -------
    val : scalar
        The maximum representable value.

    Raises
    ------
    TypeError
        If `obj` isn't a suitable numeric type.

    See Also
    --------
    maximum_fill_value : The inverse function.
    set_fill_value : Set the filling value of a masked array.
    MaskedArray.fill_value : Return current fill value.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.int8()
    >>> ma.minimum_fill_value(a)
    127
    >>> a = np.int32()
    >>> ma.minimum_fill_value(a)
    2147483647

    An array of numeric data can also be passed.

    >>> a = np.array([1, 2, 3], dtype=np.int8)
    >>> ma.minimum_fill_value(a)
    127
    >>> a = np.array([1, 2, 3], dtype=np.float32)
    >>> ma.minimum_fill_value(a)
    inf

    array(data, dtype=None, copy=False, order=False, mask=nomask,
             fill_value=None, keep_mask=True, hard_mask=False, shrink=True,
             subok=True, ndmin=0)

    Acts as shortcut to MaskedArray, with options in a different order
    for convenience.  And backwards compatibility...

    Return the internal state of the masked array, for pickling
        purposes.

        Restore the internal state of the masked array, for
        pickling purposes.  ``state`` is typically the output of the
        ``__getstate__`` output, and is a 5-tuple:

        - class name
        - a tuple giving the shape of the data
        - a typecode for the data
        - a binary string for the data
        - a binary string for the mask.

        
    Test whether input is an instance of MaskedArray.

    This function returns True if `x` is an instance of MaskedArray
    and returns False otherwise.  Any object is accepted as input.

    Parameters
    ----------
    x : object
        Object to test.

    Returns
    -------
    result : bool
        True if `x` is a MaskedArray.

    See Also
    --------
    isMA : Alias to isMaskedArray.
    isarray : Alias to isMaskedArray.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.eye(3, 3)
    >>> a
    array([[ 1.,  0.,  0.],
           [ 0.,  1.,  0.],
           [ 0.,  0.,  1.]])
    >>> m = ma.masked_values(a, 0)
    >>> m
    masked_array(data =
     [[1.0 -- --]
     [-- 1.0 --]
     [-- -- 1.0]],
          mask =
     [[False  True  True]
     [ True False  True]
     [ True  True False]],
          fill_value=0.0)
    >>> ma.isMaskedArray(a)
    False
    >>> ma.isMaskedArray(m)
    True
    >>> ma.isMaskedArray([0, 1, 2])
    False

    
        Transforms a masked array into a flexible-type array.

        The flexible type array that is returned will have two fields:

        * the ``_data`` field stores the ``_data`` part of the array.
        * the ``_mask`` field stores the ``_mask`` part of the array.

        Parameters
        ----------
        None

        Returns
        -------
        record : ndarray
            A new flexible-type `ndarray` with two fields: the first element
            containing a value, the second element containing the corresponding
            mask boolean. The returned record shape matches self.shape.

        Notes
        -----
        A side-effect of transforming a masked array into a flexible `ndarray` is
        that meta information (``fill_value``, ...) will be lost.

        Examples
        --------
        >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4)
        >>> print x
        [[1 -- 3]
         [-- 5 --]
         [7 -- 9]]
        >>> print x.toflex()
        [[(1, False) (2, True) (3, False)]
         [(4, True) (5, False) (6, True)]
         [(7, False) (8, True) (9, False)]]

        Flat version of the array.Subtract other to self, and return a new masked array.Flattens a compound of nested iterables.
    Return the mask of a masked array, or nomask.

    Return the mask of `a` as an ndarray if `a` is a `MaskedArray` and the
    mask is not `nomask`, else return `nomask`. To guarantee a full array
    of booleans of the same shape as a, use `getmaskarray`.

    Parameters
    ----------
    a : array_like
        Input `MaskedArray` for which the mask is required.

    See Also
    --------
    getdata : Return the data of a masked array as an ndarray.
    getmaskarray : Return the mask of a masked array, or full array of False.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = ma.masked_equal([[1,2],[3,4]], 2)
    >>> a
    masked_array(data =
     [[1 --]
     [3 4]],
          mask =
     [[False  True]
     [False False]],
          fill_value=999999)
    >>> ma.getmask(a)
    array([[False,  True],
           [False, False]], dtype=bool)

    Equivalently use the `MaskedArray` `mask` attribute.

    >>> a.mask
    array([[False,  True],
           [False, False]], dtype=bool)

    Result when mask == `nomask`

    >>> b = ma.masked_array([[1,2],[3,4]])
    >>> b
    masked_array(data =
     [[1 2]
     [3 4]],
          mask =
     False,
          fill_value=999999)
    >>> ma.nomask
    False
    >>> ma.getmask(b) == ma.nomask
    True
    >>> b.mask == ma.nomask
    True

    Convert to float.Flatten the mask and returns a (maybe nested) sequence of booleans.Subtract other from self in-place.Only length-1 arrays can be converted to Python scalars
numpy.ma : a package to handle missing or invalid values.

This package was initially written for numarray by Paul F. Dubois
at Lawrence Livermore National Laboratory.
In 2006, the package was completely rewritten by Pierre Gerard-Marchant
(University of Georgia) to make the MaskedArray class a subclass of ndarray,
and to improve support of structured arrays.


Copyright 1999, 2000, 2001 Regents of the University of California.
Released for unlimited redistribution.

* Adapted for numpy_core 2005 by Travis Oliphant and (mainly) Paul Dubois.
* Subclassing of the base `ndarray` 2006 by Pierre Gerard-Marchant
  (pgmdevlist_AT_gmail_DOT_com)
* Improvements suggested by Reggie Dugard (reggie_AT_merfinllc_DOT_com)

.. moduleauthor:: Pierre Gerard-Marchant

Unable to transform %s to dtype %s
        Return the array data as a string containing the raw bytes in the array.

        The array is filled with a fill value before the string conversion.

        Parameters
        ----------
        fill_value : scalar, optional
            Value used to fill in the masked values. Deafult is None, in which
            case `MaskedArray.fill_value` is used.
        order : {'C','F','A'}, optional
            Order of the data item in the copy. Default is 'C'.

            - 'C'   -- C order (row major).
            - 'F'   -- Fortran order (column major).
            - 'A'   -- Any, current order of array.
            - None  -- Same as 'A'.

        See Also
        --------
        ndarray.tostring
        tolist, tofile

        Notes
        -----
        As for `ndarray.tostring`, information about the shape, dtype, etc.,
        but also about `fill_value`, will be lost.

        Examples
        --------
        >>> x = np.ma.array(np.array([[1, 2], [3, 4]]), mask=[[0, 1], [1, 0]])
        >>> x.tostring()
        '\x01\x00\x00\x00?B\x0f\x00?B\x0f\x00\x04\x00\x00\x00'

        
    Create a boolean mask from an array.

    Return `m` as a boolean mask, creating a copy if necessary or requested.
    The function can accept any sequence that is convertible to integers,
    or ``nomask``.  Does not require that contents must be 0s and 1s, values
    of 0 are interepreted as False, everything else as True.

    Parameters
    ----------
    m : array_like
        Potential mask.
    copy : bool, optional
        Whether to return a copy of `m` (True) or `m` itself (False).
    shrink : bool, optional
        Whether to shrink `m` to ``nomask`` if all its values are False.
    dtype : dtype, optional
        Data-type of the output mask. By default, the output mask has
        a dtype of MaskType (bool). If the dtype is flexible, each field
        has a boolean dtype.

    Returns
    -------
    result : ndarray
        A boolean mask derived from `m`.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> m = [True, False, True, True]
    >>> ma.make_mask(m)
    array([ True, False,  True,  True], dtype=bool)
    >>> m = [1, 0, 1, 1]
    >>> ma.make_mask(m)
    array([ True, False,  True,  True], dtype=bool)
    >>> m = [1, 0, 2, -3]
    >>> ma.make_mask(m)
    array([ True, False,  True,  True], dtype=bool)

    Effect of the `shrink` parameter.

    >>> m = np.zeros(4)
    >>> m
    array([ 0.,  0.,  0.,  0.])
    >>> ma.make_mask(m)
    False
    >>> ma.make_mask(m, shrink=False)
    array([False, False, False, False], dtype=bool)

    Using a flexible `dtype`.

    >>> m = [1, 0, 1, 1]
    >>> n = [0, 1, 0, 0]
    >>> arr = []
    >>> for man, mouse in zip(m, n):
    ...     arr.append((man, mouse))
    >>> arr
    [(1, 0), (0, 1), (1, 0), (1, 0)]
    >>> dtype = np.dtype({'names':['man', 'mouse'],
                          'formats':[np.int, np.int]})
    >>> arr = np.array(arr, dtype=dtype)
    >>> arr
    array([(1, 0), (0, 1), (1, 0), (1, 0)],
          dtype=[('man', '<i4'), ('mouse', '<i4')])
    >>> ma.make_mask(arr, dtype=dtype)
    array([(True, False), (False, True), (True, False), (True, False)],
          dtype=[('man', '|b1'), ('mouse', '|b1')])

     _MaskedUnaryOperation(aufunc, fill=0, domain=None)
            aufunc(fill) must be defined
            self(x) returns aufunc(x)
            with masked values where domain(x) is true or getmask(x) is true.
        minimum(a, b) or minimum(a)
In one argument case, returns the scalar minimum.
        
        Return a boolean indicating whether the data is contiguous.

        Parameters
        ----------
        None

        Examples
        --------
        >>> x = np.ma.array([1, 2, 3])
        >>> x.iscontiguous()
        True

        `iscontiguous` returns one of the flags of the masked array:

        >>> x.flags
          C_CONTIGUOUS : True
          F_CONTIGUOUS : True
          OWNDATA : False
          WRITEABLE : True
          ALIGNED : True
          UPDATEIFCOPY : False

        
    Convert functions from numpy to numpy.ma.

    Parameters
    ----------
        _methodname : string
            Name of the method to transform.

    
    Mask an array where less than a given value.

    This function is a shortcut to ``masked_where``, with
    `condition` = (x < value).

    See Also
    --------
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(4)
    >>> a
    array([0, 1, 2, 3])
    >>> ma.masked_less(a, 2)
    masked_array(data = [-- -- 2 3],
          mask = [ True  True False False],
          fill_value=999999)

    Hardness of the maskComing soon: setting the mask per records!Raise self to the power other, masking the potential NaNs/Infs
    Returns True if two arrays are element-wise equal within a tolerance.

    This function is equivalent to `allclose` except that masked values
    are treated as equal (default) or unequal, depending on the `masked_equal`
    argument.

    Parameters
    ----------
    a, b : array_like
        Input arrays to compare.
    masked_equal : bool, optional
        Whether masked values in `a` and `b` are considered equal (True) or not
        (False). They are considered equal by default.
    rtol : float, optional
        Relative tolerance. The relative difference is equal to ``rtol * b``.
        Default is 1e-5.
    atol : float, optional
        Absolute tolerance. The absolute difference is equal to `atol`.
        Default is 1e-8.

    Returns
    -------
    y : bool
        Returns True if the two arrays are equal within the given
        tolerance, False otherwise. If either array contains NaN, then
        False is returned.

    See Also
    --------
    all, any
    numpy.allclose : the non-masked `allclose`.

    Notes
    -----
    If the following equation is element-wise True, then `allclose` returns
    True::

      absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))

    Return True if all elements of `a` and `b` are equal subject to
    given tolerances.

    Examples
    --------
    >>> a = ma.array([1e10, 1e-7, 42.0], mask=[0, 0, 1])
    >>> a
    masked_array(data = [10000000000.0 1e-07 --],
                 mask = [False False  True],
           fill_value = 1e+20)
    >>> b = ma.array([1e10, 1e-8, -42.0], mask=[0, 0, 1])
    >>> ma.allclose(a, b)
    False

    >>> a = ma.array([1e10, 1e-8, 42.0], mask=[0, 0, 1])
    >>> b = ma.array([1.00001e10, 1e-9, -42.0], mask=[0, 0, 1])
    >>> ma.allclose(a, b)
    True
    >>> ma.allclose(a, b, masked_equal=False)
    False

    Masked values are not compared directly.

    >>> a = ma.array([1e10, 1e-8, 42.0], mask=[0, 0, 1])
    >>> b = ma.array([1.00001e10, 1e-9, 42.0], mask=[0, 0, 1])
    >>> ma.allclose(a, b)
    True
    >>> ma.allclose(a, b, masked_equal=False)
    False

    
        Force the mask to soft.

        Whether the mask of a masked array is hard or soft is determined by
        its `hardmask` property. `soften_mask` sets `hardmask` to False.

        See Also
        --------
        hardmask

        Flexible 'hard' masks are not yet supported...
        Force the mask to hard.

        Whether the mask of a masked array is hard or soft is determined by
        its `hardmask` property. `harden_mask` sets `hardmask` to True.

        See Also
        --------
        hardmask

        
    Return input as an array with masked data replaced by a fill value.

    If `a` is not a `MaskedArray`, `a` itself is returned.
    If `a` is a `MaskedArray` and `fill_value` is None, `fill_value` is set to
    ``a.fill_value``.

    Parameters
    ----------
    a : MaskedArray or array_like
        An input object.
    fill_value : scalar, optional
        Filling value. Default is None.

    Returns
    -------
    a : ndarray
        The filled array.

    See Also
    --------
    compressed

    Examples
    --------
    >>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0],
    ...                                                   [1, 0, 0],
    ...                                                   [0, 0, 0]])
    >>> x.filled()
    array([[999999,      1,      2],
           [999999,      4,      5],
           [     6,      7,      8]])

    domain_tan(eps) = true where abs(cos(x)) < eps)(   t   clst   datat   maskt   dtypet   copyt   subokt   ndmint
   fill_valuet	   keep_maskt	   hard_maskt   shrinkt   optionst   _datat
   _baseclasst   _sharedmaskt   names_t   mdtypet   mt   ndt   nmt   msgt   _recursive_orlocdoc_vandergroupby_median1Dmaskedvalmasked_allmax_dtypescommon_maskclump_maskedcompress_colscompress_rowsclump_unmaskedmasked_all_like[*   s   apply_along_axiss   apply_over_axess
   atleast_1ds
   atleast_2ds
   atleast_3ds   averages   clump_maskeds   clump_unmaskeds   column_stacks   compress_colss   compress_rowcolss   compress_rowss   count_maskeds   corrcoefs   covs   diagflats   dots   dstacks   ediff1ds   flatnotmasked_contiguouss   flatnotmasked_edgess   hsplits   hstacks   in1ds   intersect1ds	   mask_colss   mask_rowcolss	   mask_rowss
   masked_alls   masked_all_likes   medians   mr_s   notmasked_contiguouss   notmasked_edgess   polyfits	   row_stacks	   setdiff1ds   setxor1ds   uniques   union1ds   vanders   vstack
    Union of two arrays.

    The output is always a masked array. See `numpy.union1d` for more details.

    See also
    --------
    numpy.union1d : Equivalent function for ndarrays.

    
    Mask rows and/or columns of a 2D array that contain masked values.

    Mask whole rows and/or columns of a 2D array that contain
    masked values.  The masking behavior is selected using the
    `axis` parameter.

      - If `axis` is None, rows *and* columns are masked.
      - If `axis` is 0, only rows are masked.
      - If `axis` is 1 or -1, only columns are masked.

    Parameters
    ----------
    a : array_like, MaskedArray
        The array to mask.  If not a MaskedArray instance (or if no array
        elements are masked).  The result is a MaskedArray with `mask` set
        to `nomask` (False). Must be a 2D array.
    axis : int, optional
        Axis along which to perform the operation. If None, applies to a
        flattened version of the array.

    Returns
    -------
    a : MaskedArray
        A modified version of the input array, masked depending on the value
        of the `axis` parameter.

    Raises
    ------
    NotImplementedError
        If input array `a` is not 2D.

    See Also
    --------
    mask_rows : Mask rows of a 2D array that contain masked values.
    mask_cols : Mask cols of a 2D array that contain masked values.
    masked_where : Mask where a condition is met.

    Notes
    -----
    The input array's mask is modified by this function.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.zeros((3, 3), dtype=np.int)
    >>> a[1, 1] = 1
    >>> a
    array([[0, 0, 0],
           [0, 1, 0],
           [0, 0, 0]])
    >>> a = ma.masked_equal(a, 1)
    >>> a
    masked_array(data =
     [[0 0 0]
     [0 -- 0]
     [0 0 0]],
          mask =
     [[False False False]
     [False  True False]
     [False False False]],
          fill_value=999999)
    >>> ma.mask_rowcols(a)
    masked_array(data =
     [[0 -- 0]
     [-- -- --]
     [0 -- 0]],
          mask =
     [[False  True False]
     [ True  True  True]
     [False  True False]],
          fill_value=999999)

    numpy.ma.extras
    Return the dot product of two arrays.

    .. note::
      Works only with 2-D arrays at the moment.

    This function is the equivalent of `numpy.dot` that takes masked values
    into account, see `numpy.dot` for details.

    Parameters
    ----------
    a, b : ndarray
        Inputs arrays.
    strict : bool, optional
        Whether masked data are propagated (True) or set to 0 (False) for the
        computation. Default is False.
        Propagating the mask means that if a masked value appears in a row or
        column, the whole row or column is considered masked.

    See Also
    --------
    numpy.dot : Equivalent function for ndarrays.

    Examples
    --------
    >>> a = ma.array([[1, 2, 3], [4, 5, 6]], mask=[[1, 0, 0], [0, 0, 0]])
    >>> b = ma.array([[1, 2], [3, 4], [5, 6]], mask=[[1, 0], [0, 0], [0, 0]])
    >>> np.ma.dot(a, b)
    masked_array(data =
     [[21 26]
     [45 64]],
                 mask =
     [[False False]
     [False False]],
           fill_value = 999999)
    >>> np.ma.dot(a, b, strict=True)
    masked_array(data =
     [[-- --]
     [-- 64]],
                 mask =
     [[ True  True]
     [ True False]],
           fill_value = 999999)

    
    Masked values in the input array result in rows of zeros.
    
    Private function for the computation of covariance and correlation
    coefficients.

    compress2d works for 2D arrays only.Cannot process masked data...Notes
-----
The function is applied to both the _data and the _mask, if any.
    Translate slice objects to concatenation along an axis.

    For documentation on usage, see `mr_class`.

    See Also
    --------
    mr_class

    
    Set difference of 1D arrays with unique elements.

    The output is always a masked array. See `numpy.setdiff1d` for more
    details.

    See Also
    --------
    numpy.setdiff1d : Equivalent function for ndarrays.

    Examples
    --------
    >>> x = np.ma.array([1, 2, 3, 4], mask=[0, 1, 0, 1])
    >>> np.ma.extras.setdiff1d(x, [1, 2])
    masked_array(data = [3 --],
                 mask = [False  True],
           fill_value = 999999)

    /usr/lib/python2.7/dist-packages/numpy/ma/extras.pyFunction is not returning an array of correct shape
    Any masked values in x is propagated in y, and vice-versa.
    Expected a 1D or 2D array for y!
    Return the weighted average of array over the given axis.

    Parameters
    ----------
    a : array_like
        Data to be averaged.
        Masked entries are not taken into account in the computation.
    axis : int, optional
        Axis along which the variance is computed. The default is to compute
        the variance of the flattened array.
    weights : array_like, optional
        The importance that each element has in the computation of the average.
        The weights array can either be 1-D (in which case its length must be
        the size of `a` along the given axis) or of the same shape as `a`.
        If ``weights=None``, then all data in `a` are assumed to have a
        weight equal to one.   If `weights` is complex, the imaginary parts
        are ignored.
    returned : bool, optional
        Flag indicating whether a tuple ``(result, sum of weights)``
        should be returned as output (True), or just the result (False).
        Default is False.

    Returns
    -------
    average, [sum_of_weights] : (tuple of) scalar or MaskedArray
        The average along the specified axis. When returned is `True`,
        return a tuple with the average as the first element and the sum
        of the weights as the second element. The return type is `np.float64`
        if `a` is of integer type, otherwise it is of the same type as `a`.
        If returned, `sum_of_weights` is of the same type as `average`.

    Examples
    --------
    >>> a = np.ma.array([1., 2., 3., 4.], mask=[False, False, True, True])
    >>> np.ma.average(a, weights=[3, 1, 0, 0])
    1.25

    >>> x = np.ma.arange(6.).reshape(3, 2)
    >>> print x
    [[ 0.  1.]
     [ 2.  3.]
     [ 4.  5.]]
    >>> avg, sumweights = np.ma.average(x, axis=0, weights=[1, 2, 3],
    ...                                 returned=True)
    >>> print avg
    [2.66666666667 3.66666666667]

    
    (This docstring should be overwritten)
    
        Retrieve the docstring and signature from the function.

        The ``__doc__`` attribute of the function is used as the docstring for
        the new masked array version of the function. A note on application
        of the function to the mask is appended.

        .. warning::
          If the function docstring already contained a Notes section, the
          new docstring will have two Notes sections instead of appending a note
          to the existing section.

        Parameters
        ----------
        None

        
    Empty masked array with all elements masked.

    Return an empty masked array of the given shape and dtype, where all the
    data are masked.

    Parameters
    ----------
    shape : tuple
        Shape of the required MaskedArray.
    dtype : dtype, optional
        Data type of the output.

    Returns
    -------
    a : MaskedArray
        A masked array with all data masked.

    See Also
    --------
    masked_all_like : Empty masked array modelled on an existing array.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> ma.masked_all((3, 3))
    masked_array(data =
     [[-- -- --]
     [-- -- --]
     [-- -- --]],
          mask =
     [[ True  True  True]
     [ True  True  True]
     [ True  True  True]],
          fill_value=1e+20)

    The `dtype` parameter defines the underlying data type.

    >>> a = ma.masked_all((3, 3))
    >>> a.dtype
    dtype('float64')
    >>> a = ma.masked_all((3, 3), dtype=np.int32)
    >>> a.dtype
    dtype('int32')

    
    Return correlation coefficients of the input array.

    Except for the handling of missing data this function does the same as
    `numpy.corrcoef`. For more details and examples, see `numpy.corrcoef`.

    Parameters
    ----------
    x : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `x` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        shape as `x`.
    rowvar : bool, optional
        If `rowvar` is True (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : bool, optional
        Default normalization (False) is by ``(N-1)``, where ``N`` is the
        number of observations given (unbiased estimate). If `bias` is 1,
        then normalization is by ``N``. This keyword can be overridden by
        the keyword ``ddof`` in numpy versions >= 1.5.
    allow_masked : bool, optional
        If True, masked values are propagated pair-wise: if a value is masked
        in `x`, the corresponding value is masked in `y`.
        If False, raises an exception.
    ddof : {None, int}, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.

    See Also
    --------
    numpy.corrcoef : Equivalent function in top-level NumPy module.
    cov : Estimate the covariance matrix.

    
    Mask columns of a 2D array that contain masked values.

    This function is a shortcut to ``mask_rowcols`` with `axis` equal to 1.

    See Also
    --------
    mask_rowcols : Mask rows and/or columns of a 2D array.
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.zeros((3, 3), dtype=np.int)
    >>> a[1, 1] = 1
    >>> a
    array([[0, 0, 0],
           [0, 1, 0],
           [0, 0, 0]])
    >>> a = ma.masked_equal(a, 1)
    >>> a
    masked_array(data =
     [[0 0 0]
     [0 -- 0]
     [0 0 0]],
          mask =
     [[False False False]
     [False  True False]
     [False False False]],
          fill_value=999999)
    >>> ma.mask_cols(a)
    masked_array(data =
     [[0 -- 0]
     [0 -- 0]
     [0 -- 0]],
          mask =
     [[False  True False]
     [False  True False]
     [False  True False]],
          fill_value=999999)

    Currently limited to atmost 2D array.
    Find contiguous unmasked data in a masked array along the given axis.

    Parameters
    ----------
    a : narray
        The input array.

    Returns
    -------
    slice_list : list
        A sorted sequence of slices (start index, end index).

    See Also
    --------
    flatnotmasked_edges, notmasked_contiguous, notmasked_edges,
    clump_masked, clump_unmasked

    Notes
    -----
    Only accepts 2-D arrays at most.

    Examples
    --------
    >>> a = np.ma.arange(10)
    >>> np.ma.extras.flatnotmasked_contiguous(a)
    slice(0, 10, None)

    >>> mask = (a < 3) | (a > 8) | (a == 5)
    >>> a[mask] = np.ma.masked
    >>> np.array(a[~a.mask])
    array([3, 4, 6, 7, 8])

    >>> np.ma.extras.flatnotmasked_contiguous(a)
    [slice(3, 5, None), slice(6, 9, None)]
    >>> a[:] = np.ma.masked
    >>> print np.ma.extras.flatnotmasked_edges(a)
    None

    
    Test whether each element of an array is also present in a second
    array.

    The output is always a masked array. See `numpy.in1d` for more details.

    See Also
    --------
    numpy.in1d : Equivalent function for ndarrays.

    Notes
    -----
    .. versionadded:: 1.4.0

    
Masked arrays add-ons.

A collection of utilities for `numpy.ma`.

:author: Pierre Gerard-Marchant
:contact: pierregm_at_uga_dot_edu
:version: $Id: extras.py 3473 2007-10-29 15:18:13Z jarrod.millman $


    Defines a wrapper to adapt NumPy functions to masked arrays.


    An instance of `_fromnxfunction` can be called with the same parameters
    as the wrapped NumPy function. The docstring of `newfunc` is adapted from
    the wrapped function as well, see `getdoc`.

    Parameters
    ----------
    funcname : str
        The name of the function to be adapted. The function should be
        in the NumPy namespace (i.e. ``np.funcname``).

    ] * masked_array(ones(ash, float), mask)
    Mask rows of a 2D array that contain masked values.

    This function is a shortcut to ``mask_rowcols`` with `axis` equal to 0.

    See Also
    --------
    mask_rowcols : Mask rows and/or columns of a 2D array.
    masked_where : Mask where a condition is met.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.zeros((3, 3), dtype=np.int)
    >>> a[1, 1] = 1
    >>> a
    array([[0, 0, 0],
           [0, 1, 0],
           [0, 0, 0]])
    >>> a = ma.masked_equal(a, 1)
    >>> a
    masked_array(data =
     [[0 0 0]
     [0 -- 0]
     [0 0 0]],
          mask =
     [[False False False]
     [False  True False]
     [False False False]],
          fill_value=999999)
    >>> ma.mask_rows(a)
    masked_array(data =
     [[0 0 0]
     [-- -- --]
     [0 0 0]],
          mask =
     [[False False False]
     [ True  True  True]
     [False False False]],
          fill_value=999999)

    
    Suppress whole columns of a 2-D array that contain masked values.

    This is equivalent to ``np.ma.extras.compress_rowcols(a, 1)``, see
    `extras.compress_rowcols` for details.

    See Also
    --------
    extras.compress_rowcols

    Is seq a sequence (ndarray, list or tuple)?
    Returns a list of slices corresponding to the masked clumps of a 1-D array.
    (A "clump" is defined as a contiguous region of the array).

    Parameters
    ----------
    a : ndarray
        A one-dimensional masked array.

    Returns
    -------
    slices : list of slice
        The list of slices, one for each continuous region of masked elements
        in `a`.

    Notes
    -----
    .. versionadded:: 1.4.0

    See Also
    --------
    flatnotmasked_edges, flatnotmasked_contiguous, notmasked_edges,
    notmasked_contiguous, clump_unmasked

    Examples
    --------
    >>> a = np.ma.masked_array(np.arange(10))
    >>> a[[0, 1, 2, 6, 8, 9]] = np.ma.masked
    >>> np.ma.extras.clump_masked(a)
    [slice(0, 3, None), slice(6, 7, None), slice(8, 10, None)]

    Unknown special directive
    Estimate the covariance matrix.

    Except for the handling of missing data this function does the same as
    `numpy.cov`. For more details and examples, see `numpy.cov`.

    By default, masked values are recognized as such. If `x` and `y` have the
    same shape, a common mask is allocated: if ``x[i,j]`` is masked, then
    ``y[i,j]`` will also be masked.
    Setting `allow_masked` to False will raise an exception if values are
    missing in either of the input arrays.

    Parameters
    ----------
    x : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `x` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        form as `x`.
    rowvar : bool, optional
        If `rowvar` is True (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : bool, optional
        Default normalization (False) is by ``(N-1)``, where ``N`` is the
        number of observations given (unbiased estimate). If `bias` is True,
        then normalization is by ``N``. This keyword can be overridden by
        the keyword ``ddof`` in numpy versions >= 1.5.
    allow_masked : bool, optional
        If True, masked values are propagated pair-wise: if a value is masked
        in `x`, the corresponding value is masked in `y`.
        If False, raises a `ValueError` exception when some values are missing.
    ddof : {None, int}, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.


    Raises
    ------
    ValueError
        Raised if some values are missing and `allow_masked` is False.

    See Also
    --------
    numpy.cov

    
    Finds the clumps (groups of data with the same values) for a 1D bool array.

    Returns a series of slices.
    
    Compute the median along the specified axis.

    Returns the median of the array elements.

    Parameters
    ----------
    a : array_like
        Input array or object that can be converted to an array.
    axis : int, optional
        Axis along which the medians are computed. The default (None) is
        to compute the median along a flattened version of the array.
    out : ndarray, optional
        Alternative output array in which to place the result. It must
        have the same shape and buffer length as the expected output
        but the type will be cast if necessary.
    overwrite_input : bool, optional
        If True, then allow use of memory of input array (a) for
        calculations. The input array will be modified by the call to
        median. This will save memory when you do not need to preserve
        the contents of the input array. Treat the input as undefined,
        but it will probably be fully or partially sorted. Default is
        False. Note that, if `overwrite_input` is True, and the input
        is not already an `ndarray`, an error will be raised.

    Returns
    -------
    median : ndarray
        A new array holding the result is returned unless out is
        specified, in which case a reference to out is returned.
        Return data-type is `float64` for integers and floats smaller than
        `float64`, or the input data-type, otherwise.

    See Also
    --------
    mean

    Notes
    -----
    Given a vector ``V`` with ``N`` non masked values, the median of ``V``
    is the middle value of a sorted copy of ``V`` (``Vs``) - i.e.
    ``Vs[(N-1)/2]``, when ``N`` is odd, or ``{Vs[N/2 - 1] + Vs[N/2]}/2``
    when ``N`` is even.

    Examples
    --------
    >>> x = np.ma.array(np.arange(8), mask=[0]*4 + [1]*4)
    >>> np.ma.extras.median(x)
    1.5

    >>> x = np.ma.array(np.arange(10).reshape(2, 5), mask=[0]*6 + [1]*4)
    >>> np.ma.extras.median(x)
    2.5
    >>> np.ma.extras.median(x, axis=-1, overwrite_input=True)
    masked_array(data = [ 2.  5.],
                 mask = False,
           fill_value = 1e+20)

    ] * ones(ash, float)
    Compute the differences between consecutive elements of an array.

    This function is the equivalent of `numpy.ediff1d` that takes masked
    values into account, see `numpy.ediff1d` for details.

    See Also
    --------
    numpy.ediff1d : Equivalent function for ndarrays.

    
    Empty masked array with the properties of an existing array.

    Return an empty masked array of the same shape and dtype as
    the array `arr`, where all the data are masked.

    Parameters
    ----------
    arr : ndarray
        An array describing the shape and dtype of the required MaskedArray.

    Returns
    -------
    a : MaskedArray
        A masked array with all data masked.

    Raises
    ------
    AttributeError
        If `arr` doesn't have a shape attribute (i.e. not an ndarray)

    See Also
    --------
    masked_all : Empty masked array with all elements masked.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> arr = np.zeros((2, 3), dtype=np.float32)
    >>> arr
    array([[ 0.,  0.,  0.],
           [ 0.,  0.,  0.]], dtype=float32)
    >>> ma.masked_all_like(arr)
    masked_array(data =
     [[-- -- --]
     [-- -- --]],
          mask =
     [[ True  True  True]
     [ True  True  True]],
          fill_value=1e+20)

    The dtype of the masked array matches the dtype of `arr`.

    >>> arr.dtype
    dtype('float32')
    >>> ma.masked_all_like(arr).dtype
    dtype('float32')

    
    Suppress whole rows of a 2-D array that contain masked values.

    This is equivalent to ``np.ma.extras.compress_rowcols(a, 0)``, see
    `extras.compress_rowcols` for details.

    See Also
    --------
    extras.compress_rowcols

    
    Returns the unique elements common to both arrays.

    Masked values are considered equal one to the other.
    The output is always a masked array.

    See `numpy.intersect1d` for more details.

    See Also
    --------
    numpy.intersect1d : Equivalent function for ndarrays.

    Examples
    --------
    >>> x = array([1, 3, 3, 3], mask=[0, 0, 0, 1])
    >>> y = array([3, 1, 1, 1], mask=[0, 0, 0, 1])
    >>> intersect1d(x, y)
    masked_array(data = [1 3 --],
                 mask = [False False  True],
           fill_value = 999999)

    
    Find the indices of the first and last unmasked values.

    Expects a 1-D `MaskedArray`, returns None if all values are masked.

    Parameters
    ----------
    arr : array_like
        Input 1-D `MaskedArray`

    Returns
    -------
    edges : ndarray or None
        The indices of first and last non-masked value in the array.
        Returns None if all values are masked.

    See Also
    --------
    flatnotmasked_contiguous, notmasked_contiguous, notmasked_edges,
    clump_masked, clump_unmasked

    Notes
    -----
    Only accepts 1-D arrays.

    Examples
    --------
    >>> a = np.ma.arange(10)
    >>> flatnotmasked_edges(a)
    [0,-1]

    >>> mask = (a < 3) | (a > 8) | (a == 5)
    >>> a[mask] = np.ma.masked
    >>> np.array(a[~a.mask])
    array([3, 4, 6, 7, 8])

    >>> flatnotmasked_edges(a)
    array([3, 8])

    >>> a[:] = np.ma.masked
    >>> print flatnotmasked_edges(ma)
    None

    
    Find contiguous unmasked data in a masked array along the given axis.

    Parameters
    ----------
    a : array_like
        The input array.
    axis : int, optional
        Axis along which to perform the operation.
        If None (default), applies to a flattened version of the array.

    Returns
    -------
    endpoints : list
        A list of slices (start and end indexes) of unmasked indexes
        in the array.

    See Also
    --------
    flatnotmasked_edges, flatnotmasked_contiguous, notmasked_edges,
    clump_masked, clump_unmasked

    Notes
    -----
    Only accepts 2-D arrays at most.

    Examples
    --------
    >>> a = np.arange(9).reshape((3, 3))
    >>> mask = np.zeros_like(a)
    >>> mask[1:, 1:] = 1

    >>> ma = np.ma.array(a, mask=mask)
    >>> np.array(ma[~ma.mask])
    array([0, 1, 2, 3, 6])

    >>> np.ma.extras.notmasked_contiguous(ma)
    [slice(0, 4, None), slice(6, 7, None)]

    
    Find the indices of the first and last unmasked values along an axis.

    If all values are masked, return None.  Otherwise, return a list
    of two tuples, corresponding to the indices of the first and last
    unmasked values respectively.

    Parameters
    ----------
    a : array_like
        The input array.
    axis : int, optional
        Axis along which to perform the operation.
        If None (default), applies to a flattened version of the array.

    Returns
    -------
    edges : ndarray or list
        An array of start and end indexes if there are any masked data in
        the array. If there are no masked data in the array, `edges` is a
        list of the first and last index.

    See Also
    --------
    flatnotmasked_contiguous, flatnotmasked_edges, notmasked_contiguous,
    clump_masked, clump_unmasked

    Examples
    --------
    >>> a = np.arange(9).reshape((3, 3))
    >>> m = np.zeros_like(a)
    >>> m[1:, 1:] = 1

    >>> am = np.ma.array(a, mask=m)
    >>> np.array(am[~am.mask])
    array([0, 1, 2, 3, 6])

    >>> np.ma.extras.notmasked_edges(ma)
    array([0, 6])

    ddof must be an integer
    (This docstring will be overwritten)
    Unavailable for masked array.
    Translate slice objects to concatenation along the first axis.

    This is the masked array version of `lib.index_tricks.RClass`.

    See Also
    --------
    lib.index_tricks.RClass

    Examples
    --------
    >>> np.ma.mr_[np.ma.array([1,2,3]), 0, 0, np.ma.array([4,5,6])]
    array([1, 2, 3, 0, 0, 4, 5, 6])

    average: weights wrong shape.Flatten a sequence in place.
    Set exclusive-or of 1-D arrays with unique elements.

    The output is always a masked array. See `numpy.setxor1d` for more details.

    See Also
    --------
    numpy.setxor1d : Equivalent function for ndarrays.

    
    Return list of slices corresponding to the unmasked clumps of a 1-D array.
    (A "clump" is defined as a contiguous region of the array).

    Parameters
    ----------
    a : ndarray
        A one-dimensional masked array.

    Returns
    -------
    slices : list of slice
        The list of slices, one for each continuous region of unmasked
        elements in `a`.

    Notes
    -----
    .. versionadded:: 1.4.0

    See Also
    --------
    flatnotmasked_edges, flatnotmasked_contiguous, notmasked_edges,
    notmasked_contiguous, clump_masked

    Examples
    --------
    >>> a = np.ma.masked_array(np.arange(10))
    >>> a[[0, 1, 2, 6, 8, 9]] = np.ma.masked
    >>> np.ma.extras.clump_unmasked(a)
    [slice(3, 6, None), slice(7, 8, None)]

    
    Finds the unique elements of an array.

    Masked values are considered the same element (masked). The output array
    is always a masked array. See `numpy.unique` for more details.

    See Also
    --------
    numpy.unique : Equivalent function for ndarrays.

    
    Count the number of masked elements along the given axis.

    Parameters
    ----------
    arr : array_like
        An array with (possibly) masked elements.
    axis : int, optional
        Axis along which to count. If None (default), a flattened
        version of the array is used.

    Returns
    -------
    count : int, ndarray
        The total number of masked elements (axis=None) or the number
        of masked elements along each slice of the given axis.

    See Also
    --------
    MaskedArray.count : Count non-masked elements.

    Examples
    --------
    >>> import numpy.ma as ma
    >>> a = np.arange(9).reshape((3,3))
    >>> a = ma.array(a)
    >>> a[1, 0] = ma.masked
    >>> a[1, 2] = ma.masked
    >>> a[2, 1] = ma.masked
    >>> a
    masked_array(data =
     [[0 1 2]
     [-- 4 --]
     [6 -- 8]],
          mask =
     [[False False False]
     [ True False  True]
     [False  True False]],
          fill_value=999999)
    >>> ma.count_masked(a)
    3

    When the `axis` keyword is used an array is returned.

    >>> ma.count_masked(a, axis=0)
    array([1, 1, 1])
    >>> ma.count_masked(a, axis=1)
    array([0, 2, 1])

    
    Suppress the rows and/or columns of a 2-D array that contain
    masked values.

    The suppression behavior is selected with the `axis` parameter.

    - If axis is None, both rows and columns are suppressed.
    - If axis is 0, only rows are suppressed.
    - If axis is 1 or -1, only columns are suppressed.

    Parameters
    ----------
    axis : int, optional
        Axis along which to perform the operation. Default is None.

    Returns
    -------
    compressed_array : ndarray
        The compressed array.

    Examples
    --------
    >>> x = np.ma.array(np.arange(9).reshape(3, 3), mask=[[1, 0, 0],
    ...                                                   [1, 0, 0],
    ...                                                   [0, 0, 0]])
    >>> x
    masked_array(data =
     [[-- 1 2]
     [-- 4 5]
     [6 7 8]],
                 mask =
     [[ True False False]
     [ True False False]
     [False False False]],
           fill_value = 999999)

    >>> np.ma.extras.compress_rowcols(x)
    array([[7, 8]])
    >>> np.ma.extras.compress_rowcols(x, 0)
    array([[6, 7, 8]])
    >>> np.ma.extras.compress_rowcols(x, 1)
    array([[1, 2],
           [4, 5],
           [7, 8]])

    (   t   func1dt   axist   arrt   argst   kwargst   ndt   indt   it   indlistt   outshapet   jt   rest   asscalart   dtypest   outarrt   Ntott   kt   nt	   holdshapet
   max_dtypest   resultfdmasknnamesobjmask_getdataaddfieldfieldmaskhasmaskednewmdtype_fieldmask_checknames_getformatsfromtextfile_getfieldmask_get_fieldmaskmaskrecordlengthCalculates the repr representation.Attempting to %i dtypes for %i fields!/usr/lib/python2.7/dist-packages/numpy/ma/mrecords.pyThe array should be 2D at most!Adds a new field to the masked record array, using `newfield` as data
and `newfieldname` as name. If `newfieldname` is None, the new field name is
set to 'fi', where `i` is the number of existing fields.
    MaskedRecords is currently limited tosimple records...%%%is : %%s:mod:`numpy.ma..mrecords`

Defines the equivalent of :class:`numpy.recarrays` for masked arrays,
where fields can be accessed as attributes.
Note that :class:`numpy.ma.MaskedArray` already supports structured datatypes
and the masking of individual fields.

:author: Pierre Gerard-Marchant

Sets the given record to value.Sets the attribute attr to the value val.No such file: '%s'Creates a MaskedRecords from a list of records.

    Parameters
    ----------
    reclist : sequence
        A list of records. Each element of the sequence is first converted
        to a masked array if needed. If a 2D array is passed as argument, it is
        processed line by line
    dtype : {None, dtype}, optional
        Data type descriptor.
    shape : {None,int}, optional
        Number of records. If None, ``shape`` is defined from the shape of the
        first array in the list.
    formats : {None, sequence}, optional
        Sequence of formats for each individual field. If None, the formats will
        be autodetected by inspecting the fields and selecting the highest dtype
        possible.
    names : {None, sequence}, optional
        Sequence of the names of each field.
    fill_value : {None, sequence}, optional
        Sequence of data to be used as filling values.
    mask : {nomask, sequence}, optional.
        External mask to apply on the data.

    Notes
    -----
    Lists of tuples should be preferred over lists of lists for faster processing.
    Return the internal state of the masked array, for pickling purposes.

        Alias to maskCreates a mrecarray from a (flat) list of masked arrays.

    Parameters
    ----------
    arraylist : sequence
        A list of (masked) arrays. Each element of the sequence is first converted
        to a masked array if needed. If a 2D array is passed as argument, it is
        processed line by line
    dtype : {None, dtype}, optional
        Data type descriptor.
    shape : {None, integer}, optional
        Number of records. If None, shape is defined from the shape of the
        first array in the list.
    formats : {None, sequence}, optional
        Sequence of formats for each individual field. If None, the formats will
        be autodetected by inspecting the fields and selecting the highest dtype
        possible.
    names : {None, sequence}, optional
        Sequence of the names of each field.
    fill_value : {None, sequence}, optional
        Sequence of data to be used as filling values.

    Notes
    -----
    Lists of tuples should be preferred over lists of lists for faster processing.
    Wow, binary fileForces the mask to hardReturns the formats of each array of arraylist as a comma-separated string.Returns the lengthOpens the file handle of file `fname`

*IVariables*:
    _data : {recarray}
        Underlying data, as a record array.
    _mask : {boolean array}
        Mask of the records. A record is masked when all its fields are masked.
    _fieldmask : {boolean recarray}
        Record array of booleans, setting the mask of each individual field of each record.
    _fill_value : {record}
        Filling values for each field.
    Tries to guess the dtypes of the str_ ndarray `arr`, by testing element-wise
conversion. Returns a list of dtypes.
The array is first converted to ndarray. If the array is 2D, the test is performed
on the first line. An exception is raised if the file is 3D or more.
                  )Copy the data portion of the array to a hierarchical python
        list and returns that list.

        Data items are converted to the nearest compatible Python
        type.  Masked values are converted to fill_value. If
        fill_value is None, the corresponding entries in the output
        list will be ``None``.

        Calculates the string representation.Returns the data as a recarray.Creates a mrecarray from data stored in the file `filename`.

    Parameters
    ----------
    filename : {file name/handle}
        Handle of an opened file.
    delimitor : {None, string}, optional
        Alphanumeric character used to separate columns in the file.
        If None, any (group of) white spacestring(s) will be used.
    commentchar : {'#', string}, optional
        Alphanumeric character used to mark the start of a comment.
    missingchar : {'', string}, optional
        String indicating missing data, and used to create the masks.
    varnames : {None, sequence}, optional
        Sequence of the variable names. If None, a list will be created from
        the first non empty line of the file.
    vartypes : {None, sequence}, optional
        Sequence of the variables dtypes. If None, it will be estimated from
        the first non-commented line.


    Ultra simple: the varnames are in the header, one lineRestore the internal state of the masked array, for pickling purposes.
    ``state`` is typically the output of the ``__getstate__`` output, and is a
    5-tuple:

        - class name
        - a tuple giving the shape of the data
        - a typecode for the data
        - a binary string for the data
        - a binary string for the mask.

        Returns a copy of the masked record.masked_records(Checks that the field names of the descriptor ``descr`` are not some
reserved keywords. If this is the case, a default 'f%i' is substituted.
If the argument `names` is not None, updates the field names to valid names.
     Reverting to default.Returns a view of the mrecarray.Returns all the fields sharing the same fieldname base.
The fieldname base is either `_data` or `_mask`.Forces the mask to soft(   t   clst   shapet   dtypet   buft   offsett   stridest   formatst   namest   titlest	   byteordert   alignedt   maskt	   hard_maskt
   fill_valuet	   keep_maskt   copyt   optionst   selft   mdtypet   ndt   nmt   msgt   _maskt   m(   t   fnamet	   delimitort   commentchart   missingchart   varnamest   vartypest   ft   linet	   firstlinet	   _varnamest
   _variablest   _t   nfieldst   vt   msgt   nt   mdescrt   mfillvt   _maskt   at   mt   tt	   _datalist/usr/lib/python2.7/dist-packages/numpy/matrixlibSub-package containing the matrix class and related functions.

/usr/lib/python2.7/dist-packages/numpy/matrixlib/__init__.pygetAgetIgetTtrowgetA1loc_dict_collapseglob_dict1-d base arrayhermitian (conjugate) transpose[   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN/usr/lib/python2.7/dist-packages/numpy/matrixlib/defmatrix.py
        Returns the variance of the matrix elements, along the given axis.

        Refer to `numpy.var` for full documentation.

        See Also
        --------
        numpy.var

        Notes
        -----
        This is the same as `ndarray.var`, except that where an `ndarray` would
        be returned, a `matrix` object is returned instead.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3, 4)))
        >>> x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.var()
        11.916666666666666
        >>> x.var(0)
        matrix([[ 10.66666667,  10.66666667,  10.66666667,  10.66666667]])
        >>> x.var(1)
        matrix([[ 1.25],
                [ 1.25],
                [ 1.25]])

        Invalid data string supplied: 
        Return the product of the array elements over the given axis.

        Refer to `prod` for full documentation.

        See Also
        --------
        prod, ndarray.prod

        Notes
        -----
        Same as `ndarray.prod`, except, where that returns an `ndarray`, this
        returns a `matrix` object instead.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.prod()
        0
        >>> x.prod(0)
        matrix([[  0,  45, 120, 231]])
        >>> x.prod(1)
        matrix([[   0],
                [ 840],
                [7920]])

        Rows not the same size.
        Test whether any array element along a given axis evaluates to True.

        Refer to `numpy.any` for full documentation.

        Parameters
        ----------
        axis : int, optional
            Axis along which logical OR is performed
        out : ndarray, optional
            Output to existing array instead of creating new one, must have
            same shape as expected output

        Returns
        -------
            any : bool, ndarray
                Returns a single bool if `axis` is ``None``; otherwise,
                returns `ndarray`

        
        Return the indices of the minimum values along an axis.

        Parameters
        ----------
        See `numpy.argmin` for complete descriptions.

        See Also
        --------
        numpy.argmin

        Notes
        -----
        This is the same as `ndarray.argmin`, but returns a `matrix` object
        where `ndarray.argmin` would return an `ndarray`.

        Examples
        --------
        >>> x = -np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[  0,  -1,  -2,  -3],
                [ -4,  -5,  -6,  -7],
                [ -8,  -9, -10, -11]])
        >>> x.argmin()
        11
        >>> x.argmin(0)
        matrix([[2, 2, 2, 2]])
        >>> x.argmin(1)
        matrix([[3],
                [3],
                [3]])

        0123456789.-+jeEL
        Returns the (multiplicative) inverse of invertible `self`.

        Parameters
        ----------
        None

        Returns
        -------
        ret : matrix object
            If `self` is non-singular, `ret` is such that ``ret * self`` ==
            ``self * ret`` == ``np.matrix(np.eye(self[0,:].size)`` all return
            ``True``.

        Raises
        ------
        numpy.linalg.LinAlgError: Singular matrix
            If `self` is singular.

        See Also
        --------
        linalg.inv

        Examples
        --------
        >>> m = np.matrix('[1, 2; 3, 4]'); m
        matrix([[1, 2],
                [3, 4]])
        >>> m.getI()
        matrix([[-2. ,  1. ],
                [ 1.5, -0.5]])
        >>> m.getI() * m
        matrix([[ 1.,  0.],
                [ 0.,  1.]])

        
        Return `self` as a flattened `ndarray`.

        Equivalent to ``np.asarray(x).ravel()``

        Parameters
        ----------
        None

        Returns
        -------
        ret : ndarray
            `self`, 1-D, as an `ndarray`

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.getA1()
        array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

        
        Return the standard deviation of the array elements along the given axis.

        Refer to `numpy.std` for full documentation.

        See Also
        --------
        numpy.std

        Notes
        -----
        This is the same as `ndarray.std`, except that where an `ndarray` would
        be returned, a `matrix` object is returned instead.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3, 4)))
        >>> x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.std()
        3.4520525295346629
        >>> x.std(0)
        matrix([[ 3.26598632,  3.26598632,  3.26598632,  3.26598632]])
        >>> x.std(1)
        matrix([[ 1.11803399],
                [ 1.11803399],
                [ 1.11803399]])

        
    Raise a square matrix to the (integer) power `n`.

    For positive integers `n`, the power is computed by repeated matrix
    squarings and matrix multiplications. If ``n == 0``, the identity matrix
    of the same shape as M is returned. If ``n < 0``, the inverse
    is computed and then raised to the ``abs(n)``.

    Parameters
    ----------
    M : ndarray or matrix object
        Matrix to be "powered."  Must be square, i.e. ``M.shape == (m, m)``,
        with `m` a positive integer.
    n : int
        The exponent can be any integer or long integer, positive,
        negative, or zero.

    Returns
    -------
    M**n : ndarray or matrix object
        The return value is the same shape and type as `M`;
        if the exponent is positive or zero then the type of the
        elements is the same as those of `M`. If the exponent is
        negative the elements are floating-point.

    Raises
    ------
    LinAlgError
        If the matrix is not numerically invertible.

    See Also
    --------
    matrix
        Provides an equivalent function as the exponentiation operator
        (``**``, not ``^``).

    Examples
    --------
    >>> from numpy import linalg as LA
    >>> i = np.array([[0, 1], [-1, 0]]) # matrix equiv. of the imaginary unit
    >>> LA.matrix_power(i, 3) # should = -i
    array([[ 0, -1],
           [ 1,  0]])
    >>> LA.matrix_power(np.matrix(i), 3) # matrix arg returns matrix
    matrix([[ 0, -1],
            [ 1,  0]])
    >>> LA.matrix_power(i, 0)
    array([[1, 0],
           [0, 1]])
    >>> LA.matrix_power(i, -3) # should = 1/(-i) = i, but w/ f.p. elements
    array([[ 0.,  1.],
           [-1.,  0.]])

    Somewhat more sophisticated example

    >>> q = np.zeros((4, 4))
    >>> q[0:2, 0:2] = -i
    >>> q[2:4, 2:4] = i
    >>> q # one of the three quarternion units not equal to 1
    array([[ 0., -1.,  0.,  0.],
           [ 1.,  0.,  0.,  0.],
           [ 0.,  0.,  0.,  1.],
           [ 0.,  0., -1.,  0.]])
    >>> LA.matrix_power(q, 2) # = -np.eye(4)
    array([[-1.,  0.,  0.,  0.],
           [ 0., -1.,  0.,  0.],
           [ 0.,  0., -1.,  0.],
           [ 0.,  0.,  0., -1.]])

    
    Interpret the input as a matrix.

    Unlike `matrix`, `asmatrix` does not make a copy if the input is already
    a matrix or an ndarray.  Equivalent to ``matrix(data, copy=False)``.

    Parameters
    ----------
    data : array_like
        Input data.

    Returns
    -------
    mat : matrix
        `data` interpreted as a matrix.

    Examples
    --------
    >>> x = np.array([[1, 2], [3, 4]])

    >>> m = np.asmatrix(x)

    >>> x[0,0] = 5

    >>> m
    matrix([[5, 2],
            [3, 4]])

    unsupported axis
        Return `self` as an `ndarray` object.

        Equivalent to ``np.asarray(self)``.

        Parameters
        ----------
        None

        Returns
        -------
        ret : ndarray
            `self` as an `ndarray`

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.getA()
        array([[ 0,  1,  2,  3],
               [ 4,  5,  6,  7],
               [ 8,  9, 10, 11]])

        
        Peak-to-peak (maximum - minimum) value along the given axis.

        Refer to `numpy.ptp` for full documentation.

        See Also
        --------
        numpy.ptp

        Notes
        -----
        Same as `ndarray.ptp`, except, where that would return an `ndarray` object,
        this returns a `matrix` object.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.ptp()
        11
        >>> x.ptp(0)
        matrix([[8, 8, 8, 8]])
        >>> x.ptp(1)
        matrix([[3],
                [3],
                [3]])

        
        Returns the sum of the matrix elements, along the given axis.

        Refer to `numpy.sum` for full documentation.

        See Also
        --------
        numpy.sum

        Notes
        -----
        This is the same as `ndarray.sum`, except that where an `ndarray` would
        be returned, a `matrix` object is returned instead.

        Examples
        --------
        >>> x = np.matrix([[1, 2], [4, 3]])
        >>> x.sum()
        10
        >>> x.sum(axis=1)
        matrix([[3],
                [7]])
        >>> x.sum(axis=1, dtype='float')
        matrix([[ 3.],
                [ 7.]])
        >>> out = np.zeros((1, 2), dtype='float')
        >>> x.sum(axis=1, dtype='float', out=out)
        matrix([[ 3.],
                [ 7.]])

        
        Indices of the maximum values along an axis.

        Parameters
        ----------
        See `numpy.argmax` for complete descriptions

        See Also
        --------
        numpy.argmax

        Notes
        -----
        This is the same as `ndarray.argmax`, but returns a `matrix` object
        where `ndarray.argmax` would return an `ndarray`.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.argmax()
        11
        >>> x.argmax(0)
        matrix([[2, 2, 2, 2]])
        >>> x.argmax(1)
        matrix([[3],
                [3],
                [3]])

        A convenience function for operations that want to collapse
        to a scalar like _align, but are using keepdims=True
        
    matrix(data, dtype=None, copy=True)

    Returns a matrix from an array-like object, or from a string of data.
    A matrix is a specialized 2-D array that retains its 2-D nature
    through operations.  It has certain special operators, such as ``*``
    (matrix multiplication) and ``**`` (matrix power).

    Parameters
    ----------
    data : array_like or string
       If `data` is a string, it is interpreted as a matrix with commas
       or spaces separating columns, and semicolons separating rows.
    dtype : data-type
       Data-type of the output matrix.
    copy : bool
       If `data` is already an `ndarray`, then this flag determines
       whether the data is copied (the default), or whether a view is
       constructed.

    See Also
    --------
    array

    Examples
    --------
    >>> a = np.matrix('1 2; 3 4')
    >>> print a
    [[1 2]
     [3 4]]

    >>> np.matrix([[1, 2], [3, 4]])
    matrix([[1, 2],
            [3, 4]])

    
        Return the matrix as a (possibly nested) list.

        See `ndarray.tolist` for full documentation.

        See Also
        --------
        ndarray.tolist

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.tolist()
        [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]

        
    Build a matrix object from a string, nested sequence, or array.

    Parameters
    ----------
    obj : str or array_like
        Input data.  Names of variables in the current scope may be
        referenced, even if `obj` is a string.

    Returns
    -------
    out : matrix
        Returns a matrix object, which is a specialized 2-D array.

    See Also
    --------
    matrix

    Examples
    --------
    >>> A = np.mat('1 1; 1 1')
    >>> B = np.mat('2 2; 2 2')
    >>> C = np.mat('3 4; 5 6')
    >>> D = np.mat('7 8; 9 0')

    All the following expressions construct the same block matrix:

    >>> np.bmat([[A, B], [C, D]])
    matrix([[1, 1, 2, 2],
            [1, 1, 2, 2],
            [3, 4, 7, 8],
            [5, 6, 9, 0]])
    >>> np.bmat(np.r_[np.c_[A, B], np.c_[C, D]])
    matrix([[1, 1, 2, 2],
            [1, 1, 2, 2],
            [3, 4, 7, 8],
            [5, 6, 9, 0]])
    >>> np.bmat('A,B; C,D')
    matrix([[1, 1, 2, 2],
            [1, 1, 2, 2],
            [3, 4, 7, 8],
            [5, 6, 9, 0]])

    
        Returns the (complex) conjugate transpose of `self`.

        Equivalent to ``np.transpose(self)`` if `self` is real-valued.

        Parameters
        ----------
        None

        Returns
        -------
        ret : matrix object
            complex conjugate transpose of `self`

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4)))
        >>> z = x - 1j*x; z
        matrix([[  0. +0.j,   1. -1.j,   2. -2.j,   3. -3.j],
                [  4. -4.j,   5. -5.j,   6. -6.j,   7. -7.j],
                [  8. -8.j,   9. -9.j,  10.-10.j,  11.-11.j]])
        >>> z.getH()
        matrix([[  0. +0.j,   4. +4.j,   8. +8.j],
                [  1. +1.j,   5. +5.j,   9. +9.j],
                [  2. +2.j,   6. +6.j,  10.+10.j],
                [  3. +3.j,   7. +7.j,  11.+11.j]])

        
        Returns the transpose of the matrix.

        Does *not* conjugate!  For the complex conjugate transpose, use `getH`.

        Parameters
        ----------
        None

        Returns
        -------
        ret : matrix object
            The (non-conjugated) transpose of the matrix.

        See Also
        --------
        transpose, getH

        Examples
        --------
        >>> m = np.matrix('[1, 2; 3, 4]')
        >>> m
        matrix([[1, 2],
                [3, 4]])
        >>> m.getT()
        matrix([[1, 3],
                [2, 4]])

        
        Return the minimum value along an axis.

        Parameters
        ----------
        See `amin` for complete descriptions.

        See Also
        --------
        amin, ndarray.min

        Notes
        -----
        This is the same as `ndarray.min`, but returns a `matrix` object
        where `ndarray.min` would return an ndarray.

        Examples
        --------
        >>> x = -np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[  0,  -1,  -2,  -3],
                [ -4,  -5,  -6,  -7],
                [ -8,  -9, -10, -11]])
        >>> x.min()
        -11
        >>> x.min(0)
        matrix([[ -8,  -9, -10, -11]])
        >>> x.min(1)
        matrix([[ -3],
                [ -7],
                [-11]])

        
        Test whether all matrix elements along a given axis evaluate to True.

        Parameters
        ----------
        See `numpy.all` for complete descriptions

        See Also
        --------
        numpy.all

        Notes
        -----
        This is the same as `ndarray.all`, but it returns a `matrix` object.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> y = x[0]; y
        matrix([[0, 1, 2, 3]])
        >>> (x == y)
        matrix([[ True,  True,  True,  True],
                [False, False, False, False],
                [False, False, False, False]], dtype=bool)
        >>> (x == y).all()
        False
        >>> (x == y).all(0)
        matrix([[False, False, False, False]], dtype=bool)
        >>> (x == y).all(1)
        matrix([[ True],
                [False],
                [False]], dtype=bool)

        shape too large to be a matrix.
        Return the maximum value along an axis.

        Parameters
        ----------
        See `amax` for complete descriptions

        See Also
        --------
        amax, ndarray.max

        Notes
        -----
        This is the same as `ndarray.max`, but returns a `matrix` object
        where `ndarray.max` would return an ndarray.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3,4))); x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.max()
        11
        >>> x.max(0)
        matrix([[ 8,  9, 10, 11]])
        >>> x.max(1)
        matrix([[ 3],
                [ 7],
                [11]])

        
        Returns the average of the matrix elements along the given axis.

        Refer to `numpy.mean` for full documentation.

        See Also
        --------
        numpy.mean

        Notes
        -----
        Same as `ndarray.mean` except that, where that returns an `ndarray`,
        this returns a `matrix` object.

        Examples
        --------
        >>> x = np.matrix(np.arange(12).reshape((3, 4)))
        >>> x
        matrix([[ 0,  1,  2,  3],
                [ 4,  5,  6,  7],
                [ 8,  9, 10, 11]])
        >>> x.mean()
        5.5
        >>> x.mean(0)
        matrix([[ 4.,  5.,  6.,  7.]])
        >>> x.mean(1)
        matrix([[ 1.5],
                [ 5.5],
                [ 9.5]])

        matrix must be 2-dimensionalA convenience function for operations that need to preserve axis
        orientation.
        The numarray module will be dropped in Numpy 1.9/usr/lib/python2.7/dist-packages/numpy/numarray/usr/lib/python2.7/dist-packages/numpy/numarray/__init__.pyNewAxisArrayType/usr/lib/python2.7/dist-packages/numpy/numarray/compat.pynumpy.numarray.compatuidxSLOPPYdatasizefromlistgetShapesavespacearray2listinputarrayisBigEndianflush_cachesexplicit_typegetTypeObjectcheck_overflowmatrixmultiplytensormultiplytogglebyteorderdivide_remainderkroneckerproduct[X   s   vdots   dots   matrixmultiplys   ravels   indicess   aranges   concatenates   alls   allcloses   alltrues   and_s   anys   argmaxs   argmins   argsorts   arounds   array_equals   array_equivs
   arrayranges	   array_strs
   array_reprs
   array2lists   averages   chooses   CLIPs   RAISEs   WRAPs   clips   compresss   copys   copy_regs   diagonals   divide_remaindert   es   explicit_types   pis   flush_cachess   fromfiles   oss   syss   STRICTs   SLOPPYs   WARNs   EarlyEOFErrors   SizeMismatchErrors   SizeMismatchWarnings   FileSeekWarnings
   fromstrings   fromfunctions   fromlists   getShapes   getTypeObjects   identitys   infos   innerproducts
   inputarrays   isBigEndians   kroneckerproducts   lexsorts   maths   operators   outerproducts   puts   putmasks   ranks   repeats   reshapes   resizes   rounds   searchsorteds   shapes   sizes   sometrues   sorts   swapaxess   takes   tcodes   tnames   tensormultiplys   traces	   transposes   typess   values   cumsums
   cumproducts   nonzeros   newobjs   togglebyteorderRaised in fromfile() if EOF unexpectedly occurs./usr/lib/python2.7/dist-packages/numpy/numarray/functions.pysizing must be STRICT if size completecontiguous: Can't determine a reasonable type from sequenceSame as a & b
    byteoffset: 0data pointer: %s%sCould not rewind (IOError in seek)buffer: strides: Raised in fromfile() if file size does not match shape.Shape must be a sequence of integersIssued in fromfile() if file size does not match shape.shape: itemsize: byteswap:  (DEBUG ONLY)bytestride: Could not rewind (no seek support)byteorder: aligned: numpy.numarray.functionsUnexpected EOF reading data for size complete array%slittle%sput only works on subclass of ndarrayReturn a copy of BUF of size NEWSIZE.Unmatched dimensionsAt most one unspecified dimension in shaperound() is deprecated. Switch to around()Filesize does not match specified shape%sbig%sIssued in fromfile() if there is unused data and seek() fails(   t   infilet   typet   shapet   sizingt   typecodet   dtypet   arrt	   bytesleftt	   bytesreadt   datat   it   recsizet	   blocksizet   curpost   endpost   initsizet   buft   datasizet   uidxt   a($   t   dotR    t   vdott   ravelt   concatenatet   allt   allcloset   anyt   argsortt   array_equalt   array_equivt	   array_strt
   array_reprt   CLIPt   RAISEt   WRAPt   clipR   t   diagonalt   et   pit   innert   nonzerot   outert   kront   lexsortt   putmaskt   rankt   resizet   searchsortedt   shapet   sizet   sortt   swapaxest   tracet	   transposec161silNUByteULongbBwuUIsTypeUShortmaptype2MAX_ALIGNMaybeLongscalarTypesgenericPromotionExclusions{s   UInt64(   s   Float32s	   Complex32s   Int32(   s   Float32s	   Complex32s	   Complex64(    s   Float64(   s	   Complex32s   UInt8(    s   Int8(    s   Int16(    s   UInt16(    s   Int64(   s   Float32s	   Complex32s	   Complex32(    s   Bool(    s   UInt32(   s   Float32s	   Complex32s   Float32(    0[.   s   NumericTypes	   HasUInt64s   typeDicts   IsTypes   BooleanTypes
   SignedTypes   UnsignedTypes   IntegralTypes   SignedIntegralTypes   UnsignedIntegralTypes   FloatingTypes   ComplexTypes   AnyTypes
   ObjectTypes   Anys   Objects   Bools   Int8s   Int16s   Int32s   Int64s   Float32s   Float64s   UInt8s   UInt16s   UInt32s   UInt64s	   Complex32s	   Complex64s   Bytes   Shorts   Ints   Longs   Floats   Complexs   genericTypeRanks   pythonTypeRanks   pythonTypeMaps   scalarTypeMaps   genericCoercionss	   typecodess   genericPromotionExclusionss   MaximumTypes   getTypes   scalarTypess   typefromnumerictypes: Define the numeric type objects

This module is designed so 'from numerictypes import *' is safe.
Exported symbols include:

  Dictionary with all registered number types (including aliases):
    typeDict

  Numeric type objects:
    Bool
    Int8 Int16 Int32 Int64
    UInt8 UInt16 UInt32 UInt64
    Float32 Double64
    Complex32 Complex64

  Numeric type classes:
    NumericType
      BooleanType
      SignedType
      UnsignedType
      IntegralType
        SignedIntegralType
        UnsignedIntegralType
      FloatingType
      ComplexType

$Id: numerictypes.py,v 1.55 2005/12/01 16:22:03 jaytmiller Exp $

Numeric type class

    Used both as a type identification and the repository of
    characteristics and conversion functions.
    Register the type object.  Raise an exception if it is already registered
    unless force is true.
    Redeclaration of existing NumericType with different parameters.returns the type of highest precision of the same general kind as 't'Not a numeric typeDetermines whether the given object or string, 'rep', represents
    a numarray type.numpy.numarray.numerictypes__new__() implements a 'quasi-singleton pattern because attempts
        to create duplicate types return the first created instance of that
        particular type parameterization,  i.e. the second time you try to
        create "Int32",  you get the original Int32, not a new one.
        Marker class used for signed type checkReturn the numeric type object for type

    type may be the name of a type object or the actual object
    support pickling protocol... no __setstate__ required.Type %s has already been registeredsupport the pickling protocol./usr/lib/python2.7/dist-packages/numpy/numarray/numerictypes.pyMarker class used for unsigned type checkPicklertestmodUnpicklerPicklingError This module contains a "session saver" which saves the state of a
NumPy session to a file.  At a later time, a different Python
process can be started and the saved session can be restored using
load().

The session saver relies on the Python pickle protocol to save and
restore objects.  Objects which are not themselves picklable (e.g.
modules) can sometimes be saved by "proxy",  particularly when they
are global constants of some kind.  If it's not known that proxying
will work,  a warning is issued at save time.  If a proxy fails to
reload properly (e.g. because it's not a global constant),  a warning
is issued at reload time and that name is bound to a _ProxyFailure
instance which tries to identify what should have been restored.

First, some unfortunate (probably unnecessary) concessions to doctest
to keep the test run free of warnings.

>>> del _PROXY_ALLOWED
>>> del __builtins__

By default, save() stores every variable in the caller's namespace:

>>> import numpy as na
>>> a = na.arange(10)
>>> save()

Alternately,  save() can be passed a comma seperated string of variables:

>>> save("a,na")

Alternately,  save() can be passed a dictionary, typically one you already
have lying around somewhere rather than created inline as shown here:

>>> save(dictionary={"a":a,"na":na})

If both variables and a dictionary are specified, the variables to be
saved are taken from the dictionary.

>>> save(variables="a,na",dictionary={"a":a,"na":na})

Remove names from the session namespace

>>> del a, na

By default, load() restores every variable/object in the session file
to the caller's namespace.

>>> load()

load() can be passed a comma seperated string of variables to be
restored from the session file to the caller's namespace:

>>> load("a,na")

load() can also be passed a dictionary to *restore to*:

>>> d = {}
>>> load(dictionary=d)

load can be passed both a list variables of variables to restore and a
dictionary to restore to:

>>> load(variables="a,na", dictionary=d)

>>> na.all(a == na.arange(10))
1
>>> na.__name__
'numpy'

NOTE:  session saving is faked for modules using module proxy objects.
Saved modules are re-imported at load time but any "state" in the module
which is not restored by a simple import is lost.

Tag object which marks the end of a save session and holds the
    saved session variable names as a list of strings in the same
    order as the session pickles.session.datload a numpy session from a file and store the specified
    'variables' into 'dictionary'.

    'variables'       a string of comma seperated variables: e.g. "a,b,c"
                      Defaults to dictionary.keys().

    'file'            a filename or file object for the session file.

    'dictionary'      the dictionary in which to look up the variables.
                      Defaults to the caller's globals()

    'verbose'         print additional debug output when True.
    Suppress warnings for known un-picklables with working proxies.updating dictionary with session variables./usr/lib/python2.7/dist-packages/numpy/numarray/session.pywarning: object proxycallers_globals() returns the global dictionary of the caller.it may not reload later.saves variables from a numpy session to a file.  Variables
    which won't pickle are "proxied" if possible.

    'variables'       a string of comma seperated variables: e.g. "a,b,c"
                      Defaults to dictionary.keys().

    'file'            a filename or file object for the session file.

    'dictionary'      the dictionary in which to look up the variables.
                      Defaults to the caller's globals()

    'verbose'         print additional debug output when True.
    unpickled objectproxying objectwarning: loading object proxyloading sessionwarning: proxying objectProxy object which fakes pickling an arbitrary object.  Only global
    constants can really be proxied.import failed.caller() returns the frame object of the function's caller.proxying moduleProxy object which fakes pickling a modulebecause it wouldn't pickle...warning: modulereturns a list containing the names of all the modules in the caller's
    global namespace.numpy.numarray.sessionreturns True iff _type isn't known as OK to proxywarning: couldn't find objectunsupported operand type(s) for +: 'int' and 'str'saving sessionwouldn't reload fromObject which is bound to a variable for a proxy pickle which failed to reloadmodule import failed.loading module proxyProxyingFailure('%s','%s','%s')in any module... skipping.lshiftrshift[9   s   abss   absolutes   adds   arccoss   arccoshs   arcsins   arcsinhs   arctans   arctan2s   arctanhs   bitwise_ands   bitwise_nots
   bitwise_ors   bitwise_xors   ceils   coss   coshs   divides   equals   exps   fabss   floors   floor_divides   fmods   greaters   greater_equals   hypots   isnans   lesss
   less_equals   logs   log10s   logical_ands   logical_nots
   logical_ors   logical_xors   lshifts   maximums   minimums   minuss   multiplys   negatives	   not_equals   powers   products	   remainders   rshifts   sins   sinhs   sqrts   subtracts   sums   tans   tanhs   true_divides	   conjugates   sign/usr/lib/python2.7/dist-packages/numpy/numarray/ufuncs.pynumpy.numarray.ufuncs(9   t   absoluteR    t   addt   arccost   arccosht   arcsint   arcsinht   arctant   arctan2t   arctanht   bitwise_andt   invertt
   bitwise_ort   bitwise_xort   ceilt   cost   cosht   dividet   equalt   expt   fabst   floort   floor_dividet   fmodt   greatert   greater_equalt   hypott   isnant   lesst
   less_equalt   logt   log10t   logical_andt   logical_nott
   logical_ort   logical_xort
   left_shiftt   maximumt   minimumt   negativet   multiplyR&   t	   not_equalt   powert   productt	   remaindert   right_shiftt   sint   sinht   sqrtt   subtractt   sumt   tant   tanht   true_dividet	   conjugatet   signnewdirsFPE_INVALIDhandleErrorFPE_OVERFLOWdividebyzeroFPE_UNDERFLOWFPE_DIVIDEBYZEROWarning: Encountered overflow(s)/usr/lib/python2.7/dist-packages/numpy/numarray/util.pyWarning: Encountered underflow(s)Warning: Encountered divide by zero(s)Take error status and use error mode to handle it.Warning: Encountered invalid numeric result(s)numpy.polynomial/usr/lib/python2.7/dist-packages/numpy/polynomial/__init__.py
A sub-package for efficiently dealing with polynomials.

Within the documentation for this sub-package, a "finite power series,"
i.e., a polynomial (also referred to simply as a "series") is represented
by a 1-D numpy array of the polynomial's coefficients, ordered from lowest
order term to highest.  For example, array([1,2,3]) represents
``P_0 + 2*P_1 + 3*P_2``, where P_n is the n-th order basis polynomial
applicable to the specific module in question, e.g., `polynomial` (which
"wraps" the "standard" basis) or `chebyshev`.  For optimal performance,
all operations on polynomials, including evaluation at an argument, are
implemented as operations on the coefficients.  Additional (module-specific)
information can be found in the docstring for the module of interest.

_nptschebxchebderchebdivchebfitchebintchebonechebpowchebsubchebpts1chebpts2chebtrimchebzerocheb2polychebgausschebrootschebval2dchebval3dpoly2chebchebdomainchebgrid2dchebgrid3dchebweight_zseries_der_zseries_intchebvander2dchebvander3dchebfromroots[!   s   chebzeros   chebones   chebxs
   chebdomains   cheblines   chebadds   chebsubs   chebmulxs   chebmuls   chebdivs   chebpows   chebvals   chebders   chebints	   cheb2polys	   poly2chebs   chebfromrootss
   chebvanders   chebfits   chebtrims	   chebrootss   chebpts1s   chebpts2s	   Chebyshevs	   chebval2ds	   chebval3ds
   chebgrid2ds
   chebgrid3ds   chebvander2ds   chebvander3ds   chebcompanions	   chebgausss
   chebweightCovert z-series to a Chebyshev series.

    Covert a z series to the equivalent Chebyshev series. The result is
    never an empty array. The dtype of the return is the same as that of
    the input. No checks are run on the arguments as this routine is for
    internal use.

    Parameters
    ----------
    zs : 1-D ndarray
        Odd length symmetric z-series, ordered from  low to high.

    Returns
    -------
    c : 1-D ndarray
        Chebyshev coefficients, ordered from  low to high.

    npts must be integer
    Evaluate a 3-D Chebyshev series at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * T_i(x) * T_j(y) * T_k(z)

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimensional polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    chebval, chebval2d, chebgrid2d, chebgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    Multiply a Chebyshev series by x.

    Multiply the polynomial `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of Chebyshev series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----

    .. versionadded:: 1.5.0

    
    Evaluate a 2-D Chebyshev series on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * T_i(a) * T_j(b),

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape + y.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j is contained in `c[i,j]`. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional Chebyshev series at points in the
        Cartesian product of `x` and `y`.

    See Also
    --------
    chebval, chebval2d, chebval3d, chebgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Convert a Chebyshev series to a polynomial.

    Convert an array representing the coefficients of a Chebyshev series,
    ordered from lowest degree to highest, to an array of the coefficients
    of the equivalent polynomial (relative to the "standard" basis) ordered
    from lowest to highest degree.

    Parameters
    ----------
    c : array_like
        1-D array containing the Chebyshev series coefficients, ordered
        from lowest order term to highest.

    Returns
    -------
    pol : ndarray
        1-D array containing the coefficients of the equivalent polynomial
        (relative to the "standard" basis) ordered from lowest order term
        to highest.

    See Also
    --------
    poly2cheb

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> c = P.Chebyshev(range(4))
    >>> c
    Chebyshev([ 0.,  1.,  2.,  3.], [-1.,  1.])
    >>> p = c.convert(kind=P.Polynomial)
    >>> p
    Polynomial([ -2.,  -8.,   4.,  12.], [-1.,  1.])
    >>> P.cheb2poly(range(4))
    array([ -2.,  -8.,   4.,  12.])

    
    Integrate a Chebyshev series.

    Returns the Chebyshev series coefficients `c` integrated `m` times from
    `lbnd` along `axis`. At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.)  The argument `c` is an array of
    coefficients from low to high degree along each axis, e.g., [1,2,3]
    represents the series ``T_0 + 2*T_1 + 3*T_2`` while [[1,2],[1,2]]
    represents ``1*T_0(x)*T_0(y) + 1*T_1(x)*T_0(y) + 2*T_0(x)*T_1(y) +
    2*T_1(x)*T_1(y)`` if axis=0 is ``x`` and axis=1 is ``y``.

    Parameters
    ----------
    c : array_like
        Array of Chebyshev series coefficients. If c is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at zero
        is the first value in the list, the value of the second integral
        at zero is the second value, etc.  If ``k == []`` (the default),
        all constants are set to zero.  If ``m == 1``, a single scalar can
        be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        C-series coefficients of the integral.

    Raises
    ------
    ValueError
        If ``m < 1``, ``len(k) > m``, ``np.isscalar(lbnd) == False``, or
        ``np.isscalar(scl) == False``.

    See Also
    --------
    chebder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.
    Why is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`.  Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a`- perhaps not what one would have first thought.

    Also note that, in general, the result of integrating a C-series needs
    to be "reprojected" onto the C-series basis set.  Thus, typically,
    the result of this function is "unintuitive," albeit correct; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c = (1,2,3)
    >>> C.chebint(c)
    array([ 0.5, -0.5,  0.5,  0.5])
    >>> C.chebint(c,3)
    array([ 0.03125   , -0.1875    ,  0.04166667, -0.05208333,  0.01041667,
            0.00625   ])
    >>> C.chebint(c, k=3)
    array([ 3.5, -0.5,  0.5,  0.5])
    >>> C.chebint(c,lbnd=-2)
    array([ 8.5, -0.5,  0.5,  0.5])
    >>> C.chebint(c,scl=-2)
    array([-1.,  1., -1., -1.])

    npts must be >= 2Covert Chebyshev series to z-series.

    Covert a Chebyshev series to the equivalent z-series. The result is
    never an empty array. The dtype of the return is the same as that of
    the input. No checks are run on the arguments as this routine is for
    internal use.

    Parameters
    ----------
    c : 1-D ndarray
        Chebyshev coefficients, ordered from low to high

    Returns
    -------
    zs : 1-D ndarray
        Odd length symmetric z-series, ordered from  low to high.

    
    Chebyshev points of the first kind.

    The Chebyshev points of the first kind are the points ``cos(x)``,
    where ``x = [pi*(k + .5)/npts for k in range(npts)]``.

    Parameters
    ----------
    npts : int
        Number of sample points desired.

    Returns
    -------
    pts : ndarray
        The Chebyshev points of the first kind.

    See Also
    --------
    chebpts2

    Notes
    -----

    .. versionadded:: 1.5.0

    
    Differentiate a Chebyshev series.

    Returns the Chebyshev series coefficients `c` differentiated `m` times
    along `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable). The argument
    `c` is an array of coefficients from low to high degree along each
    axis, e.g., [1,2,3] represents the series ``1*T_0 + 2*T_1 + 3*T_2``
    while [[1,2],[1,2]] represents ``1*T_0(x)*T_0(y) + 1*T_1(x)*T_0(y) +
    2*T_0(x)*T_1(y) + 2*T_1(x)*T_1(y)`` if axis=0 is ``x`` and axis=1 is
    ``y``.

    Parameters
    ----------
    c : array_like
        Array of Chebyshev series coefficients. If c is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change of
        variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Chebyshev series of the derivative.

    See Also
    --------
    chebint

    Notes
    -----
    In general, the result of differentiating a C-series needs to be
    "reprojected" onto the C-series basis set. Thus, typically, the
    result of this function is "unintuitive," albeit correct; see Examples
    section below.

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c = (1,2,3,4)
    >>> C.chebder(c)
    array([ 14.,  12.,  24.])
    >>> C.chebder(c,3)
    array([ 96.])
    >>> C.chebder(c,scl=-1)
    array([-14., -12., -24.])
    >>> C.chebder(c,2,-1)
    array([ 12.,  96.])

    Multiply two z-series.

    Multiply two z-series to produce a z-series.

    Parameters
    ----------
    z1, z2 : 1-D ndarray
        The arrays must be 1-D but this is not checked.

    Returns
    -------
    product : 1-D ndarray
        The product z-series.

    Notes
    -----
    This is simply convolution. If symmetric/anti-symmetric z-series are
    denoted by S/A then the following rules apply:

    S*S, A*A -> S
    S*A, A*S -> A

    Raise a Chebyshev series to a power.

    Returns the Chebyshev series `c` raised to the power `pow`. The
    argument `c` is a sequence of coefficients ordered from low to high.
    i.e., [1,2,3] is the series  ``T_0 + 2*T_1 + 3*T_2.``

    Parameters
    ----------
    c : array_like
        1-D array of Chebyshev series coefficients ordered from low to
        high.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Chebyshev series of power.

    See Also
    --------
    chebadd, chebsub, chebmul, chebdiv

    Examples
    --------

    npts must be >= 1Divide the first z-series by the second.

    Divide `z1` by `z2` and return the quotient and remainder as z-series.
    Warning: this implementation only applies when both z1 and z2 have the
    same symmetry, which is sufficient for present purposes.

    Parameters
    ----------
    z1, z2 : 1-D ndarray
        The arrays must be 1-D and have the same symmetry, but this is not
        checked.

    Returns
    -------

    (quotient, remainder) : 1-D ndarrays
        Quotient and remainder as z-series.

    Notes
    -----
    This is not the same as polynomial division on account of the desired form
    of the remainder. If symmetric/anti-symmetric z-series are denoted by S/A
    then the following rules apply:

    S/S -> S,S
    A/A -> S,A

    The restriction to types of the same symmetry could be fixed but seems like
    unneeded generality. There is no natural form for the remainder in the case
    where there is no symmetry.

    
    Compute the roots of a Chebyshev series.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * T_i(x).

    Parameters
    ----------
    c : 1-D array_like
        1-D array of coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the series. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    polyroots, legroots, lagroots, hermroots, hermeroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    The Chebyshev series basis polynomials aren't powers of `x` so the
    results of this function may seem unintuitive.

    Examples
    --------
    >>> import numpy.polynomial.chebyshev as cheb
    >>> cheb.chebroots((-1, 1,-1, 1)) # T3 - T2 + T1 - T0 has real roots
    array([ -5.00000000e-01,   2.60860684e-17,   1.00000000e+00])

    
    Multiply one Chebyshev series by another.

    Returns the product of two Chebyshev series `c1` * `c2`.  The arguments
    are sequences of coefficients, from lowest order "term" to highest,
    e.g., [1,2,3] represents the series ``T_0 + 2*T_1 + 3*T_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Chebyshev series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Chebyshev series coefficients representing their product.

    See Also
    --------
    chebadd, chebsub, chebdiv, chebpow

    Notes
    -----
    In general, the (polynomial) product of two C-series results in terms
    that are not in the Chebyshev polynomial basis set.  Thus, to express
    the product as a C-series, it is typically necessary to "reproject"
    the product onto said basis set, which typically produces
    "unintuitive live" (but correct) results; see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> C.chebmul(c1,c2) # multiplication requires "reprojection"
    array([  6.5,  12. ,  12. ,   4. ,   1.5])

    
    The weight function of the Chebyshev polynomials.

    The weight function is :math:`1/\sqrt{1 - x^2}` and the interval of
    integration is :math:`[-1, 1]`. The Chebyshev polynomials are orthogonal, but
    not normalized, with respect to this weight function.

    Parameters
    ----------
    x : array_like
       Values at which the weight function will be computed.

    Returns
    -------
    w : ndarray
       The weight function at `x`.

    Notes
    -----

    .. versionadded:: 1.7.0

    Pseudo-Vandermonde matrix of given degree.

    Returns the pseudo-Vandermonde matrix of degree `deg` and sample points
    `x`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., i] = T_i(x),

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the degree of the Chebyshev polynomial.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    matrix ``V = chebvander(x, n)``, then ``np.dot(V, c)`` and
    ``chebval(x, c)`` are the same up to roundoff.  This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of Chebyshev series of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray
        The pseudo Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where The last index is the degree of the
        corresponding Chebyshev polynomial.  The dtype will be the same as
        the converted `x`.

    Integrate a z-series.

    The integral is with respect to x, not z. This is achieved by a change
    of variable using dx/dz given in the module notes.

    Parameters
    ----------
    zs : z-series
        The z-series to integrate

    Returns
    -------
    integral : z-series
        The indefinite integral

    Notes
    -----
    The zseries for x (ns) has been multiplied by two in order to avoid
    using floats that are incompatible with Decimal and likely other
    specialized scalar types. This scaling has been compensated by
    dividing the resulting zs by two.

    Differentiate a z-series.

    The derivative is with respect to x, not z. This is achieved using the
    chain rule and the value of dx/dz given in the module notes.

    Parameters
    ----------
    zs : z-series
        The z-series to differentiate.

    Returns
    -------
    derivative : z-series
        The derivative

    Notes
    -----
    The zseries for x (ns) has been multiplied by two in order to avoid
    using floats that are incompatible with Decimal and likely other
    specialized scalar types. This scaling has been compensated by
    multiplying the value of zs by two also so that the two cancels in the
    division.

    Return the scaled companion matrix of c.

    The basis polynomials are scaled so that the companion matrix is
    symmetric when `c` is aa Chebyshev basis polynomial. This provides
    better eigenvalue estimates than the unscaled case and for basis
    polynomials the eigenvalues are guaranteed to be real if
    `numpy.linalg.eigvalsh` is used to obtain them.

    Parameters
    ----------
    c : array_like
        1-D array of Chebyshev series coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Scaled companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a Chebyshev series at points x.

    If `c` is of length `n + 1`, this function returns the value:

    .. math:: p(x) = c_0 * T_0(x) + c_1 * T_1(x) + ... + c_n * T_n(x)

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, algebra_like
        The shape of the return value is described above.

    See Also
    --------
    chebval2d, chebgrid2d, chebval3d, chebgrid3d

    Notes
    -----
    The evaluation uses Clenshaw recursion, aka synthetic division.

    Examples
    --------

    /usr/lib/python2.7/dist-packages/numpy/polynomial/chebyshev.py
    Least squares fit of Chebyshev series to data.

    Return the coefficients of a Legendre series of degree `deg` that is the
    least squares fit to the data values `y` given at points `x`. If `y` is
    1-D the returned coefficients will also be 1-D. If `y` is 2-D multiple
    fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * T_1(x) + ... + c_n * T_n(x),

    where `n` is `deg`.

    Since numpy version 1.7.0, chebfit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting series
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than
        this relative to the largest singular value will be ignored. The
        default value is len(x)*eps, where eps is the relative precision of
        the float type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is False (the
        default) just the coefficients are returned, when True diagnostic
        information from the singular value decomposition is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

        .. versionadded:: 1.5.0

    Returns
    -------
    coef : ndarray, shape (M,) or (M, K)
        Chebyshev coefficients ordered from low to high. If `y` was 2-D,
        the coefficients for the data in column k  of `y` are in column
        `k`.

    [residuals, rank, singular_values, rcond] : present when `full` = True
        Residuals of the least-squares fit, the effective rank of the
        scaled Vandermonde matrix and its singular values, and the
        specified value of `rcond`. For more details, see `linalg.lstsq`.

    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.  The
        warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    polyfit, legfit, lagfit, hermfit, hermefit
    chebval : Evaluates a Chebyshev series.
    chebvander : Vandermonde matrix of Chebyshev series.
    chebweight : Chebyshev weight function.
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the Chebyshev series `p` that
    minimizes the sum of the weighted squared errors

    .. math:: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where :math:`w_j` are the weights. This problem is solved by setting up
    as the (typically) overdetermined matrix equation

    .. math:: V(x) * c = w * y,

    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the
    coefficients to be solved for, `w` are the weights, and `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected, then a `RankWarning` will be issued. This means that the
    coefficient values may be poorly determined. Using a lower order fit
    will usually get rid of the warning.  The `rcond` parameter can also be
    set to a value smaller than its default, but the resulting fit may be
    spurious and have large contributions from roundoff error.

    Fits using Chebyshev series are usually better conditioned than fits
    using power series, but much can depend on the distribution of the
    sample points and the smoothness of the data. If the quality of the fit
    is inadequate splines may be a good alternative.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting

    Examples
    --------

    
Objects for dealing with Chebyshev series.

This module provides a number of objects (mostly functions) useful for
dealing with Chebyshev series, including a `Chebyshev` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with such polynomials is in the
docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------
- `chebdomain` -- Chebyshev series default domain, [-1,1].
- `chebzero` -- (Coefficients of the) Chebyshev series that evaluates
  identically to 0.
- `chebone` -- (Coefficients of the) Chebyshev series that evaluates
  identically to 1.
- `chebx` -- (Coefficients of the) Chebyshev series for the identity map,
  ``f(x) = x``.

Arithmetic
----------
- `chebadd` -- add two Chebyshev series.
- `chebsub` -- subtract one Chebyshev series from another.
- `chebmul` -- multiply two Chebyshev series.
- `chebdiv` -- divide one Chebyshev series by another.
- `chebpow` -- raise a Chebyshev series to an positive integer power
- `chebval` -- evaluate a Chebyshev series at given points.
- `chebval2d` -- evaluate a 2D Chebyshev series at given points.
- `chebval3d` -- evaluate a 3D Chebyshev series at given points.
- `chebgrid2d` -- evaluate a 2D Chebyshev series on a Cartesian product.
- `chebgrid3d` -- evaluate a 3D Chebyshev series on a Cartesian product.

Calculus
--------
- `chebder` -- differentiate a Chebyshev series.
- `chebint` -- integrate a Chebyshev series.

Misc Functions
--------------
- `chebfromroots` -- create a Chebyshev series with specified roots.
- `chebroots` -- find the roots of a Chebyshev series.
- `chebvander` -- Vandermonde-like matrix for Chebyshev polynomials.
- `chebvander2d` -- Vandermonde-like matrix for 2D power series.
- `chebvander3d` -- Vandermonde-like matrix for 3D power series.
- `chebgauss` -- Gauss-Chebyshev quadrature, points and weights.
- `chebweight` -- Chebyshev weight function.
- `chebcompanion` -- symmetrized companion matrix in Chebyshev form.
- `chebfit` -- least-squares fit returning a Chebyshev series.
- `chebpts1` -- Chebyshev points of the first kind.
- `chebpts2` -- Chebyshev points of the second kind.
- `chebtrim` -- trim leading coefficients from a Chebyshev series.
- `chebline` -- Chebyshev series representing given straight line.
- `cheb2poly` -- convert a Chebyshev series to a polynomial.
- `poly2cheb` -- convert a polynomial to a Chebyshev series.

Classes
-------
- `Chebyshev` -- A Chebyshev series class.

See also
--------
`numpy.polynomial`

Notes
-----
The implementations of multiplication, division, integration, and
differentiation use the algebraic identities [1]_:

.. math ::
    T_n(x) = \frac{z^n + z^{-n}}{2} \\
    z\frac{dx}{dz} = \frac{z - z^{-1}}{2}.

where

.. math :: x = \frac{z + z^{-1}}{2}.

These identities allow a Chebyshev series to be expressed as a finite,
symmetric Laurent series.  In this module, this sort of Laurent series
is referred to as a "z-series."

References
----------
.. [1] A. T. Benjamin, et al., "Combinatorial Trigonometry with Chebyshev
  Polynomials," *Journal of Statistical Planning and Inference 14*, 2008
  (preprint: http://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf, pg. 4)


    Gauss-Chebyshev quadrature.

    Computes the sample points and weights for Gauss-Chebyshev quadrature.
    These sample points and weights will correctly integrate polynomials of
    degree :math:`2*deg - 1` or less over the interval :math:`[-1, 1]` with
    the weight function :math:`f(x) = 1/\sqrt{1 - x^2}`.

    Parameters
    ----------
    deg : int
        Number of sample points and weights. It must be >= 1.

    Returns
    -------
    x : ndarray
        1-D ndarray containing the sample points.
    y : ndarray
        1-D ndarray containing the weights.

    Notes
    -----

    .. versionadded:: 1.7.0

    The results have only been tested up to degree 100, higher degrees may
    be problematic. For Gauss-Chebyshev there are closed form solutions for
    the sample points and weights. If n = `deg`, then

    .. math:: x_i = \cos(\pi (2 i - 1) / (2 n))

    .. math:: w_i = \pi / n

    
    Chebyshev series whose graph is a straight line.



    Parameters
    ----------
    off, scl : scalars
        The specified line is given by ``off + scl*x``.

    Returns
    -------
    y : ndarray
        This module's representation of the Chebyshev series for
        ``off + scl*x``.

    See Also
    --------
    polyline

    Examples
    --------
    >>> import numpy.polynomial.chebyshev as C
    >>> C.chebline(3,2)
    array([3, 2])
    >>> C.chebval(-3, C.chebline(3,2)) # should be -3
    -3.0

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = T_i(x)*T_j(y)*T_k(z),

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the degrees of the Chebyshev polynomials.

    If ``V = chebvander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and ``np.dot(V, c.flat)`` and ``chebval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D Chebyshev
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    chebvander, chebvander3d. chebval2d, chebval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 2-D Chebyshev series at points (x, y).

    This function returns the values:

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * T_i(x) * T_j(y)

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` is a 1-D array a one is implicitly appended to its shape to make
    it 2-D. The shape of the result will be c.shape[2:] + x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and if it isn't an ndarray it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in ``c[i,j]``. If `c` has
        dimension greater than 2 the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional Chebyshev series at points formed
        from pairs of corresponding values from `x` and `y`.

    See Also
    --------
    chebval, chebgrid2d, chebval3d, chebgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Subtract one Chebyshev series from another.

    Returns the difference of two Chebyshev series `c1` - `c2`.  The
    sequences of coefficients are from lowest order term to highest, i.e.,
    [1,2,3] represents the series ``T_0 + 2*T_1 + 3*T_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Chebyshev series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Chebyshev series coefficients representing their difference.

    See Also
    --------
    chebadd, chebmul, chebdiv, chebpow

    Notes
    -----
    Unlike multiplication, division, etc., the difference of two Chebyshev
    series is a Chebyshev series (without having to "reproject" the result
    onto the basis set) so subtraction, just like that of "standard"
    polynomials, is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> C.chebsub(c1,c2)
    array([-2.,  0.,  2.])
    >>> C.chebsub(c2,c1) # -C.chebsub(c1,c2)
    array([ 2.,  0., -2.])

    
    Generate a Chebyshev series with given roots.

    The function returns the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    in Chebyshev form, where the `r_n` are the roots specified in `roots`.
    If a zero has multiplicity n, then it must appear in `roots` n times.
    For instance, if 2 is a root of multiplicity three and 3 is a root of
    multiplicity 2, then `roots` looks something like [2, 2, 2, 3, 3]. The
    roots can appear in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * T_1(x) + ... +  c_n * T_n(x)

    The coefficient of the last term is not generally 1 for monic
    polynomials in Chebyshev form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of coefficients.  If all roots are real then `out` is a
        real array, if some of the roots are complex, then `out` is complex
        even if all the coefficients in the result are real (see Examples
        below).

    See Also
    --------
    polyfromroots, legfromroots, lagfromroots, hermfromroots,
    hermefromroots.

    Examples
    --------
    >>> import numpy.polynomial.chebyshev as C
    >>> C.chebfromroots((-1,0,1)) # x^3 - x relative to the standard basis
    array([ 0.  , -0.25,  0.  ,  0.25])
    >>> j = complex(0,1)
    >>> C.chebfromroots((-j,j)) # x^2 + 1 relative to the standard basis
    array([ 1.5+0.j,  0.0+0.j,  0.5+0.j])

    
    Evaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * T_i(a) * T_j(b) * T_k(c)

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    chebval, chebval2d, chebgrid2d, chebval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Add one Chebyshev series to another.

    Returns the sum of two Chebyshev series `c1` + `c2`.  The arguments
    are sequences of coefficients ordered from lowest order term to
    highest, i.e., [1,2,3] represents the series ``T_0 + 2*T_1 + 3*T_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Chebyshev series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the Chebyshev series of their sum.

    See Also
    --------
    chebsub, chebmul, chebdiv, chebpow

    Notes
    -----
    Unlike multiplication, division, etc., the sum of two Chebyshev series
    is a Chebyshev series (without having to "reproject" the result onto
    the basis set) so addition, just like that of "standard" polynomials,
    is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> C.chebadd(c1,c2)
    array([ 4.,  4.,  4.])

    
    Divide one Chebyshev series by another.

    Returns the quotient-with-remainder of two Chebyshev series
    `c1` / `c2`.  The arguments are sequences of coefficients from lowest
    order "term" to highest, e.g., [1,2,3] represents the series
    ``T_0 + 2*T_1 + 3*T_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Chebyshev series coefficients ordered from low to
        high.

    Returns
    -------
    [quo, rem] : ndarrays
        Of Chebyshev series coefficients representing the quotient and
        remainder.

    See Also
    --------
    chebadd, chebsub, chebmul, chebpow

    Notes
    -----
    In general, the (polynomial) division of one C-series by another
    results in quotient and remainder terms that are not in the Chebyshev
    polynomial basis set.  Thus, to express these results as C-series, it
    is typically necessary to "reproject" the results onto said basis
    set, which typically produces "unintuitive" (but correct) results;
    see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import chebyshev as C
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> C.chebdiv(c1,c2) # quotient "intuitive," remainder not
    (array([ 3.]), array([-8., -4.]))
    >>> c2 = (0,1,2,3)
    >>> C.chebdiv(c2,c1) # neither "intuitive"
    (array([ 0.,  2.]), array([-2., -4.]))

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = T_i(x) * T_j(y),

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the degrees of
    the Chebyshev polynomials.

    If ``V = chebvander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``chebval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D Chebyshev
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to
        1-D arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    chebvander, chebvander3d. chebval2d, chebval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Convert a polynomial to a Chebyshev series.

    Convert an array representing the coefficients of a polynomial (relative
    to the "standard" basis) ordered from lowest degree to highest, to an
    array of the coefficients of the equivalent Chebyshev series, ordered
    from lowest to highest degree.

    Parameters
    ----------
    pol : array_like
        1-D array containing the polynomial coefficients

    Returns
    -------
    c : ndarray
        1-D array containing the coefficients of the equivalent Chebyshev
        series.

    See Also
    --------
    cheb2poly

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> p = P.Polynomial(range(4))
    >>> p
    Polynomial([ 0.,  1.,  2.,  3.], [-1.,  1.])
    >>> c = p.convert(kind=P.Chebyshev)
    >>> c
    Chebyshev([ 1.  ,  3.25,  1.  ,  0.75], [-1.,  1.])
    >>> P.poly2cheb(range(4))
    array([ 1.  ,  3.25,  1.  ,  0.75])

    
    Chebyshev points of the second kind.

    The Chebyshev points of the second kind are the points ``cos(x)``,
    where ``x = [pi*k/(npts - 1) for k in range(npts)]``.

    Parameters
    ----------
    npts : int
        Number of sample points desired.

    Returns
    -------
    pts : ndarray
        The Chebyshev points of the second kind.

    Notes
    -----

    .. versionadded:: 1.5.0

    hermxhermdivherminthermonehermpowhermtrimhermzeroherm2polyhermgausshermval2dhermval3dpoly2hermhermdomainhermgrid2dhermgrid3dhermweighthermvander2dhermvander3d[   s   hermzeros   hermones   hermxs
   hermdomains   hermlines   hermadds   hermsubs   hermmulxs   hermmuls   hermdivs   hermpows   hermvals   hermders   hermints	   herm2polys	   poly2herms   hermfromrootss
   hermvanders   hermfits   hermtrims	   hermrootss   Hermites	   hermval2ds	   hermval3ds
   hermgrid2ds
   hermgrid3ds   hermvander2ds   hermvander3ds   hermcompanions	   hermgausss
   hermweight
    Gauss-Hermite quadrature.

    Computes the sample points and weights for Gauss-Hermite quadrature.
    These sample points and weights will correctly integrate polynomials of
    degree :math:`2*deg - 1` or less over the interval :math:`[-\inf, \inf]`
    with the weight function :math:`f(x) = \exp(-x^2)`.

    Parameters
    ----------
    deg : int
        Number of sample points and weights. It must be >= 1.

    Returns
    -------
    x : ndarray
        1-D ndarray containing the sample points.
    y : ndarray
        1-D ndarray containing the weights.

    Notes
    -----

    .. versionadded::1.7.0

    The results have only been tested up to degree 100, higher degrees may
    be problematic. The weights are determined by using the fact that

    .. math:: w_k = c / (H'_n(x_k) * H_{n-1}(x_k))

    where :math:`c` is a constant independent of :math:`k` and :math:`x_k`
    is the k'th root of :math:`H_n`, and then scaling the results to get
    the right value when integrating 1.

    
    Hermite series whose graph is a straight line.



    Parameters
    ----------
    off, scl : scalars
        The specified line is given by ``off + scl*x``.

    Returns
    -------
    y : ndarray
        This module's representation of the Hermite series for
        ``off + scl*x``.

    See Also
    --------
    polyline, chebline

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermline, hermval
    >>> hermval(0,hermline(3, 2))
    3.0
    >>> hermval(1,hermline(3, 2))
    5.0

    Raise a Hermite series to a power.

    Returns the Hermite series `c` raised to the power `pow`. The
    argument `c` is a sequence of coefficients ordered from low to high.
    i.e., [1,2,3] is the series  ``P_0 + 2*P_1 + 3*P_2.``

    Parameters
    ----------
    c : array_like
        1-D array of Hermite series coefficients ordered from low to
        high.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Hermite series of power.

    See Also
    --------
    hermadd, hermsub, hermmul, hermdiv

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermpow
    >>> hermpow([1, 2, 3], 2)
    array([ 81.,  52.,  82.,  12.,   9.])

    Pseudo-Vandermonde matrix of given degree.

    Returns the pseudo-Vandermonde matrix of degree `deg` and sample points
    `x`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., i] = H_i(x),

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the degree of the Hermite polynomial.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    array ``V = hermvander(x, n)``, then ``np.dot(V, c)`` and
    ``hermval(x, c)`` are the same up to roundoff. This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of Hermite series of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray
        The pseudo-Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where The last index is the degree of the
        corresponding Hermite polynomial.  The dtype will be the same as
        the converted `x`.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermvander
    >>> x = np.array([-1, 0, 1])
    >>> hermvander(x, 3)
    array([[ 1., -2.,  2.,  4.],
           [ 1.,  0., -2., -0.],
           [ 1.,  2.,  2., -4.]])

    
    Subtract one Hermite series from another.

    Returns the difference of two Hermite series `c1` - `c2`.  The
    sequences of coefficients are from lowest order term to highest, i.e.,
    [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Hermite series coefficients representing their difference.

    See Also
    --------
    hermadd, hermmul, hermdiv, hermpow

    Notes
    -----
    Unlike multiplication, division, etc., the difference of two Hermite
    series is a Hermite series (without having to "reproject" the result
    onto the basis set) so subtraction, just like that of "standard"
    polynomials, is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermsub
    >>> hermsub([1, 2, 3, 4], [1, 2, 3])
    array([ 0.,  0.,  0.,  4.])

    /usr/lib/python2.7/dist-packages/numpy/polynomial/hermite.py
    poly2herm(pol)

    Convert a polynomial to a Hermite series.

    Convert an array representing the coefficients of a polynomial (relative
    to the "standard" basis) ordered from lowest degree to highest, to an
    array of the coefficients of the equivalent Hermite series, ordered
    from lowest to highest degree.

    Parameters
    ----------
    pol : array_like
        1-D array containing the polynomial coefficients

    Returns
    -------
    c : ndarray
        1-D array containing the coefficients of the equivalent Hermite
        series.

    See Also
    --------
    herm2poly

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import poly2herme
    >>> poly2herm(np.arange(4))
    array([ 1.   ,  2.75 ,  0.5  ,  0.375])

    
    Multiply one Hermite series by another.

    Returns the product of two Hermite series `c1` * `c2`.  The arguments
    are sequences of coefficients, from lowest order "term" to highest,
    e.g., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Hermite series coefficients representing their product.

    See Also
    --------
    hermadd, hermsub, hermdiv, hermpow

    Notes
    -----
    In general, the (polynomial) product of two C-series results in terms
    that are not in the Hermite polynomial basis set.  Thus, to express
    the product as a Hermite series, it is necessary to "reproject" the
    product onto said basis set, which may produce "unintuitive" (but
    correct) results; see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermmul
    >>> hermmul([1, 2, 3], [0, 1, 2])
    array([ 52.,  29.,  52.,   7.,   6.])

    
Objects for dealing with Hermite series.

This module provides a number of objects (mostly functions) useful for
dealing with Hermite series, including a `Hermite` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with such polynomials is in the
docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------
- `hermdomain` -- Hermite series default domain, [-1,1].
- `hermzero` -- Hermite series that evaluates identically to 0.
- `hermone` -- Hermite series that evaluates identically to 1.
- `hermx` -- Hermite series for the identity map, ``f(x) = x``.

Arithmetic
----------
- `hermmulx` -- multiply a Hermite series in ``P_i(x)`` by ``x``.
- `hermadd` -- add two Hermite series.
- `hermsub` -- subtract one Hermite series from another.
- `hermmul` -- multiply two Hermite series.
- `hermdiv` -- divide one Hermite series by another.
- `hermval` -- evaluate a Hermite series at given points.
- `hermval2d` -- evaluate a 2D Hermite series at given points.
- `hermval3d` -- evaluate a 3D Hermite series at given points.
- `hermgrid2d` -- evaluate a 2D Hermite series on a Cartesian product.
- `hermgrid3d` -- evaluate a 3D Hermite series on a Cartesian product.

Calculus
--------
- `hermder` -- differentiate a Hermite series.
- `hermint` -- integrate a Hermite series.

Misc Functions
--------------
- `hermfromroots` -- create a Hermite series with specified roots.
- `hermroots` -- find the roots of a Hermite series.
- `hermvander` -- Vandermonde-like matrix for Hermite polynomials.
- `hermvander2d` -- Vandermonde-like matrix for 2D power series.
- `hermvander3d` -- Vandermonde-like matrix for 3D power series.
- `hermgauss` -- Gauss-Hermite quadrature, points and weights.
- `hermweight` -- Hermite weight function.
- `hermcompanion` -- symmetrized companion matrix in Hermite form.
- `hermfit` -- least-squares fit returning a Hermite series.
- `hermtrim` -- trim leading coefficients from a Hermite series.
- `hermline` -- Hermite series of given straight line.
- `herm2poly` -- convert a Hermite series to a polynomial.
- `poly2herm` -- convert a polynomial to a Hermite series.

Classes
-------
- `Hermite` -- A Hermite series class.

See also
--------
`numpy.polynomial`

Return the scaled companion matrix of c.

    The basis polynomials are scaled so that the companion matrix is
    symmetric when `c` is an Hermite basis polynomial. This provides
    better eigenvalue estimates than the unscaled case and for basis
    polynomials the eigenvalues are guaranteed to be real if
    `numpy.linalg.eigvalsh` is used to obtain them.

    Parameters
    ----------
    c : array_like
        1-D array of Hermite series coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Scaled companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded::1.7.0

    
    Convert a Hermite series to a polynomial.

    Convert an array representing the coefficients of a Hermite series,
    ordered from lowest degree to highest, to an array of the coefficients
    of the equivalent polynomial (relative to the "standard" basis) ordered
    from lowest to highest degree.

    Parameters
    ----------
    c : array_like
        1-D array containing the Hermite series coefficients, ordered
        from lowest order term to highest.

    Returns
    -------
    pol : ndarray
        1-D array containing the coefficients of the equivalent polynomial
        (relative to the "standard" basis) ordered from lowest order term
        to highest.

    See Also
    --------
    poly2herm

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.hermite import herm2poly
    >>> herm2poly([ 1.   ,  2.75 ,  0.5  ,  0.375])
    array([ 0.,  1.,  2.,  3.])

    
    Integrate a Hermite series.

    Returns the Hermite series coefficients `c` integrated `m` times from
    `lbnd` along `axis`. At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.)  The argument `c` is an array of
    coefficients from low to high degree along each axis, e.g., [1,2,3]
    represents the series ``H_0 + 2*H_1 + 3*H_2`` while [[1,2],[1,2]]
    represents ``1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) +
    2*H_1(x)*H_1(y)`` if axis=0 is ``x`` and axis=1 is ``y``.

    Parameters
    ----------
    c : array_like
        Array of Hermite series coefficients. If c is multidimensional the
        different axis correspond to different variables with the degree in
        each axis given by the corresponding index.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at
        ``lbnd`` is the first value in the list, the value of the second
        integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the
        default), all constants are set to zero.  If ``m == 1``, a single
        scalar can be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        Hermite series coefficients of the integral.

    Raises
    ------
    ValueError
        If ``m < 0``, ``len(k) > m``, ``np.isscalar(lbnd) == False``, or
        ``np.isscalar(scl) == False``.

    See Also
    --------
    hermder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.
    Why is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`.  Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a` - perhaps not what one would have first thought.

    Also note that, in general, the result of integrating a C-series needs
    to be "reprojected" onto the C-series basis set.  Thus, typically,
    the result of this function is "unintuitive," albeit correct; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermint
    >>> hermint([1,2,3]) # integrate once, value 0 at 0.
    array([ 1. ,  0.5,  0.5,  0.5])
    >>> hermint([1,2,3], m=2) # integrate twice, value & deriv 0 at 0
    array([-0.5       ,  0.5       ,  0.125     ,  0.08333333,  0.0625    ])
    >>> hermint([1,2,3], k=1) # integrate once, value 1 at 0.
    array([ 2. ,  0.5,  0.5,  0.5])
    >>> hermint([1,2,3], lbnd=-1) # integrate once, value 0 at -1
    array([-2. ,  0.5,  0.5,  0.5])
    >>> hermint([1,2,3], m=2, k=[1,2], lbnd=-1)
    array([ 1.66666667, -0.5       ,  0.125     ,  0.08333333,  0.0625    ])

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = H_i(x)*H_j(y)*H_k(z),

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the degrees of the Hermite polynomials.

    If ``V = hermvander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and  ``np.dot(V, c.flat)`` and ``hermval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D Hermite
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    hermvander, hermvander3d. hermval2d, hermval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Divide one Hermite series by another.

    Returns the quotient-with-remainder of two Hermite series
    `c1` / `c2`.  The arguments are sequences of coefficients from lowest
    order "term" to highest, e.g., [1,2,3] represents the series
    ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    [quo, rem] : ndarrays
        Of Hermite series coefficients representing the quotient and
        remainder.

    See Also
    --------
    hermadd, hermsub, hermmul, hermpow

    Notes
    -----
    In general, the (polynomial) division of one Hermite series by another
    results in quotient and remainder terms that are not in the Hermite
    polynomial basis set.  Thus, to express these results as a Hermite
    series, it is necessary to "reproject" the results onto the Hermite
    basis set, which may produce "unintuitive" (but correct) results; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermdiv
    >>> hermdiv([ 52.,  29.,  52.,   7.,   6.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 0.]))
    >>> hermdiv([ 54.,  31.,  52.,   7.,   6.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 2.,  2.]))
    >>> hermdiv([ 53.,  30.,  52.,   7.,   6.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 1.,  1.]))

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = H_i(x) * H_j(y),

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the degrees of
    the Hermite polynomials.

    If ``V = hermvander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``hermval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D Hermite
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    hermvander, hermvander3d. hermval2d, hermval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Least squares fit of Hermite series to data.

    Return the coefficients of a Hermite series of degree `deg` that is the
    least squares fit to the data values `y` given at points `x`. If `y` is
    1-D the returned coefficients will also be 1-D. If `y` is 2-D multiple
    fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * H_1(x) + ... + c_n * H_n(x),

    where `n` is `deg`.

    Since numpy version 1.7.0, hermfit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting polynomial
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than
        this relative to the largest singular value will be ignored. The
        default value is len(x)*eps, where eps is the relative precision of
        the float type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is False (the
        default) just the coefficients are returned, when True diagnostic
        information from the singular value decomposition is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

    Returns
    -------
    coef : ndarray, shape (M,) or (M, K)
        Hermite coefficients ordered from low to high. If `y` was 2-D,
        the coefficients for the data in column k  of `y` are in column
        `k`.

    [residuals, rank, singular_values, rcond] : present when `full` = True
        Residuals of the least-squares fit, the effective rank of the
        scaled Vandermonde matrix and its singular values, and the
        specified value of `rcond`. For more details, see `linalg.lstsq`.

    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.  The
        warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    chebfit, legfit, lagfit, polyfit, hermefit
    hermval : Evaluates a Hermite series.
    hermvander : Vandermonde matrix of Hermite series.
    hermweight : Hermite weight function
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the Hermite series `p` that
    minimizes the sum of the weighted squared errors

    .. math:: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where the :math:`w_j` are the weights. This problem is solved by
    setting up the (typically) overdetermined matrix equation

    .. math:: V(x) * c = w * y,

    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the
    coefficients to be solved for, `w` are the weights, `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected, then a `RankWarning` will be issued. This means that the
    coefficient values may be poorly determined. Using a lower order fit
    will usually get rid of the warning.  The `rcond` parameter can also be
    set to a value smaller than its default, but the resulting fit may be
    spurious and have large contributions from roundoff error.

    Fits using Hermite series are probably most useful when the data can be
    approximated by ``sqrt(w(x)) * p(x)``, where `w(x)` is the Hermite
    weight. In that case the weight ``sqrt(w(x[i])`` should be used
    together with data values ``y[i]/sqrt(w(x[i])``. The weight function is
    available as `hermweight`.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermfit, hermval
    >>> x = np.linspace(-10, 10)
    >>> err = np.random.randn(len(x))/10
    >>> y = hermval(x, [1, 2, 3]) + err
    >>> hermfit(x, y, 2)
    array([ 0.97902637,  1.99849131,  3.00006   ])

    
    Weight function of the Hermite polynomials.

    The weight function is :math:`\exp(-x^2)` and the interval of
    integration is :math:`[-\inf, \inf]`. the Hermite polynomials are
    orthogonal, but not normalized, with respect to this weight function.

    Parameters
    ----------
    x : array_like
       Values at which the weight function will be computed.

    Returns
    -------
    w : ndarray
       The weight function at `x`.

    Notes
    -----

    .. versionadded::1.7.0

    Multiply a Hermite series by x.

    Multiply the Hermite series `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----
    The multiplication uses the recursion relationship for Hermite
    polynomials in the form

    .. math::

    xP_i(x) = (P_{i + 1}(x)/2 + i*P_{i - 1}(x))

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermmulx
    >>> hermmulx([1, 2, 3])
    array([ 2. ,  6.5,  1. ,  1.5])

    
    Compute the roots of a Hermite series.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * H_i(x).

    Parameters
    ----------
    c : 1-D array_like
        1-D array of coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the series. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    polyroots, legroots, lagroots, chebroots, hermeroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    The Hermite series basis polynomials aren't powers of `x` so the
    results of this function may seem unintuitive.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermroots, hermfromroots
    >>> coef = hermfromroots([-1, 0, 1])
    >>> coef
    array([ 0.   ,  0.25 ,  0.   ,  0.125])
    >>> hermroots(coef)
    array([ -1.00000000e+00,  -1.38777878e-17,   1.00000000e+00])

    
    Evaluate a 3-D Hermite series on the Cartesian product of x, y, and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * H_i(a) * H_j(b) * H_k(c)

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    hermval, hermval2d, hermgrid2d, hermval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 2-D Hermite series on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * H_i(a) * H_j(b)

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    hermval, hermval2d, hermval3d, hermgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Generate a Hermite series with given roots.

    The function returns the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    in Hermite form, where the `r_n` are the roots specified in `roots`.
    If a zero has multiplicity n, then it must appear in `roots` n times.
    For instance, if 2 is a root of multiplicity three and 3 is a root of
    multiplicity 2, then `roots` looks something like [2, 2, 2, 3, 3]. The
    roots can appear in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * H_1(x) + ... +  c_n * H_n(x)

    The coefficient of the last term is not generally 1 for monic
    polynomials in Hermite form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of coefficients.  If all roots are real then `out` is a
        real array, if some of the roots are complex, then `out` is complex
        even if all the coefficients in the result are real (see Examples
        below).

    See Also
    --------
    polyfromroots, legfromroots, lagfromroots, chebfromroots,
    hermefromroots.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermfromroots, hermval
    >>> coef = hermfromroots((-1, 0, 1))
    >>> hermval((-1, 0, 1), coef)
    array([ 0.,  0.,  0.])
    >>> coef = hermfromroots((-1j, 1j))
    >>> hermval((-1j, 1j), coef)
    array([ 0.+0.j,  0.+0.j])

    
    Evaluate a 2-D Hermite series at points (x, y).

    This function returns the values:

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * H_i(x) * H_j(y)

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` is a 1-D array a one is implicitly appended to its shape to make
    it 2-D. The shape of the result will be c.shape[2:] + x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and if it isn't an ndarray it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in ``c[i,j]``. If `c` has
        dimension greater than two the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points formed with
        pairs of corresponding values from `x` and `y`.

    See Also
    --------
    hermval, hermgrid2d, hermval3d, hermgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Differentiate a Hermite series.

    Returns the Hermite series coefficients `c` differentiated `m` times
    along `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable). The argument
    `c` is an array of coefficients from low to high degree along each
    axis, e.g., [1,2,3] represents the series ``1*H_0 + 2*H_1 + 3*H_2``
    while [[1,2],[1,2]] represents ``1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) +
    2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)`` if axis=0 is ``x`` and axis=1 is
    ``y``.

    Parameters
    ----------
    c : array_like
        Array of Hermite series coefficients. If `c` is multidimensional the
        different axis correspond to different variables with the degree in
        each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change of
        variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Hermite series of the derivative.

    See Also
    --------
    hermint

    Notes
    -----
    In general, the result of differentiating a Hermite series does not
    resemble the same operation on a power series. Thus the result of this
    function may be "unintuitive," albeit correct; see Examples section
    below.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermder
    >>> hermder([ 1. ,  0.5,  0.5,  0.5])
    array([ 1.,  2.,  3.])
    >>> hermder([-0.5,  1./2.,  1./8.,  1./12.,  1./16.], m=2)
    array([ 1.,  2.,  3.])

    
    Evaluate an Hermite series at points x.

    If `c` is of length `n + 1`, this function returns the value:

    .. math:: p(x) = c_0 * H_0(x) + c_1 * H_1(x) + ... + c_n * H_n(x)

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, algebra_like
        The shape of the return value is described above.

    See Also
    --------
    hermval2d, hermgrid2d, hermval3d, hermgrid3d

    Notes
    -----
    The evaluation uses Clenshaw recursion, aka synthetic division.

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermval
    >>> coef = [1,2,3]
    >>> hermval(1, coef)
    11.0
    >>> hermval([[1,2],[3,4]], coef)
    array([[  11.,   51.],
           [ 115.,  203.]])

    
    Evaluate a 3-D Hermite series at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * H_i(x) * H_j(y) * H_k(z)

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimensional polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    hermval, hermval2d, hermgrid2d, hermgrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Add one Hermite series to another.

    Returns the sum of two Hermite series `c1` + `c2`.  The arguments
    are sequences of coefficients ordered from lowest order term to
    highest, i.e., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the Hermite series of their sum.

    See Also
    --------
    hermsub, hermmul, hermdiv, hermpow

    Notes
    -----
    Unlike multiplication, division, etc., the sum of two Hermite series
    is a Hermite series (without having to "reproject" the result onto
    the basis set) so addition, just like that of "standard" polynomials,
    is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.hermite import hermadd
    >>> hermadd([1, 2, 3], [1, 2, 3, 4])
    array([ 2.,  4.,  6.,  4.])

    hermexhermedivhermeinthermeonehermepowhermetrimhermezeroherme2polyhermegausshermeval2dhermeval3dhermedomainhermegrid2dhermegrid3dhermeweighthermevander2dhermevander3d[   s	   hermezeros   hermeones   hermexs   hermedomains	   hermelines   hermeadds   hermesubs	   hermemulxs   hermemuls   hermedivs   hermpows   hermevals   hermeders   hermeints
   herme2polys
   poly2hermes   hermefromrootss   hermevanders   hermefits	   hermetrims
   hermerootss   HermiteEs
   hermeval2ds
   hermeval3ds   hermegrid2ds   hermegrid3ds   hermevander2ds   hermevander3ds   hermecompanions
   hermegausss   hermeweight
    Least squares fit of Hermite series to data.

    Return the coefficients of a HermiteE series of degree `deg` that is
    the least squares fit to the data values `y` given at points `x`. If
    `y` is 1-D the returned coefficients will also be 1-D. If `y` is 2-D
    multiple fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * He_1(x) + ... + c_n * He_n(x),

    where `n` is `deg`.

    Since numpy version 1.7.0, hermefit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting polynomial
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than
        this relative to the largest singular value will be ignored. The
        default value is len(x)*eps, where eps is the relative precision of
        the float type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is False (the
        default) just the coefficients are returned, when True diagnostic
        information from the singular value decomposition is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

    Returns
    -------
    coef : ndarray, shape (M,) or (M, K)
        Hermite coefficients ordered from low to high. If `y` was 2-D,
        the coefficients for the data in column k  of `y` are in column
        `k`.

    [residuals, rank, singular_values, rcond] : present when `full` = True
        Residuals of the least-squares fit, the effective rank of the
        scaled Vandermonde matrix and its singular values, and the
        specified value of `rcond`. For more details, see `linalg.lstsq`.

    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.  The
        warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    chebfit, legfit, polyfit, hermfit, polyfit
    hermeval : Evaluates a Hermite series.
    hermevander : pseudo Vandermonde matrix of Hermite series.
    hermeweight : HermiteE weight function.
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the HermiteE series `p` that
    minimizes the sum of the weighted squared errors

    .. math:: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where the :math:`w_j` are the weights. This problem is solved by
    setting up the (typically) overdetermined matrix equation

    .. math:: V(x) * c = w * y,

    where `V` is the pseudo Vandermonde matrix of `x`, the elements of `c`
    are the coefficients to be solved for, and the elements of `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected, then a `RankWarning` will be issued. This means that the
    coefficient values may be poorly determined. Using a lower order fit
    will usually get rid of the warning.  The `rcond` parameter can also be
    set to a value smaller than its default, but the resulting fit may be
    spurious and have large contributions from roundoff error.

    Fits using HermiteE series are probably most useful when the data can
    be approximated by ``sqrt(w(x)) * p(x)``, where `w(x)` is the HermiteE
    weight. In that case the weight ``sqrt(w(x[i])`` should be used
    together with data values ``y[i]/sqrt(w(x[i])``. The weight function is
    available as `hermeweight`.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermefik, hermeval
    >>> x = np.linspace(-10, 10)
    >>> err = np.random.randn(len(x))/10
    >>> y = hermeval(x, [1, 2, 3]) + err
    >>> hermefit(x, y, 2)
    array([ 1.01690445,  1.99951418,  2.99948696])

    
    Differentiate a Hermite_e series.

    Returns the series coefficients `c` differentiated `m` times along
    `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable). The argument
    `c` is an array of coefficients from low to high degree along each
    axis, e.g., [1,2,3] represents the series ``1*He_0 + 2*He_1 + 3*He_2``
    while [[1,2],[1,2]] represents ``1*He_0(x)*He_0(y) + 1*He_1(x)*He_0(y)
    + 2*He_0(x)*He_1(y) + 2*He_1(x)*He_1(y)`` if axis=0 is ``x`` and axis=1
    is ``y``.

    Parameters
    ----------
    c : array_like
        Array of Hermite_e series coefficients. If `c` is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change of
        variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Hermite series of the derivative.

    See Also
    --------
    hermeint

    Notes
    -----
    In general, the result of differentiating a Hermite series does not
    resemble the same operation on a power series. Thus the result of this
    function may be "unintuitive," albeit correct; see Examples section
    below.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeder
    >>> hermeder([ 1.,  1.,  1.,  1.])
    array([ 1.,  2.,  3.])
    >>> hermeder([-0.25,  1.,  1./2.,  1./3.,  1./4 ], m=2)
    array([ 1.,  2.,  3.])

    
    Evaluate a 2-D HermiteE series at points (x, y).

    This function returns the values:

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * He_i(x) * He_j(y)

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` is a 1-D array a one is implicitly appended to its shape to make
    it 2-D. The shape of the result will be c.shape[2:] + x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and if it isn't an ndarray it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in ``c[i,j]``. If `c` has
        dimension greater than two the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points formed with
        pairs of corresponding values from `x` and `y`.

    See Also
    --------
    hermeval, hermegrid2d, hermeval3d, hermegrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 2-D HermiteE series on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * H_i(a) * H_j(b)

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    hermeval, hermeval2d, hermeval3d, hermegrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Generate a HermiteE series with given roots.

    The function returns the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    in HermiteE form, where the `r_n` are the roots specified in `roots`.
    If a zero has multiplicity n, then it must appear in `roots` n times.
    For instance, if 2 is a root of multiplicity three and 3 is a root of
    multiplicity 2, then `roots` looks something like [2, 2, 2, 3, 3]. The
    roots can appear in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * He_1(x) + ... +  c_n * He_n(x)

    The coefficient of the last term is not generally 1 for monic
    polynomials in HermiteE form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of coefficients.  If all roots are real then `out` is a
        real array, if some of the roots are complex, then `out` is complex
        even if all the coefficients in the result are real (see Examples
        below).

    See Also
    --------
    polyfromroots, legfromroots, lagfromroots, hermfromroots,
    chebfromroots.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermefromroots, hermeval
    >>> coef = hermefromroots((-1, 0, 1))
    >>> hermeval((-1, 0, 1), coef)
    array([ 0.,  0.,  0.])
    >>> coef = hermefromroots((-1j, 1j))
    >>> hermeval((-1j, 1j), coef)
    array([ 0.+0.j,  0.+0.j])

    
    Compute the roots of a HermiteE series.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * He_i(x).

    Parameters
    ----------
    c : 1-D array_like
        1-D array of coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the series. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    polyroots, legroots, lagroots, hermroots, chebroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    The HermiteE series basis polynomials aren't powers of `x` so the
    results of this function may seem unintuitive.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeroots, hermefromroots
    >>> coef = hermefromroots([-1, 0, 1])
    >>> coef
    array([ 0.,  2.,  0.,  1.])
    >>> hermeroots(coef)
    array([-1.,  0.,  1.])

    
    Multiply one Hermite series by another.

    Returns the product of two Hermite series `c1` * `c2`.  The arguments
    are sequences of coefficients, from lowest order "term" to highest,
    e.g., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Hermite series coefficients representing their product.

    See Also
    --------
    hermeadd, hermesub, hermediv, hermepow

    Notes
    -----
    In general, the (polynomial) product of two C-series results in terms
    that are not in the Hermite polynomial basis set.  Thus, to express
    the product as a Hermite series, it is necessary to "reproject" the
    product onto said basis set, which may produce "unintuitive" (but
    correct) results; see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermemul
    >>> hermemul([1, 2, 3], [0, 1, 2])
    array([ 14.,  15.,  28.,   7.,   6.])

    
    Evaluate a 3-D Hermite_e series at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * He_i(x) * He_j(y) * He_k(z)

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimensional polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    hermeval, hermeval2d, hermegrid2d, hermegrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Add one Hermite series to another.

    Returns the sum of two Hermite series `c1` + `c2`.  The arguments
    are sequences of coefficients ordered from lowest order term to
    highest, i.e., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the Hermite series of their sum.

    See Also
    --------
    hermesub, hermemul, hermediv, hermepow

    Notes
    -----
    Unlike multiplication, division, etc., the sum of two Hermite series
    is a Hermite series (without having to "reproject" the result onto
    the basis set) so addition, just like that of "standard" polynomials,
    is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeadd
    >>> hermeadd([1, 2, 3], [1, 2, 3, 4])
    array([ 2.,  4.,  6.,  4.])

    
    Divide one Hermite series by another.

    Returns the quotient-with-remainder of two Hermite series
    `c1` / `c2`.  The arguments are sequences of coefficients from lowest
    order "term" to highest, e.g., [1,2,3] represents the series
    ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    [quo, rem] : ndarrays
        Of Hermite series coefficients representing the quotient and
        remainder.

    See Also
    --------
    hermeadd, hermesub, hermemul, hermepow

    Notes
    -----
    In general, the (polynomial) division of one Hermite series by another
    results in quotient and remainder terms that are not in the Hermite
    polynomial basis set.  Thus, to express these results as a Hermite
    series, it is necessary to "reproject" the results onto the Hermite
    basis set, which may produce "unintuitive" (but correct) results; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermediv
    >>> hermediv([ 14.,  15.,  28.,   7.,   6.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 0.]))
    >>> hermediv([ 15.,  17.,  28.,   7.,   6.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 1.,  2.]))

    Weight function of the Hermite_e polynomials.

    The weight function is :math:`\exp(-x^2/2)` and the interval of
    integration is :math:`[-\inf, \inf]`. the HermiteE polynomials are
    orthogonal, but not normalized, with respect to this weight function.

    Parameters
    ----------
    x : array_like
       Values at which the weight function will be computed.

    Returns
    -------
    w : ndarray
       The weight function at `x`.

    Notes
    -----

    .. versionadded::1.7.0

    Pseudo-Vandermonde matrix of given degree.

    Returns the pseudo-Vandermonde matrix of degree `deg` and sample points
    `x`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., i] = He_i(x),

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the degree of the HermiteE polynomial.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    array ``V = hermevander(x, n)``, then ``np.dot(V, c)`` and
    ``hermeval(x, c)`` are the same up to roundoff. This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of HermiteE series of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray
        The pseudo-Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where The last index is the degree of the
        corresponding HermiteE polynomial.  The dtype will be the same as
        the converted `x`.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermevander
    >>> x = np.array([-1, 0, 1])
    >>> hermevander(x, 3)
    array([[ 1., -1.,  0.,  2.],
           [ 1.,  0., -1., -0.],
           [ 1.,  1.,  0., -2.]])

    
    poly2herme(pol)

    Convert a polynomial to a Hermite series.

    Convert an array representing the coefficients of a polynomial (relative
    to the "standard" basis) ordered from lowest degree to highest, to an
    array of the coefficients of the equivalent Hermite series, ordered
    from lowest to highest degree.

    Parameters
    ----------
    pol : array_like
        1-D array containing the polynomial coefficients

    Returns
    -------
    c : ndarray
        1-D array containing the coefficients of the equivalent Hermite
        series.

    See Also
    --------
    herme2poly

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import poly2herme
    >>> poly2herme(np.arange(4))
    array([  2.,  10.,   2.,   3.])

    
    Evaluate an HermiteE series at points x.

    If `c` is of length `n + 1`, this function returns the value:

    .. math:: p(x) = c_0 * He_0(x) + c_1 * He_1(x) + ... + c_n * He_n(x)

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, algebra_like
        The shape of the return value is described above.

    See Also
    --------
    hermeval2d, hermegrid2d, hermeval3d, hermegrid3d

    Notes
    -----
    The evaluation uses Clenshaw recursion, aka synthetic division.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeval
    >>> coef = [1,2,3]
    >>> hermeval(1, coef)
    3.0
    >>> hermeval([[1,2],[3,4]], coef)
    array([[  3.,  14.],
           [ 31.,  54.]])

    
    Convert a Hermite series to a polynomial.

    Convert an array representing the coefficients of a Hermite series,
    ordered from lowest degree to highest, to an array of the coefficients
    of the equivalent polynomial (relative to the "standard" basis) ordered
    from lowest to highest degree.

    Parameters
    ----------
    c : array_like
        1-D array containing the Hermite series coefficients, ordered
        from lowest order term to highest.

    Returns
    -------
    pol : ndarray
        1-D array containing the coefficients of the equivalent polynomial
        (relative to the "standard" basis) ordered from lowest order term
        to highest.

    See Also
    --------
    poly2herme

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import herme2poly
    >>> herme2poly([  2.,  10.,   2.,   3.])
    array([ 0.,  1.,  2.,  3.])

    
    Return the scaled companion matrix of c.

    The basis polynomials are scaled so that the companion matrix is
    symmetric when `c` is an HermiteE basis polynomial. This provides
    better eigenvalue estimates than the unscaled case and for basis
    polynomials the eigenvalues are guaranteed to be real if
    `numpy.linalg.eigvalsh` is used to obtain them.

    Parameters
    ----------
    c : array_like
        1-D array of HermiteE series coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Scaled companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 3-D HermiteE series on the Cartesian product of x, y, and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * He_i(a) * He_j(b) * He_k(c)

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    hermeval, hermeval2d, hermegrid2d, hermeval3d

    Notes
    -----

    .. versionadded::1.7.0

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = He_i(x) * He_j(y),

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the degrees of
    the HermiteE polynomials.

    If ``V = hermevander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``hermeval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D HermiteE
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to
        1-D arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    hermevander, hermevander3d. hermeval2d, hermeval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Gauss-HermiteE quadrature.

    Computes the sample points and weights for Gauss-HermiteE quadrature.
    These sample points and weights will correctly integrate polynomials of
    degree :math:`2*deg - 1` or less over the interval :math:`[-\inf, \inf]`
    with the weight function :math:`f(x) = \exp(-x^2/2)`.

    Parameters
    ----------
    deg : int
        Number of sample points and weights. It must be >= 1.

    Returns
    -------
    x : ndarray
        1-D ndarray containing the sample points.
    y : ndarray
        1-D ndarray containing the weights.

    Notes
    -----

    .. versionadded::1.7.0

    The results have only been tested up to degree 100, higher degrees may
    be problematic. The weights are determined by using the fact that

    .. math:: w_k = c / (He'_n(x_k) * He_{n-1}(x_k))

    where :math:`c` is a constant independent of :math:`k` and :math:`x_k`
    is the k'th root of :math:`He_n`, and then scaling the results to get
    the right value when integrating 1.

    Raise a Hermite series to a power.

    Returns the Hermite series `c` raised to the power `pow`. The
    argument `c` is a sequence of coefficients ordered from low to high.
    i.e., [1,2,3] is the series  ``P_0 + 2*P_1 + 3*P_2.``

    Parameters
    ----------
    c : array_like
        1-D array of Hermite series coefficients ordered from low to
        high.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Hermite series of power.

    See Also
    --------
    hermeadd, hermesub, hermemul, hermediv

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermepow
    >>> hermepow([1, 2, 3], 2)
    array([ 23.,  28.,  46.,  12.,   9.])

    Multiply a Hermite series by x.

    Multiply the Hermite series `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----
    The multiplication uses the recursion relationship for Hermite
    polynomials in the form

    .. math::

    xP_i(x) = (P_{i + 1}(x) + iP_{i - 1}(x)))

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermemulx
    >>> hermemulx([1, 2, 3])
    array([ 2.,  7.,  2.,  3.])

    
    Hermite series whose graph is a straight line.



    Parameters
    ----------
    off, scl : scalars
        The specified line is given by ``off + scl*x``.

    Returns
    -------
    y : ndarray
        This module's representation of the Hermite series for
        ``off + scl*x``.

    See Also
    --------
    polyline, chebline

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeline
    >>> from numpy.polynomial.hermite_e import hermeline, hermeval
    >>> hermeval(0,hermeline(3, 2))
    3.0
    >>> hermeval(1,hermeline(3, 2))
    5.0

    
    Subtract one Hermite series from another.

    Returns the difference of two Hermite series `c1` - `c2`.  The
    sequences of coefficients are from lowest order term to highest, i.e.,
    [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Hermite series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Hermite series coefficients representing their difference.

    See Also
    --------
    hermeadd, hermemul, hermediv, hermepow

    Notes
    -----
    Unlike multiplication, division, etc., the difference of two Hermite
    series is a Hermite series (without having to "reproject" the result
    onto the basis set) so subtraction, just like that of "standard"
    polynomials, is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermesub
    >>> hermesub([1, 2, 3, 4], [1, 2, 3])
    array([ 0.,  0.,  0.,  4.])

    /usr/lib/python2.7/dist-packages/numpy/polynomial/hermite_e.py
    Integrate a Hermite_e series.

    Returns the Hermite_e series coefficients `c` integrated `m` times from
    `lbnd` along `axis`. At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.)  The argument `c` is an array of
    coefficients from low to high degree along each axis, e.g., [1,2,3]
    represents the series ``H_0 + 2*H_1 + 3*H_2`` while [[1,2],[1,2]]
    represents ``1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) +
    2*H_1(x)*H_1(y)`` if axis=0 is ``x`` and axis=1 is ``y``.

    Parameters
    ----------
    c : array_like
        Array of Hermite_e series coefficients. If c is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at
        ``lbnd`` is the first value in the list, the value of the second
        integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the
        default), all constants are set to zero.  If ``m == 1``, a single
        scalar can be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        Hermite_e series coefficients of the integral.

    Raises
    ------
    ValueError
        If ``m < 0``, ``len(k) > m``, ``np.isscalar(lbnd) == False``, or
        ``np.isscalar(scl) == False``.

    See Also
    --------
    hermeder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.
    Why is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`.  Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a` - perhaps not what one would have first thought.

    Also note that, in general, the result of integrating a C-series needs
    to be "reprojected" onto the C-series basis set.  Thus, typically,
    the result of this function is "unintuitive," albeit correct; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.hermite_e import hermeint
    >>> hermeint([1, 2, 3]) # integrate once, value 0 at 0.
    array([ 1.,  1.,  1.,  1.])
    >>> hermeint([1, 2, 3], m=2) # integrate twice, value & deriv 0 at 0
    array([-0.25      ,  1.        ,  0.5       ,  0.33333333,  0.25      ])
    >>> hermeint([1, 2, 3], k=1) # integrate once, value 1 at 0.
    array([ 2.,  1.,  1.,  1.])
    >>> hermeint([1, 2, 3], lbnd=-1) # integrate once, value 0 at -1
    array([-1.,  1.,  1.,  1.])
    >>> hermeint([1, 2, 3], m=2, k=[1, 2], lbnd=-1)
    array([ 1.83333333,  0.        ,  0.5       ,  0.33333333,  0.25      ])

    
Objects for dealing with Hermite_e series.

This module provides a number of objects (mostly functions) useful for
dealing with Hermite_e series, including a `HermiteE` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with such polynomials is in the
docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------
- `hermedomain` -- Hermite_e series default domain, [-1,1].
- `hermezero` -- Hermite_e series that evaluates identically to 0.
- `hermeone` -- Hermite_e series that evaluates identically to 1.
- `hermex` -- Hermite_e series for the identity map, ``f(x) = x``.

Arithmetic
----------
- `hermemulx` -- multiply a Hermite_e series in ``P_i(x)`` by ``x``.
- `hermeadd` -- add two Hermite_e series.
- `hermesub` -- subtract one Hermite_e series from another.
- `hermemul` -- multiply two Hermite_e series.
- `hermediv` -- divide one Hermite_e series by another.
- `hermeval` -- evaluate a Hermite_e series at given points.
- `hermeval2d` -- evaluate a 2D Hermite_e series at given points.
- `hermeval3d` -- evaluate a 3D Hermite_e series at given points.
- `hermegrid2d` -- evaluate a 2D Hermite_e series on a Cartesian product.
- `hermegrid3d` -- evaluate a 3D Hermite_e series on a Cartesian product.

Calculus
--------
- `hermeder` -- differentiate a Hermite_e series.
- `hermeint` -- integrate a Hermite_e series.

Misc Functions
--------------
- `hermefromroots` -- create a Hermite_e series with specified roots.
- `hermeroots` -- find the roots of a Hermite_e series.
- `hermevander` -- Vandermonde-like matrix for Hermite_e polynomials.
- `hermevander2d` -- Vandermonde-like matrix for 2D power series.
- `hermevander3d` -- Vandermonde-like matrix for 3D power series.
- `hermegauss` -- Gauss-Hermite_e quadrature, points and weights.
- `hermeweight` -- Hermite_e weight function.
- `hermecompanion` -- symmetrized companion matrix in Hermite_e form.
- `hermefit` -- least-squares fit returning a Hermite_e series.
- `hermetrim` -- trim leading coefficients from a Hermite_e series.
- `hermeline` -- Hermite_e series of given straight line.
- `herme2poly` -- convert a Hermite_e series to a polynomial.
- `poly2herme` -- convert a polynomial to a Hermite_e series.

Classes
-------
- `HermiteE` -- A Hermite_e series class.

See also
--------
`numpy.polynomial`

Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then Hehe pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = He_i(x)*He_j(y)*He_k(z),

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the degrees of the HermiteE polynomials.

    If ``V = hermevander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and  ``np.dot(V, c.flat)`` and ``hermeval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D HermiteE
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    hermevander, hermevander3d. hermeval2d, hermeval3d

    Notes
    -----

    .. versionadded::1.7.0

    lagxlagdivlagintlagonelagpowlagtrimlagzerolag2polylaggausslagval2dlagval3dpoly2laglagdomainlaggrid2dlaggrid3dlagweightlagvander2dlagvander3d[   s   lagzeros   lagones   lagxs	   lagdomains   laglines   lagadds   lagsubs   lagmulxs   lagmuls   lagdivs   lagpows   lagvals   lagders   lagints   lag2polys   poly2lags   lagfromrootss	   lagvanders   lagfits   lagtrims   lagrootss   Laguerres   lagval2ds   lagval3ds	   laggrid2ds	   laggrid3ds   lagvander2ds   lagvander3ds   lagcompanions   laggausss	   lagweight
    Gauss-Laguerre quadrature.

    Computes the sample points and weights for Gauss-Laguerre quadrature.
    These sample points and weights will correctly integrate polynomials of
    degree :math:`2*deg - 1` or less over the interval :math:`[0, \inf]` with the
    weight function :math:`f(x) = \exp(-x)`.

    Parameters
    ----------
    deg : int
        Number of sample points and weights. It must be >= 1.

    Returns
    -------
    x : ndarray
        1-D ndarray containing the sample points.
    y : ndarray
        1-D ndarray containing the weights.

    Notes
    -----

    .. versionadded::1.7.0

    The results have only been tested up to degree 100 higher degrees may
    be problematic. The weights are determined by using the fact that

    .. math:: w_k = c / (L'_n(x_k) * L_{n-1}(x_k))

    where :math:`c` is a constant independent of :math:`k` and :math:`x_k`
    is the k'th root of :math:`L_n`, and then scaling the results to get
    the right value when integrating 1.

    Weight function of the Laguerre polynomials.

    The weight function is :math:`exp(-x)` and the interval of integration
    is :math:`[0, \inf]`. The Laguerre polynomials are orthogonal, but not
    normalized, with respect to this weight function.

    Parameters
    ----------
    x : array_like
       Values at which the weight function will be computed.

    Returns
    -------
    w : ndarray
       The weight function at `x`.

    Notes
    -----

    .. versionadded::1.7.0

    numpy.polynomial.laguerre
    Convert a Laguerre series to a polynomial.

    Convert an array representing the coefficients of a Laguerre series,
    ordered from lowest degree to highest, to an array of the coefficients
    of the equivalent polynomial (relative to the "standard" basis) ordered
    from lowest to highest degree.

    Parameters
    ----------
    c : array_like
        1-D array containing the Laguerre series coefficients, ordered
        from lowest order term to highest.

    Returns
    -------
    pol : ndarray
        1-D array containing the coefficients of the equivalent polynomial
        (relative to the "standard" basis) ordered from lowest order term
        to highest.

    See Also
    --------
    poly2lag

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lag2poly
    >>> lag2poly([ 23., -63.,  58., -18.])
    array([ 0.,  1.,  2.,  3.])

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = L_i(x)*L_j(y)*L_k(z),

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the degrees of the Laguerre polynomials.

    If ``V = lagvander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and  ``np.dot(V, c.flat)`` and ``lagval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D Laguerre
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    lagvander, lagvander3d. lagval2d, lagval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Laguerre series whose graph is a straight line.



    Parameters
    ----------
    off, scl : scalars
        The specified line is given by ``off + scl*x``.

    Returns
    -------
    y : ndarray
        This module's representation of the Laguerre series for
        ``off + scl*x``.

    See Also
    --------
    polyline, chebline

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagline, lagval
    >>> lagval(0,lagline(3, 2))
    3.0
    >>> lagval(1,lagline(3, 2))
    5.0

    
    poly2lag(pol)

    Convert a polynomial to a Laguerre series.

    Convert an array representing the coefficients of a polynomial (relative
    to the "standard" basis) ordered from lowest degree to highest, to an
    array of the coefficients of the equivalent Laguerre series, ordered
    from lowest to highest degree.

    Parameters
    ----------
    pol : array_like
        1-D array containing the polynomial coefficients

    Returns
    -------
    c : ndarray
        1-D array containing the coefficients of the equivalent Laguerre
        series.

    See Also
    --------
    lag2poly

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import poly2lag
    >>> poly2lag(np.arange(4))
    array([ 23., -63.,  58., -18.])

    
    Evaluate a Laguerre series at points x.

    If `c` is of length `n + 1`, this function returns the value:

    .. math:: p(x) = c_0 * L_0(x) + c_1 * L_1(x) + ... + c_n * L_n(x)

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, algebra_like
        The shape of the return value is described above.

    See Also
    --------
    lagval2d, laggrid2d, lagval3d, laggrid3d

    Notes
    -----
    The evaluation uses Clenshaw recursion, aka synthetic division.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagval
    >>> coef = [1,2,3]
    >>> lagval(1, coef)
    -0.5
    >>> lagval([[1,2],[3,4]], coef)
    array([[-0.5, -4. ],
           [-4.5, -2. ]])

    
    Compute the roots of a Laguerre series.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * L_i(x).

    Parameters
    ----------
    c : 1-D array_like
        1-D array of coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the series. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    polyroots, legroots, chebroots, hermroots, hermeroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    The Laguerre series basis polynomials aren't powers of `x` so the
    results of this function may seem unintuitive.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagroots, lagfromroots
    >>> coef = lagfromroots([0, 1, 2])
    >>> coef
    array([  2.,  -8.,  12.,  -6.])
    >>> lagroots(coef)
    array([ -4.44089210e-16,   1.00000000e+00,   2.00000000e+00])

    Pseudo-Vandermonde matrix of given degree.

    Returns the pseudo-Vandermonde matrix of degree `deg` and sample points
    `x`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., i] = L_i(x)

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the degree of the Laguerre polynomial.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    array ``V = lagvander(x, n)``, then ``np.dot(V, c)`` and
    ``lagval(x, c)`` are the same up to roundoff. This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of Laguerre series of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray
        The pseudo-Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where The last index is the degree of the
        corresponding Laguerre polynomial.  The dtype will be the same as
        the converted `x`.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagvander
    >>> x = np.array([0, 1, 2])
    >>> lagvander(x, 3)
    array([[ 1.        ,  1.        ,  1.        ,  1.        ],
           [ 1.        ,  0.        , -0.5       , -0.66666667],
           [ 1.        , -1.        , -1.        , -0.33333333]])

    
    Divide one Laguerre series by another.

    Returns the quotient-with-remainder of two Laguerre series
    `c1` / `c2`.  The arguments are sequences of coefficients from lowest
    order "term" to highest, e.g., [1,2,3] represents the series
    ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Laguerre series coefficients ordered from low to
        high.

    Returns
    -------
    [quo, rem] : ndarrays
        Of Laguerre series coefficients representing the quotient and
        remainder.

    See Also
    --------
    lagadd, lagsub, lagmul, lagpow

    Notes
    -----
    In general, the (polynomial) division of one Laguerre series by another
    results in quotient and remainder terms that are not in the Laguerre
    polynomial basis set.  Thus, to express these results as a Laguerre
    series, it is necessary to "reproject" the results onto the Laguerre
    basis set, which may produce "unintuitive" (but correct) results; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagdiv
    >>> lagdiv([  8., -13.,  38., -51.,  36.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 0.]))
    >>> lagdiv([  9., -12.,  38., -51.,  36.], [0, 1, 2])
    (array([ 1.,  2.,  3.]), array([ 1.,  1.]))

    
    Evaluate a 3-D Laguerre series at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) * L_k(z)

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimension polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    lagval, lagval2d, laggrid2d, laggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Integrate a Laguerre series.

    Returns the Laguerre series coefficients `c` integrated `m` times from
    `lbnd` along `axis`. At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.)  The argument `c` is an array of
    coefficients from low to high degree along each axis, e.g., [1,2,3]
    represents the series ``L_0 + 2*L_1 + 3*L_2`` while [[1,2],[1,2]]
    represents ``1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) +
    2*L_1(x)*L_1(y)`` if axis=0 is ``x`` and axis=1 is ``y``.


    Parameters
    ----------
    c : array_like
        Array of Laguerre series coefficients. If `c` is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at
        ``lbnd`` is the first value in the list, the value of the second
        integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the
        default), all constants are set to zero.  If ``m == 1``, a single
        scalar can be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        Laguerre series coefficients of the integral.

    Raises
    ------
    ValueError
        If ``m < 0``, ``len(k) > m``, ``np.isscalar(lbnd) == False``, or
        ``np.isscalar(scl) == False``.

    See Also
    --------
    lagder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.
    Why is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`.  Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a` - perhaps not what one would have first thought.

    Also note that, in general, the result of integrating a C-series needs
    to be "reprojected" onto the C-series basis set.  Thus, typically,
    the result of this function is "unintuitive," albeit correct; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagint
    >>> lagint([1,2,3])
    array([ 1.,  1.,  1., -3.])
    >>> lagint([1,2,3], m=2)
    array([ 1.,  0.,  0., -4.,  3.])
    >>> lagint([1,2,3], k=1)
    array([ 2.,  1.,  1., -3.])
    >>> lagint([1,2,3], lbnd=-1)
    array([ 11.5,   1. ,   1. ,  -3. ])
    >>> lagint([1,2], m=2, k=[1,2], lbnd=-1)
    array([ 11.16666667,  -5.        ,  -3.        ,   2.        ])

    
Objects for dealing with Laguerre series.

This module provides a number of objects (mostly functions) useful for
dealing with Laguerre series, including a `Laguerre` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with such polynomials is in the
docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------
- `lagdomain` -- Laguerre series default domain, [-1,1].
- `lagzero` -- Laguerre series that evaluates identically to 0.
- `lagone` -- Laguerre series that evaluates identically to 1.
- `lagx` -- Laguerre series for the identity map, ``f(x) = x``.

Arithmetic
----------
- `lagmulx` -- multiply a Laguerre series in ``P_i(x)`` by ``x``.
- `lagadd` -- add two Laguerre series.
- `lagsub` -- subtract one Laguerre series from another.
- `lagmul` -- multiply two Laguerre series.
- `lagdiv` -- divide one Laguerre series by another.
- `lagval` -- evaluate a Laguerre series at given points.
- `lagval2d` -- evaluate a 2D Laguerre series at given points.
- `lagval3d` -- evaluate a 3D Laguerre series at given points.
- `laggrid2d` -- evaluate a 2D Laguerre series on a Cartesian product.
- `laggrid3d` -- evaluate a 3D Laguerre series on a Cartesian product.

Calculus
--------
- `lagder` -- differentiate a Laguerre series.
- `lagint` -- integrate a Laguerre series.

Misc Functions
--------------
- `lagfromroots` -- create a Laguerre series with specified roots.
- `lagroots` -- find the roots of a Laguerre series.
- `lagvander` -- Vandermonde-like matrix for Laguerre polynomials.
- `lagvander2d` -- Vandermonde-like matrix for 2D power series.
- `lagvander3d` -- Vandermonde-like matrix for 3D power series.
- `laggauss` -- Gauss-Laguerre quadrature, points and weights.
- `lagweight` -- Laguerre weight function.
- `lagcompanion` -- symmetrized companion matrix in Laguerre form.
- `lagfit` -- least-squares fit returning a Laguerre series.
- `lagtrim` -- trim leading coefficients from a Laguerre series.
- `lagline` -- Laguerre series of given straight line.
- `lag2poly` -- convert a Laguerre series to a polynomial.
- `poly2lag` -- convert a polynomial to a Laguerre series.

Classes
-------
- `Laguerre` -- A Laguerre series class.

See also
--------
`numpy.polynomial`


    Differentiate a Laguerre series.

    Returns the Laguerre series coefficients `c` differentiated `m` times
    along `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable). The argument
    `c` is an array of coefficients from low to high degree along each
    axis, e.g., [1,2,3] represents the series ``1*L_0 + 2*L_1 + 3*L_2``
    while [[1,2],[1,2]] represents ``1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) +
    2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)`` if axis=0 is ``x`` and axis=1 is
    ``y``.

    Parameters
    ----------
    c : array_like
        Array of Laguerre series coefficients. If `c` is multidimensional
        the different axis correspond to different variables with the
        degree in each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change of
        variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Laguerre series of the derivative.

    See Also
    --------
    lagint

    Notes
    -----
    In general, the result of differentiating a Laguerre series does not
    resemble the same operation on a power series. Thus the result of this
    function may be "unintuitive," albeit correct; see Examples section
    below.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagder
    >>> lagder([ 1.,  1.,  1., -3.])
    array([ 1.,  2.,  3.])
    >>> lagder([ 1.,  0.,  0., -4.,  3.], m=2)
    array([ 1.,  2.,  3.])

    
    Evaluate a 2-D Laguerre series at points (x, y).

    This function returns the values:

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * L_i(x) * L_j(y)

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` is a 1-D array a one is implicitly appended to its shape to make
    it 2-D. The shape of the result will be c.shape[2:] + x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and if it isn't an ndarray it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in ``c[i,j]``. If `c` has
        dimension greater than two the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points formed with
        pairs of corresponding values from `x` and `y`.

    See Also
    --------
    lagval, laggrid2d, lagval3d, laggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Multiply one Laguerre series by another.

    Returns the product of two Laguerre series `c1` * `c2`.  The arguments
    are sequences of coefficients, from lowest order "term" to highest,
    e.g., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Laguerre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Laguerre series coefficients representing their product.

    See Also
    --------
    lagadd, lagsub, lagdiv, lagpow

    Notes
    -----
    In general, the (polynomial) product of two C-series results in terms
    that are not in the Laguerre polynomial basis set.  Thus, to express
    the product as a Laguerre series, it is necessary to "reproject" the
    product onto said basis set, which may produce "unintuitive" (but
    correct) results; see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagmul
    >>> lagmul([1, 2, 3], [0, 1, 2])
    array([  8., -13.,  38., -51.,  36.])

    Multiply a Laguerre series by x.

    Multiply the Laguerre series `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of Laguerre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----
    The multiplication uses the recursion relationship for Laguerre
    polynomials in the form

    .. math::

    xP_i(x) = (-(i + 1)*P_{i + 1}(x) + (2i + 1)P_{i}(x) - iP_{i - 1}(x))

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagmulx
    >>> lagmulx([1, 2, 3])
    array([ -1.,  -1.,  11.,  -9.])

    
    Return the companion matrix of c.

    The usual companion matrix of the Laguerre polynomials is already
    symmetric when `c` is a basis Laguerre polynomial, so no scaling is
    applied.

    Parameters
    ----------
    c : array_like
        1-D array of Laguerre series coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded::1.7.0

    
    Least squares fit of Laguerre series to data.

    Return the coefficients of a Laguerre series of degree `deg` that is the
    least squares fit to the data values `y` given at points `x`. If `y` is
    1-D the returned coefficients will also be 1-D. If `y` is 2-D multiple
    fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x),

    where `n` is `deg`.

    Since numpy version 1.7.0, lagfit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting polynomial
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than
        this relative to the largest singular value will be ignored. The
        default value is len(x)*eps, where eps is the relative precision of
        the float type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is False (the
        default) just the coefficients are returned, when True diagnostic
        information from the singular value decomposition is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

    Returns
    -------
    coef : ndarray, shape (M,) or (M, K)
        Laguerre coefficients ordered from low to high. If `y` was 2-D,
        the coefficients for the data in column k  of `y` are in column
        `k`.

    [residuals, rank, singular_values, rcond] : present when `full` = True
        Residuals of the least-squares fit, the effective rank of the
        scaled Vandermonde matrix and its singular values, and the
        specified value of `rcond`. For more details, see `linalg.lstsq`.

    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.  The
        warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    chebfit, legfit, polyfit, hermfit, hermefit
    lagval : Evaluates a Laguerre series.
    lagvander : pseudo Vandermonde matrix of Laguerre series.
    lagweight : Laguerre weight function.
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the Laguerre series `p` that
    minimizes the sum of the weighted squared errors

    .. math:: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where the :math:`w_j` are the weights. This problem is solved by
    setting up as the (typically) overdetermined matrix equation

    .. math:: V(x) * c = w * y,

    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the
    coefficients to be solved for, `w` are the weights, and `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected, then a `RankWarning` will be issued. This means that the
    coefficient values may be poorly determined. Using a lower order fit
    will usually get rid of the warning.  The `rcond` parameter can also be
    set to a value smaller than its default, but the resulting fit may be
    spurious and have large contributions from roundoff error.

    Fits using Laguerre series are probably most useful when the data can
    be approximated by ``sqrt(w(x)) * p(x)``, where `w(x)` is the Laguerre
    weight. In that case the weight ``sqrt(w(x[i])`` should be used
    together with data values ``y[i]/sqrt(w(x[i])``. The weight function is
    available as `lagweight`.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagfit, lagval
    >>> x = np.linspace(0, 10)
    >>> err = np.random.randn(len(x))/10
    >>> y = lagval(x, [1, 2, 3]) + err
    >>> lagfit(x, y, 2)
    array([ 0.96971004,  2.00193749,  3.00288744])

    
    Subtract one Laguerre series from another.

    Returns the difference of two Laguerre series `c1` - `c2`.  The
    sequences of coefficients are from lowest order term to highest, i.e.,
    [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Laguerre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Laguerre series coefficients representing their difference.

    See Also
    --------
    lagadd, lagmul, lagdiv, lagpow

    Notes
    -----
    Unlike multiplication, division, etc., the difference of two Laguerre
    series is a Laguerre series (without having to "reproject" the result
    onto the basis set) so subtraction, just like that of "standard"
    polynomials, is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagsub
    >>> lagsub([1, 2, 3, 4], [1, 2, 3])
    array([ 0.,  0.,  0.,  4.])

    
    Generate a Laguerre series with given roots.

    The function returns the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    in Laguerre form, where the `r_n` are the roots specified in `roots`.
    If a zero has multiplicity n, then it must appear in `roots` n times.
    For instance, if 2 is a root of multiplicity three and 3 is a root of
    multiplicity 2, then `roots` looks something like [2, 2, 2, 3, 3]. The
    roots can appear in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * L_1(x) + ... +  c_n * L_n(x)

    The coefficient of the last term is not generally 1 for monic
    polynomials in Laguerre form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of coefficients.  If all roots are real then `out` is a
        real array, if some of the roots are complex, then `out` is complex
        even if all the coefficients in the result are real (see Examples
        below).

    See Also
    --------
    polyfromroots, legfromroots, chebfromroots, hermfromroots,
    hermefromroots.

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagfromroots, lagval
    >>> coef = lagfromroots((-1, 0, 1))
    >>> lagval((-1, 0, 1), coef)
    array([ 0.,  0.,  0.])
    >>> coef = lagfromroots((-1j, 1j))
    >>> lagval((-1j, 1j), coef)
    array([ 0.+0.j,  0.+0.j])

    Raise a Laguerre series to a power.

    Returns the Laguerre series `c` raised to the power `pow`. The
    argument `c` is a sequence of coefficients ordered from low to high.
    i.e., [1,2,3] is the series  ``P_0 + 2*P_1 + 3*P_2.``

    Parameters
    ----------
    c : array_like
        1-D array of Laguerre series coefficients ordered from low to
        high.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Laguerre series of power.

    See Also
    --------
    lagadd, lagsub, lagmul, lagdiv

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagpow
    >>> lagpow([1, 2, 3], 2)
    array([ 14., -16.,  56., -72.,  54.])

    
    Add one Laguerre series to another.

    Returns the sum of two Laguerre series `c1` + `c2`.  The arguments
    are sequences of coefficients ordered from lowest order term to
    highest, i.e., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Laguerre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the Laguerre series of their sum.

    See Also
    --------
    lagsub, lagmul, lagdiv, lagpow

    Notes
    -----
    Unlike multiplication, division, etc., the sum of two Laguerre series
    is a Laguerre series (without having to "reproject" the result onto
    the basis set) so addition, just like that of "standard" polynomials,
    is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial.laguerre import lagadd
    >>> lagadd([1, 2, 3], [1, 2, 3, 4])
    array([ 2.,  4.,  6.,  4.])


    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = L_i(x) * L_j(y),

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the degrees of
    the Laguerre polynomials.

    If ``V = lagvander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``lagval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D Laguerre
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to
        1-D arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    lagvander, lagvander3d. lagval2d, lagval3d

    Notes
    -----

    .. versionadded::1.7.0

    /usr/lib/python2.7/dist-packages/numpy/polynomial/laguerre.py
    Evaluate a 3-D Laguerre series on the Cartesian product of x, y, and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * L_i(a) * L_j(b) * L_k(c)

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    lagval, lagval2d, laggrid2d, lagval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 2-D Laguerre series on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * L_i(a) * L_j(b)

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape + y.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j is contained in `c[i,j]`. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional Chebyshev series at points in the
        Cartesian product of `x` and `y`.

    See Also
    --------
    lagval, lagval2d, lagval3d, laggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    legxlegdivlegintlegonelegpowlegtrimlegzeroleg2polyleggausslegval2dlegval3dpoly2leglegdomainleggrid2dleggrid3dlegweightlegvander2dlegvander3d[   s   legzeros   legones   legxs	   legdomains   leglines   legadds   legsubs   legmulxs   legmuls   legdivs   legpows   legvals   legders   legints   leg2polys   poly2legs   legfromrootss	   legvanders   legfits   legtrims   legrootss   Legendres   legval2ds   legval3ds	   leggrid2ds	   leggrid3ds   legvander2ds   legvander3ds   legcompanions   leggausss	   legweight
    Evaluate a 2-D Legendre series at points (x, y).

    This function returns the values:

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * L_i(x) * L_j(y)

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` is a 1-D array a one is implicitly appended to its shape to make
    it 2-D. The shape of the result will be c.shape[2:] + x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and if it isn't an ndarray it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in ``c[i,j]``. If `c` has
        dimension greater than two the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional Legendre series at points formed
        from pairs of corresponding values from `x` and `y`.

    See Also
    --------
    legval, leggrid2d, legval3d, leggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 3-D Legendre series on the Cartesian product of x, y, and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * L_i(a) * L_j(b) * L_k(c)

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    legval, legval2d, leggrid2d, legval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Legendre series whose graph is a straight line.



    Parameters
    ----------
    off, scl : scalars
        The specified line is given by ``off + scl*x``.

    Returns
    -------
    y : ndarray
        This module's representation of the Legendre series for
        ``off + scl*x``.

    See Also
    --------
    polyline, chebline

    Examples
    --------
    >>> import numpy.polynomial.legendre as L
    >>> L.legline(3,2)
    array([3, 2])
    >>> L.legval(-3, L.legline(3,2)) # should be -3
    -3.0

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = L_i(x) * L_j(y),

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the degrees of
    the Legendre polynomials.

    If ``V = legvander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``legval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D Legendre
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to
        1-D arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    legvander, legvander3d. legval2d, legval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Subtract one Legendre series from another.

    Returns the difference of two Legendre series `c1` - `c2`.  The
    sequences of coefficients are from lowest order term to highest, i.e.,
    [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Legendre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Legendre series coefficients representing their difference.

    See Also
    --------
    legadd, legmul, legdiv, legpow

    Notes
    -----
    Unlike multiplication, division, etc., the difference of two Legendre
    series is a Legendre series (without having to "reproject" the result
    onto the basis set) so subtraction, just like that of "standard"
    polynomials, is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> L.legsub(c1,c2)
    array([-2.,  0.,  2.])
    >>> L.legsub(c2,c1) # -C.legsub(c1,c2)
    array([ 2.,  0., -2.])

    
    Convert a Legendre series to a polynomial.

    Convert an array representing the coefficients of a Legendre series,
    ordered from lowest degree to highest, to an array of the coefficients
    of the equivalent polynomial (relative to the "standard" basis) ordered
    from lowest to highest degree.

    Parameters
    ----------
    c : array_like
        1-D array containing the Legendre series coefficients, ordered
        from lowest order term to highest.

    Returns
    -------
    pol : ndarray
        1-D array containing the coefficients of the equivalent polynomial
        (relative to the "standard" basis) ordered from lowest order term
        to highest.

    See Also
    --------
    poly2leg

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> c = P.Legendre(range(4))
    >>> c
    Legendre([ 0.,  1.,  2.,  3.], [-1.,  1.])
    >>> p = c.convert(kind=P.Polynomial)
    >>> p
    Polynomial([-1. , -3.5,  3. ,  7.5], [-1.,  1.])
    >>> P.leg2poly(range(4))
    array([-1. , -3.5,  3. ,  7.5])


    
    Evaluate a 2-D Legendre series on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * L_i(a) * L_j(b)

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape + y.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j is contained in `c[i,j]`. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional Chebyshev series at points in the
        Cartesian product of `x` and `y`.

    See Also
    --------
    legval, legval2d, legval3d, leggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Gauss-Legendre quadrature.

    Computes the sample points and weights for Gauss-Legendre quadrature.
    These sample points and weights will correctly integrate polynomials of
    degree :math:`2*deg - 1` or less over the interval :math:`[-1, 1]` with
    the weight function :math:`f(x) = 1`.

    Parameters
    ----------
    deg : int
        Number of sample points and weights. It must be >= 1.

    Returns
    -------
    x : ndarray
        1-D ndarray containing the sample points.
    y : ndarray
        1-D ndarray containing the weights.

    Notes
    -----

    .. versionadded::1.7.0

    The results have only been tested up to degree 100, higher degrees may
    be problematic. The weights are determined by using the fact that

    .. math:: w_k = c / (L'_n(x_k) * L_{n-1}(x_k))

    where :math:`c` is a constant independent of :math:`k` and :math:`x_k`
    is the k'th root of :math:`L_n`, and then scaling the results to get
    the right value when integrating 1.

    
    Divide one Legendre series by another.

    Returns the quotient-with-remainder of two Legendre series
    `c1` / `c2`.  The arguments are sequences of coefficients from lowest
    order "term" to highest, e.g., [1,2,3] represents the series
    ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Legendre series coefficients ordered from low to
        high.

    Returns
    -------
    quo, rem : ndarrays
        Of Legendre series coefficients representing the quotient and
        remainder.

    See Also
    --------
    legadd, legsub, legmul, legpow

    Notes
    -----
    In general, the (polynomial) division of one Legendre series by another
    results in quotient and remainder terms that are not in the Legendre
    polynomial basis set.  Thus, to express these results as a Legendre
    series, it is necessary to "reproject" the results onto the Legendre
    basis set, which may produce "unintuitive" (but correct) results; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> L.legdiv(c1,c2) # quotient "intuitive," remainder not
    (array([ 3.]), array([-8., -4.]))
    >>> c2 = (0,1,2,3)
    >>> L.legdiv(c2,c1) # neither "intuitive"
    (array([-0.07407407,  1.66666667]), array([-1.03703704, -2.51851852]))

    
    Differentiate a Legendre series.

    Returns the Legendre series coefficients `c` differentiated `m` times
    along `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable). The argument
    `c` is an array of coefficients from low to high degree along each
    axis, e.g., [1,2,3] represents the series ``1*L_0 + 2*L_1 + 3*L_2``
    while [[1,2],[1,2]] represents ``1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) +
    2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)`` if axis=0 is ``x`` and axis=1 is
    ``y``.

    Parameters
    ----------
    c : array_like
        Array of Legendre series coefficients. If c is multidimensional the
        different axis correspond to different variables with the degree in
        each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change of
        variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Legendre series of the derivative.

    See Also
    --------
    legint

    Notes
    -----
    In general, the result of differentiating a Legendre series does not
    resemble the same operation on a power series. Thus the result of this
    function may be "unintuitive," albeit correct; see Examples section
    below.

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c = (1,2,3,4)
    >>> L.legder(c)
    array([  6.,   9.,  20.])
    >>> L.legder(c, 3)
    array([ 60.])
    >>> L.legder(c, scl=-1)
    array([ -6.,  -9., -20.])
    >>> L.legder(c, 2,-1)
    array([  9.,  60.])

    
    Convert a polynomial to a Legendre series.

    Convert an array representing the coefficients of a polynomial (relative
    to the "standard" basis) ordered from lowest degree to highest, to an
    array of the coefficients of the equivalent Legendre series, ordered
    from lowest to highest degree.

    Parameters
    ----------
    pol : array_like
        1-D array containing the polynomial coefficients

    Returns
    -------
    c : ndarray
        1-D array containing the coefficients of the equivalent Legendre
        series.

    See Also
    --------
    leg2poly

    Notes
    -----
    The easy way to do conversions between polynomial basis sets
    is to use the convert method of a class instance.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> p = P.Polynomial(np.arange(4))
    >>> p
    Polynomial([ 0.,  1.,  2.,  3.], [-1.,  1.])
    >>> c = P.Legendre(P.poly2leg(p.coef))
    >>> c
    Legendre([ 1.  ,  3.25,  1.  ,  0.75], [-1.,  1.])

    Pseudo-Vandermonde matrix of given degree.

    Returns the pseudo-Vandermonde matrix of degree `deg` and sample points
    `x`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., i] = L_i(x)

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the degree of the Legendre polynomial.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    array ``V = legvander(x, n)``, then ``np.dot(V, c)`` and
    ``legval(x, c)`` are the same up to roundoff. This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of Legendre series of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray
        The pseudo-Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where The last index is the degree of the
        corresponding Legendre polynomial.  The dtype will be the same as
        the converted `x`.

    
Legendre Series (:mod: `numpy.polynomial.legendre`)
===================================================

.. currentmodule:: numpy.polynomial.polynomial

This module provides a number of objects (mostly functions) useful for
dealing with Legendre series, including a `Legendre` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with such polynomials is in the
docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------

.. autosummary::
   :toctree: generated/

   legdomain            Legendre series default domain, [-1,1].
   legzero              Legendre series that evaluates identically to 0.
   legone               Legendre series that evaluates identically to 1.
   legx                 Legendre series for the identity map, ``f(x) = x``.

Arithmetic
----------

.. autosummary::
   :toctree: generated/

   legmulx              multiply a Legendre series in P_i(x) by x.
   legadd               add two Legendre series.
   legsub               subtract one Legendre series from another.
   legmul               multiply two Legendre series.
   legdiv               divide one Legendre series by another.
   legpow               raise a Legendre series to an positive integer power
   legval               evaluate a Legendre series at given points.
   legval2d             evaluate a 2D Legendre series at given points.
   legval3d             evaluate a 3D Legendre series at given points.
   leggrid2d            evaluate a 2D Legendre series on a Cartesian product.
   leggrid3d            evaluate a 3D Legendre series on a Cartesian product.

Calculus
--------

.. autosummary::
   :toctree: generated/

   legder               differentiate a Legendre series.
   legint               integrate a Legendre series.

Misc Functions
--------------

.. autosummary::
   :toctree: generated/

   legfromroots          create a Legendre series with specified roots.
   legroots              find the roots of a Legendre series.
   legvander             Vandermonde-like matrix for Legendre polynomials.
   legvander2d           Vandermonde-like matrix for 2D power series.
   legvander3d           Vandermonde-like matrix for 3D power series.
   leggauss              Gauss-Legendre quadrature, points and weights.
   legweight             Legendre weight function.
   legcompanion          symmetrized companion matrix in Legendre form.
   legfit                least-squares fit returning a Legendre series.
   legtrim               trim leading coefficients from a Legendre series.
   legline               Legendre series representing given straight line.
   leg2poly              convert a Legendre series to a polynomial.
   poly2leg              convert a polynomial to a Legendre series.

Classes
-------
    Legendre            A Legendre series class.

See also
--------
numpy.polynomial.polynomial
numpy.polynomial.chebyshev
numpy.polynomial.laguerre
numpy.polynomial.hermite
numpy.polynomial.hermite_e


    Evaluate a Legendre series at points x.

    If `c` is of length `n + 1`, this function returns the value:

    .. math:: p(x) = c_0 * L_0(x) + c_1 * L_1(x) + ... + c_n * L_n(x)

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, algebra_like
        The shape of the return value is described above.

    See Also
    --------
    legval2d, leggrid2d, legval3d, leggrid3d

    Notes
    -----
    The evaluation uses Clenshaw recursion, aka synthetic division.

    Examples
    --------

    
    Generate a Legendre series with given roots.

    The function returns the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    in Legendre form, where the `r_n` are the roots specified in `roots`.
    If a zero has multiplicity n, then it must appear in `roots` n times.
    For instance, if 2 is a root of multiplicity three and 3 is a root of
    multiplicity 2, then `roots` looks something like [2, 2, 2, 3, 3]. The
    roots can appear in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * L_1(x) + ... +  c_n * L_n(x)

    The coefficient of the last term is not generally 1 for monic
    polynomials in Legendre form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of coefficients.  If all roots are real then `out` is a
        real array, if some of the roots are complex, then `out` is complex
        even if all the coefficients in the result are real (see Examples
        below).

    See Also
    --------
    polyfromroots, chebfromroots, lagfromroots, hermfromroots,
    hermefromroots.

    Examples
    --------
    >>> import numpy.polynomial.legendre as L
    >>> L.legfromroots((-1,0,1)) # x^3 - x relative to the standard basis
    array([ 0. , -0.4,  0. ,  0.4])
    >>> j = complex(0,1)
    >>> L.legfromroots((-j,j)) # x^2 + 1 relative to the standard basis
    array([ 1.33333333+0.j,  0.00000000+0.j,  0.66666667+0.j])

    /usr/lib/python2.7/dist-packages/numpy/polynomial/legendre.py
    Compute the roots of a Legendre series.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * L_i(x).

    Parameters
    ----------
    c : 1-D array_like
        1-D array of coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the series. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    polyroots, chebroots, lagroots, hermroots, hermeroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    The Legendre series basis polynomials aren't powers of ``x`` so the
    results of this function may seem unintuitive.

    Examples
    --------
    >>> import numpy.polynomial.legendre as leg
    >>> leg.legroots((1, 2, 3, 4)) # 4L_3 + 3L_2 + 2L_1 + 1L_0 has only real roots
    array([-0.85099543, -0.11407192,  0.51506735])

    
    Add one Legendre series to another.

    Returns the sum of two Legendre series `c1` + `c2`.  The arguments
    are sequences of coefficients ordered from lowest order term to
    highest, i.e., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Legendre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the Legendre series of their sum.

    See Also
    --------
    legsub, legmul, legdiv, legpow

    Notes
    -----
    Unlike multiplication, division, etc., the sum of two Legendre series
    is a Legendre series (without having to "reproject" the result onto
    the basis set) so addition, just like that of "standard" polynomials,
    is simply "component-wise."

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> L.legadd(c1,c2)
    array([ 4.,  4.,  4.])

    
    Integrate a Legendre series.

    Returns the Legendre series coefficients `c` integrated `m` times from
    `lbnd` along `axis`. At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.)  The argument `c` is an array of
    coefficients from low to high degree along each axis, e.g., [1,2,3]
    represents the series ``L_0 + 2*L_1 + 3*L_2`` while [[1,2],[1,2]]
    represents ``1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) +
    2*L_1(x)*L_1(y)`` if axis=0 is ``x`` and axis=1 is ``y``.

    Parameters
    ----------
    c : array_like
        Array of Legendre series coefficients. If c is multidimensional the
        different axis correspond to different variables with the degree in
        each axis given by the corresponding index.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at
        ``lbnd`` is the first value in the list, the value of the second
        integral at ``lbnd`` is the second value, etc.  If ``k == []`` (the
        default), all constants are set to zero.  If ``m == 1``, a single
        scalar can be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        Legendre series coefficient array of the integral.

    Raises
    ------
    ValueError
        If ``m < 0``, ``len(k) > m``, ``np.isscalar(lbnd) == False``, or
        ``np.isscalar(scl) == False``.

    See Also
    --------
    legder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.
    Why is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`.  Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a` - perhaps not what one would have first thought.

    Also note that, in general, the result of integrating a C-series needs
    to be "reprojected" onto the C-series basis set.  Thus, typically,
    the result of this function is "unintuitive," albeit correct; see
    Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c = (1,2,3)
    >>> L.legint(c)
    array([ 0.33333333,  0.4       ,  0.66666667,  0.6       ])
    >>> L.legint(c, 3)
    array([  1.66666667e-02,  -1.78571429e-02,   4.76190476e-02,
            -1.73472348e-18,   1.90476190e-02,   9.52380952e-03])
    >>> L.legint(c, k=3)
    array([ 3.33333333,  0.4       ,  0.66666667,  0.6       ])
    >>> L.legint(c, lbnd=-2)
    array([ 7.33333333,  0.4       ,  0.66666667,  0.6       ])
    >>> L.legint(c, scl=2)
    array([ 0.66666667,  0.8       ,  1.33333333,  1.2       ])

    
    Evaluate a 3-D Legendre series at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * L_i(x) * L_j(y) * L_k(z)

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimensional polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    legval, legval2d, leggrid2d, leggrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Least squares fit of Legendre series to data.

    Return the coefficients of a Legendre series of degree `deg` that is the
    least squares fit to the data values `y` given at points `x`. If `y` is
    1-D the returned coefficients will also be 1-D. If `y` is 2-D multiple
    fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * L_1(x) + ... + c_n * L_n(x),

    where `n` is `deg`.

    Since numpy version 1.7.0, legfit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (M,)
        x-coordinates of the M sample points ``(x[i], y[i])``.
    y : array_like, shape (M,) or (M, K)
        y-coordinates of the sample points. Several data sets of sample
        points sharing the same x-coordinates can be fitted at once by
        passing in a 2D-array that contains one dataset per column.
    deg : int
        Degree of the fitting polynomial
    rcond : float, optional
        Relative condition number of the fit. Singular values smaller than
        this relative to the largest singular value will be ignored. The
        default value is len(x)*eps, where eps is the relative precision of
        the float type, about 2e-16 in most cases.
    full : bool, optional
        Switch determining nature of return value. When it is False (the
        default) just the coefficients are returned, when True diagnostic
        information from the singular value decomposition is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

        .. versionadded:: 1.5.0

    Returns
    -------
    coef : ndarray, shape (M,) or (M, K)
        Legendre coefficients ordered from low to high. If `y` was 2-D,
        the coefficients for the data in column k  of `y` are in column
        `k`.

    [residuals, rank, singular_values, rcond] : present when `full` = True
        Residuals of the least-squares fit, the effective rank of the
        scaled Vandermonde matrix and its singular values, and the
        specified value of `rcond`. For more details, see `linalg.lstsq`.

    Warns
    -----
    RankWarning
        The rank of the coefficient matrix in the least-squares fit is
        deficient. The warning is only raised if `full` = False.  The
        warnings can be turned off by

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    chebfit, polyfit, lagfit, hermfit, hermefit
    legval : Evaluates a Legendre series.
    legvander : Vandermonde matrix of Legendre series.
    legweight : Legendre weight function (= 1).
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the Legendre series `p` that
    minimizes the sum of the weighted squared errors

    .. math:: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where :math:`w_j` are the weights. This problem is solved by setting up
    as the (typically) overdetermined matrix equation

    .. math:: V(x) * c = w * y,

    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the
    coefficients to be solved for, `w` are the weights, and `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected, then a `RankWarning` will be issued. This means that the
    coefficient values may be poorly determined. Using a lower order fit
    will usually get rid of the warning.  The `rcond` parameter can also be
    set to a value smaller than its default, but the resulting fit may be
    spurious and have large contributions from roundoff error.

    Fits using Legendre series are usually better conditioned than fits
    using power series, but much can depend on the distribution of the
    sample points and the smoothness of the data. If the quality of the fit
    is inadequate splines may be a good alternative.

    References
    ----------
    .. [1] Wikipedia, "Curve fitting",
           http://en.wikipedia.org/wiki/Curve_fitting

    Examples
    --------

    Return the scaled companion matrix of c.

    The basis polynomials are scaled so that the companion matrix is
    symmetric when `c` is an Legendre basis polynomial. This provides
    better eigenvalue estimates than the unscaled case and for basis
    polynomials the eigenvalues are guaranteed to be real if
    `numpy.linalg.eigvalsh` is used to obtain them.

    Parameters
    ----------
    c : array_like
        1-D array of Legendre series coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Scaled companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded::1.7.0

    Raise a Legendre series to a power.

    Returns the Legendre series `c` raised to the power `pow`. The
    arguement `c` is a sequence of coefficients ordered from low to high.
    i.e., [1,2,3] is the series  ``P_0 + 2*P_1 + 3*P_2.``

    Parameters
    ----------
    c : array_like
        1-D array of Legendre series coefficients ordered from low to
        high.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Legendre series of power.

    See Also
    --------
    legadd, legsub, legmul, legdiv

    Examples
    --------

    
    Weight function of the Legendre polynomials.

    The weight function is :math:`1` and the interval of integration is
    :math:`[-1, 1]`. The Legendre polynomials are orthogonal, but not
    normalized, with respect to this weight function.

    Parameters
    ----------
    x : array_like
       Values at which the weight function will be computed.

    Returns
    -------
    w : ndarray
       The weight function at `x`.

    Notes
    -----

    .. versionadded::1.7.0

    Multiply a Legendre series by x.

    Multiply the Legendre series `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of Legendre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----
    The multiplication uses the recursion relationship for Legendre
    polynomials in the form

    .. math::

      xP_i(x) = ((i + 1)*P_{i + 1}(x) + i*P_{i - 1}(x))/(2i + 1)

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = L_i(x)*L_j(y)*L_k(z),

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the degrees of the Legendre polynomials.

    If ``V = legvander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and ``np.dot(V, c.flat)`` and ``legval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D Legendre
    series of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    legvander, legvander3d. legval2d, legval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Multiply one Legendre series by another.

    Returns the product of two Legendre series `c1` * `c2`.  The arguments
    are sequences of coefficients, from lowest order "term" to highest,
    e.g., [1,2,3] represents the series ``P_0 + 2*P_1 + 3*P_2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of Legendre series coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of Legendre series coefficients representing their product.

    See Also
    --------
    legadd, legsub, legdiv, legpow

    Notes
    -----
    In general, the (polynomial) product of two C-series results in terms
    that are not in the Legendre polynomial basis set.  Thus, to express
    the product as a Legendre series, it is necessary to "reproject" the
    product onto said basis set, which may produce "unintuitive" (but
    correct) results; see Examples section below.

    Examples
    --------
    >>> from numpy.polynomial import legendre as L
    >>> c1 = (1,2,3)
    >>> c2 = (3,2)
    >>> P.legmul(c1,c2) # multiplication requires "reprojection"
    array([  4.33333333,  10.4       ,  11.66666667,   3.6       ])

    polyxpolyonepolypowpolytrimpolyzeropolyval2dpolyval3dpolydomainpolygrid2dpolygrid3dpolyvander2dpolyvander3d[   s   polyzeros   polyones   polyxs
   polydomains   polylines   polyadds   polysubs   polymulxs   polymuls   polydivs   polypows   polyvals   polyders   polyints   polyfromrootss
   polyvanders   polyfits   polytrims	   polyrootss
   Polynomials	   polyval2ds	   polyval3ds
   polygrid2ds
   polygrid3ds   polyvander2ds   polyvander3d
    Evaluate a 3-D polynomial on the Cartesian product of x, y and z.

    This function returns the values:

    .. math:: p(a,b,c) = \sum_{i,j,k} c_{i,j,k} * a^i * b^j * c^k

    where the points `(a, b, c)` consist of all triples formed by taking
    `a` from `x`, `b` from `y`, and `c` from `z`. The resulting points form
    a grid with `x` in the first dimension, `y` in the second, and `z` in
    the third.

    The parameters `x`, `y`, and `z` are converted to arrays only if they
    are tuples or a lists, otherwise they are treated as a scalars. In
    either case, either `x`, `y`, and `z` or their elements must support
    multiplication and addition both with themselves and with the elements
    of `c`.

    If `c` has fewer than three dimensions, ones are implicitly appended to
    its shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape + y.shape + z.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible objects
        The three dimensional series is evaluated at the points in the
        Cartesian product of `x`, `y`, and `z`.  If `x`,`y`, or `z` is a
        list or tuple, it is first converted to an ndarray, otherwise it is
        left unchanged and, if it isn't an ndarray, it is treated as a
        scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    polyval, polyval2d, polygrid2d, polyval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Evaluate a 2-D polynomial at points (x, y).

    This function returns the value

    .. math:: p(x,y) = \sum_{i,j} c_{i,j} * x^i * y^j

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars and they
    must have the same shape after conversion. In either case, either `x`
    and `y` or their elements must support multiplication and addition both
    with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points `(x, y)`,
        where `x` and `y` must have the same shape. If `x` or `y` is a list
        or tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term
        of multi-degree i,j is contained in `c[i,j]`. If `c` has
        dimension greater than two the remaining indices enumerate multiple
        sets of coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points formed with
        pairs of corresponding values from `x` and `y`.

    See Also
    --------
    polyval, polygrid2d, polyval3d, polygrid3d

    Notes
    -----

    .. versionadded::1.7.0

    /usr/lib/python2.7/dist-packages/numpy/polynomial/polynomial.py
    Multiply one polynomial by another.

    Returns the product of two polynomials `c1` * `c2`.  The arguments are
    sequences of coefficients, from lowest order term to highest, e.g.,
    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2.``

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of coefficients representing a polynomial, relative to the
        "standard" basis, and ordered from lowest order term to highest.

    Returns
    -------
    out : ndarray
        Of the coefficients of their product.

    See Also
    --------
    polyadd, polysub, polydiv, polypow

    Examples
    --------
    >>> import numpy.polynomial as P
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> P.polymul(c1,c2)
    array([  3.,   8.,  14.,   8.,   3.])

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y, z)`. If `l, m, n` are the given degrees in `x, y, z`,
    then The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., (m+1)(n+1)i + (n+1)j + k] = x^i * y^j * z^k,

    where `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`.  The leading
    indices of `V` index the points `(x, y, z)` and the last index encodes
    the powers of `x`, `y`, and `z`.

    If ``V = polyvander3d(x, y, z, [xdeg, ydeg, zdeg])``, then the columns
    of `V` correspond to the elements of a 3-D coefficient array `c` of
    shape (xdeg + 1, ydeg + 1, zdeg + 1) in the order

    .. math:: c_{000}, c_{001}, c_{002},... , c_{010}, c_{011}, c_{012},...

    and  ``np.dot(V, c.flat)`` and ``polyval3d(x, y, z, c)`` will be the
    same up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 3-D polynomials
    of the same degrees and sample points.

    Parameters
    ----------
    x, y, z : array_like
        Arrays of point coordinates, all of the same shape. The dtypes will
        be converted to either float64 or complex128 depending on whether
        any of the elements are complex. Scalars are converted to 1-D
        arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg, z_deg].

    Returns
    -------
    vander3d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)*(deg[2]+1)`.  The dtype will
        be the same as the converted `x`, `y`, and `z`.

    See Also
    --------
    polyvander, polyvander3d. polyval2d, polyval3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Divide one polynomial by another.

    Returns the quotient-with-remainder of two polynomials `c1` / `c2`.
    The arguments are sequences of coefficients, from lowest order term
    to highest, e.g., [1,2,3] represents ``1 + 2*x + 3*x**2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of polynomial coefficients ordered from low to high.

    Returns
    -------
    [quo, rem] : ndarrays
        Of coefficient series representing the quotient and remainder.

    See Also
    --------
    polyadd, polysub, polymul, polypow

    Examples
    --------
    >>> import numpy.polynomial as P
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> P.polydiv(c1,c2)
    (array([ 3.]), array([-8., -4.]))
    >>> P.polydiv(c2,c1)
    (array([ 0.33333333]), array([ 2.66666667,  1.33333333]))

    Raise a polynomial to a power.

    Returns the polynomial `c` raised to the power `pow`. The argument
    `c` is a sequence of coefficients ordered from low to high. i.e.,
    [1,2,3] is the series  ``1 + 2*x + 3*x**2.``

    Parameters
    ----------
    c : array_like
        1-D array of array of series coefficients ordered from low to
        high degree.
    pow : integer
        Power to which the series will be raised
    maxpower : integer, optional
        Maximum power allowed. This is mainly to limit growth of the series
        to unmanageable size. Default is 16

    Returns
    -------
    coef : ndarray
        Power series of power.

    See Also
    --------
    polyadd, polysub, polymul, polydiv

    Examples
    --------

    Multiply a polynomial by x.

    Multiply the polynomial `c` by x, where x is the independent
    variable.


    Parameters
    ----------
    c : array_like
        1-D array of polynomial coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Array representing the result of the multiplication.

    Notes
    -----

    .. versionadded:: 1.5.0

    
    Differentiate a polynomial.

    Returns the polynomial coefficients `c` differentiated `m` times along
    `axis`.  At each iteration the result is multiplied by `scl` (the
    scaling factor is for use in a linear change of variable).  The
    argument `c` is an array of coefficients from low to high degree along
    each axis, e.g., [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``
    while [[1,2],[1,2]] represents ``1 + 1*x + 2*y + 2*x*y`` if axis=0 is
    ``x`` and axis=1 is ``y``.

    Parameters
    ----------
    c : array_like
        Array of polynomial coefficients. If c is multidimensional the
        different axis correspond to different variables with the degree
        in each axis given by the corresponding index.
    m : int, optional
        Number of derivatives taken, must be non-negative. (Default: 1)
    scl : scalar, optional
        Each differentiation is multiplied by `scl`.  The end result is
        multiplication by ``scl**m``.  This is for use in a linear change
        of variable. (Default: 1)
    axis : int, optional
        Axis over which the derivative is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    der : ndarray
        Polynomial coefficients of the derivative.

    See Also
    --------
    polyint

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> c = (1,2,3,4) # 1 + 2x + 3x**2 + 4x**3
    >>> P.polyder(c) # (d/dx)(c) = 2 + 6x + 12x**2
    array([  2.,   6.,  12.])
    >>> P.polyder(c,3) # (d**3/dx**3)(c) = 24
    array([ 24.])
    >>> P.polyder(c,scl=-1) # (d/d(-x))(c) = -2 - 6x - 12x**2
    array([ -2.,  -6., -12.])
    >>> P.polyder(c,2,-1) # (d**2/d(-x)**2)(c) = 6 + 24x
    array([  6.,  24.])

    
    Compute the roots of a polynomial.

    Return the roots (a.k.a. "zeros") of the polynomial

    .. math:: p(x) = \sum_i c[i] * x^i.

    Parameters
    ----------
    c : 1-D array_like
        1-D array of polynomial coefficients.

    Returns
    -------
    out : ndarray
        Array of the roots of the polynomial. If all the roots are real,
        then `out` is also real, otherwise it is complex.

    See Also
    --------
    chebroots

    Notes
    -----
    The root estimates are obtained as the eigenvalues of the companion
    matrix, Roots far from the origin of the complex plane may have large
    errors due to the numerical instability of the power series for such
    values. Roots with multiplicity greater than 1 will also show larger
    errors as the value of the series near such points is relatively
    insensitive to errors in the roots. Isolated roots near the origin can
    be improved by a few iterations of Newton's method.

    Examples
    --------
    >>> import numpy.polynomial.polynomial as poly
    >>> poly.polyroots(poly.polyfromroots((-1,0,1)))
    array([-1.,  0.,  1.])
    >>> poly.polyroots(poly.polyfromroots((-1,0,1))).dtype
    dtype('float64')
    >>> j = complex(0,1)
    >>> poly.polyroots(poly.polyfromroots((-j,0,j)))
    array([  0.00000000e+00+0.j,   0.00000000e+00+1.j,   2.77555756e-17-1.j])

    
    Evaluate a 3-D polynomial at points (x, y, z).

    This function returns the values:

    .. math:: p(x,y,z) = \sum_{i,j,k} c_{i,j,k} * x^i * y^j * z^k

    The parameters `x`, `y`, and `z` are converted to arrays only if
    they are tuples or a lists, otherwise they are treated as a scalars and
    they must have the same shape after conversion. In either case, either
    `x`, `y`, and `z` or their elements must support multiplication and
    addition both with themselves and with the elements of `c`.

    If `c` has fewer than 3 dimensions, ones are implicitly appended to its
    shape to make it 3-D. The shape of the result will be c.shape[3:] +
    x.shape.

    Parameters
    ----------
    x, y, z : array_like, compatible object
        The three dimensional series is evaluated at the points
        `(x, y, z)`, where `x`, `y`, and `z` must have the same shape.  If
        any of `x`, `y`, or `z` is a list or tuple, it is first converted
        to an ndarray, otherwise it is left unchanged and if it isn't an
        ndarray it is  treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficient of the term of
        multi-degree i,j,k is contained in ``c[i,j,k]``. If `c` has dimension
        greater than 3 the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the multidimensional polynomial on points formed with
        triples of corresponding values from `x`, `y`, and `z`.

    See Also
    --------
    polyval, polyval2d, polygrid2d, polygrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Subtract one polynomial from another.

    Returns the difference of two polynomials `c1` - `c2`.  The arguments
    are sequences of coefficients from lowest order term to highest, i.e.,
    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of polynomial coefficients ordered from low to
        high.

    Returns
    -------
    out : ndarray
        Of coefficients representing their difference.

    See Also
    --------
    polyadd, polymul, polydiv, polypow

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> P.polysub(c1,c2)
    array([-2.,  0.,  2.])
    >>> P.polysub(c2,c1) # -P.polysub(c1,c2)
    array([ 2.,  0., -2.])

    Vandermonde matrix of given degree.

    Returns the Vandermonde matrix of degree `deg` and sample points
    `x`. The Vandermonde matrix is defined by

    .. math:: V[..., i] = x^i,

    where `0 <= i <= deg`. The leading indices of `V` index the elements of
    `x` and the last index is the power of `x`.

    If `c` is a 1-D array of coefficients of length `n + 1` and `V` is the
    matrix ``V = polyvander(x, n)``, then ``np.dot(V, c)`` and
    ``polyval(x, c)`` are the same up to roundoff. This equivalence is
    useful both for least squares fitting and for the evaluation of a large
    number of polynomials of the same degree and sample points.

    Parameters
    ----------
    x : array_like
        Array of points. The dtype is converted to float64 or complex128
        depending on whether any of the elements are complex. If `x` is
        scalar it is converted to a 1-D array.
    deg : int
        Degree of the resulting matrix.

    Returns
    -------
    vander : ndarray.
        The Vandermonde matrix. The shape of the returned matrix is
        ``x.shape + (deg + 1,)``, where the last index is the power of `x`.
        The dtype will be the same as the converted `x`.

    See Also
    --------
    polyvander2d, polyvander3d

    
    Add one polynomial to another.

    Returns the sum of two polynomials `c1` + `c2`.  The arguments are
    sequences of coefficients from lowest order term to highest, i.e.,
    [1,2,3] represents the polynomial ``1 + 2*x + 3*x**2``.

    Parameters
    ----------
    c1, c2 : array_like
        1-D arrays of polynomial coefficients ordered from low to high.

    Returns
    -------
    out : ndarray
        The coefficient array representing their sum.

    See Also
    --------
    polysub, polymul, polydiv, polypow

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> c1 = (1,2,3)
    >>> c2 = (3,2,1)
    >>> sum = P.polyadd(c1,c2); sum
    array([ 4.,  4.,  4.])
    >>> P.polyval(2, sum) # 4 + 4(2) + 4(2**2)
    28.0

    
    Returns an array representing a linear polynomial.

    Parameters
    ----------
    off, scl : scalars
        The "y-intercept" and "slope" of the line, respectively.

    Returns
    -------
    y : ndarray
        This module's representation of the linear polynomial ``off +
        scl*x``.

    See Also
    --------
    chebline

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> P.polyline(1,-1)
    array([ 1, -1])
    >>> P.polyval(1, P.polyline(1,-1)) # should be 0
    0.0

    
    Generate a monic polynomial with given roots.

    Return the coefficients of the polynomial

    .. math:: p(x) = (x - r_0) * (x - r_1) * ... * (x - r_n),

    where the `r_n` are the roots specified in `roots`.  If a zero has
    multiplicity n, then it must appear in `roots` n times. For instance,
    if 2 is a root of multiplicity three and 3 is a root of multiplicity 2,
    then `roots` looks something like [2, 2, 2, 3, 3]. The roots can appear
    in any order.

    If the returned coefficients are `c`, then

    .. math:: p(x) = c_0 + c_1 * x + ... +  x^n

    The coefficient of the last term is 1 for monic polynomials in this
    form.

    Parameters
    ----------
    roots : array_like
        Sequence containing the roots.

    Returns
    -------
    out : ndarray
        1-D array of the polynomial's coefficients If all the roots are
        real, then `out` is also real, otherwise it is complex.  (see
        Examples below).

    See Also
    --------
    chebfromroots, legfromroots, lagfromroots, hermfromroots
    hermefromroots

    Notes
    -----
    The coefficients are determined by multiplying together linear factors
    of the form `(x - r_i)`, i.e.

    .. math:: p(x) = (x - r_0) (x - r_1) ... (x - r_n)

    where ``n == len(roots) - 1``; note that this implies that `1` is always
    returned for :math:`a_n`.

    Examples
    --------
    >>> import numpy.polynomial as P
    >>> P.polyfromroots((-1,0,1)) # x(x - 1)(x + 1) = x^3 - x
    array([ 0., -1.,  0.,  1.])
    >>> j = complex(0,1)
    >>> P.polyfromroots((-j,j)) # complex returned, though values are real
    array([ 1.+0.j,  0.+0.j,  1.+0.j])

    
    Least-squares fit of a polynomial to data.

    Return the coefficients of a polynomial of degree `deg` that is the
    least squares fit to the data values `y` given at points `x`. If `y` is
    1-D the returned coefficients will also be 1-D. If `y` is 2-D multiple
    fits are done, one for each column of `y`, and the resulting
    coefficients are stored in the corresponding columns of a 2-D return.
    The fitted polynomial(s) are in the form

    .. math::  p(x) = c_0 + c_1 * x + ... + c_n * x^n,

    where `n` is `deg`.

    Since numpy version 1.7.0, polyfit also supports NA. If any of the
    elements of `x`, `y`, or `w` are NA, then the corresponding rows of the
    linear least squares problem (see Notes) are set to 0. If `y` is 2-D,
    then an NA in any row of `y` invalidates that whole row.

    Parameters
    ----------
    x : array_like, shape (`M`,)
        x-coordinates of the `M` sample (data) points ``(x[i], y[i])``.
    y : array_like, shape (`M`,) or (`M`, `K`)
        y-coordinates of the sample points.  Several sets of sample points
        sharing the same x-coordinates can be (independently) fit with one
        call to `polyfit` by passing in for `y` a 2-D array that contains
        one data set per column.
    deg : int
        Degree of the polynomial(s) to be fit.
    rcond : float, optional
        Relative condition number of the fit.  Singular values smaller
        than `rcond`, relative to the largest singular value, will be
        ignored.  The default value is ``len(x)*eps``, where `eps` is the
        relative precision of the platform's float type, about 2e-16 in
        most cases.
    full : bool, optional
        Switch determining the nature of the return value.  When ``False``
        (the default) just the coefficients are returned; when ``True``,
        diagnostic information from the singular value decomposition (used
        to solve the fit's matrix equation) is also returned.
    w : array_like, shape (`M`,), optional
        Weights. If not None, the contribution of each point
        ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
        weights are chosen so that the errors of the products ``w[i]*y[i]``
        all have the same variance.  The default value is None.

        .. versionadded:: 1.5.0

    Returns
    -------
    coef : ndarray, shape (`deg` + 1,) or (`deg` + 1, `K`)
        Polynomial coefficients ordered from low to high.  If `y` was 2-D,
        the coefficients in column `k` of `coef` represent the polynomial
        fit to the data in `y`'s `k`-th column.

    [residuals, rank, singular_values, rcond] : present when `full` == True
        Sum of the squared residuals (SSR) of the least-squares fit; the
        effective rank of the scaled Vandermonde matrix; its singular
        values; and the specified value of `rcond`.  For more information,
        see `linalg.lstsq`.

    Raises
    ------
    RankWarning
        Raised if the matrix in the least-squares fit is rank deficient.
        The warning is only raised if `full` == False.  The warnings can
        be turned off by:

        >>> import warnings
        >>> warnings.simplefilter('ignore', RankWarning)

    See Also
    --------
    chebfit, legfit, lagfit, hermfit, hermefit
    polyval : Evaluates a polynomial.
    polyvander : Vandermonde matrix for powers.
    linalg.lstsq : Computes a least-squares fit from the matrix.
    scipy.interpolate.UnivariateSpline : Computes spline fits.

    Notes
    -----
    The solution is the coefficients of the polynomial `p` that minimizes
    the sum of the weighted squared errors

    .. math :: E = \sum_j w_j^2 * |y_j - p(x_j)|^2,

    where the :math:`w_j` are the weights. This problem is solved by
    setting up the (typically) over-determined matrix equation:

    .. math :: V(x) * c = w * y,

    where `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the
    coefficients to be solved for, `w` are the weights, and `y` are the
    observed values.  This equation is then solved using the singular value
    decomposition of `V`.

    If some of the singular values of `V` are so small that they are
    neglected (and `full` == ``False``), a `RankWarning` will be raised.
    This means that the coefficient values may be poorly determined.
    Fitting to a lower order polynomial will usually get rid of the warning
    (but may not be what you want, of course; if you have independent
    reason(s) for choosing the degree which isn't working, you may have to:
    a) reconsider those reasons, and/or b) reconsider the quality of your
    data).  The `rcond` parameter can also be set to a value smaller than
    its default, but the resulting fit may be spurious and have large
    contributions from roundoff error.

    Polynomial fits using double precision tend to "fail" at about
    (polynomial) degree 20. Fits using Chebyshev or Legendre series are
    generally better conditioned, but much can still depend on the
    distribution of the sample points and the smoothness of the data.  If
    the quality of the fit is inadequate, splines may be a good
    alternative.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> x = np.linspace(-1,1,51) # x "data": [-1, -0.96, ..., 0.96, 1]
    >>> y = x**3 - x + np.random.randn(len(x)) # x^3 - x + N(0,1) "noise"
    >>> c, stats = P.polyfit(x,y,3,full=True)
    >>> c # c[0], c[2] should be approx. 0, c[1] approx. -1, c[3] approx. 1
    array([ 0.01909725, -1.30598256, -0.00577963,  1.02644286])
    >>> stats # note the large SSR, explaining the rather poor results
    [array([ 38.06116253]), 4, array([ 1.38446749,  1.32119158,  0.50443316,
    0.28853036]), 1.1324274851176597e-014]

    Same thing without the added noise

    >>> y = x**3 - x
    >>> c, stats = P.polyfit(x,y,3,full=True)
    >>> c # c[0], c[2] should be "very close to 0", c[1] ~= -1, c[3] ~= 1
    array([ -1.73362882e-17,  -1.00000000e+00,  -2.67471909e-16,
             1.00000000e+00])
    >>> stats # note the minuscule SSR
    [array([  7.46346754e-31]), 4, array([ 1.38446749,  1.32119158,
    0.50443316,  0.28853036]), 1.1324274851176597e-014]

    
    Evaluate a 2-D polynomial on the Cartesian product of x and y.

    This function returns the values:

    .. math:: p(a,b) = \sum_{i,j} c_{i,j} * a^i * b^j

    where the points `(a, b)` consist of all pairs formed by taking
    `a` from `x` and `b` from `y`. The resulting points form a grid with
    `x` in the first dimension and `y` in the second.

    The parameters `x` and `y` are converted to arrays only if they are
    tuples or a lists, otherwise they are treated as a scalars. In either
    case, either `x` and `y` or their elements must support multiplication
    and addition both with themselves and with the elements of `c`.

    If `c` has fewer than two dimensions, ones are implicitly appended to
    its shape to make it 2-D. The shape of the result will be c.shape[2:] +
    x.shape + y.shape.

    Parameters
    ----------
    x, y : array_like, compatible objects
        The two dimensional series is evaluated at the points in the
        Cartesian product of `x` and `y`.  If `x` or `y` is a list or
        tuple, it is first converted to an ndarray, otherwise it is left
        unchanged and, if it isn't an ndarray, it is treated as a scalar.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree i,j are contained in ``c[i,j]``. If `c` has dimension
        greater than two the remaining indices enumerate multiple sets of
        coefficients.

    Returns
    -------
    values : ndarray, compatible object
        The values of the two dimensional polynomial at points in the Cartesian
        product of `x` and `y`.

    See Also
    --------
    polyval, polyval2d, polyval3d, polygrid3d

    Notes
    -----

    .. versionadded::1.7.0

    
    Return the companion matrix of c.

    The companion matrix for power series cannot be made symmetric by
    scaling the basis, so this function differs from those for the
    orthogonal polynomials.

    Parameters
    ----------
    c : array_like
        1-D array of polynomial coefficients ordered from low to high
        degree.

    Returns
    -------
    mat : ndarray
        Companion matrix of dimensions (deg, deg).

    Notes
    -----

    .. versionadded:: 1.7.0

    
    Evaluate a polynomial at points x.

    If `c` is of length `n + 1`, this function returns the value

    .. math:: p(x) = c_0 + c_1 * x + ... + c_n * x^n

    The parameter `x` is converted to an array only if it is a tuple or a
    list, otherwise it is treated as a scalar. In either case, either `x`
    or its elements must support multiplication and addition both with
    themselves and with the elements of `c`.

    If `c` is a 1-D array, then `p(x)` will have the same shape as `x`.  If
    `c` is multidimensional, then the shape of the result depends on the
    value of `tensor`. If `tensor` is true the shape will be c.shape[1:] +
    x.shape. If `tensor` is false the shape will be c.shape[1:]. Note that
    scalars have shape (,).

    Trailing zeros in the coefficients will be used in the evaluation, so
    they should be avoided if efficiency is a concern.

    Parameters
    ----------
    x : array_like, compatible object
        If `x` is a list or tuple, it is converted to an ndarray, otherwise
        it is left unchanged and treated as a scalar. In either case, `x`
        or its elements must support addition and multiplication with
        with themselves and with the elements of `c`.
    c : array_like
        Array of coefficients ordered so that the coefficients for terms of
        degree n are contained in c[n]. If `c` is multidimensional the
        remaining indices enumerate multiple polynomials. In the two
        dimensional case the coefficients may be thought of as stored in
        the columns of `c`.
    tensor : boolean, optional
        If True, the shape of the coefficient array is extended with ones
        on the right, one for each dimension of `x`. Scalars have dimension 0
        for this action. The result is that every column of coefficients in
        `c` is evaluated for every element of `x`. If False, `x` is broadcast
        over the columns of `c` for the evaluation.  This keyword is useful
        when `c` is multidimensional. The default value is True.

        .. versionadded:: 1.7.0

    Returns
    -------
    values : ndarray, compatible object
        The shape of the returned array is described above.

    See Also
    --------
    polyval2d, polygrid2d, polyval3d, polygrid3d

    Notes
    -----
    The evaluation uses Horner's method.

    Examples
    --------
    >>> from numpy.polynomial.polynomial import polyval
    >>> polyval(1, [1,2,3])
    6.0
    >>> a = np.arange(4).reshape(2,2)
    >>> a
    array([[0, 1],
           [2, 3]])
    >>> polyval(a, [1,2,3])
    array([[  1.,   6.],
           [ 17.,  34.]])
    >>> coef = np.arange(4).reshape(2,2) # multidimensional coefficients
    >>> coef
    array([[0, 1],
           [2, 3]])
    >>> polyval([1,2], coef, tensor=True)
    array([[ 2.,  4.],
           [ 4.,  7.]])
    >>> polyval([1,2], coef, tensor=False)
    array([ 2.,  7.])

    
    Integrate a polynomial.

    Returns the polynomial coefficients `c` integrated `m` times from
    `lbnd` along `axis`.  At each iteration the resulting series is
    **multiplied** by `scl` and an integration constant, `k`, is added.
    The scaling factor is for use in a linear change of variable.  ("Buyer
    beware": note that, depending on what one is doing, one may want `scl`
    to be the reciprocal of what one might expect; for more information,
    see the Notes section below.) The argument `c` is an array of
    coefficients, from low to high degree along each axis, e.g., [1,2,3]
    represents the polynomial ``1 + 2*x + 3*x**2`` while [[1,2],[1,2]]
    represents ``1 + 1*x + 2*y + 2*x*y`` if axis=0 is ``x`` and axis=1 is
    ``y``.

    Parameters
    ----------
    c : array_like
        1-D array of polynomial coefficients, ordered from low to high.
    m : int, optional
        Order of integration, must be positive. (Default: 1)
    k : {[], list, scalar}, optional
        Integration constant(s).  The value of the first integral at zero
        is the first value in the list, the value of the second integral
        at zero is the second value, etc.  If ``k == []`` (the default),
        all constants are set to zero.  If ``m == 1``, a single scalar can
        be given instead of a list.
    lbnd : scalar, optional
        The lower bound of the integral. (Default: 0)
    scl : scalar, optional
        Following each integration the result is *multiplied* by `scl`
        before the integration constant is added. (Default: 1)
    axis : int, optional
        Axis over which the integral is taken. (Default: 0).

        .. versionadded:: 1.7.0

    Returns
    -------
    S : ndarray
        Coefficient array of the integral.

    Raises
    ------
    ValueError
        If ``m < 1``, ``len(k) > m``.

    See Also
    --------
    polyder

    Notes
    -----
    Note that the result of each integration is *multiplied* by `scl`.  Why
    is this important to note?  Say one is making a linear change of
    variable :math:`u = ax + b` in an integral relative to `x`. Then
    .. math::`dx = du/a`, so one will need to set `scl` equal to
    :math:`1/a` - perhaps not what one would have first thought.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> c = (1,2,3)
    >>> P.polyint(c) # should return array([0, 1, 1, 1])
    array([ 0.,  1.,  1.,  1.])
    >>> P.polyint(c,3) # should return array([0, 0, 0, 1/6, 1/12, 1/20])
    array([ 0.        ,  0.        ,  0.        ,  0.16666667,  0.08333333,
            0.05      ])
    >>> P.polyint(c,k=3) # should return array([3, 1, 1, 1])
    array([ 3.,  1.,  1.,  1.])
    >>> P.polyint(c,lbnd=-2) # should return array([6, 1, 1, 1])
    array([ 6.,  1.,  1.,  1.])
    >>> P.polyint(c,scl=-2) # should return array([0, -2, -2, -2])
    array([ 0., -2., -2., -2.])

    Pseudo-Vandermonde matrix of given degrees.

    Returns the pseudo-Vandermonde matrix of degrees `deg` and sample
    points `(x, y)`. The pseudo-Vandermonde matrix is defined by

    .. math:: V[..., deg[1]*i + j] = x^i * y^j,

    where `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of
    `V` index the points `(x, y)` and the last index encodes the powers of
    `x` and `y`.

    If ``V = polyvander2d(x, y, [xdeg, ydeg])``, then the columns of `V`
    correspond to the elements of a 2-D coefficient array `c` of shape
    (xdeg + 1, ydeg + 1) in the order

    .. math:: c_{00}, c_{01}, c_{02} ... , c_{10}, c_{11}, c_{12} ...

    and ``np.dot(V, c.flat)`` and ``polyval2d(x, y, c)`` will be the same
    up to roundoff. This equivalence is useful both for least squares
    fitting and for the evaluation of a large number of 2-D polynomials
    of the same degrees and sample points.

    Parameters
    ----------
    x, y : array_like
        Arrays of point coordinates, all of the same shape. The dtypes
        will be converted to either float64 or complex128 depending on
        whether any of the elements are complex. Scalars are converted to
        1-D arrays.
    deg : list of ints
        List of maximum degrees of the form [x_deg, y_deg].

    Returns
    -------
    vander2d : ndarray
        The shape of the returned matrix is ``x.shape + (order,)``, where
        :math:`order = (deg[0]+1)*(deg([1]+1)`.  The dtype will be the same
        as the converted `x` and `y`.

    See Also
    --------
    polyvander, polyvander3d. polyval2d, polyval3d

    
Objects for dealing with polynomials.

This module provides a number of objects (mostly functions) useful for
dealing with polynomials, including a `Polynomial` class that
encapsulates the usual arithmetic operations.  (General information
on how this module represents and works with polynomial objects is in
the docstring for its "parent" sub-package, `numpy.polynomial`).

Constants
---------
- `polydomain` -- Polynomial default domain, [-1,1].
- `polyzero` -- (Coefficients of the) "zero polynomial."
- `polyone` -- (Coefficients of the) constant polynomial 1.
- `polyx` -- (Coefficients of the) identity map polynomial, ``f(x) = x``.

Arithmetic
----------
- `polyadd` -- add two polynomials.
- `polysub` -- subtract one polynomial from another.
- `polymul` -- multiply two polynomials.
- `polydiv` -- divide one polynomial by another.
- `polypow` -- raise a polynomial to an positive integer power
- `polyval` -- evaluate a polynomial at given points.
- `polyval2d` -- evaluate a 2D polynomial at given points.
- `polyval3d` -- evaluate a 3D polynomial at given points.
- `polygrid2d` -- evaluate a 2D polynomial on a Cartesian product.
- `polygrid3d` -- evaluate a 3D polynomial on a Cartesian product.

Calculus
--------
- `polyder` -- differentiate a polynomial.
- `polyint` -- integrate a polynomial.

Misc Functions
--------------
- `polyfromroots` -- create a polynomial with specified roots.
- `polyroots` -- find the roots of a polynomial.
- `polyvander` -- Vandermonde-like matrix for powers.
- `polyvander2d` -- Vandermonde-like matrix for 2D power series.
- `polyvander3d` -- Vandermonde-like matrix for 3D power series.
- `polycompanion` -- companion matrix in power series form.
- `polyfit` -- least-squares fit returning a polynomial.
- `polytrim` -- trim leading coefficients from a polynomial.
- `polyline` -- polynomial representing given straight line.

Classes
-------
- `Polynomial` -- polynomial class.

See also
--------
`numpy.polynomial`

Templatenumpy.polynomial.polytemplate
Template for the Chebyshev and Polynomial classes.

This module houses a Python string module Template object (see, e.g.,
http://docs.python.org/library/string.html#template-strings) used by
the `polynomial` and `chebyshev` modules to implement their respective
`Polynomial` and `Chebyshev` classes.  It provides a mechanism for easily
creating additional specific polynomial classes (e.g., Legendre, Jacobi,
etc.) in the future, such that all these classes will have a common API.

/usr/lib/python2.7/dist-packages/numpy/polynomial/polytemplate.py
from __future__ import division, absolute_import, print_function
import numpy as np
import warnings
from . import polyutils as pu

class $name(pu.PolyBase) :
    """A $name series class.

    $name instances provide the standard Python numerical methods '+',
    '-', '*', '//', '%', 'divmod', '**', and '()' as well as the listed
    methods.

    Parameters
    ----------
    coef : array_like
        $name coefficients, in increasing order.  For example,
        ``(1, 2, 3)`` implies ``P_0 + 2P_1 + 3P_2`` where the
        ``P_i`` are a graded polynomial basis.
    domain : (2,) array_like, optional
        Domain to use. The interval ``[domain[0], domain[1]]`` is mapped to
        the interval ``[window[0], window[1]]`` by shifting and scaling.
        The default value is $domain.
    window : (2,) array_like, optional
        Window, see ``domain`` for its use. The default value is $domain.
        .. versionadded:: 1.6.0

    Attributes
    ----------
    coef : (N,) ndarray
        $name coefficients, from low to high.
    domain : (2,) ndarray
        Domain that is mapped to ``window``.
    window : (2,) ndarray
        Window that ``domain`` is mapped to.

    Class Attributes
    ----------------
    maxpower : int
        Maximum power allowed, i.e., the largest number ``n`` such that
        ``p(x)**n`` is allowed. This is to limit runaway polynomial size.
    domain : (2,) ndarray
        Default domain of the class.
    window : (2,) ndarray
        Default window of the class.

    Notes
    -----
    It is important to specify the domain in many cases, for instance in
    fitting data, because many of the important properties of the
    polynomial basis only hold in a specified interval and consequently
    the data must be mapped into that interval in order to benefit.

    Examples
    --------

    """
    # Limit runaway size. T_n^m has degree n*2^m
    maxpower = 16
    # Default domain
    domain = np.array($domain)
    # Default window
    window = np.array($domain)
    # Don't let participate in array operations. Value doesn't matter.
    __array_priority__ = 1000
    # Not hashable
    __hash__ = None

    def has_samecoef(self, other):
        """Check if coefficients match.

        Parameters
        ----------
        other : class instance
            The other class must have the ``coef`` attribute.

        Returns
        -------
        bool : boolean
            True if the coefficients are the same, False otherwise.

        Notes
        -----
        .. versionadded:: 1.6.0

        """
        if len(self.coef) != len(other.coef):
            return False
        elif not np.all(self.coef == other.coef):
            return False
        else:
            return True

    def has_samedomain(self, other):
        """Check if domains match.

        Parameters
        ----------
        other : class instance
            The other class must have the ``domain`` attribute.

        Returns
        -------
        bool : boolean
            True if the domains are the same, False otherwise.

        Notes
        -----
        .. versionadded:: 1.6.0

        """
        return np.all(self.domain == other.domain)

    def has_samewindow(self, other):
        """Check if windows match.

        Parameters
        ----------
        other : class instance
            The other class must have the ``window`` attribute.

        Returns
        -------
        bool : boolean
            True if the windows are the same, False otherwise.

        Notes
        -----
        .. versionadded:: 1.6.0

        """
        return np.all(self.window == other.window)

    def has_sametype(self, other):
        """Check if types match.

        Parameters
        ----------
        other : object
            Class instance.

        Returns
        -------
        bool : boolean
            True if other is same class as self

        Notes
        -----
        .. versionadded:: 1.7.0

        """
        return isinstance(other, self.__class__)

    def __init__(self, coef, domain=$domain, window=$domain) :
        [coef, dom, win] = pu.as_series([coef, domain, window], trim=False)
        if len(dom) != 2 :
            raise ValueError("Domain has wrong number of elements.")
        if len(win) != 2 :
            raise ValueError("Window has wrong number of elements.")
        self.coef = coef
        self.domain = dom
        self.window = win

    def __repr__(self):
        format = "%s(%s, %s, %s)"
        coef = repr(self.coef)[6:-1]
        domain = repr(self.domain)[6:-1]
        window = repr(self.window)[6:-1]
        return format % ('$name', coef, domain, window)

    def __str__(self) :
        format = "%s(%s)"
        coef = str(self.coef)
        return format % ('$nick', coef)

    # Pickle and copy

    def __getstate__(self) :
        ret = self.__dict__.copy()
        ret['coef'] = self.coef.copy()
        ret['domain'] = self.domain.copy()
        ret['window'] = self.window.copy()
        return ret

    def __setstate__(self, dict) :
        self.__dict__ = dict

    # Call

    def __call__(self, arg) :
        off, scl = pu.mapparms(self.domain, self.window)
        arg = off + scl*arg
        return ${nick}val(arg, self.coef)

    def __iter__(self) :
        return iter(self.coef)

    def __len__(self) :
        return len(self.coef)

    # Numeric properties.

    def __neg__(self) :
        return self.__class__(-self.coef, self.domain, self.window)

    def __pos__(self) :
        return self

    def __add__(self, other) :
        """Returns sum"""
        if isinstance(other, pu.PolyBase):
            if not self.has_sametype(other):
                raise TypeError("Polynomial types differ")
            elif not self.has_samedomain(other):
                raise TypeError("Domains differ")
            elif not self.has_samewindow(other):
                raise TypeError("Windows differ")
            else:
                coef = ${nick}add(self.coef, other.coef)
        else :
            try :
                coef = ${nick}add(self.coef, other)
            except :
                return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __sub__(self, other) :
        """Returns difference"""
        if isinstance(other, pu.PolyBase):
            if not self.has_sametype(other):
                raise TypeError("Polynomial types differ")
            elif not self.has_samedomain(other):
                raise TypeError("Domains differ")
            elif not self.has_samewindow(other):
                raise TypeError("Windows differ")
            else:
                coef = ${nick}sub(self.coef, other.coef)
        else :
            try :
                coef = ${nick}sub(self.coef, other)
            except :
                return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __mul__(self, other) :
        """Returns product"""
        if isinstance(other, pu.PolyBase):
            if not self.has_sametype(other):
                raise TypeError("Polynomial types differ")
            elif not self.has_samedomain(other):
                raise TypeError("Domains differ")
            elif not self.has_samewindow(other):
                raise TypeError("Windows differ")
            else:
                coef = ${nick}mul(self.coef, other.coef)
        else :
            try :
                coef = ${nick}mul(self.coef, other)
            except :
                return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __div__(self, other):
        # set to __floordiv__,  /, for now.
        return self.__floordiv__(other)

    def __truediv__(self, other) :
        # there is no true divide if the rhs is not a scalar, although it
        # could return the first n elements of an infinite series.
        # It is hard to see where n would come from, though.
        if np.isscalar(other) :
            # this might be overly restrictive
            coef = self.coef/other
            return self.__class__(coef, self.domain, self.window)
        else :
            return NotImplemented

    def __floordiv__(self, other) :
        """Returns the quotient."""
        if isinstance(other, pu.PolyBase):
            if not self.has_sametype(other):
                raise TypeError("Polynomial types differ")
            elif not self.has_samedomain(other):
                raise TypeError("Domains differ")
            elif not self.has_samewindow(other):
                raise TypeError("Windows differ")
            else:
                quo, rem = ${nick}div(self.coef, other.coef)
        else :
            try :
                quo, rem = ${nick}div(self.coef, other)
            except :
                return NotImplemented
        return self.__class__(quo, self.domain, self.window)

    def __mod__(self, other) :
        """Returns the remainder."""
        if isinstance(other, pu.PolyBase):
            if not self.has_sametype(other):
                raise TypeError("Polynomial types differ")
            elif not self.has_samedomain(other):
                raise TypeError("Domains differ")
            elif not self.has_samewindow(other):
                raise TypeError("Windows differ")
            else:
                quo, rem = ${nick}div(self.coef, other.coef)
        else :
            try :
                quo, rem = ${nick}div(self.coef, other)
            except :
                return NotImplemented
        return self.__class__(rem, self.domain, self.window)

    def __divmod__(self, other) :
        """Returns quo, remainder"""
        if isinstance(other, self.__class__) :
            if not self.has_samedomain(other):
                raise TypeError("Domains are not equal")
            elif not self.has_samewindow(other):
                raise TypeError("Windows are not equal")
            else:
                quo, rem = ${nick}div(self.coef, other.coef)
        else :
            try :
                quo, rem = ${nick}div(self.coef, other)
            except :
                return NotImplemented
        quo = self.__class__(quo, self.domain, self.window)
        rem = self.__class__(rem, self.domain, self.window)
        return quo, rem

    def __pow__(self, other) :
        try :
            coef = ${nick}pow(self.coef, other, maxpower = self.maxpower)
        except :
            raise
        return self.__class__(coef, self.domain, self.window)

    def __radd__(self, other) :
        try :
            coef = ${nick}add(other, self.coef)
        except :
            return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __rsub__(self, other):
        try :
            coef = ${nick}sub(other, self.coef)
        except :
            return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __rmul__(self, other) :
        try :
            coef = ${nick}mul(other, self.coef)
        except :
            return NotImplemented
        return self.__class__(coef, self.domain, self.window)

    def __rdiv__(self, other):
        # set to __floordiv__ /.
        return self.__rfloordiv__(other)

    def __rtruediv__(self, other) :
        # there is no true divide if the rhs is not a scalar, although it
        # could return the first n elements of an infinite series.
        # It is hard to see where n would come from, though.
        if len(self.coef) == 1 :
            try :
                quo, rem = ${nick}div(other, self.coef[0])
            except :
                return NotImplemented
        return self.__class__(quo, self.domain, self.window)

    def __rfloordiv__(self, other) :
        try :
            quo, rem = ${nick}div(other, self.coef)
        except :
            return NotImplemented
        return self.__class__(quo, self.domain, self.window)

    def __rmod__(self, other) :
        try :
            quo, rem = ${nick}div(other, self.coef)
        except :
            return NotImplemented
        return self.__class__(rem, self.domain, self.window)

    def __rdivmod__(self, other) :
        try :
            quo, rem = ${nick}div(other, self.coef)
        except :
            return NotImplemented
        quo = self.__class__(quo, self.domain, self.window)
        rem = self.__class__(rem, self.domain, self.window)
        return quo, rem

    # Enhance me
    # some augmented arithmetic operations could be added here

    def __eq__(self, other) :
        res = isinstance(other, self.__class__)                 and self.has_samecoef(other)                 and self.has_samedomain(other)                 and self.has_samewindow(other)
        return res

    def __ne__(self, other) :
        return not self.__eq__(other)

    #
    # Extra methods.
    #

    def copy(self) :
        """Return a copy.

        Return a copy of the current $name instance.

        Returns
        -------
        new_instance : $name
            Copy of current instance.

        """
        return self.__class__(self.coef, self.domain, self.window)

    def degree(self) :
        """The degree of the series.

        Notes
        -----
        .. versionadded:: 1.5.0

        """
        return len(self) - 1

    def cutdeg(self, deg) :
        """Truncate series to the given degree.

        Reduce the degree of the $name series to `deg` by discarding the
        high order terms. If `deg` is greater than the current degree a
        copy of the current series is returned. This can be useful in least
        squares where the coefficients of the high degree terms may be very
        small.

        Parameters
        ----------
        deg : non-negative int
            The series is reduced to degree `deg` by discarding the high
            order terms. The value of `deg` must be a non-negative integer.

        Returns
        -------
        new_instance : $name
            New instance of $name with reduced degree.

        Notes
        -----
        .. versionadded:: 1.5.0

        """
        return self.truncate(deg + 1)

    def trim(self, tol=0) :
        """Remove small leading coefficients

        Remove leading coefficients until a coefficient is reached whose
        absolute value greater than `tol` or the beginning of the series is
        reached. If all the coefficients would be removed the series is set to
        ``[0]``. A new $name instance is returned with the new coefficients.
        The current instance remains unchanged.

        Parameters
        ----------
        tol : non-negative number.
            All trailing coefficients less than `tol` will be removed.

        Returns
        -------
        new_instance : $name
            Contains the new set of coefficients.

        """
        coef = pu.trimcoef(self.coef, tol)
        return self.__class__(coef, self.domain, self.window)

    def truncate(self, size) :
        """Truncate series to length `size`.

        Reduce the $name series to length `size` by discarding the high
        degree terms. The value of `size` must be a positive integer. This
        can be useful in least squares where the coefficients of the
        high degree terms may be very small.

        Parameters
        ----------
        size : positive int
            The series is reduced to length `size` by discarding the high
            degree terms. The value of `size` must be a positive integer.

        Returns
        -------
        new_instance : $name
            New instance of $name with truncated coefficients.

        """
        isize = int(size)
        if isize != size or isize < 1 :
            raise ValueError("size must be a positive integer")
        if isize >= len(self.coef) :
            coef = self.coef
        else :
            coef = self.coef[:isize]
        return self.__class__(coef, self.domain, self.window)

    def convert(self, domain=None, kind=None, window=None) :
        """Convert to different class and/or domain.

        Parameters
        ----------
        domain : array_like, optional
            The domain of the converted series. If the value is None,
            the default domain of `kind` is used.
        kind : class, optional
            The polynomial series type class to which the current instance
            should be converted. If kind is None, then the class of the
            current instance is used.
        window : array_like, optional
            The window of the converted series. If the value is None,
            the default window of `kind` is used.

        Returns
        -------
        new_series_instance : `kind`
            The returned class can be of different type than the current
            instance and/or have a different domain.

        Notes
        -----
        Conversion between domains and class types can result in
        numerically ill defined series.

        Examples
        --------

        """
        if kind is None:
            kind = $name
        if domain is None:
            domain = kind.domain
        if window is None:
            window = kind.window
        return self(kind.identity(domain, window=window))

    def mapparms(self) :
        """Return the mapping parameters.

        The returned values define a linear map ``off + scl*x`` that is
        applied to the input arguments before the series is evaluated. The
        map depends on the ``domain`` and ``window``; if the current
        ``domain`` is equal to the ``window`` the resulting map is the
        identity.  If the coefficients of the ``$name`` instance are to be
        used by themselves outside this class, then the linear function
        must be substituted for the ``x`` in the standard representation of
        the base polynomials.

        Returns
        -------
        off, scl : floats or complex
            The mapping function is defined by ``off + scl*x``.

        Notes
        -----
        If the current domain is the interval ``[l_1, r_1]`` and the window
        is ``[l_2, r_2]``, then the linear mapping function ``L`` is
        defined by the equations::

            L(l_1) = l_2
            L(r_1) = r_2

        """
        return pu.mapparms(self.domain, self.window)

    def integ(self, m=1, k=[], lbnd=None) :
        """Integrate.

        Return an instance of $name that is the definite integral of the
        current series. Refer to `${nick}int` for full documentation.

        Parameters
        ----------
        m : non-negative int
            The number of integrations to perform.
        k : array_like
            Integration constants. The first constant is applied to the
            first integration, the second to the second, and so on. The
            list of values must less than or equal to `m` in length and any
            missing values are set to zero.
        lbnd : Scalar
            The lower bound of the definite integral.

        Returns
        -------
        integral : $name
            The integral of the series using the same domain.

        See Also
        --------
        ${nick}int : similar function.
        ${nick}der : similar function for derivative.

        """
        off, scl = self.mapparms()
        if lbnd is None :
            lbnd = 0
        else :
            lbnd = off + scl*lbnd
        coef = ${nick}int(self.coef, m, k, lbnd, 1./scl)
        return self.__class__(coef, self.domain, self.window)

    def deriv(self, m=1):
        """Differentiate.

        Return an instance of $name that is the derivative of the current
        series.  Refer to `${nick}der` for full documentation.

        Parameters
        ----------
        m : non-negative int
            The number of integrations to perform.

        Returns
        -------
        derivative : $name
            The derivative of the series using the same domain.

        See Also
        --------
        ${nick}der : similar function.
        ${nick}int : similar function for integration.

        """
        off, scl = self.mapparms()
        coef = ${nick}der(self.coef, m, scl)
        return self.__class__(coef, self.domain, self.window)

    def roots(self) :
        """Return list of roots.

        Return ndarray of roots for this series. See `${nick}roots` for
        full documentation. Note that the accuracy of the roots is likely to
        decrease the further outside the domain they lie.

        See Also
        --------
        ${nick}roots : similar function
        ${nick}fromroots : function to go generate series from roots.

        """
        roots = ${nick}roots(self.coef)
        return pu.mapdomain(roots, self.window, self.domain)

    def linspace(self, n=100, domain=None):
        """Return x,y values at equally spaced points in domain.

        Returns x, y values at `n` linearly spaced points across domain.
        Here y is the value of the polynomial at the points x. By default
        the domain is the same as that of the $name instance.  This method
        is intended mostly as a plotting aid.

        Parameters
        ----------
        n : int, optional
            Number of point pairs to return. The default value is 100.
        domain : {None, array_like}
            If not None, the specified domain is used instead of that of
            the calling instance. It should be of the form ``[beg,end]``.
            The default is None.

        Returns
        -------
        x, y : ndarrays
            ``x`` is equal to linspace(self.domain[0], self.domain[1], n)
            ``y`` is the polynomial evaluated at ``x``.

        .. versionadded:: 1.5.0

        """
        if domain is None:
            domain = self.domain
        x = np.linspace(domain[0], domain[1], n)
        y = self(x)
        return x, y



    @staticmethod
    def fit(x, y, deg, domain=None, rcond=None, full=False, w=None,
        window=$domain):
        """Least squares fit to data.

        Return a `$name` instance that is the least squares fit to the data
        `y` sampled at `x`. Unlike `${nick}fit`, the domain of the returned
        instance can be specified and this will often result in a superior
        fit with less chance of ill conditioning. Support for NA was added
        in version 1.7.0. See `${nick}fit` for full documentation of the
        implementation.

        Parameters
        ----------
        x : array_like, shape (M,)
            x-coordinates of the M sample points ``(x[i], y[i])``.
        y : array_like, shape (M,) or (M, K)
            y-coordinates of the sample points. Several data sets of sample
            points sharing the same x-coordinates can be fitted at once by
            passing in a 2D-array that contains one dataset per column.
        deg : int
            Degree of the fitting polynomial.
        domain : {None, [beg, end], []}, optional
            Domain to use for the returned $name instance. If ``None``,
            then a minimal domain that covers the points `x` is chosen.  If
            ``[]`` the default domain ``$domain`` is used. The default
            value is $domain in numpy 1.4.x and ``None`` in later versions.
            The ``'[]`` value was added in numpy 1.5.0.
        rcond : float, optional
            Relative condition number of the fit. Singular values smaller
            than this relative to the largest singular value will be
            ignored. The default value is len(x)*eps, where eps is the
            relative precision of the float type, about 2e-16 in most
            cases.
        full : bool, optional
            Switch determining nature of return value. When it is False
            (the default) just the coefficients are returned, when True
            diagnostic information from the singular value decomposition is
            also returned.
        w : array_like, shape (M,), optional
            Weights. If not None the contribution of each point
            ``(x[i],y[i])`` to the fit is weighted by `w[i]`. Ideally the
            weights are chosen so that the errors of the products
            ``w[i]*y[i]`` all have the same variance.  The default value is
            None.
            .. versionadded:: 1.5.0
        window : {[beg, end]}, optional
            Window to use for the returned $name instance. The default
            value is ``$domain``
            .. versionadded:: 1.6.0

        Returns
        -------
        least_squares_fit : instance of $name
            The $name instance is the least squares fit to the data and
            has the domain specified in the call.

        [residuals, rank, singular_values, rcond] : only if `full` = True
            Residuals of the least squares fit, the effective rank of the
            scaled Vandermonde matrix and its singular values, and the
            specified value of `rcond`. For more details, see
            `linalg.lstsq`.

        See Also
        --------
        ${nick}fit : similar function

        """
        if domain is None:
            domain = pu.getdomain(x)
        elif domain == []:
            domain = $domain

        if window == []:
            window = $domain

        xnew = pu.mapdomain(x, domain, window)
        res = ${nick}fit(xnew, y, deg, w=w, rcond=rcond, full=full)
        if full :
            [coef, status] = res
            return $name(coef, domain=domain, window=window), status
        else :
            coef = res
            return $name(coef, domain=domain, window=window)

    @staticmethod
    def fromroots(roots, domain=$domain, window=$domain) :
        """Return $name instance with specified roots.

        Returns an instance of $name representing the product
        ``(x - r[0])*(x - r[1])*...*(x - r[n-1])``, where ``r`` is the
        list of roots.

        Parameters
        ----------
        roots : array_like
            List of roots.
        domain : {array_like, None}, optional
            Domain for the resulting instance of $name. If none the domain
            is the interval from the smallest root to the largest. The
            default is $domain.
        window : array_like, optional
            Window for the resulting instance of $name. The default value
            is $domain.

        Returns
        -------
        object : $name instance
            Series with the specified roots.

        See Also
        --------
        ${nick}fromroots : equivalent function

        """
        [roots] = pu.as_series([roots], trim=False)
        if domain is None :
            domain = pu.getdomain(roots)
        deg = len(roots)
        off, scl = pu.mapparms(domain, window)
        rnew = off + scl*roots
        coef = ${nick}fromroots(rnew) / scl**deg
        return $name(coef, domain=domain, window=window)

    @staticmethod
    def identity(domain=$domain, window=$domain) :
        """Identity function.

        If ``p`` is the returned $name object, then ``p(x) == x`` for all
        values of x.

        Parameters
        ----------
        domain : array_like
            The resulting array must be of the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the domain.
        window : array_like
            The resulting array must be if the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the window.

        Returns
        -------
        identity : $name instance

        """
        off, scl = pu.mapparms(window, domain)
        coef = ${nick}line(off, scl)
        return $name(coef, domain, window)

    @staticmethod
    def basis(deg, domain=$domain, window=$domain):
        """$name polynomial of degree `deg`.

        Returns an instance of the $name polynomial of degree `d`.

        Parameters
        ----------
        deg : int
            Degree of the $name polynomial. Must be >= 0.
        domain : array_like
            The resulting array must be of the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the domain.
        window : array_like
            The resulting array must be if the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the window.

        Returns
        p : $name instance

        Notes
        -----
        .. versionadded:: 1.7.0

        """
        ideg = int(deg)
        if ideg != deg or ideg < 0:
            raise ValueError("deg must be non-negative integer")
        return $name([0]*ideg + [1], domain, window)

    @staticmethod
    def cast(series, domain=$domain, window=$domain):
        """Convert instance to equivalent $name series.

        The `series` is expected to be an instance of some polynomial
        series of one of the types supported by by the numpy.polynomial
        module, but could be some other class that supports the convert
        method.

        Parameters
        ----------
        series : series
            The instance series to be converted.
        domain : array_like
            The resulting array must be of the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the domain.
        window : array_like
            The resulting array must be if the form ``[beg, end]``, where
            ``beg`` and ``end`` are the endpoints of the window.

        Returns
        p : $name instance
            A $name series equal to the `poly` series.

        See Also
        --------
        convert -- similar instance method

        Notes
        -----
        .. versionadded:: 1.7.0

        """
        return series.convert(domain, $name, window)

oldlenPolyDomainErrorCoefficient arrays have no common type
    Return a domain suitable for given abscissae.

    Find a domain suitable for a polynomial or Chebyshev series
    defined at the values supplied.

    Parameters
    ----------
    x : array_like
        1-d array of abscissae whose domain will be determined.

    Returns
    -------
    domain : ndarray
        1-d array containing two values.  If the inputs are complex, then
        the two returned points are the lower left and upper right corners
        of the smallest rectangle (aligned with the axes) in the complex
        plane containing the points `x`. If the inputs are real, then the
        two points are the ends of the smallest interval containing the
        points `x`.

    See Also
    --------
    mapparms, mapdomain

    Examples
    --------
    >>> from numpy.polynomial import polyutils as pu
    >>> points = np.arange(4)**2 - 5; points
    array([-5, -4, -1,  4])
    >>> pu.getdomain(points)
    array([-5.,  4.])
    >>> c = np.exp(complex(0,1)*np.pi*np.arange(12)/6) # unit circle
    >>> pu.getdomain(c)
    array([-1.-1.j,  1.+1.j])

    Coefficient array is empty
    Remove "small" "trailing" coefficients from a polynomial.

    "Small" means "small in absolute value" and is controlled by the
    parameter `tol`; "trailing" means highest order coefficient(s), e.g., in
    ``[0, 1, 1, 0, 0]`` (which represents ``0 + x + x**2 + 0*x**3 + 0*x**4``)
    both the 3-rd and 4-th order coefficients would be "trimmed."

    Parameters
    ----------
    c : array_like
        1-d array of coefficients, ordered from lowest order to highest.
    tol : number, optional
        Trailing (i.e., highest order) elements with absolute value less
        than or equal to `tol` (default value is zero) are removed.

    Returns
    -------
    trimmed : ndarray
        1-d array with trailing zeros removed.  If the resulting series
        would be empty, a series containing a single zero is returned.

    Raises
    ------
    ValueError
        If `tol` < 0

    See Also
    --------
    trimseq

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> P.trimcoef((0,0,3,0,5,0,0))
    array([ 0.,  0.,  3.,  0.,  5.])
    >>> P.trimcoef((0,0,1e-3,0,1e-5,0,0),1e-3) # item == tol is trimmed
    array([ 0.])
    >>> i = complex(0,1) # works for complex
    >>> P.trimcoef((3e-4,1e-3*(1-i),5e-4,2e-5*(1+i)), 1e-3)
    array([ 0.0003+0.j   ,  0.0010-0.001j])

    Remove small Poly series coefficients.

    Parameters
    ----------
    seq : sequence
        Sequence of Poly series coefficients. This routine fails for
        empty sequences.

    Returns
    -------
    series : sequence
        Subsequence with trailing zeros removed. If the resulting sequence
        would be empty, return the first element. The returned sequence may
        or may not be a view.

    Notes
    -----
    Do not lose the type info if the sequence contains unknown objects.

    Base class for errors in this module.numpy.polynomial.polyutils
    Apply linear map to input points.

    The linear map ``offset + scale*x`` that maps the domain `old` to
    the domain `new` is applied to the points `x`.

    Parameters
    ----------
    x : array_like
        Points to be mapped. If `x` is a subtype of ndarray the subtype
        will be preserved.
    old, new : array_like
        The two domains that determine the map.  Each must (successfully)
        convert to 1-d arrays containing precisely two values.

    Returns
    -------
    x_out : ndarray
        Array of points of the same shape as `x`, after application of the
        linear map between the two domains.

    See Also
    --------
    getdomain, mapparms

    Notes
    -----
    Effectively, this implements:

    .. math ::
        x\_out = new[0] + m(x - old[0])

    where

    .. math ::
        m = \frac{new[1]-new[0]}{old[1]-old[0]}

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> old_domain = (-1,1)
    >>> new_domain = (0,2*np.pi)
    >>> x = np.linspace(-1,1,6); x
    array([-1. , -0.6, -0.2,  0.2,  0.6,  1. ])
    >>> x_out = P.mapdomain(x, old_domain, new_domain); x_out
    array([ 0.        ,  1.25663706,  2.51327412,  3.76991118,  5.02654825,
            6.28318531])
    >>> x - P.mapdomain(x_out, new_domain, old_domain)
    array([ 0.,  0.,  0.,  0.,  0.,  0.])

    Also works for complex numbers (and thus can be used to map any line in
    the complex plane to any other line therein).

    >>> i = complex(0,1)
    >>> old = (-1 - i, 1 + i)
    >>> new = (-1 + i, 1 - i)
    >>> z = np.linspace(old[0], old[1], 6); z
    array([-1.0-1.j , -0.6-0.6j, -0.2-0.2j,  0.2+0.2j,  0.6+0.6j,  1.0+1.j ])
    >>> new_z = P.mapdomain(z, old, new); new_z
    array([-1.0+1.j , -0.6+0.6j, -0.2+0.2j,  0.2-0.2j,  0.6-0.6j,  1.0-1.j ])

    
Utililty objects for the polynomial modules.

This module provides: error and warning objects; a polynomial base class;
and some routines used in both the `polynomial` and `chebyshev` modules.

Error objects
-------------
- `PolyError` -- base class for this sub-package's errors.
- `PolyDomainError` -- raised when domains are "mismatched."

Warning objects
---------------
- `RankWarning` -- raised by a least-squares fit when a rank-deficient
  matrix is encountered.

Base class
----------
- `PolyBase` -- The base class for the `Polynomial` and `Chebyshev`
  classes.

Functions
---------
- `as_series` -- turns a list of array_likes into 1-D arrays of common
  type.
- `trimseq` -- removes trailing zeros.
- `trimcoef` -- removes trailing coefficients that are less than a given
  magnitude (thereby removing the corresponding terms).
- `getdomain` -- returns a domain appropriate for a given set of abscissae.
- `mapdomain` -- maps points between domains.
- `mapparms` -- parameters of the linear map between domains.

Coefficient array is not 1-dtol must be non-negativeIssued by the generic Poly class when two domains don't match.

    This is raised when an binary operation is passed Poly objects with
    different domains.

    Issued by chebfit when the design matrix is rank deficient.
    Linear map parameters between domains.

    Return the parameters of the linear map ``offset + scale*x`` that maps
    `old` to `new` such that ``old[i] -> new[i]``, ``i = 0, 1``.

    Parameters
    ----------
    old, new : array_like
        Domains. Each domain must (successfully) convert to a 1-d array
        containing precisely two values.

    Returns
    -------
    offset, scale : scalars
        The map ``L(x) = offset + scale*x`` maps the first domain to the
        second.

    See Also
    --------
    getdomain, mapdomain

    Notes
    -----
    Also works for complex numbers, and thus can be used to calculate the
    parameters required to map any line in the complex plane to any other
    line therein.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> P.mapparms((-1,1),(-1,1))
    (0.0, 1.0)
    >>> P.mapparms((1,-1),(-1,1))
    (0.0, -1.0)
    >>> i = complex(0,1)
    >>> P.mapparms((-i,-1),(1,i))
    ((1+1j), (1+0j))

    /usr/lib/python2.7/dist-packages/numpy/polynomial/polyutils.py
    Return argument as a list of 1-d arrays.

    The returned list contains array(s) of dtype double, complex double, or
    object.  A 1-d argument of shape ``(N,)`` is parsed into ``N`` arrays of
    size one; a 2-d argument of shape ``(M,N)`` is parsed into ``M`` arrays
    of size ``N`` (i.e., is "parsed by row"); and a higher dimensional array
    raises a Value Error if it is not first reshaped into either a 1-d or 2-d
    array.

    Parameters
    ----------
    a : array_like
        A 1- or 2-d array_like
    trim : boolean, optional
        When True, trailing zeros are removed from the inputs.
        When False, the inputs are passed through intact.

    Returns
    -------
    [a1, a2,...] : list of 1-D arrays
        A copy of the input data as a list of 1-d arrays.

    Raises
    ------
    ValueError
        Raised when `as_series` cannot convert its input to 1-d arrays, or at
        least one of the resulting arrays is empty.

    Examples
    --------
    >>> from numpy import polynomial as P
    >>> a = np.arange(4)
    >>> P.as_series(a)
    [array([ 0.]), array([ 1.]), array([ 2.]), array([ 3.])]
    >>> b = np.arange(6).reshape((2,3))
    >>> P.as_series(b)
    [array([ 0.,  1.,  2.]), array([ 3.,  4.,  5.])]

    ranfmtrand__RandomState_ctornumpy.ndarray size changed
========================
Random Number Generation
========================

==================== =========================================================
Utility functions
==============================================================================
random               Uniformly distributed values of a given shape.
bytes                Uniformly distributed random bytes.
random_integers      Uniformly distributed integers in a given range.
random_sample        Uniformly distributed floats in a given range.
random               Alias for random_sample
ranf                 Alias for random_sample
sample               Alias for random_sample
choice               Generate a weighted random sample from a given array-like
permutation          Randomly permute a sequence / generate a random sequence.
shuffle              Randomly permute a sequence in place.
seed                 Seed the random number generator.
==================== =========================================================

==================== =========================================================
Compatibility functions
==============================================================================
rand                 Uniformly distributed values.
randn                Normally distributed values.
ranf                 Uniformly distributed floating point numbers.
randint              Uniformly distributed integers in a given range.
==================== =========================================================

==================== =========================================================
Univariate distributions
==============================================================================
beta                 Beta distribution over ``[0, 1]``.
binomial             Binomial distribution.
chisquare            :math:`\chi^2` distribution.
exponential          Exponential distribution.
f                    F (Fisher-Snedecor) distribution.
gamma                Gamma distribution.
geometric            Geometric distribution.
gumbel               Gumbel distribution.
hypergeometric       Hypergeometric distribution.
laplace              Laplace distribution.
logistic             Logistic distribution.
lognormal            Log-normal distribution.
logseries            Logarithmic series distribution.
negative_binomial    Negative binomial distribution.
noncentral_chisquare Non-central chi-square distribution.
noncentral_f         Non-central F distribution.
normal               Normal / Gaussian distribution.
pareto               Pareto distribution.
poisson              Poisson distribution.
power                Power distribution.
rayleigh             Rayleigh distribution.
triangular           Triangular distribution.
uniform              Uniform distribution.
vonmises             Von Mises circular distribution.
wald                 Wald (inverse Gaussian) distribution.
weibull              Weibull distribution.
zipf                 Zipf's distribution over ranked data.
==================== =========================================================

==================== =========================================================
Multivariate distributions
==============================================================================
dirichlet            Multivariate generalization of Beta distribution.
multinomial          Multivariate generalization of the binomial distribution.
multivariate_normal  Multivariate generalization of the normal distribution.
==================== =========================================================

==================== =========================================================
Standard distributions
==============================================================================
standard_cauchy      Standard Cauchy-Lorentz distribution.
standard_exponential Standard exponential distribution.
standard_gamma       Standard Gamma distribution.
standard_normal      Standard normal distribution.
standard_t           Standard Student's t-distribution.
==================== =========================================================

==================== =========================================================
Internal functions
==============================================================================
get_state            Get tuple representing internal state of generator.
set_state            Set state of generator.
==================== =========================================================

/usr/lib/python2.7/dist-packages/numpy/random/__init__.pyReturn a RandomState instance.

    This function exists solely to assist (un)pickling.
    [-   s   betas   binomials   bytess	   chisquares   exponentialt   fs   gammas	   geometrics	   get_states   gumbels   hypergeometrics   laplaces   logistics	   lognormals	   logseriess   multinomials   multivariate_normals   negative_binomials   noncentral_chisquares   noncentral_fs   normals   paretos   permutations   poissons   powers   rands   randints   randns   random_integerss   random_samples   rayleighs   seeds	   set_states   shuffles   standard_cauchys   standard_exponentials   standard_gammas   standard_normals
   standard_ts
   triangulars   uniforms   vonmisess   walds   weibulls   zipf/usr/lib/python2.7/dist-packages/numpy/random/info.py
========================
Random Number Generation
========================

==================== =========================================================
Utility functions
==============================================================================
random               Uniformly distributed values of a given shape.
bytes                Uniformly distributed random bytes.
random_integers      Uniformly distributed integers in a given range.
random_sample        Uniformly distributed floats in a given range.
permutation          Randomly permute a sequence / generate a random sequence.
shuffle              Randomly permute a sequence in place.
seed                 Seed the random number generator.
==================== =========================================================

==================== =========================================================
Compatibility functions
==============================================================================
rand                 Uniformly distributed values.
randn                Normally distributed values.
ranf                 Uniformly distributed floating point numbers.
randint              Uniformly distributed integers in a given range.
==================== =========================================================

==================== =========================================================
Univariate distributions
==============================================================================
beta                 Beta distribution over ``[0, 1]``.
binomial             Binomial distribution.
chisquare            :math:`\chi^2` distribution.
exponential          Exponential distribution.
f                    F (Fisher-Snedecor) distribution.
gamma                Gamma distribution.
geometric            Geometric distribution.
gumbel               Gumbel distribution.
hypergeometric       Hypergeometric distribution.
laplace              Laplace distribution.
logistic             Logistic distribution.
lognormal            Log-normal distribution.
logseries            Logarithmic series distribution.
negative_binomial    Negative binomial distribution.
noncentral_chisquare Non-central chi-square distribution.
noncentral_f         Non-central F distribution.
normal               Normal / Gaussian distribution.
pareto               Pareto distribution.
poisson              Poisson distribution.
power                Power distribution.
rayleigh             Rayleigh distribution.
triangular           Triangular distribution.
uniform              Uniform distribution.
vonmises             Von Mises circular distribution.
wald                 Wald (inverse Gaussian) distribution.
weibull              Weibull distribution.
zipf                 Zipf's distribution over ranked data.
==================== =========================================================

==================== =========================================================
Multivariate distributions
==============================================================================
dirichlet            Multivariate generalization of Beta distribution.
multinomial          Multivariate generalization of the binomial distribution.
multivariate_normal  Multivariate generalization of the normal distribution.
==================== =========================================================

==================== =========================================================
Standard distributions
==============================================================================
standard_cauchy      Standard Cauchy-Lorentz distribution.
standard_exponential Standard exponential distribution.
standard_gamma       Standard Gamma distribution.
standard_normal      Standard normal distribution.
standard_t           Standard Student's t-distribution.
==================== =========================================================

==================== =========================================================
Internal functions
==============================================================================
get_state            Get tuple representing internal state of generator.
set_state            Set state of generator.
==================== =========================================================

numpy.random.info/usr/lib/python2.7/dist-packages/numpy/testingCommon test support for all numpy test scripts.

This single module should provide all the common functionality for numpy tests
in a single location, so that test scripts can just import it and work right
away.

/usr/lib/python2.7/dist-packages/numpy/testing/__init__.pyskipifskipperSkipTest__test__set_testsetastestisgeneratorknownfailerskipper_genskipper_funcknownfailureifmake_decoratorskip_decorator_deprecated_impdeprecate_decoratorknownfail_decorator/usr/lib/python2.7/dist-packages/numpy/testing/decorators.py
    Filter deprecation warnings while running the test suite.

    This decorator can be used to filter DeprecationWarning's, to avoid
    printing them during the test suite run, while checking that the test
    actually raises a DeprecationWarning.

    Parameters
    ----------
    conditional : bool or callable, optional
        Flag to determine whether to mark test as deprecated or not. If the
        condition is a callable, it is used at runtime to dynamically make the
        decision. Default is True.

    Returns
    -------
    decorator : function
        The `deprecated` decorator itself.

    Notes
    -----
    .. versionadded:: 1.4.0

    numpy.testing.decorators
    Signals to nose that this function is or is not a test.

    Parameters
    ----------
    tf : bool
        If True, specifies that the decorated callable is a test.
        If False, specifies that the decorated callable is not a test.
        Default is True.

    Notes
    -----
    This decorator can't use the nose namespace, because it can be
    called from a non-test module. See also ``istest`` and ``nottest`` in
    ``nose.tools``.

    Examples
    --------
    `setastest` can be used in the following way::

      from numpy.testing.decorators import setastest

      @setastest(False)
      def func_with_test_in_name(arg1, arg2):
          pass

    
    Label a test as 'slow'.

    The exact definition of a slow test is obviously both subjective and
    hardware-dependent, but in general any individual test that requires more
    than a second or two should be labeled as slow (the whole suite consits of
    thousands of tests, so even a second is significant).

    Parameters
    ----------
    t : callable
        The test to label as slow.

    Returns
    -------
    t : callable
        The decorated test `t`.

    Examples
    --------
    The `numpy.testing` module includes ``import decorators as dec``.
    A test can be decorated as slow like this::

      from numpy.testing import *

      @dec.slow
      def test_big(self):
          print 'Big, slow test'

    
    Make function raise KnownFailureTest exception if given condition is true.

    If the condition is a callable, it is used at runtime to dynamically
    make the decision. This is useful for tests that may require costly
    imports, to delay the cost until the test suite is actually executed.

    Parameters
    ----------
    fail_condition : bool or callable
        Flag to determine whether to mark the decorated test as a known
        failure (if True) or not (if False).
    msg : str, optional
        Message to give on raising a KnownFailureTest exception.
        Default is None.

    Returns
    -------
    decorator : function
        Decorator, which, when applied to a function, causes SkipTest
        to be raised when `skip_condition` is True, and the function
        to be called normally otherwise.

    Notes
    -----
    The decorator itself is decorated with the ``nose.tools.make_decorator``
    function in order to transmit function name, and various other metadata.

    First warning for %s is not a DeprecationWarning( is %s)
Decorators for labeling and modifying behavior of test objects.

Decorators that merely return a modified version of the original
function object are straightforward. Decorators that return a new
function object need to use
::

  nose.tools.make_decorator(original_function)(decorator)

in returning the decorator, in order to preserve meta-data such as
function name, setup and teardown functions and so on - see
``nose.tools`` for more information.

Test skipped due to test conditionSkipper for normal test functions.Skipper for test generators.Skipping test: %s: %sSkip message with information about function being skipped.Test skipped due to known failure
    Make function raise SkipTest exception if a given condition is true.

    If the condition is a callable, it is used at runtime to dynamically
    make the decision. This is useful for tests that may require costly
    imports, to delay the cost until the test suite is actually executed.

    Parameters
    ----------
    skip_condition : bool or callable
        Flag to determine whether to skip the decorated test.
    msg : str, optional
        Message to give on raising a SkipTest exception. Default is None.

    Returns
    -------
    decorator : function
        Decorator which, when applied to a function, causes SkipTest
        to be raised when `skip_condition` is True, and the function
        to be called normally otherwise.

    Notes
    -----
    The decorator itself is decorated with the ``nose.tools.make_decorator``
    function in order to transmit function name, and various other metadata.

    Doctestenv_optELLIPSIS_recurserunTestswantFileKNOWNFAIL_nose_objgetmoduleisfailureunplugger_result_varnoKnownFailplug_runner_from_moduleafterContextnumpydoctestDocTestParsercan_configuredoctest_testswasSuccessfuldoctest_ignoreout_check_classdoctest_optflagsset_test_contextprepareTestRunnertest_finder_classdoctest_case_classdoctest_result_varloadTestsFromModuleNORMALIZE_WHITESPACENOSE_WITHOUT_KNOWNFAILgenerate_numpy_api.py/usr/lib/python2.7/dist-packages/numpy/testing/noseclasses.pynose.plugins.errorclassRaise this exception to mark a test as a known failing test.nose.plugins.basePlugin that installs a KNOWNFAIL error class for the
    KnownFailureClass exception.  When KnownFailureTest is raised,
    the exception will be logged in the knownfail attribute of the
    result, 'K' or 'KNOWNFAIL' (verbose) will be output, and the
    exception will not be counted as an error or failure. Configure `test` object to set test context

        We set the numpy / scipy standard doctest namespace

        Parameters
        ----------
        test : test object
            with ``globs`` dictionary defining namespace

        Returns
        -------
        None

        Notes
        -----
        `test` object modified in place
        Doctest doesn't want module %sRun Tests. Returns true on success, false on failure, and
        sets self.success to the same value.

        Because nose currently discards the test result object, but we need
        to return it to the user, override TestProgram.runTests to retain
        the result
        '<i%d'
        Find tests for the given object and any contained objects, and
        add them to `tests`.
        nose.util--no-knownfail
        Return true if the given object is defined in the given
        module.
        Disable special handling of KnownFailureTest exceptions Nose plugin to remove named plugin late in loading

    By default it removes the "doctest" plugin.
    numpy.testing.noseclassesobject must be a class or functionnpdirspdirgen_extf2py_extswig_extpyrex_extpyversion_test_argv_warn_optsaddpluginsadd_pluginswarningtypef2py_f90_extresetwarnings__versioninfo___show_system_infoprepare_test_args_get_custom_doctesterNot importing directory(?:^|[\\b_\\.%s-])[Bb]ench
        Run benchmarks for module using nose.

        Parameters
        ----------
        label : {'fast', 'full', '', attribute identifier}, optional
            Identifies the benchmarks to run. This can be a string to pass to
            the nosetests executable with the '-A' option, or one of several
            special values.  Special values are:
            * 'fast' - the default - which corresponds to the ``nosetests -A``
              option of 'not slow'.
            * 'full' - fast (as above) and slow benchmarks as in the
              'no -A' option to nosetests - this is the same as ''.
            * None or '' - run all tests.
            attribute_identifier - string passed directly to nosetests as '-A'.
        verbose : int, optional
            Verbosity value for benchmark outputs, in the range 1-10. Default is 1.
        extra_argv : list, optional
            List with any extra arguments to pass to nosetests.

        Returns
        -------
        success : bool
            Returns True if running the benchmarks works, False if an error
            occurred.

        Notes
        -----
        Benchmarks are like tests, but have names starting with "bench" instead
        of "test", and can be found under the "benchmarks" sub-directory of the
        module.

        Each NumPy module exposes `bench` in its namespace to run all benchmarks
        for it.

        Examples
        --------
        >>> success = np.lib.bench() #doctest: +SKIP
        Running benchmarks for numpy.lib
        ...
        using 562341 items:
        unique:
        0.11
        unique1d:
        0.11
        ratio: 1.0
        nUnique: 56230 == 56230
        ...
        OK

        >>> success #doctest: +SKIP
        True

        Running unit tests and doctests for %s Return instantiated plugin for doctests

        Allows subclassing of this class to override doctester

        A return value of None means use the nose builtin doctest plugin
        --cover-tests Generate argv for nosetest command

        Parameters
        ----------
        label : {'fast', 'full', '', attribute identifier}, optional
            see ``test`` docstring
        verbose : int, optional
            Verbosity value for test outputs, in the range 1-10. Default is 1.
        extra_argv : list, optional
            List with any extra arguments to pass to nosetests.

        Returns
        -------
        argv : list
            command line arguments that will be passed to nose
        Need nose >= %d.%d.%d for tests - see http://somethingaboutorange.com/mrl/projects/nose Import nose only when needed.
    --cover-erase--exeNumPy version %sRunning unit tests for %s--match--verbositySciPy is installed in %sPython version %snose.plugins.builtinNumPy is installed in %s--excludenose version %d.%d.%dSciPy version %snumpy.testing.nosetester
        Run tests for module using nose.

        Parameters
        ----------
        label : {'fast', 'full', '', attribute identifier}, optional
            Identifies the tests to run. This can be a string to pass to
            the nosetests executable with the '-A' option, or one of several
            special values.  Special values are:
            * 'fast' - the default - which corresponds to the ``nosetests -A``
              option of 'not slow'.
            * 'full' - fast (as above) and slow tests as in the
              'no -A' option to nosetests - this is the same as ''.
            * None or '' - run all tests.
            attribute_identifier - string passed directly to nosetests as '-A'.
        verbose : int, optional
            Verbosity value for test outputs, in the range 1-10. Default is 1.
        extra_argv : list, optional
            List with any extra arguments to pass to nosetests.
        doctests : bool, optional
            If True, run doctests in module. Default is False.
        coverage : bool, optional
            If True, report coverage of NumPy code. Default is False.
            (This requires the `coverage module:
             <http://nedbatchelder.com/code/modules/coverage.html>`_).
        raise_warnings : str or sequence of warnings, optional
            This specifies which warnings to configure as 'raise' instead
            of 'warn' during the test execution.  Valid strings are:

              - "develop" : equals ``(DeprecationWarning, RuntimeWarning)``
              - "release" : equals ``()``, don't raise on any warnings.

        Returns
        -------
        result : object
            Returns the result of running the tests as a
            ``nose.result.TextTestResult`` object.

        Notes
        -----
        Each NumPy module exposes `test` in its namespace to run all tests for it.
        For example, to run all tests for numpy.lib:

        >>> np.lib.test() #doctest: +SKIP

        Examples
        --------
        >>> result = np.lib.test() #doctest: +SKIP
        Running unit tests for numpy.lib
        ...
        Ran 976 tests in 3.933s

        OK

        >>> result.errors #doctest: +SKIP
        []
        >>> result.knownfail #doctest: +SKIP
        []
        --cover-package=%s
Nose test running.

This module implements ``test()`` and ``bench()`` functions for NumPy modules.

/usr/lib/python2.7/dist-packages/numpy/testing/nosetester.pyRunning benchmarks for %s--with-coverage
        Run tests for module using nose.

        This method does the heavy lifting for the `test` method. It takes all
        the same arguments, for details see `test`.

        See Also
        --------
        test

        Selection label should be a string
    Nose test runner.

    This class is made available as numpy.testing.Tester, and a test function
    is typically added to a package's __init__.py like so::

      from numpy.testing import Tester
      test = Tester().test

    Calling this test function finds and runs all tests associated with the
    package and all its sub-packages.

    Attributes
    ----------
    package_path : str
        Full path to the package to test.
    package_name : str
        Name of the package to test.

    Parameters
    ----------
    package : module, str or None, optional
        The package to test. If a string, this should be the full path to
        the package. If None (default), `package` is set to the module from
        which `NoseTester` is initialized.
    raise_warnings : str or sequence of warnings, optional
        This specifies which warnings to configure as 'raise' instead
        of 'warn' during the test execution.  Valid strings are:

          - "develop" : equals ``(DeprecationWarning, RuntimeWarning)``
          - "release" : equals ``()``, don't raise on any warnings.

        See Notes for more details.

    Notes
    -----
    The default for `raise_warnings` is
    ``(DeprecationWarning, RuntimeWarning)`` for the master branch of NumPy,
    and ``()`` for maintenance branches and released versions.  The purpose
    of this switching behavior is to catch as many warnings as possible
    during development, but not give problems for packaging of released
    versions.

    --with-doctest
    Given a path where a package is installed, determine its name.

    Parameters
    ----------
    filepath : str
        Path to a file. If the determination fails, "numpy" is returned.

    Examples
    --------
    >>> np.testing.nosetester.get_package_name('nonsense')
    'numpy'

    
    `importall` is DEPRECATED and will be removed in numpy 1.9.0

    Try recursively to import all subpackages under package.
    import %s as m`importall is deprecated, and will be remobed in numpy 1.9.0Failed importing %s: %s/usr/lib/python2.7/dist-packages/numpy/testing/numpytest.pynumpy.testing.numpytestefmtinp1inp2ACTUALHz>DESIREDactualiactualraliaseddifflibrundocs_entered_filterscls_attrdesiredidesiredrmax_nulpOpenQuerydiff_listrunstringAddCounterCloseQueryformat_excgetrefcountshowwarningPDH_FMT_LONG_showwarningassert_warnsDocTestRunnerRemoveCounterWarningManager_category_nameIgnoreExceptionMakeCounterPathassert_allcloseCollectQueryData_WARNING_DETAILScompat_func_namedecorate_methodsassert_array_lessassert_no_warningsprint_assert_equal_gen_alignment_dataassert_approx_equalassert_string_equalassert_array_max_ulp_assert_valid_refcountGetFormattedCounterValue+infassert_array_almost_equal_nulp[   s   assert_equals   assert_almost_equals   assert_approx_equals   assert_array_equals   assert_array_lesss   assert_string_equals   assert_array_almost_equals   assert_raisess   build_err_msgs   decorate_methodss   jiffiess   memusages   print_assert_equals   raisess   rands   rundocss	   runstrings   verboses   measures   assert_s   assert_array_almost_equal_nulps   assert_array_max_ulps   assert_warnss   assert_no_warningss   assert_allcloses   IgnoreExceptionisnan not supported for this typein place1
    Check that all items of arrays differ in at most N Units in the Last Place.

    Parameters
    ----------
    a, b : array_like
        Input arrays to be compared.
    maxulp : int, optional
        The maximum number of units in the last place that elements of `a` and
        `b` can differ. Default is 1.
    dtype : dtype, optional
        Data-type to convert `a` and `b` to if given. Default is None.

    Returns
    -------
    ret : ndarray
        Array containing number of representable floating point numbers between
        items in `a` and `b`.

    Raises
    ------
    AssertionError
        If one or more elements differ by more than `maxulp`.

    See Also
    --------
    assert_array_almost_equal_nulp : Compare two arrays relatively to their
        spacing.

    Examples
    --------
    >>> a = np.linspace(0., 1., 100)
    >>> res = np.testing.assert_array_max_ulp(a, np.arcsin(np.sin(a)))

    
    Test if two objects are equal, and print an error message if test fails.

    The test is performed with ``actual == desired``.

    Parameters
    ----------
    test_string : str
        The message supplied to AssertionError.
    actual : object
        The object to test for equality against `desired`.
    desired : object
        The expected result.

    Examples
    --------
    >>> np.testing.print_assert_equal('Test XYZ of func xyz', [0, 1], [0, 1])
    >>> np.testing.print_assert_equal('Test XYZ of func xyz', [0, 1], [0, 2])
    Traceback (most recent call last):
    ...
    AssertionError: Test XYZ of func xyz failed
    ACTUAL:
    [0, 1]
    DESIRED:
    [0, 2]

    Virtual Bytes
(shapes %s, %s mismatch)like isfinite, but always raise an error if type not supported instead of
    returning a TypeError object.

    Notes
    -----
    isfinite and other ufunc sometimes return a NotImplementedType object instead
    of raising any exception. This function is a wrapper to make sure an
    exception is always raised.

    This should be removed once this problem is solved at the Ufunc level.isinf not supported for this type
x and y %s location mismatch:Handling nan/inf: check that x and y have the nan/inf at the same
        locations.
    Return elapsed time for executing code in the namespace of the caller.

    The supplied code string is compiled with the Python builtin ``compile``.
    The precision of the timing is 10 milli-seconds. If the code will execute
    fast on this timescale, it can be executed many times to get reasonable
    timing accuracy.

    Parameters
    ----------
    code_str : str
        The code to be timed.
    times : int, optional
        The number of times the code is executed. Default is 1. The code is
        only compiled once.
    label : str, optional
        A label to identify `code_str` with. This is passed into ``compile``
        as the second argument (for run-time error messages).

    Returns
    -------
    elapsed : float
        Total elapsed time in seconds for executing `code_str` `times` times.

    Examples
    --------
    >>> etime = np.testing.measure('for i in range(1000): np.sqrt(i**2)',
    ...                            times=times)
    >>> print "Time for a single execution : ", etime / times, "s"
    Time for a single execution :  0.005 s

    For each item in x and y, return the number of representable floating
    points between them.

    Parameters
    ----------
    x : array_like
        first input array
    y : array_like
        second input array

    Returns
    -------
    nulp : array_like
        number of representable floating point numbers between each item in x
        and y.

    Examples
    --------
    # By definition, epsilon is the smallest number such as 1 + eps != 1, so
    # there should be exactly one ULP between 1 and 1 + eps
    >>> nulp_diff(1, 1 + np.finfo(x.dtype).eps)
    1.0
    like isinf, but always raise an error if type not supported instead of
    returning a TypeError object.

    Notes
    -----
    isinf and other ufunc sometimes return a NotImplementedType object instead
    of raising any exception. This function is a wrapper to make sure an
    exception is always raised.

    This should be removed once this problem is solved at the Ufunc level.like isnan, but always raise an error if type not supported instead of
    returning a TypeError object.

    Notes
    -----
    isnan and other ufunc sometimes return a NotImplementedType object instead
    of raising any exception. This function is a wrapper to make sure an
    exception is always raised.

    This should be removed once this problem is solved at the Ufunc level.Cannot enter %r twiceArrays are not almost equal up to %g ULPbinary offset=(%d, %d, %d), size=%d, dtype=%r, %s Return number of jiffies (1/100ths of a second) that this
    process has been scheduled in user mode. See man 5 proc. Arrays are not equal_nulp not implemented for complex arraySome doctests failed:
%sDESIRED: 

    Raise an assertion if two array_like objects are not ordered by less than.

    Given two array_like objects, check that the shape is equal and all
    elements of the first object are strictly smaller than those of the
    second object. An exception is raised at shape mismatch or incorrectly
    ordered values. Shape mismatch does not raise if an object has zero
    dimension. In contrast to the standard usage in numpy, NaNs are
    compared, no assertion is raised if both objects have NaNs in the same
    positions.



    Parameters
    ----------
    x : array_like
      The smaller object to check.
    y : array_like
      The larger object to compare.
    err_msg : string
      The error message to be printed in case of failure.
    verbose : bool
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
      If actual and desired objects are not equal.

    See Also
    --------
    assert_array_equal: tests objects for equality
    assert_array_almost_equal: test objects for equality up to precision



    Examples
    --------
    >>> np.testing.assert_array_less([1.0, 1.0, np.nan], [1.1, 2.0, np.nan])
    >>> np.testing.assert_array_less([1.0, 1.0, np.nan], [1, 2.0, np.nan])
    ...
    <type 'exceptions.ValueError'>:
    Arrays are not less-ordered
    (mismatch 50.0%)
     x: array([  1.,   1.,  NaN])
     y: array([  1.,   2.,  NaN])

    >>> np.testing.assert_array_less([1.0, 4.0], 3)
    ...
    <type 'exceptions.ValueError'>:
    Arrays are not less-ordered
    (mismatch 50.0%)
     x: array([ 1.,  4.])
     y: array(3)

    >>> np.testing.assert_array_less([1.0, 2.0, 3.0], [4])
    ...
    <type 'exceptions.ValueError'>:
    Arrays are not less-ordered
    (shapes (3,), (1,) mismatch)
     x: array([ 1.,  2.,  3.])
     y: array([4])

    Arrays are not almost equal to %d decimalsNot equal to tolerance rtol=%g, atol=%g
    Raise an assertion if two objects are not equal up to desired tolerance.

    The test is equivalent to ``allclose(actual, desired, rtol, atol)``.
    It compares the difference between `actual` and `desired` to
    ``atol + rtol * abs(desired)``.

    .. versionadded:: 1.5.0

    Parameters
    ----------
    actual : array_like
        Array obtained.
    desired : array_like
        Array desired.
    rtol : float, optional
        Relative tolerance.
    atol : float, optional
        Absolute tolerance.
    err_msg : str, optional
        The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
        If actual and desired are not equal up to specified precision.

    See Also
    --------
    assert_array_almost_equal_nulp, assert_array_max_ulp

    Examples
    --------
    >>> x = [1e-5, 1e-3, 1e-1]
    >>> y = np.arccos(np.cos(x))
    >>> assert_allclose(x, y, rtol=1e-5, atol=0)

    Unsupported dtype %s
    Holds the result of a single showwarning() call.

    Deprecated in 1.8.0

    Notes
    -----
    `WarningMessage` is copied from the Python 2.6 warnings module,
    so it can be used in NumPy with older Python versions.

    {message : %r, category : %r, filename : %r, lineno : %s, line : %r}
    Assert that works in release mode.

    The Python built-in ``assert`` does not work when executing code in
    optimized mode (the ``-O`` flag) - no byte-code is generated for it.

    For documentation on usage, refer to the Python documentation.

    
    A context manager that copies and restores the warnings filter upon
    exiting the context.

    The 'record' argument specifies whether warnings should be captured by a
    custom implementation of ``warnings.showwarning()`` and be appended to a
    list returned by the context manager. Otherwise None is returned by the
    context manager. The objects appended to the list are arguments whose
    attributes mirror the arguments to ``showwarning()``.

    The 'module' argument is to specify an alternative module to the module
    named 'warnings' and imported under that name. This argument is only useful
    when testing the warnings module itself.

    Deprecated in 1.8.0

    Notes
    -----
    `WarningManager` is a copy of the ``catch_warnings`` context manager
    from the Python 2.6 warnings module, with slight modifications.
    It is copied so it can be used in NumPy with older Python versions.

    error during assertion:

%s

%sGot warnings when calling %s: %sunary offset=(%d, %d), size=%d, dtype=%r, %sReturns an array of random numbers with the given shape.

    This only uses the standard library, so it is useful for testing purposes.
    
    assert_raises(exception_class, callable, *args, **kwargs)

    Fail unless an exception of class exception_class is thrown
    by callable when invoked with arguments args and keyword
    arguments kwargs. If a different type of exception is
    thrown, it will not be caught, and the test case will be
    deemed to have suffered an error, exactly as for an
    unexpected exception.

     Return memory usage of running python. [Not implemented]Test name: %s [repr failed]First warning for %s is not a %s( is %s)
    Fail if the given callable produces any warnings.

    .. versionadded:: 1.7.0

    Parameters
    ----------
    func : callable
        The callable to test.
    \*args : Arguments
        Arguments passed to `func`.
    \*\*kwargs : Kwargs
        Keyword arguments passed to `func`.

    Returns
    -------
    The value returned by `func`.

    out of placeReturn the signed-magnitude interpretation of the binary representation of
    x.item=%r
%sIgnoring this exception due to disabled feature/proc/%s/stat
(mismatch %s%%)
    Test if two strings are equal.

    If the given strings are equal, `assert_string_equal` does nothing.
    If they are not equal, an AssertionError is raised, and the diff
    between the strings is shown.

    Parameters
    ----------
    actual : str
        The string to test for equality against the expected string.
    desired : str
        The expected string.

    Examples
    --------
    >>> np.testing.assert_string_equal('abc', 'abc')
    >>> np.testing.assert_string_equal('abc', 'abcd')
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ...
    AssertionError: Differences in strings:
    - abc+ abcd?    +

    Differences in strings:
%s failed
ACTUAL: 

    Raise an assertion if two array_like objects are not equal.

    Given two array_like objects, check that the shape is equal and all
    elements of these objects are equal. An exception is raised at
    shape mismatch or conflicting values. In contrast to the standard usage
    in numpy, NaNs are compared like numbers, no assertion is raised if
    both objects have NaNs in the same positions.

    The usual caution for verifying equality with floating point numbers is
    advised.

    Parameters
    ----------
    x : array_like
        The actual object to check.
    y : array_like
        The desired, expected object.
    err_msg : str, optional
        The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
        If actual and desired objects are not equal.

    See Also
    --------
    assert_allclose: Compare two array_like objects for equality with desired
                     relative and/or absolute precision.
    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal

    Examples
    --------
    The first assert does not raise an exception:

    >>> np.testing.assert_array_equal([1.0,2.33333,np.nan],
    ...                               [np.exp(0),2.33333, np.nan])

    Assert fails with numerical inprecision with floats:

    >>> np.testing.assert_array_equal([1.0,np.pi,np.nan],
    ...                               [1, np.sqrt(np.pi)**2, np.nan])
    ...
    <type 'exceptions.ValueError'>:
    AssertionError:
    Arrays are not equal
    <BLANKLINE>
    (mismatch 50.0%)
     x: array([ 1.        ,  3.14159265,         NaN])
     y: array([ 1.        ,  3.14159265,         NaN])

    Use `assert_allclose` or one of the nulp (number of floating point values)
    functions for these cases instead:

    >>> np.testing.assert_allclose([1.0,np.pi,np.nan],
    ...                            [1, np.sqrt(np.pi)**2, np.nan],
    ...                            rtol=1e-10, atol=0)

    (?:^|[\\b_\\.%s-])[Tt]est
    Raise an assertion if two objects are not equal up to desired precision.

    .. note:: It is recommended to use one of `assert_allclose`,
              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`
              instead of this function for more consistent floating point
              comparisons.

    The test verifies identical shapes and verifies values with
    ``abs(desired-actual) < 0.5 * 10**(-decimal)``.

    Given two array_like objects, check that the shape is equal and all
    elements of these objects are almost equal. An exception is raised at
    shape mismatch or conflicting values. In contrast to the standard usage
    in numpy, NaNs are compared like numbers, no assertion is raised if
    both objects have NaNs in the same positions.

    Parameters
    ----------
    x : array_like
        The actual object to check.
    y : array_like
        The desired, expected object.
    decimal : int, optional
        Desired precision, default is 6.
    err_msg : str, optional
      The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
        If actual and desired are not equal up to specified precision.

    See Also
    --------
    assert_allclose: Compare two array_like objects for equality with desired
                     relative and/or absolute precision.
    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal

    Examples
    --------
    the first assert does not raise an exception

    >>> np.testing.assert_array_almost_equal([1.0,2.333,np.nan],
                                             [1.0,2.333,np.nan])

    >>> np.testing.assert_array_almost_equal([1.0,2.33333,np.nan],
    ...                                      [1.0,2.33339,np.nan], decimal=5)
    ...
    <type 'exceptions.AssertionError'>:
    AssertionError:
    Arrays are not almost equal
    <BLANKLINE>
    (mismatch 50.0%)
     x: array([ 1.     ,  2.33333,      NaN])
     y: array([ 1.     ,  2.33339,      NaN])

    >>> np.testing.assert_array_almost_equal([1.0,2.33333,np.nan],
    ...                                      [1.0,2.33333, 5], decimal=5)
    <type 'exceptions.ValueError'>:
    ValueError:
    Arrays are not almost equal
     x: array([ 1.     ,  2.33333,      NaN])
     y: array([ 1.     ,  2.33333,  5.     ])

    
    Raise an assertion if two objects are not equal.

    Given two objects (scalars, lists, tuples, dictionaries or numpy arrays),
    check that all elements of these objects are equal. An exception is raised
    at the first conflicting values.

    Parameters
    ----------
    actual : array_like
        The object to check.
    desired : array_like
        The expected object.
    err_msg : str, optional
        The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
        If actual and desired are not equal.

    Examples
    --------
    >>> np.testing.assert_equal([4,5], [4,6])
    ...
    <type 'exceptions.AssertionError'>:
    Items are not equal:
    item=1
     ACTUAL: 5
     DESIRED: 6

    
    Check that ufuncs don't mishandle refcount of object `1`.
    Used in a few regression tests.
    
    Raise an assertion if two items are not equal up to significant digits.

    .. note:: It is recommended to use one of `assert_allclose`,
              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`
              instead of this function for more consistent floating point
              comparisons.

    Given two numbers, check that they are approximately equal.
    Approximately equal is defined as the number of significant digits
    that agree.

    Parameters
    ----------
    actual : scalar
        The object to check.
    desired : scalar
        The expected object.
    significant : int, optional
        Desired precision, default is 7.
    err_msg : str, optional
        The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
      If actual and desired are not equal up to specified precision.

    See Also
    --------
    assert_allclose: Compare two array_like objects for equality with desired
                     relative and/or absolute precision.
    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal

    Examples
    --------
    >>> np.testing.assert_approx_equal(0.12345677777777e-20, 0.1234567e-20)
    >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345671e-20,
                                       significant=8)
    >>> np.testing.assert_approx_equal(0.12345670e-20, 0.12345672e-20,
                                       significant=8)
    ...
    <type 'exceptions.AssertionError'>:
    Items are not equal to 8 significant digits:
     ACTUAL: 1.234567e-021
     DESIRED: 1.2345672000000001e-021

    the evaluated condition that raises the exception is

    >>> abs(0.12345670e-20/1e-21 - 0.12345672e-20/1e-21) >= 10**-(8-1)
    True

    Cannot exit %r without entering firstkey=%r
%s
    Compare two arrays relatively to their spacing.

    This is a relatively robust method to compare two arrays whose amplitude
    is variable.

    Parameters
    ----------
    x, y : array_like
        Input arrays.
    nulp : int, optional
        The maximum number of unit in the last place for tolerance (see Notes).
        Default is 1.

    Returns
    -------
    None

    Raises
    ------
    AssertionError
        If the spacing between `x` and `y` for one or more elements is larger
        than `nulp`.

    See Also
    --------
    assert_array_max_ulp : Check that all items of arrays differ in at most
        N Units in the Last Place.
    spacing : Return the distance between x and the nearest adjacent number.

    Notes
    -----
    An assertion is raised if the following condition is not met::

        abs(x - y) <= nulps * spacing(max(abs(x), abs(y)))

    Examples
    --------
    >>> x = np.array([1., 1e-10, 1e-20])
    >>> eps = np.finfo(x.dtype).eps
    >>> np.testing.assert_array_almost_equal_nulp(x, x*eps/2 + x)

    >>> np.testing.assert_array_almost_equal_nulp(x, x*eps + x)
    ------------------------------------------------------------
    Traceback (most recent call last):
      ...
    AssertionError: X and Y are not equal to 1 ULP (max is 2)

    X and Y are not equal to %d ULP
    Raise an assertion if two items are not equal up to desired precision.

    .. note:: It is recommended to use one of `assert_allclose`,
              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`
              instead of this function for more consistent floating point
              comparisons.

    The test is equivalent to ``abs(desired-actual) < 0.5 * 10**(-decimal)``.

    Given two objects (numbers or ndarrays), check that all elements of these
    objects are almost equal. An exception is raised at conflicting values.
    For ndarrays this delegates to assert_array_almost_equal

    Parameters
    ----------
    actual : array_like
        The object to check.
    desired : array_like
        The expected object.
    decimal : int, optional
        Desired precision, default is 7.
    err_msg : str, optional
        The error message to be printed in case of failure.
    verbose : bool, optional
        If True, the conflicting values are appended to the error message.

    Raises
    ------
    AssertionError
      If actual and desired are not equal up to specified precision.

    See Also
    --------
    assert_allclose: Compare two array_like objects for equality with desired
                     relative and/or absolute precision.
    assert_array_almost_equal_nulp, assert_array_max_ulp, assert_equal

    Examples
    --------
    >>> import numpy.testing as npt
    >>> npt.assert_almost_equal(2.3333333333333, 2.33333334)
    >>> npt.assert_almost_equal(2.3333333333333, 2.33333334, decimal=10)
    ...
    <type 'exceptions.AssertionError'>:
    Items are not equal:
     ACTUAL: 2.3333333333333002
     DESIRED: 2.3333333399999998

    >>> npt.assert_almost_equal(np.array([1.0,2.3333333333333]),
    ...                         np.array([1.0,2.33333334]), decimal=9)
    ...
    <type 'exceptions.AssertionError'>:
    Arrays are not almost equal
    <BLANKLINE>
    (mismatch 50.0%)
     x: array([ 1.        ,  2.33333333])
     y: array([ 1.        ,  2.33333334])

    /usr/lib/python2.7/dist-packages/numpy/testing/utils.py
    generator producing data with different alignment and offsets
    to test simd vectorization

    Parameters
    ----------
    dtype : dtype
        data type to produce
    type : string
        'unary': create data for unary operations, creates one input
                 and output array
        'binary': create data for unary operations, creates two input
                 and output array
    max_size : integer
        maximum size of data to produce

    Returns
    -------
    if type is 'unary' yields one output, one input array and a message
    containing information on the data
    if type is 'binary' yields one output array, two input array and a message
    containing information on the data

    
    Apply a decorator to all methods in a class matching a regular expression.

    The given decorator is applied to all public methods of `cls` that are
    matched by the regular expression `testmatch`
    (``testmatch.search(methodname)``). Methods that are private, i.e. start
    with an underscore, are ignored.

    Parameters
    ----------
    cls : class
        Class whose methods to decorate.
    decorator : function
        Decorator to apply to methods
    testmatch : compiled regexp or str, optional
        The regular expression. Default value is None, in which case the
        nose default (``re.compile(r'(?:^|[\b_\.%s-])[Tt]est' % os.sep)``)
        is used.
        If `testmatch` is a string, it is compiled to a regular expression
        first.

    
Utility function to facilitate testing.

isfinite not supported for this typex and y do not have the same shape: %s - %s
    Run doctests found in the given file.

    By default `rundocs` raises an AssertionError on failure.

    Parameters
    ----------
    filename : str
        The path to the file for which the doctests are run.
    raise_on_error : bool
        Whether to raise an AssertionError when a doctest fails. Default is
        True.

    Notes
    -----
    The doctests can be run by the user/developer by adding the ``doctests``
    argument to the ``test()`` call. For example, to run all tests (including
    doctests) for `numpy.lib`:

    >>> np.lib.test(doctests=True) #doctest: +SKIP
    X and Y are not equal to %d ULP (max is %g)in place2
    Fail unless the given callable throws the specified warning.

    A warning of class warning_class should be thrown by the callable when
    invoked with arguments args and keyword arguments kwargs.
    If a different type of warning is thrown, it will not be caught, and the
    test case will be deemed to have suffered an error.

    .. versionadded:: 1.4.0

    Parameters
    ----------
    warning_class : class
        The class defining the warning that `func` is expected to throw.
    func : callable
        The callable to test.
    \*args : Arguments
        Arguments passed to `func`.
    \*\*kwargs : Kwargs
        Keyword arguments passed to `func`.

    Returns
    -------
    The value returned by `func`.

     Return virtual memory size in bytes of the running python.
        Items are not equal to %d significant digits: Return number of jiffies (1/100ths of a second) that this
    process has been scheduled in user mode. [Emulation with time.time]. (   t
   comparisont   xt   yt   err_msgt   verboset   headert   arrayt   isnant   isinft   anyt   allt   inft   isnumbert   chk_same_positiont   condt   msgt   x_isnant   y_isnant   x_isinft   y_isinft   x_idt   y_idt   valt   reducedt   matcht   et	   tracebackt   efmt(   t   actualt   desiredt   err_msgt   verboset   kt   it   ndarrayt   isscalart   signbitt   iscomplexobjt   realt   imagt   msgt
   usecomplext   actualrt   actualit   desiredrt   desiredit   isdesnant   isactnan1.8.2/usr/lib/python2.7/dist-packages/numpy/version.py4563730a2d036307f1b67b2856d749aabdd8d546EQEQLPARRPARR_OKtmpl_isdir_sget__sset_get_opmktimewindirAPPDATAPowerPCS_IWGRPS_IWOTH_ep_mapcan_addcpythongetinfohashCmphashcmpmac_vernew_keyor_testos_namepreviewsubitemtotuplezip_prezipinfo<execfile>HOMEPATHMETADATAPKG_INFO_dep_map_distmap_listdirand_testapp_dataegg_rootold_openparsestrst_mtimeHOMEDRIVE_dirindexadd_entryapp_homesdate_timefile_sizeinsert_onlinecachereadPlistsubscribeFileFinder_added_new_sget_dict_sget_none_sset_dict_sset_nonebest_matchentry_keysnamedtupleprovDarwinImpImporterUSERPROFILE_is_currenthas_versionmodule_pathscript_codeImmutableSet_safe_string_sget_object_sset_objectacquire_lockcached_filesfind_pluginshas_resourcemanifest_modrelease_locksys_platform_build_master_eager_to_zip_get_metadata_setup_prefix_zipinfo_nameplist_contentProductVersion_zip_manifestsget_cache_pathget_entry_infooriginal_errorparsed_versionresource_isdirextraction_pathresource_existsresource_streamscript_filenamePYTHON_EGG_CACHESourceFileLoader_parsed_pkg_info_resource_to_zipdistribution_keyextraction_errorload_entry_pointplatform_machineplatform_versionresource_listdirIResourceProvider_extract_resourcecleanup_resourcesis_invalid_marker_Requirement__hash_get_date_and_size_markerlib_evaluateget_resource_streamget_resource_stringnormalize_exceptionset_extraction_path_get_eager_resources_compute_dependencies_preparse_requirementget_resource_filenameAvailableDistributions_Distribution__dep_map_Requirement__iteratorcheck_version_conflict_ZipManifests__iterator_build_from_requirementsT+FT..T-TF++--TF+Fparenthesis is never closedunexpected EOF while parsingfinal-_warn_unsafe_extraction_path_DistInfoDistribution__dep_map[E   s   requires
   run_scripts   get_providers   get_distributions   load_entry_points   get_entry_maps   get_entry_infos   iter_entry_pointss   resource_strings   resource_streams   resource_filenames   resource_listdirs   resource_existss   resource_isdirs   declare_namespaces   working_sets   add_activation_listeners   find_distributionss   set_extraction_paths   cleanup_resourcess   get_default_caches   Environments
   WorkingSets   ResourceManagers   Distributions   Requirements
   EntryPoints   ResolutionErrors   VersionConflicts   DistributionNotFounds   UnknownExtras   ExtractionErrors   parse_requirementss   parse_versions	   safe_names   safe_versions   get_platforms   compatible_platformss   yield_liness   split_sectionss
   safe_extras   to_filenames   invalid_markers   evaluate_markers   ensure_directorys   normalize_paths   EGG_DISTs   BINARY_DISTs   SOURCE_DISTs   CHECKOUT_DISTs   DEVELOP_DISTs   IMetadataProviders   IResourceProviders   FileMetadatas   PathMetadatas   EggMetadatas   EmptyProviders   empty_providers   NullProviders   EggProviders   DefaultProviders   ZipProviders   register_finders   register_namespace_handlers   register_loader_types   fixup_namespace_packagess   get_importers   run_mains   AvailableDistributionsApplication DataRegister `namespace_handler` to declare namespace packages

    `importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
    handler), and `namespace_handler` is a callable like this::

        def namespace_handler(importer, path_entry, moduleName, module):
            # return a path_entry to use for child packages

    Namespace handlers are only called if the importer object has already
    agreed that it can handle the relevant path item, and they should only
    return a subpath if the module __path__ does not already contain an
    equivalent subpath.  For an example namespace handler, see
    ``pkg_resources.file_ns_handler``.
    
        Validate text as a PEP 426 environment marker; return an exception
        if invalid or False otherwise.
        List the contents of the named resource directory
        Return True if the file_path is current for this zip_path
        Ensure that previously-declared namespace packages include path_itemScan `search_path` for distributions usable in this environment

        Any distributions found are added to the environment.
        `search_path` should be a sequence of ``sys.path`` items.  If not
        supplied, ``sys.path`` is used.  Only distributions conforming to
        the platform/python version defined at initialization are added.
        Module %s was already imported from %s, but %s is being added to sys.pathSplit a string or iterable thereof into (section, content) pairs

    Each ``section`` is a stripped version of the section header ("[section]")
    and each ``content`` is a list of stripped lines excluding blank lines and
    comment-only lines.  If there are any such lines before the first section
    header, they're returned in a first ``section`` of ``None``.
    Find all activatable distributions in `plugin_env`

        Example usage::

            distributions, errors = working_set.find_plugins(
                Environment(plugin_dirlist)
            )
            # add plugins+libs to sys.path
            map(working_set.add, distributions)
            # display errors
            print('Could not load', errors)

        The `plugin_env` should be an ``Environment`` instance that contains
        only distributions that are in the project's "plugin directory" or
        directories. The `full_env`, if supplied, should be an ``Environment``
        contains all currently-available distributions.  If `full_env` is not
        supplied, one is created automatically from the ``WorkingSet`` this
        method is called on, which will typically mean that every directory on
        ``sys.path`` will be scanned for distributions.

        `installer` is a standard installer callback as used by the
        ``resolve()`` method. The `fallback` flag indicates whether we should
        attempt to resolve older versions of a plugin if the newest version
        cannot be resolved.

        This method returns a 2-tuple: (`distributions`, `error_info`), where
        `distributions` is a list of the distributions found in `plugin_env`
        that were loadable, along with any other distributions that are needed
        to resolve their dependencies.  `error_info` is a dictionary mapping
        unloadable plugin distributions to an exception instance describing the
        error that occurred. Usually this will be a ``DistributionNotFound`` or
        ``VersionConflict`` instance.
        Can't require() without a distributionIs the named resource a directory?  (like ``os.path.isdir()``)
        Evaluate a PEP 426 environment marker on CPython 2.4+.
        Return a boolean indicating the marker result in this environment.
        Raise SyntaxError if marker is invalid.

        This implementation uses the 'parser' module, which is not implemented
        on
        Jython and has been superseded by the 'ast' module in Python 2.6 and
        later.
        Return a true filesystem path for specified resource(\d+ | [a-z]+ | \.| -)Return this platform's string for platform-specific distributions

    XXX Currently this is the same as ``distutils.util.get_platform()``, but it
    needs some hacks for Linux and Mac OS X.
    Wrap an actual or potential sys.path entry w/metadata, .dist-info styleversion specmacosx-Return a ``Requirement`` that matches this distribution exactlyPython-EggsFind a distribution matching requirement `req`

        If there is an active distribution for the requested project, this
        returns it as long as it meets the version requirement specified by
        `req`.  But, if there is an active distribution for the project and it
        does *not* meet the `req` requirement, ``VersionConflict`` is raised.
        If there is no active distribution for the requested project, ``None``
        is returned.
        \s*(<=?|>=?|==|!=)\s*((\w|[-.])+)List of resource names in the directory (like ``os.listdir()``)Find distribution best matching `req` and usable on `working_set`

        This calls the ``find(req)`` method of the `working_set` to see if a
        suitable distribution is already active.  (This may raise
        ``VersionConflict`` if an unsuitable version of the project is already
        active in the specified `working_set`.)  If a suitable distribution
        isn't active, this method returns the newest distribution in the
        environment that meets the ``Requirement`` in `req`.  If no suitable
        distribution is found, and `installer` is supplied, then the result of
        calling the environment's ``obtain(req, installer)`` method will be
        returned.
        Invalid group name
        Prepare the master working set.
        manifest mtimeSearchable snapshot of distributions on a search pathParse a single entry point from string `src`

        Entry point syntax follows the form::

            name = some.module:some.attr [extra1, extra2]

        The entry name and module name are required, but the ``:attrs`` and
        ``[extras]`` parts are optional
        An already-installed version conflicts with the requested version/usr/lib/python2.7/dist-packages/pkg_resources.pyDeclare that package 'packageName' is a namespace package operator not allowed in environment markers.whlYield ``Requirement`` objects for each specification in `strs`

    `strs` must be an instance of ``basestring``, or a (possibly-nested)
    iterable thereof.
    Metadata handler for standalone PKG-INFO files

    Usage::

        metadata = FileMetadata("/path/to/PKG-INFO")

    This provider rejects all data and metadata requests except for PKG-INFO,
    which is treated as existing, and will be the contents of the file at
    the provided location.
    Unbuilt egg for Entry points must be listed in groups\s*\[Object representing an advertised importable objectTry to implement resources and metadata for arbitrary PEP 302 loadersReturn an adapter factory for `ob` from `registry`Yield named metadata resource as list of non-blank non-comment lines

       Leading and trailing whitespace is stripped from each line, and lines
       with ``#`` as the first non-blank character are omitted.Register `distribution_finder` to find distributions in sys.path items

    `importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
    handler), and `distribution_finder` is a callable that, passed a path
    item and the importer instance, yields ``Distribution`` instances found on
    that path item.  See ``pkg_resources.find_on_path`` for an example.Snapshot distributions available on a search path

        Any distributions found on `search_path` are added to the environment.
        `search_path` should be a sequence of ``sys.path`` items.  If not
        supplied, ``sys.path`` is used.

        `platform` is an optional string specifying the name of the platform
        that platform-specific distributions must be compatible with.  If
        unspecified, it defaults to the current platform.  `python` is an
        optional string naming the desired version of Python (e.g. ``'3.3'``);
        it defaults to the current version.

        You may explicitly set `platform` (and/or `python`) to ``None`` if you
        wish to map *all* distributions, not just those compatible with the
        running platform or Python version.
        Duplicate entry pointAdd `dist` to working set, associated with `entry`

        If `entry` is unspecified, it defaults to the ``.location`` of `dist`.
        On exit from this routine, `entry` is added to the end of the working
        set's ``.entries`` (if it wasn't already present).

        `dist` is only added to the working set if it's for a project that
        doesn't already have a distribution in the set, unless `replace=True`.
        If it's added, any callbacks registered with the ``subscribe()`` method
        will be called.
        Perform any platform-specific postprocessing of `tempname`

        This is where Mac header rewrites should be done; other platforms don't
        have anything special they should do.

        Resource providers should call this method ONLY after successfully
        extracting a compressed resource.  They must NOT call it on resources
        that are already in the filesystem.

        `tempname` is the current (temporary) name of the file, and `filename`
        is the name it will be renamed to by the caller after this routine
        returns.
        Compute an ns-package subpath for a filesystem or zipfile importerAdd an environment or distribution to an environmentAdd a path item to ``.entries``, finding any distributions on it

        ``find_distributions(entry, True)`` is used to find distributions
        corresponding to the path entry, and they are added.  `entry` is
        always appended to ``.entries``, even if it is already present.
        (This is because ``sys.path`` can contain the same value more than
        once, and the ``.entries`` of the ``sys.path`` WorkingSet should always
        equal ``sys.path``.)
        The named metadata resource as a string10.3No script named %r
Package resource API
--------------------

A resource is a logical file contained within a package, or a logical
subdirectory thereof.  The package resource API expects resource names
to have their path parts separated with ``/``, *not* whatever the local
path separator is.  Do not use os.path operations to manipulate resource
names being passed into the API.

The package resource API is designed to work with normal filesystem packages,
.egg files, and unpacked .egg files.  It can also work in a limited way with
.zip files and with custom PEP 302 loaders that support the ``get_data()``
method.
Parse an entry point groupentry_points.txtLocate distribution `dist_spec` and run its `script_name` scriptIs distribution `dist` acceptable for this environment?

        The distribution must match the platform and python version
        requirements specified when this environment was created, or False
        is returned.
        Return an IResourceProvider for the named module or requirementReturn what this distribution's standard .egg filename should beEntryPoint must be in 'name=module:attrs [extras]' format%s is writable by group/others and vulnerable to attack when used with get_resource_filename. Consider a more secure location (set with .set_extraction_path or the PYTHON_EGG_CACHE environment variable).List of metadata names in the directory (like ``os.listdir()``)Manage resource extraction and packages [%s]-tmpReturn specified resource as a stringAbstract base for dependency resolution errors(?P<name>[^-]+)( -(?P<ver>[^-]+) (-py(?P<pyver>[^-]+) (-(?P<plat>.+))? )? )?
        Evaluate a PEP 426 environment marker using markerlib.
        Return a boolean indicating the marker result in this environment.
        Raise SyntaxError if marker is invalid.
        importlib._bootstrap[^A-Za-z0-9.]+Convert an arbitrary string to a standard 'extra' name

    Any runs of non-alphanumeric characters are replaced with a single '_',
    and the result is always lowercased.
    Determine the default cache location

    This returns the ``PYTHON_EGG_CACHE`` environment variable, if set.
    Otherwise, on Windows, it returns a "Python-Eggs" subdirectory of the
    "Application Data" directory.  On all other systems, it's "~/.python-eggs".
    Ensure that the parent directory of `path` existsEntry point %r not foundReturn a readable file-like object for `resource_name`

        `manager` must be an ``IResourceManager``\w+(\.\w+)*$Can't perform this operation for loaders without 'get_data()'macosx-%s-%s
        Delete all extracted resource files and directories, returning a list
        of the file and directory names that could not be successfully removed.
        This function does not have any concurrency protection, so it should
        generally only be called when the extraction path is a temporary
        directory exclusive to a single process.  This method is not
        automatically called; you must call it explicitly or register it as an
        ``atexit`` function if you wish to ensure cleanup of a temporary
        directory used for extractions.
        
        Load a manifest at path or return a suitable manifest already loaded.
        Parse and cache metadataResource support for zips and eggs"os.rename" and "os.unlink" are not supported on this platformRemove `dist` from the environment\s*\\\s*(#.*)?$Convert a project or version name to its filename-escaped form

    Any '-' characters are currently replaced with '_'.
    Provider based on a virtual filesystem
        Build a working set from a requirement spec. Rewrites sys.path.
        
    zip manifest builder
    Ensure distribution is importable on `path` (default=sys.path)%s-%s-py%sIs the named metadata a directory?  (like ``os.path.isdir()``)Locate distribution for `requires` and run `script_name` scriptReturn a current distribution object for a Requirement or stringresource_filename() only supported for .egg, not .zipInsert self.location in path before its nearest parent directoryYield non-empty/non-comment lines of a ``basestring`` or sequence%s is not a subpath of %sObtain a distribution matching `requirement` (e.g. via download)

        Obtain a distro that matches requirement (e.g. via download).  In the
        base ``Environment`` class, this routine just returns
        ``installer(requirement)``, unless `installer` is None, in which case
        None is returned instead.  This method is a hook that allows subclasses
        to attempt other ways of obtaining a distribution before falling back
        to the `installer` argument.requires.txtReturn this platform's maximum compatible version.

    distutils.util.get_platform() normally reports the minimum version
    of Mac OS X that would be required to *use* extensions produced by
    distutils.  But what we want when checking compatibility is to know the
    version of Mac OS X that we are *running*.  To allow usage of packages that
    explicitly require a newer version of Mac OS X, we must also know the
    current version of the OS.

    If this condition occurs for any other platform with a version in its
    platform strings, this function should be extended accordingly.
    Yield distributions accessible on a sys.path directory\1==\2\3Provides-ExtraConvert 'Foobar (1); baz' to ('Foobar ==1', 'baz')
        Split environment marker, add == prefix to version specifiers as
        necessary, and remove parenthesis.
        Expected only one requirementCan't add %r to environment*finalProvides access to package resources in the filesystemMissing 'Version:' header and/or %s fileNo requirements found*final-DO NOT CALL THIS UNDOCUMENTED METHOD; use Requirement.parse()!Is the named resource an existing directory?Parse a map of entry point groupsReturn the `name` entry point of `group` or raise ImportErroremail.parserYield the unique project names of the available distributionsPlease set the PYTHON_EGG_CACHE enviroment variableDoes the package contain the named resource?macosx-%d.%d-%sIn-place addition of a distribution or environmentReturn a newest-to-oldest list of distributions for `project_name`

        Uses case-insensitive `project_name` comparison, assuming all the
        project's distributions use their project's name converted to all
        lowercase as their key.

        Give an error message for problems extracting file(s)
        If the default extraction path is overridden and set to an insecure
        location, such as /tmp, it opens up an opportunity for an attacker to
        replace an extracted file with an unauthorized payload. Warn the user
        if a known insecure location is used.

        See Distribute #375 for more details.
        
        Given a SyntaxError from a marker evaluation, normalize the error
        message:
         - Remove indications of filename and line number.
         - Replace platform-specific error messages with standard error
           messages.
        
    Supplement ZipFile class to support context manager for Python 2.6
    x[%s]Language feature not supported in environment markers"os.mkdir" not supported on this platform.A requested distribution was not found([\(,])\s*(\d.*?)\s*([,\)])Return the entry point map for `group`, or the full entry mapCreate working set from list of path entries (default=sys.path)Convert an arbitrary string to a standard version string

    Spaces become dots, and all other non-alphanumeric characters become
    dashes, with runs of multiple dashes condensed to a single dash.
    Expected string, Requirement, or DistributionDuplicate group nameDistribution doesn't have an "extra feature" of the given nameCan't extract file(s) to egg cache

The following error occurred while trying to extract file(s) to the Python egg
cache:

  %s

The Python egg cache directory is currently set to:

  %s

Perhaps your account does not have write access to this directory?  You can
change the cache directory by setting the PYTHON_EGG_CACHE environment
variable to point to an accessible directory.
Create a metadata provider from a zipimporterAn object that provides access to package resourcesDelegate all unrecognized public attributes to .metadata provider.$extractRegister `provider_factory` to make providers for `loader_type`

    `loader_type` is the type or class of a PEP 302 ``module.__loader__``,
    and `provider_factory` is a function that, passed a *module* object,
    returns an ``IResourceProvider`` for that module.
    Only plain strings allowed in environment markerseager_resources.txtA collection of active distributions on sys.path (or a similar list)Missing distribution spec/System/Library/CoreServices/SystemVersion.plisttop_level.txt
    Memoized zipfile manifests.
    Ensure that named package includes a subpath of path_item (if needed)Comparison or logical expression expectedYield distributions accessible via `path_item`project_name version py_version platform location precedenceUnknown name %rInvalid module name\s*\]Add `dist` if we ``can_add()`` it and it has not already been added
        [unknown version]Invoke `callback` for all distributions (including existing ones)Set the base path where resources will be extracted to, if needed.

        If you do not call this routine before any extractions take place, the
        path defaults to the return value of ``get_default_cache()``.  (Which
        is based on the ``PYTHON_EGG_CACHE`` environment variable, with various
        platform-specific fallbacks.  See that routine's documentation for more
        details.)

        Resources are extracted to subdirectories of this path based upon
        information given by the ``IResourceProvider``.  You may set this to a
        temporary directory, but then you must call ``cleanup_resources()`` to
        delete the extracted files when done.  There is no guarantee that
        ``cleanup_resources()`` will be able to remove all extracted files.

        (Note: you may not change the extraction path for a given resource
        manager once resources have been extracted, unless you first call
        ``cleanup_resources()``.)
        Convert an arbitrary string to a standard distribution name

    Any runs of non-alphanumeric/. characters are replaced with a single '-'.
    List of Requirements needed for this distro if `extras` are used
    Find eggs in zip files; possibly multiple nested eggs.
    Return `name` entry point of `group` for `dist` or raise ImportErrorCan't change extraction path, files already extractedReturn a string containing the contents of `resource_name`

        `manager` must be an ``IResourceManager``Not a package:Requires-DistExecute the named script in the supplied namespace dictionaryInvalid section headingCan't perform this operation for unregistered loader typemd5=Return absolute location in cache for `archive_name` and `names`

        The parent directory of the resulting path will be created if it does
        not already exist.  `archive_name` should be the base filename of the
        enclosing egg (which may not be the name of the enclosing zipfile!),
        including its ".egg" extension.  `names`, if provided, should be a
        sequence of path name parts "under" the egg's extraction location.

        This method should only be called by resource providers that need to
        obtain an extraction location, and only for names they intend to
        extract, as it tracks the generated names for possible cleanup later.
        Copy this distribution, substituting in any changed keyword argsMetadata provider for egg directories

    Usage::

        # Development eggs:

        egg_info = "/path/to/PackageName.egg-info"
        base_dir = os.path.dirname(egg_info)
        metadata = PathMetadata(base_dir, egg_info)
        dist_name = os.path.splitext(os.path.basename(egg_info))[0]
        dist = Distribution(basedir, project_name=dist_name, metadata=metadata)

        # Unpacked egg directories:

        egg_path = "/path/to/PackageName-ver-pyver-etc.egg"
        metadata = PathMetadata(egg_path, os.path.join(egg_path,'EGG-INFO'))
        dist = Distribution.from_filename(egg_path, metadata=metadata)
    Does the package's distribution contain the named metadata?Convert a version string to a chronologically-sortable key

    This is a rough cross between distutils' StrictVersion and LooseVersion;
    if you give it versions that would work with StrictVersion, then it behaves
    the same; otherwise it acts like a slightly-smarter LooseVersion. It is
    *possible* to create pathological version coding schemes that will fool
    this parser, but they should be very rare in practice.

    The returned value will be a tuple of strings.  Numeric portions of the
    version are padded to 8 digits so they will compare numerically, but
    without relying on how numbers compare relative to strings.  Dots are
    dropped, but dashes are retained.  Trailing zeros between alpha segments
    or dashes are suppressed, so that e.g. "2.4.0" is considered the same as
    "2.4". Alphanumeric parts are lower-cased.

    The algorithm assumes that strings like "-" and any alpha string that
    alphabetically follows "final"  represents a "patch level".  So, "2.4-1"
    is assumed to be a branch or patch of "2.4", and therefore "2.4.1" is
    considered newer than "2.4-1", which in turn is newer than "2.4".

    Strings like "a", "b", "c", "alpha", "beta", "candidate" and so on (that
    come before "final" alphabetically) are assumed to be pre-release versions,
    so that the version "2.4" is considered newer than "2.4a1".

    Finally, to handle miscellaneous cases, the strings "pre", "preview", and
    "rc" are treated as if they were "c", i.e. as though they were release
    candidates, and therefore are not as new as a version string that does not
    contain them, and "dev" is replaced with an '@' so that it sorts lower than
    than any other pre-release tag.
    %r has no %r attributeList all distributions needed to (recursively) meet `requirements`

        `requirements` must be a sequence of ``Requirement`` objects.  `env`,
        if supplied, should be an ``Environment`` instance.  If
        not supplied, it defaults to all distributions available within any
        entry or distribution in the working set.  `installer`, if supplied,
        will be invoked with each requirement that cannot be met by an
        already-installed distribution; it should return a ``Distribution`` or
        ``None``.

        Unless `replace_conflicting=True`, raises a VersionConflict exception if
        any requirements are found on the path that have the correct name but
        the wrong version.  Otherwise, if an `installer` is supplied it will be
        invoked to obtain the correct version of the requirement and activate
        it.
        Normalize a file/dir name for comparison purposesnamespace_packages.txtTrue if `dist` is the active distribution for its projectExpected ',' or end-of-list inGet an mro for a type or classic class\ must not appear on the last nonblank linedarwin-(\d+)\.(\d+)\.(\d+)-(.*)Ensure that distributions matching `requirements` are activated

        `requirements` must be a string or a (possibly-nested) sequence
        thereof, specifying the distributions and versions required.  The
        return value is a sequence of the distributions that needed to be
        activated to fulfill the requirements; all relevant distributions are
        included, even if they were already activated in this working set.
        Return a readable file-like object for specified resource%s has no such extra feature %r
        Build a dictionary similar to the zipimport directory
        caches, except instead of tuples, store ZipInfo objects.

        Use a platform-specific path separator (os.sep) for the path keys
        for compatibility with pypy on Windows.
        EntryPoint.parse(%r)Yield distributions for non-duplicate projects in the working set

        The yield order is the order in which the items' path entries were
        added to the working set.
        
        Construct a ZipFile or ContextualZipFile as appropriate
        Empty parenthesesDoes the named resource exist?Chained comparison not allowed in environment markersmacosx-(\d+)\.(\d+)-(.*)An error occurred extracting a resource

    The following attributes are available from instances of this exception:

    manager
        The resource manager that raised this exception

    cache_path
        The base directory for resource extraction

    original_error
        The exception instance that caused extraction to fail
    Requirement.parse(%r)Yield entry point objects from `group` matching `name`

        If `name` is None, yields all entry points in `group` from all
        distributions in the working set, otherwise only ones matching
        both `group` and `name` are yielded (in distribution order).
        No metadata except PKG-INFO is availableCan code for the `provided` platform run on the `required` platform?

    Returns true if either platform is ``None``, or the platforms are equal.

    XXX Needs compatibility checks for Linux and other unixy OSes.
    Return the EntryPoint object for `group`+`name`, or ``None``Metadata provider for .egg filesReturn a true filesystem path for `resource_name`

        `manager` must be an ``IResourceManager``Provider that returns nothing for all requestsRecompute this distribution's dependencies.PKG_RESOURCES_CACHE_ZIP_MANIFESTS/usr/local/lib/python2.7/dist-packages/pykeyboard/usr/local/lib/python2.7/dist-packages/pykeyboard/__init__.py
The goal of PyMouse is to have a cross-platform way to control the mouse.
PyMouse should work on Windows, Mac and any Unix that has xlib.

PyKeyboard is a part of PyUserInput, along with PyMouse, for more information
about this project, see:
http://github.com/SavinaRoja/PyUserInput
daemontype_stringlookup_character_value
As the base file, this provides a rough operational model along with the
framework to be extended by each platform.
/usr/local/lib/python2.7/dist-packages/pykeyboard/base.py
        A function that defines when to stop listening; subclass this with your
        escape behavior. If the program is meant to stop, this method should
        return True. Every key event will go through this method before going to
        tap(), allowing this method to check for exit conditions.

        The default behavior is to stop when the 'Esc' key is pressed.

        If one wishes to use key combinations, or key series, one might be
        interested in reading about Finite State Machines.
        http://en.wikipedia.org/wiki/Deterministic_finite_automaton
        <>?:"{}|~!@#$%^&*()_+
    The base class for PyKeyboard. Represents basic operational model.
    Press and release a given character key n times.pykeyboard.baseReturns True if the key character is uppercase or shifted.
        If necessary, lookup a valid API value for the key press from the
        character.
        Release a given character key.A convenience method for typing longer strings of characters.
        Subclass this method with your key event handler. It will receive
        the keycode associated with the key event, as well as string name for
        the key if one can be assigned (keyboard mask states will apply). The
        argument 'press' will be True if the key was depressed and False if the
        key was released.
        Press a given character key.Makes special keys more accessible./usr/local/lib/python2.7/dist-packages/pykeyboard/java_.pypykeyboard.java_AppKitQuartzrefconkey_codekey_pressloopsourceKEYTYPE_MUTEKEYTYPE_PLAYKEYTYPE_SOUND_UP_press_normal_keyKEYTYPE_SOUND_DOWN_press_special_key{s   KEYTYPE_ILLUMINATION_UPi   s   KEYTYPE_BRIGHTNESS_DOWNi   s   KEYTYPE_NEXTi   s   KEYTYPE_HELPi   s   KEYTYPE_EJECTi   s   KEYTYPE_SOUND_UPi    s   KEYTYPE_CONTRAST_DOWNi   s   KEYTYPE_SOUND_DOWNi   s   KEYTYPE_NUM_LOCKi
   s   KEYTYPE_REWINDi   s	   POWER_KEYi   s   KEYTYPE_VIDMIRRORi   s   KEYTYPE_PLAYi   s   KEYTYPE_LAUNCH_PANELi   s   DOWN_ARROW_KEYi	   s   UP_ARROW_KEYi   s   KEYTYPE_MUTEi   s   KEYTYPE_CAPS_LOCKi   s   KEYTYPE_PREVIOUSi   s   KEYTYPE_ILLUMINATION_DOWNi   s   KEYTYPE_ILLUMINATION_TOGGLEi   s   KEYTYPE_FASTi   s   KEYTYPE_BRIGHTNESS_UPi   s   KEYTYPE_CONTRAST_UPi   0{s   	i0   s   i$   t    i1   s   'i'   t   -i   t   ,i+   t   /i,   t   .i/   t   1i   t   0i   t   3i   t   2i   t   5i   t   4i   t   7i   t   6i   t   9i   t   8i   t   ;i)   t   =i   t   hi   t   [i!   t   ]i   s   \i*   t   ai    t   `i2   t   ci   t   bi   t   ei   t   di   t   gi   t   fi   t   ii"   s   shifti8   t   ki(   t   ji&   t   mi.   t   li%   t   oi   t   ni-   t   qi   t   pi#   t   si   t   ri   t   ui    t   ti   t   wi   t   vi	   t   yi   t   xi   t   zi   0Key {} not implemented.pykeyboard.macotherEventWithType_location_modifierFlags_timestamp_windowNumber_context_subtype_data1_data2_ Helper method for special keys. 

        Source: http://stackoverflow.com/questions/11045814/emulate-media-key-press-on-mac
        /usr/local/lib/python2.7/dist-packages/pykeyboard/mac.pyKeyIDLmenuRmenuKeyAllLshiftRshiftCapitalchar_vkpa1_keySYSKEYUPWM_KEYUPattn_keyplay_keywin32conzoom_keyVkKeyScanalt_statecrsel_keyereof_keyexsel_keyspace_keyWM_KEYDOWN_key_pressnoname_keyHookManagerescape_codekeybd_eventshift_stateHookKeyboardSupportError_key_releaseHookConstantsWM_SYSKEYDOWNoem_clear_keyUnhookKeyboardprocesskey_keybrowser_back_keytoggle_alt_statetoggle_shift_statePumpWaitingMessagesbrowser_forward_keymedia_next_track_keymedia_prev_track_key
        Special Key assignment for windows
        pykeyboard.windows/usr/local/lib/python2.7/dist-packages/pykeyboard/windows.pyKeyboard event message unhandled: {0}
    The PyKeyboard implementation for Windows systems. This allows one to
    simulate keyboard input.
    
        Press a given character key.
        For keys not supported on this systemDoes toggling for the alt state.Does toggling for the shift state.
    The PyKeyboardEvent implementation for Windows Systems. This allows one
    to listen for keyboard input.
    The {0} key is not supported in Windows
        Release a given character key.
        KP_Redo_tapAlt_LAlt_RgreekCancelMeta_LMeta_Rkeypadlatin2latin3latin4Hyper_LHyper_RShift_LShift_RSuper_LSuper_RSys_ReqLinefeedNum_Lockdisplay2Caps_LockControl_LControl_Rmod_indexsleep_keyShift_LockMode_switchlock_meaningmodifier_bitsscript_switchconfigure_keysshift_lock_keyascii_printablekeypad_keycodescaps_lock_keycodemodifier_keycodesshift_lock_keycodeget_translation_dictslookup_char_from_keycodelookup_character_keycode{s
   Shift_Locki    s   Mod1i   s   Mod2i   s   Mod3i    s   Mod4i@   s   Mod5i   s   Locki   s   Mode_switchi    s	   Caps_Locki    s   Num_Locki    s   Shifti   s   Controli   s   Alti    s   Superi    0{s
   Shift_Locki    s   Mod1i    s   Mod2i    s   Mod3i    s   Mod4i    s   Mod5i    s   Locki    s   Mode_switchi    s	   Caps_Locki    s   Num_Locki    s   Shifti    s   Controli    s   Alti    s   Superi    0{s   	s   Tabs   
s   Returns   s   Returnt   !s   exclamt    s   spacet   #s
   numbersignt   "s   quotedblt   %s   percentt   $s   dollars   's
   apostrophet   &s	   ampersandt   )s
   parenrightt   (s	   parenleftt   +s   plust   *s   asteriskt   -s   minust   ,s   commat   /s   slasht   .s   periodt   ;s	   semicolont   :s   colont   =s   equalt   <s   lesst   ?s   questiont   >s   greatert   @s   att   [s   bracketleftt   ]s   bracketrights   \s	   backslasht   _s
   underscoret   ^s   asciicircumt   `s   graves   \es   Escapet   {s	   braceleftt   }s
   bracerightt   |s   bart   ~s
   asciitilde0[%   s   Spaces   Tabs   Enters   F1s   F2s   F3s   F4s   Homes   Lefts   Ups   Rights   Downs   Priors   Page_Ups   Nexts	   Page_Downs   Ends   Begins   Inserts   Deletes   Equals   Multiplys   Adds	   Separators   Subtracts   Decimals   Dividei    i   i   i   i   i   i   i   i   i	   /usr/local/lib/python2.7/dist-packages/pykeyboard/x11.pyUnable to determine character.Returns False if the keysym is not a printable ascii character.Lock is bound to {0}Keycode: {0} KeySym {1}
        Release a given character key. Also works with character keycodes as
        integers, but not keysyms.
        
        This function locates the keycodes corresponding to special groups of
        keys and creates data structures of them for use by the PyKeyboardEvent
        instance; including the keypad keys and the modifiers.

        The keycodes pertaining to the keyboard modifiers are assigned by the
        modifier name in a dictionary. This dictionary can be accessed in the
        following manner:
            self.modifier_keycodes['Shift']  # All keycodes for Shift Masking

        It also assigns certain named modifiers (Alt, Num_Lock, Super), which
        may be dynamically assigned to Mod1 - Mod5 on different platforms. This
        should generally allow the user to do the following lookups on any
        system:
            self.modifier_keycodes['Alt']  # All keycodes for Alt Masking
            self.modifiers['Alt']  # State of Alt mask, non-zero if "ON"
        
        Returns dictionaries for the translation of keysyms to strings and from
        strings to keysyms.
        
        Press a given character key. Also works with character keycodes as
        integers, but not keysyms.
        
        Looks up the keysym for the character then returns the keycode mapping
        for that keysym.
        
    The PyKeyboardEvent implementation for X11 systems (mostly linux). This
    allows one to listen for keyboard input.
    
        Determines the keycodes for common special keys on the keyboard. These
        are integer values and can be passed to the other key methods.
        Generally speaking, these are non-printable codes.
        pykeyboard.x11
    The PyKeyboard implementation for X11 systems (mostly linux). This
    allows one to simulate keyboard input.
    
        This will conduct a lookup of the character or string associated with a
        given keycode.
        (#   i   i   i   i   i   i   i   i   i	   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i    i!   i"   i#   (   t   selft   modifier_mappingt   all_mod_keycodest   mod_keycodest	   mod_indext   namet   indext   vt   codest   lookup_keycodet   shift_lock_keycodet   caps_lock_keycodet   num_lock_keycodest   it   alt_keycodest   super_keycodest   mode_switch_keycodest   keycodest   alt_keyt   num_lock_keyt	   super_keyt   mode_switch_keyt   keypadt   k/usr/lib/python2.7/dist-packages/scipy1.5.1
SciPy: A scientific computing package for Python
================================================

Documentation is available in the docstrings and
online at http://docs.scipy.org.

Contents
--------
SciPy imports all the functions from the NumPy namespace, and in
addition provides:

Subpackages
-----------
Using any of these subpackages requires an explicit import.  For example,
``import scipy.cluster``.

::

 cluster                      --- Vector Quantization / Kmeans
 fftpack                      --- Discrete Fourier Transform algorithms
 integrate                    --- Integration routines
 interpolate                  --- Interpolation Tools
 io                           --- Data input and output
 lib                          --- Python wrappers to external libraries
 lib.lapack                   --- Wrappers to LAPACK library
 linalg                       --- Linear algebra routines
 misc                         --- Various utilities that don't have
                                  another home.
 ndimage                      --- n-dimensional image package
 odr                          --- Orthogonal Distance Regression
 optimize                     --- Optimization Tools
 signal                       --- Signal Processing Tools
 sparse                       --- Sparse Matrices
 sparse.linalg                --- Sparse Linear Algebra
 sparse.linalg.dsolve         --- Linear Solvers
 sparse.linalg.dsolve.umfpack --- :Interface to the UMFPACK library:
                                  Conjugate Gradient Method (LOBPCG)
 sparse.linalg.eigen.lobpcg   --- Locally Optimal Block Preconditioned
                                  Conjugate Gradient Method (LOBPCG) [*]
 special                      --- Airy Functions [*]
 lib.blas                     --- Wrappers to BLAS library [*]
 sparse.linalg.eigen          --- Sparse Eigenvalue Solvers [*]
 stats                        --- Statistical Functions [*]
 lib                          --- Python wrappers to external libraries
                                  [*]
 lib.lapack                   --- Wrappers to LAPACK library [*]
 integrate                    --- Integration routines [*]
 ndimage                      --- n-dimensional image package [*]
 linalg                       --- Linear algebra routines [*]
 spatial                      --- Spatial data structures and algorithms
 special                      --- Airy Functions
 stats                        --- Statistical Functions

Utility tools
-------------
::

 test              --- Run scipy unittests
 show_config       --- Show scipy build configuration
 show_numpy_config --- Show numpy build configuration
 __version__       --- Scipy version string
 __numpy_version__ --- Numpy version string

/usr/lib/python2.7/dist-packages/scipy/__init__.pyNumpy 1.5.1 or above is recommended for this version of scipy (detected version %s)Running from scipy source directory.
Error importing scipy: you cannot import scipy while
        being in scipy source directory; please exit the scipy source
        tree first, and relaunch your python intepreter.Cannot import scipy when running from numpy source directory./usr/lib/python2.7/dist-packages/scipy/__config__.py
=============================================
Integration and ODEs (:mod:`scipy.integrate`)
=============================================

.. currentmodule:: scipy.integrate

Integrating functions, given function object
============================================

.. autosummary::
   :toctree: generated/

   quad          -- General purpose integration
   dblquad       -- General purpose double integration
   tplquad       -- General purpose triple integration
   nquad         -- General purpose n-dimensional integration
   fixed_quad    -- Integrate func(x) using Gaussian quadrature of order n
   quadrature    -- Integrate with given tolerance using Gaussian quadrature
   romberg       -- Integrate func using Romberg integration

Integrating functions, given fixed samples
==========================================

.. autosummary::
   :toctree: generated/

   cumtrapz      -- Use trapezoidal rule to cumulatively compute integral.
   simps         -- Use Simpson's rule to compute integral from samples.
   romb          -- Use Romberg Integration to compute integral from
                 -- (2**k + 1) evenly-spaced samples.

.. seealso::

   :mod:`scipy.special` for orthogonal polynomials (special) for Gaussian
   quadrature roots and weights for other weighting factors and regions.

Integrators of ODE systems
==========================

.. autosummary::
   :toctree: generated/

   odeint        -- General integration of ordinary differential equations.
   ode           -- Integrate ODE using VODE and ZVODE routines.
   complex_ode   -- Convert a complex-valued ODE to real-valued and integrate.

/usr/lib/python2.7/dist-packages/scipy/integrate/__init__.py333333??liwlrncjacioutxoldadamsdvodeicompitaskstiffzworkn_prev-q=_soloutjac_tmp_wrap_jacrun_relaxset_soloutcheck_handleset_f_paramssolout_cmplxsupports_stepset_integratorset_jac_paramssupports_soloutset_initial_valueacquire_new_handleintegrator_classessupports_run_relaxactive_global_handleExcess accuracy requested. (Tolerances too small.)Error weight became zero during problem. (Solution component i vanished, and ATOL or ATOL(i) = 0.)Repeated convergence failures. (Perhaps bad Jacobian supplied or wrong choice of MF or tolerances.)Repeated error test failures. (Check all input.)Illegal input detected. (See printed message.)Excess work done on this call. (Perhaps wrong MF.)computation successfulcomput. successful (interrupted by solout)larger nmax is neededproblem is probably stiff (interrupted)step size becomes too smallinput is not consistent
    A wrapper of ode for complex systems.

    This functions similarly as `ode`, but re-maps a complex-valued
    equation system to a real-valued one before using the integrators.

    Parameters
    ----------
    f : callable ``f(t, y, *f_args)``
        Rhs of the equation. t is a scalar, ``y.shape == (n,)``.
        ``f_args`` is set by calling ``set_f_params(*args)``.
    jac : callable ``jac(t, y, *jac_args)``
        Jacobian of the rhs, ``jac[i,j] = d f[i] / d y[j]``.
        ``jac_args`` is set by calling ``set_f_params(*args)``.

    Attributes
    ----------
    t : float
        Current time.
    y : ndarray
        Current variable values.

    Examples
    --------
    For usage examples, see `ode`.

    Unexpected mf=%s
        Set integrator by name.

        Parameters
        ----------
        name : str
            Name of the integrator
        integrator_params :
            Additional parameters for the integrator.
        zvode: selected integrator does not support solouta,choose another oneall integrators must define run(f, jac, t0, t1, y0, f_params, jac_params)
    A generic interface class to numeric integrators.

    Solve an equation system :math:`y'(t) = f(t,y)` with (optional) ``jac = df/dy``.

    Parameters
    ----------
    f : callable ``f(t, y, *f_args)``
        Rhs of the equation. t is a scalar, ``y.shape == (n,)``.
        ``f_args`` is set by calling ``set_f_params(*args)``.
        `f` should return a scalar, array or list (not a tuple).
    jac : callable ``jac(t, y, *jac_args)``
        Jacobian of the rhs, ``jac[i,j] = d f[i] / d y[j]``.
        ``jac_args`` is set by calling ``set_f_params(*args)``.

    Attributes
    ----------
    t : float
        Current time.
    y : ndarray
        Current variable values.

    See also
    --------
    odeint : an integrator with a simpler interface based on lsoda from ODEPACK
    quad : for finding the area under a curve

    Notes
    -----
    Available integrators are listed below. They can be selected using
    the `set_integrator` method.

    "vode"

        Real-valued Variable-coefficient Ordinary Differential Equation
        solver, with fixed-leading-coefficient implementation. It provides
        implicit Adams method (for non-stiff problems) and a method based on
        backward differentiation formulas (BDF) (for stiff problems).

        Source: http://www.netlib.org/ode/vode.f

        .. warning::

           This integrator is not re-entrant. You cannot have two `ode`
           instances using the "vode" integrator at the same time.

        This integrator accepts the following parameters in `set_integrator`
        method of the `ode` class:

        - atol : float or sequence
          absolute tolerance for solution
        - rtol : float or sequence
          relative tolerance for solution
        - lband : None or int
        - rband : None or int
          Jacobian band width, jac[i,j] != 0 for i-lband <= j <= i+rband.
          Setting these requires your jac routine to return the jacobian
          in packed format, jac_packed[i-j+lband, j] = jac[i,j].
        - method: 'adams' or 'bdf'
          Which solver to use, Adams (non-stiff) or BDF (stiff)
        - with_jacobian : bool
          Whether to use the jacobian
        - nsteps : int
          Maximum number of (internally defined) steps allowed during one
          call to the solver.
        - first_step : float
        - min_step : float
        - max_step : float
          Limits for the step sizes used by the integrator.
        - order : int
          Maximum order used by the integrator,
          order <= 12 for Adams, <= 5 for BDF.

    "zvode"

        Complex-valued Variable-coefficient Ordinary Differential Equation
        solver, with fixed-leading-coefficient implementation.  It provides
        implicit Adams method (for non-stiff problems) and a method based on
        backward differentiation formulas (BDF) (for stiff problems).

        Source: http://www.netlib.org/ode/zvode.f

        .. warning::

           This integrator is not re-entrant. You cannot have two `ode`
           instances using the "zvode" integrator at the same time.

        This integrator accepts the same parameters in `set_integrator`
        as the "vode" solver.

        .. note::

            When using ZVODE for a stiff system, it should only be used for
            the case in which the function f is analytic, that is, when each f(i)
            is an analytic function of each y(j).  Analyticity means that the
            partial derivative df(i)/dy(j) is a unique complex number, and this
            fact is critical in the way ZVODE solves the dense or banded linear
            systems that arise in the stiff case.  For a complex stiff ODE system
            in which f is not analytic, ZVODE is likely to have convergence
            failures, and for this problem one should instead use DVODE on the
            equivalent real system (in the real and imaginary parts of y).

    "lsoda"

        Real-valued Variable-coefficient Ordinary Differential Equation
        solver, with fixed-leading-coefficient implementation. It provides
        automatic method switching between implicit Adams method (for non-stiff
        problems) and a method based on backward differentiation formulas (BDF)
        (for stiff problems).

        Source: http://www.netlib.org/odepack

        .. warning::

           This integrator is not re-entrant. You cannot have two `ode`
           instances using the "lsoda" integrator at the same time.

        This integrator accepts the following parameters in `set_integrator`
        method of the `ode` class:

        - atol : float or sequence
          absolute tolerance for solution
        - rtol : float or sequence
          relative tolerance for solution
        - lband : None or int
        - rband : None or int
          Jacobian band width, jac[i,j] != 0 for i-lband <= j <= i+rband.
          Setting these requires your jac routine to return the jacobian
          in packed format, jac_packed[i-j+lband, j] = jac[i,j].
        - with_jacobian : bool
          Whether to use the jacobian
        - nsteps : int
          Maximum number of (internally defined) steps allowed during one
          call to the solver.
        - first_step : float
        - min_step : float
        - max_step : float
          Limits for the step sizes used by the integrator.
        - max_order_ns : int
          Maximum order used in the nonstiff case (default 12).
        - max_order_s : int
          Maximum order used in the stiff case (default 5).
        - max_hnil : int
          Maximum number of messages reporting too small step size (t + h = t)
          (default 0)
        - ixpr : int
          Whether to generate extra printing at method switches (default False).

    "dopri5"

        This is an explicit runge-kutta method of order (4)5 due to Dormand &
        Prince (with stepsize control and dense output).

        Authors:

            E. Hairer and G. Wanner
            Universite de Geneve, Dept. de Mathematiques
            CH-1211 Geneve 24, Switzerland
            e-mail:  ernst.hairer@math.unige.ch, gerhard.wanner@math.unige.ch

        This code is described in [HNW93]_.

        This integrator accepts the following parameters in set_integrator()
        method of the ode class:

        - atol : float or sequence
          absolute tolerance for solution
        - rtol : float or sequence
          relative tolerance for solution
        - nsteps : int
          Maximum number of (internally defined) steps allowed during one
          call to the solver.
        - first_step : float
        - max_step : float
        - safety : float
          Safety factor on new step selection (default 0.9)
        - ifactor : float
        - dfactor : float
          Maximum factor to increase/decrease step size by in one step
        - beta : float
          Beta parameter for stabilised step size control.
        - verbosity : int
          Switch for printing messages (< 0 for no messages).

    "dop853"

        This is an explicit runge-kutta method of order 8(5,3) due to Dormand
        & Prince (with stepsize control and dense output).

        Options and references the same as "dopri5".

    Examples
    --------

    A problem to integrate and the corresponding jacobian:

    >>> from scipy.integrate import ode
    >>>
    >>> y0, t0 = [1.0j, 2.0], 0
    >>>
    >>> def f(t, y, arg1):
    >>>     return [1j*arg1*y[0] + y[1], -arg1*y[1]**2]
    >>> def jac(t, y, arg1):
    >>>     return [[1j*arg1, 1], [0, -arg1*2*y[1]]]

    The integration:

    >>> r = ode(f, jac).set_integrator('zvode', method='bdf', with_jacobian=True)
    >>> r.set_initial_value(y0, t0).set_f_params(2.0).set_jac_params(2.0)
    >>> t1 = 10
    >>> dt = 1
    >>> while r.successful() and r.t < t1:
    >>>     r.integrate(r.t+dt)
    >>>     print("%g %g" % (r.t, r.y))

    References
    ----------
    .. [HNW93] E. Hairer, S.P. Norsett and G. Wanner, Solving Ordinary
        Differential Equations i. Nonstiff Problems. 2nd edition.
        Springer Series in Computational Mathematics,
        Springer-Verlag (1993)

    
        Set integrator by name.

        Parameters
        ----------
        name : str
            Name of the integrator.
        integrator_params :
            Additional parameters for the integrator.
        Set extra parameters for user-supplied function jac.Find y=y(t), set y as an initial condition, and return y.Integrator `%s` can be used to solve only a single problem at a time. If you want to integrate multiple problems, consider using a different integrator (see `ode.set_integrator`)Integrate from t=t0 to t=t1 using y0 as an initial condition.
        Return 2-tuple (y1,t1) where y1 is the result and t=t1
        defines the stoppage coordinate of the result.
        /usr/lib/python2.7/dist-packages/scipy/integrate/_ode.pyUnexpected idid=%sSet extra parameters for user-supplied function f.
First-order ODE integrators.

User-friendly interface to various numerical integrators for solving a
system of first order ODEs with prescribed initial conditions::

    d y(t)[i]
    ---------  = f(t,y(t))[i],
       d t

    y(t=0)[i] = y0[i],

where::

    i = 0, ..., len(y0) - 1

class ode
---------

A generic interface class to numeric integrators. It has the following
methods::

    integrator = ode(f,jac=None)
    integrator = integrator.set_integrator(name,**params)
    integrator = integrator.set_initial_value(y0,t0=0.0)
    integrator = integrator.set_f_params(*args)
    integrator = integrator.set_jac_params(*args)
    y1 = integrator.integrate(t1,step=0,relax=0)
    flag = integrator.successful()

class complex_ode
-----------------

This class has the same generic interface as ode, except it can handle complex
f, y and Jacobians by transparently translating them into the equivalent
real valued system. It supports the real valued solvers (i.e not zvode) and is
an alternative to ode with the zvode solver, sometimes performing better.
Check if integration was successful.%s does not support step() methodSet initial conditions y(t) = y.Function to integrate must not return a tuple.
        Set callable to be called at every successful integration step.

        Parameters
        ----------
        solout : callable
            ``solout(t, y)`` is called at each internal integrator step,
            t is a scalar providing the current independent position
            y is the current soloution ``y.shape == (n,)``
            solout should return -1 to stop integration
            otherwise it should return None or 0

        zvode should be used with ode, not zodeselected integrator does not support solout, choose another oneUnexpected jt=%s
    Failure due to concurrent usage of an integrator that can be used
    only for a single problem at a time.

    No integrator name match with %r or is not available.Unexpected istate=%slsoda: %s does not support run_relax() methodMake one integration step and return (y1,t1).$Id$Prepare integrator for call: allocate memory, set flags, etc.
        n - number of equations.
        has_jac - if user has supplied function for evaluating Jacobian.
        Unknown integration method %sIntegrate from t=t0 to t>=t1 and return (y1,t).scipy.integrate._odescipy.integrate.odepack
    Integrate a system of ordinary differential equations.

    Solve a system of ordinary differential equations using lsoda from the
    FORTRAN library odepack.

    Solves the initial value problem for stiff or non-stiff systems
    of first order ode-s::

        dy/dt = func(y,t0,...)

    where y can be a vector.

    Parameters
    ----------
    func : callable(y, t0, ...)
        Computes the derivative of y at t0.
    y0 : array
        Initial condition on y (can be a vector).
    t : array
        A sequence of time points for which to solve for y.  The initial
        value point should be the first element of this sequence.
    args : tuple, optional
        Extra arguments to pass to function.
    Dfun : callable(y, t0, ...)
        Gradient (Jacobian) of `func`.
    col_deriv : bool, optional
        True if `Dfun` defines derivatives down columns (faster),
        otherwise `Dfun` should define derivatives across rows.
    full_output : bool, optional
        True if to return a dictionary of optional outputs as the second output
    printmessg : bool, optional
        Whether to print the convergence message

    Returns
    -------
    y : array, shape (len(t), len(y0))
        Array containing the value of y for each desired time in t,
        with the initial value `y0` in the first row.
    infodict : dict, only returned if full_output == True
        Dictionary containing additional output information

        =======  ============================================================
        key      meaning
        =======  ============================================================
        'hu'     vector of step sizes successfully used for each time step.
        'tcur'   vector with the value of t reached for each time step.
                 (will always be at least as large as the input times).
        'tolsf'  vector of tolerance scale factors, greater than 1.0,
                 computed when a request for too much accuracy was detected.
        'tsw'    value of t at the time of the last method switch
                 (given for each time step)
        'nst'    cumulative number of time steps
        'nfe'    cumulative number of function evaluations for each time step
        'nje'    cumulative number of jacobian evaluations for each time step
        'nqu'    a vector of method orders for each successful step.
        'imxer'  index of the component of largest magnitude in the
                 weighted local error vector (e / ewt) on an error return, -1
                 otherwise.
        'lenrw'  the length of the double work array required.
        'leniw'  the length of integer work array required.
        'mused'  a vector of method indicators for each successful time step:
                 1: adams (nonstiff), 2: bdf (stiff)
        =======  ============================================================

    Other Parameters
    ----------------
    ml, mu : int, optional
        If either of these are not None or non-negative, then the
        Jacobian is assumed to be banded.  These give the number of
        lower and upper non-zero diagonals in this banded matrix.
        For the banded case, `Dfun` should return a matrix whose
        rows contain the non-zero bands (starting with the lowest diagonal).
        Thus, the return matrix `jac` from `Dfun` should have shape
        ``(ml + mu + 1, len(y0))`` when ``ml >=0`` or ``mu >=0``.
        The data in `jac` must be stored such that ``jac[i - j + mu, j]``
        holds the derivative of the `i`th equation with respect to the `j`th
        state variable.  If `col_deriv` is True, the transpose of this
        `jac` must be returned.
    rtol, atol : float, optional
        The input parameters `rtol` and `atol` determine the error
        control performed by the solver.  The solver will control the
        vector, e, of estimated local errors in y, according to an
        inequality of the form ``max-norm of (e / ewt) <= 1``,
        where ewt is a vector of positive error weights computed as
        ``ewt = rtol * abs(y) + atol``.
        rtol and atol can be either vectors the same length as y or scalars.
        Defaults to 1.49012e-8.
    tcrit : ndarray, optional
        Vector of critical points (e.g. singularities) where integration
        care should be taken.
    h0 : float, (0: solver-determined), optional
        The step size to be attempted on the first step.
    hmax : float, (0: solver-determined), optional
        The maximum absolute step size allowed.
    hmin : float, (0: solver-determined), optional
        The minimum absolute step size allowed.
    ixpr : bool, optional
        Whether to generate extra printing at method switches.
    mxstep : int, (0: solver-determined), optional
        Maximum number of (internally defined) steps allowed for each
        integration point in t.
    mxhnil : int, (0: solver-determined), optional
        Maximum number of messages printed.
    mxordn : int, (0: solver-determined), optional
        Maximum order to be allowed for the non-stiff (Adams) method.
    mxords : int, (0: solver-determined), optional
        Maximum order to be allowed for the stiff (BDF) method.

    See Also
    --------
    ode : a more object-oriented integrator based on VODE.
    quad : for finding the area under a curve.

    /usr/lib/python2.7/dist-packages/scipy/integrate/odepack.pyRun with full_output = 1 to get quantitative information.(   t   funct   y0t   tt   argst   Dfunt	   col_derivt   full_outputt   mlt   mut   rtolt   atolt   tcritt   h0t   hmaxt   hmint   ixprt   mxstept   mxhnilt   mxordnt   mxordst
   printmessg(   t   funct   y0t   tt   argst   Dfunt	   col_derivt   full_outputt   mlt   mut   rtolt   atolt   tcritt   h0t   hmaxt   hmint   ixprt   mxstept   mxhnilt   mxordnt   mxordst
   printmessgt   output_qagie_qagpe_qagse_qawce_qawfe_qawoe_qawsefn_optmomcomthefuncfn_rangemaxdepththe_pointsquad_explainalg-logaalg-logbThe maximum number of subdivisions (= limit) has been 
  achieved on this cycle.The occurrence of roundoff error is detected and prevents
  the tolerance imposed on this cycle from being achieved.Extremely bad integrand behavior occurs at some points of
  this cycle.The integral over this cycle does not converge (to within the required accuracy) due to roundoff in the extrapolation procedure invoked on this cycle.  It is assumed that the result on this interval is the best which can be obtained.The integral over this cycle is probably divergent or slowly convergent.The maximum number of cycles allowed has been achieved., e.e.
  of subintervals (a+(k-1)c, a+kc) where c = (2*int(abs(omega)+1))
  *pi/abs(omega), for k = 1, 2, ..., lst.  One can allow more cycles by increasing the value of limlst.  Look at info['ierlst'] with full_output=1.Unknown error.%s not a recognized weighting function.The input is invalid.
    Compute a double integral.

    Return the double (definite) integral of ``func(y, x)`` from ``x = a..b``
    and ``y = gfun(x)..hfun(x)``.

    Parameters
    ----------
    func : callable
        A Python function or method of at least two variables: y must be the
        first argument and x the second argument.
    (a,b) : tuple
        The limits of integration in x: `a` < `b`
    gfun : callable
        The lower boundary curve in y which is a function taking a single
        floating point argument (x) and returning a floating point result: a
        lambda function can be useful here.
    hfun : callable
        The upper boundary curve in y (same requirements as `gfun`).
    args : sequence, optional
        Extra arguments to pass to `func`.
    epsabs : float, optional
        Absolute tolerance passed directly to the inner 1-D quadrature
        integration. Default is 1.49e-8.
    epsrel : float
        Relative tolerance of the inner 1-D integrals. Default is 1.49e-8.

    Returns
    -------
    y : float
        The resultant integral.
    abserr : float
        An estimate of the error.

    See also
    --------
    quad : single integral
    tplquad : triple integral
    nquad : N-dimensional integrals
    fixed_quad : fixed-order Gaussian quadrature
    quadrature : adaptive Gaussian quadrature
    odeint : ODE integrator
    ode : ODE integrator
    simps : integrator for sampled data
    romb : integrator for sampled data
    scipy.special : for coefficients and roots of orthogonal polynomials

    Cannot integrate with this weight from -Inf to +Inf.The extrapolation table constructed for convergence acceleration
  of the series formed by the integral contributions over the cycles, 
  does not converge to within the requested accuracy.  Look at 
  info['ierlst'] with full_output=1.Extremely bad integrand behavior occurs at some points of the
  integration interval.
    Compute a triple (definite) integral.

    Return the triple integral of ``func(z, y, x)`` from ``x = a..b``,
    ``y = gfun(x)..hfun(x)``, and ``z = qfun(x,y)..rfun(x,y)``.

    Parameters
    ----------
    func : function
        A Python function or method of at least three variables in the
        order (z, y, x).
    (a,b) : tuple
        The limits of integration in x: `a` < `b`
    gfun : function
        The lower boundary curve in y which is a function taking a single
        floating point argument (x) and returning a floating point result:
        a lambda function can be useful here.
    hfun : function
        The upper boundary curve in y (same requirements as `gfun`).
    qfun : function
        The lower boundary surface in z.  It must be a function that takes
        two floats in the order (x, y) and returns a float.
    rfun : function
        The upper boundary surface in z. (Same requirements as `qfun`.)
    args : Arguments
        Extra arguments to pass to `func`.
    epsabs : float, optional
        Absolute tolerance passed directly to the innermost 1-D quadrature
        integration. Default is 1.49e-8.
    epsrel : float, optional
        Relative tolerance of the innermost 1-D integrals. Default is 1.49e-8.

    Returns
    -------
    y : float
        The resultant integral.
    abserr : float
        An estimate of the error.

    See Also
    --------
    quad: Adaptive quadrature using QUADPACK
    quadrature: Adaptive Gaussian quadrature
    fixed_quad: Fixed-order Gaussian quadrature
    dblquad: Double integrals
    nquad : N-dimensional integrals
    romb: Integrators for sampled data
    simps: Integrators for sampled data
    ode: ODE integrators
    odeint: ODE integrators
    scipy.special: For coefficients and roots of orthogonal polynomials

    Infinity comparisons don't work for you.The occurrence of roundoff error is detected, which prevents 
  the requested tolerance from being achieved.  The error may be 
  underestimated.Cannot integrate with this weight over an infinite interval.Bad integrand behavior occurs within one or more of the cycles.
  Location and type of the difficulty involved can be determined from 
  the vector info['ierlist'] obtained with full_output=1.scipy.integrate.quadpackReturn stored value.

        *args needed because range_ can be float or func, and is called with
        variable number of parameters.
        The algorithm does not converge.  Roundoff error is detected
  in the extrapolation table.  It is assumed that the requested tolerance
  cannot be achieved, and that the returned result (if full_output = 1) is 
  the best which can be obtained.Return stored dict.
    Compute a definite integral.

    Integrate func from `a` to `b` (possibly infinite interval) using a
    technique from the Fortran library QUADPACK.

    Parameters
    ----------
    func : function
        A Python function or method to integrate.  If `func` takes many
        arguments, it is integrated along the axis corresponding to the
        first argument.
    a : float
        Lower limit of integration (use -numpy.inf for -infinity).
    b : float
        Upper limit of integration (use numpy.inf for +infinity).
    args : tuple, optional
        Extra arguments to pass to `func`.
    full_output : int, optional
        Non-zero to return a dictionary of integration information.
        If non-zero, warning messages are also suppressed and the
        message is appended to the output tuple.

    Returns
    -------
    y : float
        The integral of func from `a` to `b`.
    abserr : float
        An estimate of the absolute error in the result.
    infodict : dict
        A dictionary containing additional information.
        Run scipy.integrate.quad_explain() for more information.
    message :
        A convergence message.
    explain :
        Appended only with 'cos' or 'sin' weighting and infinite
        integration limits, it contains an explanation of the codes in
        infodict['ierlst']

    Other Parameters
    ----------------
    epsabs : float or int, optional
        Absolute error tolerance.
    epsrel : float or int, optional
        Relative error tolerance.
    limit : float or int, optional
        An upper bound on the number of subintervals used in the adaptive
        algorithm.
    points : (sequence of floats,ints), optional
        A sequence of break points in the bounded integration interval
        where local difficulties of the integrand may occur (e.g.,
        singularities, discontinuities). The sequence does not have
        to be sorted.
    weight : float or int, optional
        String indicating weighting function. Full explanation for this
        and the remaining arguments can be found below.
    wvar : optional
        Variables for use with weighting functions.
    wopts : optional
        Optional input for reusing Chebyshev moments.
    maxp1 : float or int, optional
        An upper bound on the number of Chebyshev moments.
    limlst : int, optional
        Upper bound on the number of cycles (>=3) for use with a sinusoidal
        weighting and an infinite end-point.

    See Also
    --------
    dblquad : double integral
    tplquad : triple integral
    nquad : n-dimensional integrals (uses `quad` recursively)
    fixed_quad : fixed-order Gaussian quadrature
    quadrature : adaptive Gaussian quadrature
    odeint : ODE integrator
    ode : ODE integrator
    simps : integrator for sampled data
    romb : integrator for sampled data
    scipy.special : for coefficients and roots of orthogonal polynomials

    Notes
    -----

    **Extra information for quad() inputs and outputs**

    If full_output is non-zero, then the third output argument
    (infodict) is a dictionary with entries as tabulated below.  For
    infinite limits, the range is transformed to (0,1) and the
    optional outputs are given with respect to this transformed range.
    Let M be the input argument limit and let K be infodict['last'].
    The entries are:

    'neval'
        The number of function evaluations.
    'last'
        The number, K, of subintervals produced in the subdivision process.
    'alist'
        A rank-1 array of length M, the first K elements of which are the
        left end points of the subintervals in the partition of the
        integration range.
    'blist'
        A rank-1 array of length M, the first K elements of which are the
        right end points of the subintervals.
    'rlist'
        A rank-1 array of length M, the first K elements of which are the
        integral approximations on the subintervals.
    'elist'
        A rank-1 array of length M, the first K elements of which are the
        moduli of the absolute error estimates on the subintervals.
    'iord'
        A rank-1 integer array of length M, the first L elements of
        which are pointers to the error estimates over the subintervals
        with L=K if K<=M/2+2 or L=M+1-K otherwise. Let I be the sequence
        infodict['iord'] and let E be the sequence infodict['elist'].
        Then E[I[1]], ..., E[I[L]] forms a decreasing sequence.

    If the input argument points is provided (i.e. it is not None),
    the following additional outputs are placed in the output
    dictionary.  Assume the points sequence is of length P.

    'pts'
        A rank-1 array of length P+2 containing the integration limits
        and the break points of the intervals in ascending order.
        This is an array giving the subintervals over which integration
        will occur.
    'level'
        A rank-1 integer array of length M (=limit), containing the
        subdivision levels of the subintervals, i.e., if (aa,bb) is a
        subinterval of (pts[1], pts[2]) where pts[0] and pts[2] are
        adjacent elements of infodict['pts'], then (aa,bb) has level l if
        |bb-aa|=|pts[2]-pts[1]| * 2**(-l).
    'ndin'
        A rank-1 integer array of length P+2.  After the first integration
        over the intervals (pts[1], pts[2]), the error estimates over some
        of the intervals may have been increased artificially in order to
        put their subdivision forward.  This array has ones in slots
        corresponding to the subintervals for which this happens.

    **Weighting the integrand**

    The input variables, *weight* and *wvar*, are used to weight the
    integrand by a select list of functions.  Different integration
    methods are used to compute the integral with these weighting
    functions.  The possible values of weight and the corresponding
    weighting functions are.

    ==========  ===================================   =====================
    ``weight``  Weight function used                  ``wvar``
    ==========  ===================================   =====================
    'cos'       cos(w*x)                              wvar = w
    'sin'       sin(w*x)                              wvar = w
    'alg'       g(x) = ((x-a)**alpha)*((b-x)**beta)   wvar = (alpha, beta)
    'alg-loga'  g(x)*log(x-a)                         wvar = (alpha, beta)
    'alg-logb'  g(x)*log(b-x)                         wvar = (alpha, beta)
    'alg-log'   g(x)*log(x-a)*log(b-x)                wvar = (alpha, beta)
    'cauchy'    1/(x-c)                               wvar = c
    ==========  ===================================   =====================

    wvar holds the parameter w, (alpha, beta), or c depending on the weight
    selected.  In these expressions, a and b are the integration limits.

    For the 'cos' and 'sin' weighting, additional inputs and outputs are
    available.

    For finite integration limits, the integration is performed using a
    Clenshaw-Curtis method which uses Chebyshev moments.  For repeated
    calculations, these moments are saved in the output dictionary:

    'momcom'
        The maximum level of Chebyshev moments that have been computed,
        i.e., if M_c is infodict['momcom'] then the moments have been
        computed for intervals of length |b-a|* 2**(-l), l=0,1,...,M_c.
    'nnlog'
        A rank-1 integer array of length M(=limit), containing the
        subdivision levels of the subintervals, i.e., an element of this
        array is equal to l if the corresponding subinterval is
        |b-a|* 2**(-l).
    'chebmo'
        A rank-2 array of shape (25, maxp1) containing the computed
        Chebyshev moments.  These can be passed on to an integration
        over the same interval by passing this array as the second
        element of the sequence wopts and passing infodict['momcom'] as
        the first element.

    If one of the integration limits is infinite, then a Fourier integral is
    computed (assuming w neq 0).  If full_output is 1 and a numerical error
    is encountered, besides the error message attached to the output tuple,
    a dictionary is also appended to the output tuple which translates the
    error codes in the array info['ierlst'] to English messages.  The output
    information dictionary contains the following entries instead of 'last',
    'alist', 'blist', 'rlist', and 'elist':

    'lst'
        The number of subintervals needed for the integration (call it K_f).
    'rslst'
        A rank-1 array of length M_f=limlst, whose first K_f elements
        contain the integral contribution over the interval (a+(k-1)c,
        a+kc) where c = (2*floor(|w|) + 1) * pi / |w| and k=1,2,...,K_f.
    'erlst'
        A rank-1 array of length M_f containing the error estimate
        corresponding to the interval in the same position in
        infodict['rslist'].
    'ierlst'
        A rank-1 integer array of length M_f containing an error flag
        corresponding to the interval in the same position in
        infodict['rslist'].  See the explanation dictionary (last entry
        in the output tuple) for the meaning of the codes.

    Examples
    --------
    Calculate :math:`\int^4_0 x^2 dx` and compare with an analytic result

    >>> from scipy import integrate
    >>> x2 = lambda x: x**2
    >>> integrate.quad(x2, 0, 4)
    (21.333333333333332, 2.3684757858670003e-13)
    >>> print(4**3 / 3.)  # analytical result
    21.3333333333

    Calculate :math:`\int^\infty_0 e^{-x} dx`

    >>> invexp = lambda x: np.exp(-x)
    >>> integrate.quad(invexp, 0, np.inf)
    (1.0, 5.842605999138044e-11)

    >>> f = lambda x,a : a*x
    >>> y, err = integrate.quad(f, 0, 1, args=(1,))
    >>> y
    0.5
    >>> y, err = integrate.quad(f, 0, 1, args=(3,))
    >>> y
    1.5

    Abnormal termination of the routine.  The estimates for result
  and error are less reliable.  It is assumed that the requested accuracy
  has not been achieved.Infinity inputs cannot be used with break points.The maximum number of subdivisions (%d) has been achieved.
  If increasing the limit yields no improvement it is advised to analyze 
  the integrand in order to determine the difficulties.  If the position of a 
  local difficulty can be determined (singularity, discontinuity) one will 
  probably gain from splitting up the interval and calling the integrator 
  on the subranges.  Perhaps a special-purpose integrator should be used.The integral is probably divergent, or slowly convergent.unexpected kwargs
    Integration over multiple variables.

    Wraps `quad` to enable integration over multiple variables.
    Various options allow improved integration of discontinuous functions, as
    well as the use of weighted integration, and generally finer control of the
    integration process.

    Parameters
    ----------
    func : callable
        The function to be integrated. Has arguments of ``x0, ... xn``,
        ``t0, tm``, where integration is carried out over ``x0, ... xn``, which
        must be floats.  Function signature should be
        ``func(x0, x1, ..., xn, t0, t1, ..., tm)``.  Integration is carried out
        in order.  That is, integration over ``x0`` is the innermost integral,
        and ``xn`` is the outermost.
    ranges : iterable object
        Each element of ranges may be either a sequence  of 2 numbers, or else
        a callable that returns such a sequence.  ``ranges[0]`` corresponds to
        integration over x0, and so on.  If an element of ranges is a callable,
        then it will be called with all of the integration arguments available.
        e.g. if ``func = f(x0, x1, x2)``, then ``ranges[0]`` may be defined as
        either ``(a, b)`` or else as ``(a, b) = range0(x1, x2)``.
    args : iterable object, optional
        Additional arguments ``t0, ..., tn``, required by `func`.
    opts : iterable object or dict, optional
        Options to be passed to `quad`.  May be empty, a dict, or
        a sequence of dicts or functions that return a dict.  If empty, the
        default options from scipy.integrate.quadare used.  If a dict, the same
        options are used for all levels of integraion.  If a sequence, then each
        element of the sequence corresponds to a particular integration. e.g.
        opts[0] corresponds to integration over x0, and so on. The available
        options together with their default values are:

          - epsabs = 1.49e-08
          - epsrel = 1.49e-08
          - limit  = 50
          - points = None
          - weight = None
          - wvar   = None
          - wopts  = None

        The ``full_output`` option from `quad` is unavailable, due to the
        complexity of handling the large amount of data such an option would
        return for this kind of nested integration.  For more information on
        these options, see `quad` and `quad_explain`.

    Returns
    -------
    result : float
        The result of the integration.
    abserr : float
        The maximum of the estimates of the absolute error in the various
        integration results.

    See Also
    --------
    quad : 1-dimensional numerical integration
    dblquad, tplquad : double and triple integrals
    fixed_quad : fixed-order Gaussian quadrature
    quadrature : adaptive Gaussian quadrature

    Examples
    --------
    >>> from scipy import integrate
    >>> func = lambda x0,x1,x2,x3 : x0**2 + x1*x2 - x3**3 + np.sin(x0) + (
    ...                                 1 if (x0-.2*x3-.5-.25*x1>0) else 0)
    >>> points = [[lambda (x1,x2,x3) : 0.2*x3 + 0.5 + 0.25*x1], [], [], []]
    >>> def opts0(*args, **kwargs):
    ...     return {'points':[0.2*args[2] + 0.5 + 0.25*args[0]]}
    >>> integrate.nquad(func, [[0,1], [-1,1], [.13,.8], [-.15,1]],
    ...                 opts=[opts0,{},{},{}])
    (1.5267454070738633, 2.9437360001402324e-14)

    >>> scale = .1
    >>> def func2(x0, x1, x2, x3, t0, t1):
    ...     return x0*x1*x3**2 + np.sin(x2) + 1 + (1 if x0+t1*x1-t0>0 else 0)
    >>> def lim0(x1, x2, x3, t0, t1):
    ...     return [scale * (x1**2 + x2 + np.cos(x3)*t0*t1 + 1) - 1,
    ...             scale * (x1**2 + x2 + np.cos(x3)*t0*t1 + 1) + 1]
    >>> def lim1(x2, x3, t0, t1):
    ...     return [scale * (t0*x2 + t1*x3) - 1,
    ...             scale * (t0*x2 + t1*x3) + 1]
    >>> def lim2(x3, t0, t1):
    ...     return [scale * (x3 + t0**2*t1**3) - 1,
    ...             scale * (x3 + t0**2*t1**3) + 1]
    >>> def lim3(t0, t1):
    ...     return [scale * (t0+t1) - 1, scale * (t0+t1) + 1]
    >>> def opts0(x1, x2, x3, t0, t1):
    ...     return {'points' : [t0 - t1*x1]}
    >>> def opts1(x2, x3, t0, t1):
    ...     return {}
    >>> def opts2(x3, t0, t1):
    ...     return {}
    >>> def opts3(t0, t1):
    ...     return {}
    >>> integrate.nquad(func2, [lim0, lim1, lim2, lim3], args=(0,0),
                        opts=[opts0, opts1, opts2, opts3])
    (25.066666666666666, 2.7829590483937256e-13)

    
    Print extra information about integrate.quad() parameters and returns.

    Parameters
    ----------
    output : instance with "write" method
        Information about `quad` is passed to ``output.write()``.
        Default is ``sys.stdout``.

    Returns
    -------
    None

    A Python error occurred possibly while calling the function./usr/lib/python2.7/dist-packages/scipy/integrate/quadpack.pyloxsl0sl1hsumhprodNsampsshapexh0divh1last_dxslicem1numtosum`sbO>lastresultnewton_cotes{i   (   i   i   [   i   i   ii   i   (   i   i   [   i   i   i   iiZ   i   (   i   i   [   i   i   i   i   iiP   i   (   i   i-   [   i   i    i   i    i   ii  i   (   i   i   [   i   iK   i2   i2   iK   i   ii@/  i   (   i   i   [   i)   i   i   i  i   i   i)   iix  i   (   i   iC  [   i  i  i+  i  i  i+  i  i  i	i  i   (   i   i_7  [	   i  i   i`i )  iDi )  i`i   i  ii?# i	   (   i	   i ^ [
   i)  i}=  i8  iK  i  i  iK  i8  i}=  i)  ii  i
   (   i   ip [   i>  i< isBi( i:ih i:i( isBi< i>  iii0	i   (   i   i 0[   iI"! i iiijmii ii ijmiii iI"! I!l{I [7   i   (   i   iR0P [   i i@ i7i@!i!Nid7ipRid7i!Ni@!i7i@ i i<ic] i   (   i   I ]   [   I   I=   IbTDI"V$   IbIJ0   I2SI2SIJ0   IbI"V$   IbTDI=   I   IbI LP   i   (   i   I@d     [   ii`ip`*ioI    IuI\   I[I@W   I[I\   IuI    ioip`*ii`IO	!I)  0If given, length of x along axis must be the same as y./usr/lib/python2.7/dist-packages/scipy/integrate/quadrature.pymaxiter (%d) exceeded. Latest difference = %eRomberg integration only available for finite limits. Steps  StepSize   Resultsdivmax (%d) exceeded. Latest difference = %eThe sample positions must start at 0 and end at N
    Compute a definite integral using fixed-order Gaussian quadrature.

    Integrate `func` from `a` to `b` using Gaussian quadrature of
    order `n`.

    Parameters
    ----------
    func : callable
        A Python function or method to integrate (must accept vector inputs).
    a : float
        Lower limit of integration.
    b : float
        Upper limit of integration.
    args : tuple, optional
        Extra arguments to pass to function, if any.
    n : int, optional
        Order of quadrature integration. Default is 5.

    Returns
    -------
    val : float
        Gaussian quadrature approximation to the integral

    See Also
    --------
    quad : adaptive quadrature using QUADPACK
    dblquad : double integrals
    tplquad : triple integrals
    romberg : adaptive Romberg quadrature
    quadrature : adaptive Gaussian quadrature
    romb : integrators for sampled data
    simps : integrators for sampled data
    cumtrapz : cumulative integration for sampled data
    ode : ODE integrator
    odeint : ODE integrator

    
    Return weights and error coefficient for Newton-Cotes integration.

    Suppose we have (N+1) samples of f at the positions
    x_0, x_1, ..., x_N.  Then an N-point Newton-Cotes formula for the
    integral between x_0 and x_N is:

    :math:`\int_{x_0}^{x_N} f(x)dx = \Delta x \sum_{i=0}^{N} a_i f(x_i)
    + B_N (\Delta x)^{N+2} f^{N+1} (\xi)`

    where :math:`\xi \in [x_0,x_N]` and :math:`\Delta x = \frac{x_N-x_0}{N}`
    is the averages samples spacing.

    If the samples are equally-spaced and N is even, then the error
    term is :math:`B_N (\Delta x)^{N+3} f^{N+2}(\xi)`.

    Parameters
    ----------
    rn : int
        The integer order for equally-spaced data or the relative positions of
        the samples with the first sample at 0 and the last at N, where N+1 is
        the length of `rn`.  N is the order of the Newton-Cotes integration.
    equal : int, optional
        Set to 1 to enforce equally spaced data.

    Returns
    -------
    an : ndarray
        1-D array of weights to apply to the function at the provided sample
        positions.
    B : float
        Error coefficient.

    Notes
    -----
    Normally, the Newton-Cotes rules are used on smaller integration
    regions and a composite rule is used to return the total integral.

    %6d %9f
    Romberg integration using samples of a function.

    Parameters
    ----------
    y : array_like
        A vector of ``2**k + 1`` equally-spaced samples of a function.
    dx : array_like, optional
        The sample spacing. Default is 1.
    axis : int, optional
        The axis along which to integrate. Default is -1 (last axis).
    show : bool, optional
        When `y` is a single 1-D array, then if this argument is True
        print the table showing Richardson extrapolation from the
        samples. Default is False.

    Returns
    -------
    romb : ndarray
        The integrated result for `axis`.

    See also
    --------
    quad : adaptive quadrature using QUADPACK
    romberg : adaptive Romberg quadrature
    quadrature : adaptive Gaussian quadrature
    fixed_quad : fixed-order Gaussian quadrature
    dblquad : double integrals
    tplquad : triple integrals
    simps : integrators for sampled data
    cumtrapz : cumulative integration for sampled data
    ode : ODE integrators
    odeint : ODE integrators

    
    Compute a definite integral using fixed-tolerance Gaussian quadrature.

    Integrate `func` from `a` to `b` using Gaussian quadrature
    with absolute tolerance `tol`.

    Parameters
    ----------
    func : function
        A Python function or method to integrate.
    a : float
        Lower limit of integration.
    b : float
        Upper limit of integration.
    args : tuple, optional
        Extra arguments to pass to function.
    tol, rol : float, optional
        Iteration stops when error between last two iterates is less than
        `tol` OR the relative change is less than `rtol`.
    maxiter : int, optional
        Maximum order of Gaussian quadrature.
    vec_func : bool, optional
        True or False if func handles arrays as arguments (is
        a "vector" function). Default is True.
    miniter : int, optional
        Minimum order of Gaussian quadrature.

    Returns
    -------
    val : float
        Gaussian quadrature approximation (within tolerance) to integral.
    err : float
        Difference between last two estimates of the integral.

    See also
    --------
    romberg: adaptive Romberg quadrature
    fixed_quad: fixed-order Gaussian quadrature
    quad: adaptive quadrature using QUADPACK
    dblquad: double integrals
    tplquad: triple integrals
    romb: integrator for sampled data
    simps: integrator for sampled data
    cumtrapz: cumulative integration for sampled data
    ode: ODE integrator
    odeint: ODE integrator

    Vectorize the call to a function.

    This is an internal utility function used by `romberg` and
    `quadrature` to create a vectorized version of a function.

    If `vec_func` is True, the function `func` is assumed to take vector
    arguments.

    Parameters
    ----------
    func : callable
        User defined function.
    args : tuple
        Extra arguments for the function.
    vec_func : bool
        True if the function func takes vector arguments.

    Returns
    -------
    vfunc : callable
        A function that will take a vector argument and return the
        result.

    Number of samples must be one plus a non-negative power of 2.
    Romberg integration of a callable function or method.

    Returns the integral of `function` (a function of one variable)
    over the interval (`a`, `b`).

    If `show` is 1, the triangular array of the intermediate results
    will be printed.  If `vec_func` is True (default is False), then
    `function` is assumed to support vector arguments.

    Parameters
    ----------
    function : callable
        Function to be integrated.
    a : float
        Lower limit of integration.
    b : float
        Upper limit of integration.

    Returns
    -------
    results  : float
        Result of the integration.

    Other Parameters
    ----------------
    args : tuple, optional
        Extra arguments to pass to function. Each element of `args` will
        be passed as a single argument to `func`. Default is to pass no
        extra arguments.
    tol, rtol : float, optional
        The desired absolute and relative tolerances. Defaults are 1.48e-8.
    show : bool, optional
        Whether to print the results. Default is False.
    divmax : int, optional
        Maximum order of extrapolation. Default is 10.
    vec_func : bool, optional
        Whether `func` handles arrays as arguments (i.e whether it is a
        "vector" function). Default is False.

    See Also
    --------
    fixed_quad : Fixed-order Gaussian quadrature.
    quad : Adaptive quadrature using QUADPACK.
    dblquad : Double integrals.
    tplquad : Triple integrals.
    romb : Integrators for sampled data.
    simps : Integrators for sampled data.
    cumtrapz : Cumulative integration for sampled data.
    ode : ODE integrator.
    odeint : ODE integrator.

    References
    ----------
    .. [1] 'Romberg's method' http://en.wikipedia.org/wiki/Romberg%27s_method

    Examples
    --------
    Integrate a gaussian from 0 to 1 and compare to the error function.

    >>> from scipy import integrate
    >>> from scipy.special import erf
    >>> gaussian = lambda x: 1/np.sqrt(np.pi) * np.exp(-x**2)
    >>> result = integrate.romberg(gaussian, 0, 1, show=True)
    Romberg integration of <function vfunc at ...> from [0, 1]

    ::

       Steps  StepSize  Results
           1  1.000000  0.385872
           2  0.500000  0.412631  0.421551
           4  0.250000  0.419184  0.421368  0.421356
           8  0.125000  0.420810  0.421352  0.421350  0.421350
          16  0.062500  0.421215  0.421350  0.421350  0.421350  0.421350
          32  0.031250  0.421317  0.421350  0.421350  0.421350  0.421350  0.421350

    The final result is 0.421350396475 after 33 function evaluations.

    >>> print("%g %g" % (2*result, erf(1)))
    0.842701 0.842701

    
    Integrate y(x) using samples along the given axis and the composite
    Simpson's rule.  If x is None, spacing of dx is assumed.

    If there are an even number of samples, N, then there are an odd
    number of intervals (N-1), but Simpson's rule requires an even number
    of intervals.  The parameter 'even' controls how this is handled.

    Parameters
    ----------
    y : array_like
        Array to be integrated.
    x : array_like, optional
        If given, the points at which `y` is sampled.
    dx : int, optional
        Spacing of integration points along axis of `y`. Only used when
        `x` is None. Default is 1.
    axis : int, optional
        Axis along which to integrate. Default is the last axis.
    even : {'avg', 'first', 'str'}, optional
        'avg' : Average two results:1) use the first N-2 intervals with
                  a trapezoidal rule on the last interval and 2) use the last
                  N-2 intervals with a trapezoidal rule on the first interval.

        'first' : Use Simpson's rule for the first N-2 intervals with
                a trapezoidal rule on the last interval.

        'last' : Use Simpson's rule for the last N-2 intervals with a
               trapezoidal rule on the first interval.

    See Also
    --------
    quad: adaptive quadrature using QUADPACK
    romberg: adaptive Romberg quadrature
    quadrature: adaptive Gaussian quadrature
    fixed_quad: fixed-order Gaussian quadrature
    dblquad: double integrals
    tplquad: triple integrals
    romb: integrators for sampled data
    cumtrapz: cumulative integration for sampled data
    ode: ODE integrators
    odeint: ODE integrators

    Notes
    -----
    For an odd number of samples that are equally spaced the result is
    exact if the function is a polynomial of order 3 or less.  If
    the samples are not equally spaced, then the result is exact only
    if the function is a polynomial of order 2 or less.

    scipy.integrate.quadratureIf given, shape of x must be 1-d or the same as y.
    Perform part of the trapezoidal rule to integrate a function.
    Assume that we had called difftrap with all lower powers-of-2
    starting with 1.  Calling difftrap only returns the summation
    of the new ordinates.  It does _not_ multiply by the width
    of the trapezoids.  This must be performed by the caller.
        'function' is the function to evaluate (must accept vector arguments).
        'interval' is a sequence with lower and upper limits
                   of integration.
        'numtraps' is the number of trapezoids to use (must be a
                   power-of-2).
    numtraps must be > 0 in difftrap().Gaussian quadrature is only available for finite limits.`initial` parameter should be a scalar.
    Cumulatively integrate y(x) using the composite trapezoidal rule.

    Parameters
    ----------
    y : array_like
        Values to integrate.
    x : array_like, optional
        The coordinate to integrate along.  If None (default), use spacing `dx`
        between consecutive elements in `y`.
    dx : int, optional
        Spacing between elements of `y`.  Only used if `x` is None.
    axis : int, optional
        Specifies the axis to cumulate.  Default is -1 (last axis).
    initial : scalar, optional
        If given, uses this value as the first value in the returned result.
        Typically this value should be 0.  Default is None, which means no
        value at ``x[0]`` is returned and `res` has one element less than `y`
        along the axis of integration.

    Returns
    -------
    res : ndarray
        The result of cumulative integration of `y` along `axis`.
        If `initial` is None, the shape is such that the axis of integration
        has one less value than `y`.  If `initial` is given, the shape is equal
        to that of `y`.

    See Also
    --------
    numpy.cumsum, numpy.cumprod
    quad: adaptive quadrature using QUADPACK
    romberg: adaptive Romberg quadrature
    quadrature: adaptive Gaussian quadrature
    fixed_quad: fixed-order Gaussian quadrature
    dblquad: double integrals
    tplquad: triple integrals
    romb: integrators for sampled data
    ode: ODE integrators
    odeint: ODE integrators

    Examples
    --------
    >>> from scipy import integrate
    >>> import matplotlib.pyplot as plt

    >>> x = np.linspace(-2, 2, num=20)
    >>> y = x
    >>> y_int = integrate.cumtrapz(y, x, initial=0)
    >>> plt.plot(x, y_int, 'ro', x, y[0] + 0.5 * x**2, 'b-')
    >>> plt.show()

    
       Richardson Extrapolation Table for Romberg Integration       Parameter 'even' must be 'avg', 'last', or 'first'.*** Printing table only supported for integrals of a single data set.
    Compute the differences for the Romberg quadrature corrections.
    See Forman Acton's "Real Computing Made Real," p 143.
    (   t   rnt   equalt   Nt   nat   dat   vit   nbt   dbt   yit   tit   nvect   Ct   Cinvt   it   vect   ait   BNt   powert   p1t   fac(   t   yt   dxt   axist   showt   ndt   Nsampst   Nintervt   nt   kt   Rt   allt   slice0t   slicem1t   ht   slice_Rt   startt   stopt   stept   it   jt   precist   widtht   formstr(   t   yt   startt   stopt   xt   dxt   axist   ndt   stept   allt   slice0t   slice1t   slice2t   resultt   ht   sl0t   sl1t   h0t   h1t   hsumt   hprodt   h0divh1(   t   functiont   at   bt   argst   tolt   rtolt   showt   divmaxt   vec_funct   vfunct   nt   intervalt   intranget   ordsumt   resultt   resmatt   errt   it   kt
   lastresult/usr/lib/python2.7/dist-packages/scipy/lib/__init__.pyscipy.lib
Python wrappers to external libraries
=====================================

- lapack -- wrappers for `LAPACK/ATLAS <http://netlib.org/lapack/>`_
            libraries
- blas -- wrappers for `BLAS/ATLAS <http://www.netlib.org/blas/>`_
          libraries

_new_name_old_name/usr/lib/python2.7/dist-packages/scipy/lib/_util.py
    Deprecated import, with redirection + warning.

    Examples
    --------
    Suppose you previously had in some module::

        from foo import spam

    If this has to be deprecated, do::

        spam = DeprecatedImport("foo.spam", "baz")

    to redirect users to use "baz" module instead.

    Module %s is deprecated, use %s insteadbugfixpre_releaseis_devversion_compare_version_NumpyVersion__repr_compare_pre_releasea\dNumpyVersion(%s)Compare alpha/beta/rc/final.rc\d\d[.]\d+[.]\d+Compare major.minor.bugfixInvalid object to compare with NumpyVersion.Utility to compare (Numpy) version strings.

The NumpyVersion class allows properly comparing numpy version strings.
The LooseVersion and StrictVersion classes that distutils provides don't
work; they don't recognize anything like alpha/beta/rc/dev versions.

b\dParse and compare numpy version strings.

    Numpy has the following versioning scheme (numbers given are examples; they
    can be >9) in principle):

    - Released version: '1.8.0', '1.8.1', etc.
    - Alpha: '1.8.0a1', '1.8.0a2', etc.
    - Beta: '1.8.0b1', '1.8.0b2', etc.
    - Release candidates: '1.8.0rc1', '1.8.0rc2', etc.
    - Development versions: '1.8.0.dev-f1234afa' (git commit hash appended)
    - Development versions after a1: '1.8.0a1.dev-f1234afa',
                                     '1.8.0b2.dev-f1234afa',
                                     '1.8.1rc1.dev-f1234afa', etc.
    - Development versions (no git hash available): '1.8.0.dev-Unknown'

    Comparing needs to be done against a valid version string or other
    `NumpyVersion` instance.

    Parameters
    ----------
    vstring : str
        Numpy version string (``np.__version__``).

    Notes
    -----
    All dev versions of the same (pre-)release compare equal.

    Examples
    --------
    >>> from scipy.lib._version import NumpyVersion
    >>> if NumpyVersion(np.__version__) < '1.7.0'):
    ...     print('skip')
    skip

    >>> NumpyVersion('1.7')  # raises ValueError, add ".0"

    Not a valid numpy version string/usr/lib/python2.7/dist-packages/scipy/lib/_version.py
====================================
Linear algebra (:mod:`scipy.linalg`)
====================================

.. currentmodule:: scipy.linalg

Linear algebra functions.

.. seealso::

   `numpy.linalg` for more linear algebra functions.  Note that
   although `scipy.linalg` imports most of them, identically named
   functions from `scipy.linalg` may offer more or slightly differing
   functionality.


Basics
======

.. autosummary::
   :toctree: generated/

   inv - Find the inverse of a square matrix
   solve - Solve a linear system of equations
   solve_banded - Solve a banded linear system
   solveh_banded - Solve a Hermitian or symmetric banded system
   solve_triangular - Solve a triangular matrix
   det - Find the determinant of a square matrix
   norm - Matrix and vector norm
   lstsq - Solve a linear least-squares problem
   pinv - Pseudo-inverse (Moore-Penrose) using lstsq
   pinv2 - Pseudo-inverse using svd
   pinvh - Pseudo-inverse of hermitian matrix
   kron - Kronecker product of two arrays
   tril - Construct a lower-triangular matrix from a given matrix
   triu - Construct an upper-triangular matrix from a given matrix

Eigenvalue Problems
===================

.. autosummary::
   :toctree: generated/

   eig - Find the eigenvalues and eigenvectors of a square matrix
   eigvals - Find just the eigenvalues of a square matrix
   eigh - Find the e-vals and e-vectors of a Hermitian or symmetric matrix
   eigvalsh - Find just the eigenvalues of a Hermitian or symmetric matrix
   eig_banded - Find the eigenvalues and eigenvectors of a banded matrix
   eigvals_banded - Find just the eigenvalues of a banded matrix

Decompositions
==============

.. autosummary::
   :toctree: generated/

   lu - LU decomposition of a matrix
   lu_factor - LU decomposition returning unordered matrix and pivots
   lu_solve - Solve Ax=b using back substitution with output of lu_factor
   svd - Singular value decomposition of a matrix
   svdvals - Singular values of a matrix
   diagsvd - Construct matrix of singular values from output of svd
   orth - Construct orthonormal basis for the range of A using svd
   cholesky - Cholesky decomposition of a matrix
   cholesky_banded - Cholesky decomp. of a sym. or Hermitian banded matrix
   cho_factor - Cholesky decomposition for use in solving a linear system
   cho_solve - Solve previously factored linear system
   cho_solve_banded - Solve previously factored banded linear system
   polar - Compute the polar decomposition.
   qr - QR decomposition of a matrix
   qr_multiply - QR decomposition and multiplication by Q
   qz - QZ decomposition of a pair of matrices
   schur - Schur decomposition of a matrix
   rsf2csf - Real to complex Schur form
   hessenberg - Hessenberg form of a matrix

.. seealso::

   `scipy.linalg.interpolative` -- Interpolative matrix decompositions


Matrix Functions
================

.. autosummary::
   :toctree: generated/

   expm - Matrix exponential
   logm - Matrix logarithm
   cosm - Matrix cosine
   sinm - Matrix sine
   tanm - Matrix tangent
   coshm - Matrix hyperbolic cosine
   sinhm - Matrix hyperbolic sine
   tanhm - Matrix hyperbolic tangent
   signm - Matrix sign
   sqrtm - Matrix square root
   funm - Evaluating an arbitrary matrix function
   expm_frechet - Frechet derivative of the matrix exponential
   expm_cond - Relative condition number of expm in the Frobenius norm
   fractional_matrix_power - Fractional matrix power


Matrix Equation Solvers
=======================

.. autosummary::
   :toctree: generated/

   solve_sylvester - Solve the Sylvester matrix equation
   solve_continuous_are - Solve the continuous-time algebraic Riccati equation
   solve_discrete_are - Solve the discrete-time algebraic Riccati equation
   solve_discrete_lyapunov - Solve the discrete-time Lyapunov equation
   solve_lyapunov - Solve the (continous-time) Lyapunov equation


Special Matrices
================

.. autosummary::
   :toctree: generated/

   block_diag - Construct a block diagonal matrix from submatrices
   circulant - Circulant matrix
   companion - Companion matrix
   dft - Discrete Fourier transform matrix
   hadamard - Hadamard matrix of order 2**n
   hankel - Hankel matrix
   hilbert - Hilbert matrix
   invhilbert - Inverse Hilbert matrix
   leslie - Leslie matrix
   pascal - Pascal matrix
   toeplitz - Toeplitz matrix
   tri - Construct a matrix filled with ones at and below a given diagonal

Low-level routines
==================

.. autosummary::
   :toctree: generated/

   get_blas_funcs
   get_lapack_funcs
   find_best_blas_type

.. seealso::

   `scipy.linalg.blas` -- Low-level BLAS functions

   `scipy.linalg.lapack` -- Low-level LAPACK functions

/usr/lib/python2.7/dist-packages/scipy/linalg/usr/lib/python2.7/dist-packages/scipy/linalg/__init__.pyscipy.linalg._decomp_polar
    Compute the polar decomposition.

    Returns the factors of the polar decomposition [1]_ `u` and `p` such
    that ``a = up`` (if `side` is "right") or ``a = pu`` (if `side` is
    "left"), where `p` is positive semidefinite.  Depending on the shape
    of `a`, either the rows or columns of `u` are orthonormal.  When `a`
    is a square array, `u` is a square unitary array.  When `a` is not
    square, the "canonical polar decomposition" [2]_ is computed.

    Parameters
    ----------
    a : (m, n) array_like
        The array to be factored.
    side : string, optional
        Determines whether a right or left polar decomposition is computed.
        If `side` is "right", then ``a = up``.  If `side` is "left",  then
        ``a = pu``.  The default is "right".

    Returns
    -------
    u : (m, n) ndarray
        If `a` is square, then `u` is unitary.  If m > n, then the columns
        of `a` are orthonormal, and if m < n, then the rows of `u` are
        orthonormal.
    p : ndarray
        `p` is Hermitian positive semidefinite.  If `a` is nonsingular, `p`
        is positive definite.  The shape of `p` is (n, n) or (m, m), depending
        on whether `side` is "right" or "left", respectively.

    References
    ----------
    .. [1] R. A. Horn and C. R. Johnson, "Matrix Analysis", Cambridge University
           Press, 1985.
    .. [2] N. J. Higham, "Functions of Matrices: Theory and Computation",
           SIAM, 2008.

    Examples
    --------
    >>> a = np.array([[1, -1], [2, 4]])
    >>> u, p = polar(a)
    >>> u
    array([[ 0.85749293, -0.51449576],
           [ 0.51449576,  0.85749293]])
    >>> p
    array([[ 1.88648444,  1.2004901 ],
           [ 1.2004901 ,  3.94446746]])

    A non-square example, with m < n:

    >>> b = np.array([[0.5, 1, 2], [1.5, 3, 4]])
    >>> u, p = polar(b)
    >>> u
    array([[-0.21196618, -0.42393237,  0.88054056],
           [ 0.39378971,  0.78757942,  0.4739708 ]])
    >>> p
    array([[ 0.48470147,  0.96940295,  1.15122648],
           [ 0.96940295,  1.9388059 ,  2.30245295],
           [ 1.15122648,  2.30245295,  3.65696431]])
    >>> u.dot(p)   # Verify the decomposition.
    array([[ 0.5,  1. ,  2. ],
           [ 1.5,  3. ,  4. ]])
    >>> u.dot(u.T)   # The rows of u are orthonormal.
    array([[  1.00000000e+00,  -2.07353665e-17],
           [ -2.07353665e-17,   1.00000000e+00]])

    Another non-square example, with m > n:

    >>> c = b.T
    >>> u, p = polar(c)
    >>> u
    array([[-0.21196618,  0.39378971],
           [-0.42393237,  0.78757942],
           [ 0.88054056,  0.4739708 ]])
    >>> p
    array([[ 1.23116567,  1.93241587],
           [ 1.93241587,  4.84930602]])
    >>> u.dot(p)   # Verify the decomposition.
    array([[ 0.5,  1.5],
           [ 1. ,  3. ],
           [ 2. ,  4. ]])
    >>> u.T.dot(u)  # The columns of u are orthonormal.
    array([[  1.00000000e+00,  -1.26363763e-16],
           [ -1.26363763e-16,   1.00000000e+00]])

    `side` must be either 'right' or 'left'/usr/lib/python2.7/dist-packages/scipy/linalg/_decomp_polar.py`a` must be a 2-D array.scipy.linalg._decomp_qzArray dimensions must be square and agree
    QZ decompostion for generalized eigenvalues of a pair of matrices.

    The QZ, or generalized Schur, decomposition for a pair of N x N
    nonsymmetric matrices (A,B) is::

        (A,B) = (Q*AA*Z', Q*BB*Z')

    where AA, BB is in generalized Schur form if BB is upper-triangular
    with non-negative diagonal and AA is upper-triangular, or for real QZ
    decomposition (``output='real'``) block upper triangular with 1x1
    and 2x2 blocks.  In this case, the 1x1 blocks correspond to real
    generalized eigenvalues and 2x2 blocks are 'standardized' by making
    the corresponding elements of BB have the form::

        [ a 0 ]
        [ 0 b ]

    and the pair of corresponding 2x2 blocks in AA and BB will have a complex
    conjugate pair of generalized eigenvalues.  If (``output='complex'``) or
    A and B are complex matrices, Z' denotes the conjugate-transpose of Z.
    Q and Z are unitary matrices.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    A : (N, N) array_like
        2d array to decompose
    B : (N, N) array_like
        2d array to decompose
    output : str {'real','complex'}
        Construct the real or complex QZ decomposition for real matrices.
        Default is 'real'.
    lwork : int, optional
        Work array size.  If None or -1, it is automatically computed.
    sort : {None, callable, 'lhp', 'rhp', 'iuc', 'ouc'}, optional
        NOTE: THIS INPUT IS DISABLED FOR NOW, IT DOESN'T WORK WELL ON WINDOWS.

        Specifies whether the upper eigenvalues should be sorted.  A callable
        may be passed that, given a eigenvalue, returns a boolean denoting
        whether the eigenvalue should be sorted to the top-left (True). For
        real matrix pairs, the sort function takes three real arguments
        (alphar, alphai, beta). The eigenvalue x = (alphar + alphai*1j)/beta.
        For complex matrix pairs or output='complex', the sort function
        takes two complex arguments (alpha, beta). The eigenvalue
        x = (alpha/beta).
        Alternatively, string parameters may be used:

            - 'lhp'   Left-hand plane (x.real < 0.0)
            - 'rhp'   Right-hand plane (x.real > 0.0)
            - 'iuc'   Inside the unit circle (x*x.conjugate() <= 1.0)
            - 'ouc'   Outside the unit circle (x*x.conjugate() > 1.0)

        Defaults to None (no sorting).
    check_finite : boolean
        If true checks the elements of `A` and `B` are finite numbers. If
        false does no checking and passes matrix through to
        underlying algorithm.

    Returns
    -------
    AA : (N, N) ndarray
        Generalized Schur form of A.
    BB : (N, N) ndarray
        Generalized Schur form of B.
    Q : (N, N) ndarray
        The left Schur vectors.
    Z : (N, N) ndarray
        The right Schur vectors.
    sdim : int, optional
        If sorting was requested, a fifth return value will contain the
        number of eigenvalues for which the sort condition was True.

    Notes
    -----
    Q is transposed versus the equivalent function in Matlab.

    Examples
    --------
    >>> from scipy import linalg
    >>> np.random.seed(1234)
    >>> A = np.arange(9).reshape((3, 3))
    >>> B = np.random.randn(3, 3)

    >>> AA, BB, Q, Z = linalg.qz(A, B)
    >>> AA
    array([[-13.40928183,  -4.62471562,   1.09215523],
           [  0.        ,   0.        ,   1.22805978],
           [  0.        ,   0.        ,   0.31973817]])
    >>> BB
    array([[ 0.33362547, -1.37393632,  0.02179805],
           [ 0.        ,  1.68144922,  0.74683866],
           [ 0.        ,  0.        ,  0.9258294 ]])
    >>> Q
    array([[ 0.14134727, -0.97562773,  0.16784365],
           [ 0.49835904, -0.07636948, -0.86360059],
           [ 0.85537081,  0.20571399,  0.47541828]])
    >>> Z
    array([[-0.24900855, -0.51772687,  0.81850696],
           [-0.79813178,  0.58842606,  0.12938478],
           [-0.54861681, -0.6210585 , -0.55973739]])

    dtype %s not understoodIllegal value in argument %d of ggesSomething other than QZ iteration failedThe 'sort' input of qz() has to be None (will  change when this functionality is made more robust).After reordering, roundoff changed values of some complex eigenvalues so that leading eigenvalues in the Generalized Schur form no longer satisfy sort=True. This could also be caused due to scaling./usr/lib/python2.7/dist-packages/scipy/linalg/_decomp_qz.pyThe QZ iteration failed. (a,b) are not in Schur form, but ALPHAR(j), ALPHAI(j), and BETA(j) should be correct for J=%d,...,NReordering failed in <s,d,c,z>tgsen(   t   At   Bt   outputt   lworkt   sortt   overwrite_at   overwrite_bt   check_finitet   a1t   b1t   a_mt   a_nt   b_mt   b_nt   typat   typbt   ggest   resultt   sort_tt	   sfunctiont   infoLwM4W1W2Z1Z2Lw1Lw2Lz1Lz2SPSkappaK_normX_normexpm_Mlu_pivblockEnlargem_pade_pairsUnknown implementation %s
    Construct the Kronecker form of the Frechet derivative of expm.

    Parameters
    ----------
    A : array-like with shape (N, N)
        Matrix to be expm'd.
    method : str, optional
        Extra keyword to be passed to expm_frechet.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    K : 2d ndarray with shape (N*N, N*N)
        Kronecker form of the Frechet derivative of the matrix exponential.

    Notes
    -----
    This function is used to help compute the condition number
    of the matrix exponential.

    See also
    --------
    expm : Compute a matrix exponential.
    expm_frechet : Compute the Frechet derivative of the matrix exponential.
    expm_cond : Compute the relative condition number of the matrix exponential
                in the Frobenius norm.

    expected A to be a square matrix
    Stack columns of M to construct a single vector.

    This is somewhat standard notation in linear algebra.

    Parameters
    ----------
    M : 2d array-like
        Input matrix
    
    Returns
    -------
    v : 1d ndarray
        Output vector

    /usr/lib/python2.7/dist-packages/scipy/linalg/_expm_frechet.py
    This is a helper function, mostly for testing and profiling.
    Return expm(A), frechet(A, E)
    scipy.linalg._expm_frechet
    Frechet derivative of the matrix exponential of A in the direction E.

    .. versionadded:: 0.13.0

    Parameters
    ----------
    A : (N, N) array_like
        Matrix of which to take the matrix exponential.
    E : (N, N) array_like
        Matrix direction in which to take the Frechet derivative.
    method : str, optional
        Choice of algorithm.  Should be one of

        - `SPS` (default)
        - `blockEnlarge`

    compute_expm : bool, optional
        Whether to compute also `expm_A` in addition to `expm_frechet_AE`.
        Default is True.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    expm_A : ndarray
        Matrix exponential of A.
    expm_frechet_AE : ndarray
        Frechet derivative of the matrix exponential of A in the direction E.

    For ``compute_expm = False``, only `expm_frechet_AE` is returned.

    See also
    --------
    expm : Compute the exponential of a matrix.

    Notes
    -----
    This section describes the available implementations that can be selected
    by the `method` parameter. The default method is *SPS*.

    Method *blockEnlarge* is a naive algorithm.

    Method *SPS* is Scaling-Pade-Squaring [1]_.
    It is a sophisticated implementation which should take
    only about 3/8 as much time as the naive implementation.
    The asymptotics are the same.

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2009)
           Computing the Frechet Derivative of the Matrix Exponential,
           with an application to Condition Number Estimation.
           SIAM Journal On Matrix Analysis and Applications.,
           30 (4). pp. 1639-1657. ISSN 1095-7162

    Examples
    --------
    >>> import scipy.linalg
    >>> A = np.random.randn(3, 3)
    >>> E = np.random.randn(3, 3)
    >>> expm_A, expm_frechet_AE = scipy.linalg.expm_frechet(A, E)
    >>> expm_A.shape, expm_frechet_AE.shape
    ((3, 3), (3, 3))

    >>> import scipy.linalg
    >>> A = np.random.randn(3, 3)
    >>> E = np.random.randn(3, 3)
    >>> expm_A, expm_frechet_AE = scipy.linalg.expm_frechet(A, E)
    >>> M = np.zeros((6, 6))
    >>> M[:3, :3] = A; M[:3, 3:] = E; M[3:, 3:] = A
    >>> expm_M = scipy.linalg.expm(M)
    >>> np.allclose(expm_A, expm_M[:3, :3])
    True
    >>> np.allclose(expm_frechet_AE, expm_M[:3, 3:])
    True

    
    Relative condition number of the matrix exponential in the Frobenius norm.

    .. versionadded:: 0.14.0

    Parameters
    ----------
    A : 2d array-like
        Square input matrix with shape (N, N).
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    kappa : float
        The relative condition number of the matrix exponential
        in the Frobenius norm

    Notes
    -----
    A faster estimate for the condition number in the 1-norm
    has been published but is not yet implemented in scipy.

    See also
    --------
    expm : Compute the exponential of a matrix.
    expm_frechet : Compute the Frechet derivative of the matrix exponential.

    expected E to be a square matrixexpected A and E to be the same shape("   t   At   Et   nt   st   identt   A_norm_1t   m_pade_pairst   mt   padet   Ut   Vt   Lut   Lvt   A2t   M2t   A4t   M4t   A6t   M6t   bt   W1t   W2t   Z1t   Z2t   Wt   Lw1t   Lw2t   Lz1t   Lz2t   Lwt   lu_pivt   Rt   Lt   k(   NgaV>gX|[T7?g_vO?gQI?g?g+?guV?gGz?g{Gz?g\(\@g
p=
	@g333333@g(\@gQ@g=
p=@gGz@g(\!@gQ#@g333333%@gffffff'@Q?X9v?Mb?|?5^?B`"?;On?rh|?jt?jt?rh|?w/??5^I?On?+?UN@?j+??W[?z):?Yb?3kb?exp2k_hattmp_btmp_ctmp_ueivalslog_l1log_l2abs_diagarctanh_z2>0>near_singularity_msgexact_singularity_msg
    Compute the scalar unwinding number.

    Uses Eq. (5.3) in [1]_, and should be equal to (z - log(exp(z)) / (2 pi i).
    Note that this definition differs in sign from the original definition
    in equations (5, 6) in [2]_.  The sign convention is justified in [3]_.

    Parameters
    ----------
    z : complex
        A complex number.

    Returns
    -------
    unwinding_number : integer
        The scalar unwinding number of z.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    .. [2] Robert M. Corless and David J. Jeffrey,
           "The unwinding number." Newsletter ACM SIGSAM Bulletin
           Volume 30, Issue 2, June 1996, Pages 28-35.

    .. [3] Russell Bradford and Robert M. Corless and James H. Davenport and
           David J. Jeffrey and Stephen M. Watt,
           "Reasoning about the elementary functions of complex analysis"
           Annals of Mathematics and Artificial Intelligence,
           36: 303-318, 2002.

    
    Compute the fractional power of a matrix, for fractions -1 < t < 1.

    This uses algorithm (3.1) of [1]_.
    The Pade approximation itself uses algorithm (4.1) of [2]_.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix whose fractional power to evaluate.
    t : float
        Fractional power between -1 and 1 exclusive.

    Returns
    -------
    X : (N, N) array_like
        The fractional power of the matrix.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing Lin (2013)
           "An Improved Schur-Pade Algorithm for Fractional Powers
           of a Matrix and their Frechet Derivatives."

    .. [2] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    
    Compute the fractional power of a matrix.

    Proceeds according to the discussion in section (6) of [1]_.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix whose fractional power to evaluate.
    p : float
        Fractional power.

    Returns
    -------
    X : (N, N) array_like
        The fractional power of the matrix.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    
    A helper function for inverse scaling and squaring for Pade approximation.

    Parameters
    ----------
    T0 : (N, N) array_like upper triangular
        Matrix involved in inverse scaling and squaring.
    theta : indexable
        The values theta[1] .. theta[7] must be available.
        They represent bounds related to Pade approximation, and they depend
        on the matrix function which is being computed.
        For example, different values of theta are required for
        matrix logarithm than for fractional matrix power.

    Returns
    -------
    R : (N, N) array_like upper triangular
        Composition of zero or more matrix square roots of T0, minus I.
    s : non-negative integer
        Number of square roots taken.
    m : positive integer
        The degree of the Pade approximation.

    Notes
    -----
    This subroutine appears as a chunk of lines within
    a couple of published algorithms; for example it appears
    as lines 4--35 in algorithm (3.1) of [1]_, and
    as lines 3--34 in algorithm (4.1) of [2]_.
    The instances of 'goto line 38' in algorithm (3.1) of [1]_
    probably mean 'goto line 36' and have been intepreted accordingly.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing Lin (2013)
           "An Improved Schur-Pade Algorithm for Fractional Powers
           of a Matrix and their Frechet Derivatives."

    .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2012)
           "Improved Inverse Scaling and Squaring Algorithms
           for the Matrix Logarithm."
           SIAM Journal on Scientific Computing, 34 (4). C152-C169.
           ISSN 1095-7197

    
    Compute a fractional power of an upper triangular matrix.

    The fractional power is restricted to fractions -1 < t < 1.
    This uses algorithm (3.1) of [1]_.
    The Pade approximation itself uses algorithm (4.1) of [2]_.

    Parameters
    ----------
    T : (N, N) array_like
        Upper triangular matrix whose fractional power to evaluate.
    t : float
        Fractional power between -1 and 1 exclusive.

    Returns
    -------
    X : (N, N) array_like
        The fractional power of the matrix.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing Lin (2013)
           "An Improved Schur-Pade Algorithm for Fractional Powers
           of a Matrix and their Frechet Derivatives."

    .. [2] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    cannot use inverse scaling and squaring to find the fractional matrix power of a singular matrixexpected an upper triangular square matrix/usr/lib/python2.7/dist-packages/scipy/linalg/_matfuncs_inv_ssq.py
    Computes r = a^(1 / (2^k)) - 1.

    This is algorithm (2) of [1]_.
    The purpose is to avoid a danger of subtractive cancellation.
    For more computational efficiency it should probably be cythonized.

    Parameters
    ----------
    a : complex
        A complex number preferably belonging to the closed negative real axis.
    k : integer
        A nonnegative integer.

    Returns
    -------
    r : complex
        The value r = a^(1 / (2^k)) - 1 computed with less cancellation.

    Notes
    -----
    The algorithm as written in the publication does not handle k=0 or k=1
    correctly, so these are special-cased in this implementation.
    This function is intended to not allow `a` to belong to the closed
    negative real axis, but this is constraint is relaxed.

    References
    ----------
    .. [1] Awad H. Al-Mohy (2012)
           "A more accurate Briggs method for the logarithm",
           Numerical Algorithms, 59 : 393--402.

    
Matrix functions that use Pade approximation with inverse scaling and squaring.


    Compute a superdiagonal entry of a fractional matrix power.

    This is Eq. (5.6) in [1]_.

    Parameters
    ----------
    l1 : complex
        A diagonal entry of the matrix.
    l2 : complex
        A diagonal entry of the matrix.
    t12 : complex
        A superdiagonal entry of the matrix.
    p : float
        A fractional power.

    Returns
    -------
    f12 : complex
        A superdiagonal entry of the fractional matrix power.

    Notes
    -----
    Some amount of care has been taken to return a real number
    if all of the inputs are real.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    expected a positive integer iThe logm input matrix is exactly singular.
    Compute matrix logarithm of an upper triangular matrix.

    The matrix logarithm is the inverse of
    expm: expm(logm(`T`)) == `T`

    Parameters
    ----------
    T : (N, N) array_like
        Upper triangular matrix whose logarithm to evaluate

    Returns
    -------
    logm : (N, N) ndarray
        Matrix logarithm of `T`

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2012)
           "Improved Inverse Scaling and Squaring Algorithms
           for the Matrix Logarithm."
           SIAM Journal on Scientific Computing, 34 (4). C152-C169.
           ISSN 1095-7197

    .. [2] Nicholas J. Higham (2008)
           "Functions of Matrices: Theory and Computation"
           ISBN 978-0-898716-46-7

    .. [3] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    
    Compute matrix logarithm.

    The matrix logarithm is the inverse of
    expm: expm(logm(`A`)) == `A`

    Parameters
    ----------
    A : (N, N) array_like
        Matrix whose logarithm to evaluate

    Returns
    -------
    logm : (N, N) ndarray
        Matrix logarithm of `A`

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2012)
           "Improved Inverse Scaling and Squaring Algorithms
           for the Matrix Logarithm."
           SIAM Journal on Scientific Computing, 34 (4). C152-C169.
           ISSN 1095-7197

    .. [2] Nicholas J. Higham (2008)
           "Functions of Matrices: Theory and Computation"
           ISBN 978-0-898716-46-7

    .. [3] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    
    Efficiently estimate the 1-norm of (A - I)^p.

    Parameters
    ----------
    A : ndarray
        Matrix whose 1-norm of a power is to be computed.
    p : int
        Non-negative integer power.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.
        Larger values take longer and use more memory
        but give more accurate output.
    itmax : int, optional
        Use at most this many iterations.
    compute_v : bool, optional
        Request a norm-maximizing linear operator input vector if True.
    compute_w : bool, optional
        Request a norm-maximizing linear operator output vector if True.

    Returns
    -------
    est : float
        An underestimate of the 1-norm of the sparse matrix.
    v : ndarray, optional
        The vector such that ||Av||_1 == est*||v||_1.
        It can be thought of as an input to the linear operator
        that gives an output with particularly large norm.
    w : ndarray, optional
        The vector Av which has relatively large 1-norm.
        It can be thought of as an output of the linear operator
        that is relatively large in norm compared to the input.

    The logm input matrix may be nearly singular.expected -1 < t < 1
    Compute a superdiagonal entry of a matrix logarithm.

    This is Eq. (11.28) in [1]_.

    Parameters
    ----------
    l1 : complex
        A diagonal entry of the matrix.
    l2 : complex
        A diagonal entry of the matrix.
    t12 : complex
        A superdiagonal entry of the matrix.

    Returns
    -------
    f12 : complex
        A superdiagonal entry of the matrix logarithm.

    Notes
    -----
    Some amount of care has been taken to return a real number
    if all of the inputs are real.

    References
    ----------
    .. [1] Nicholas J. Higham (2008)
           "Functions of Matrices: Theory and Computation"
           ISBN 978-0-898716-46-7

    expected a nonnegative integer k
    Evaluate the Pade approximation of a fractional matrix power.

    Evaluate the degree-m Pade approximation of R
    to the fractional matrix power t using the continued fraction
    in bottom-up fashion using algorithm (4.1) in [1]_.

    Parameters
    ----------
    R : (N, N) array_like
        Upper triangular matrix whose fractional power to evaluate.
    t : float
        Fractional power between -1 and 1 exclusive.
    m : positive integer
        Degree of Pade approximation.

    Returns
    -------
    U : (N, N) array_like
        The degree-m Pade approximation of R to the fractional power t.
        This matrix will be upper triangular.

    References
    ----------
    .. [1] Nicholas J. Higham and Lijing lin (2011)
           "A Schur-Pade Algorithm for Fractional Powers of a Matrix."
           SIAM Journal on Matrix Analysis and Applications,
           32 (3). pp. 1056-1078. ISSN 0895-4798

    np.count_nonzero not available in numpy 1.5.x
    A representation of the linear operator (A - I)^p.
    expected a positive integer m(   t   T0t   thetat   nt   Tt   s0t   tmp_diagt   it   st   kt   d2t   d3t   a2t   mt   d4t   a3t   j1t   d5t   a4t   etat   Rt   has_principal_brancht   jt   at   rt   pt   l1t   l2t   t12t   f12(   t   Tt   nt   T_diagt   keep_it_realt   T0t   thetat   Rt   st   mt   nodest   weightst   identt   Ut   alphat   betat   has_principal_brancht   it   l1t   l2t   t12RjjnzeigblargensmallNon-matrix input to matrix function.
    Matrix square root.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix whose square root to evaluate
    disp : bool, optional
        Print warning if error in the result is estimated large
        instead of returning estimated error. (Default: True)
    blocksize : integer, optional
        If the blocksize is not degenerate with respect to the
        size of the input array, then use a blocked algorithm. (Default: 64)

    Returns
    -------
    sqrtm : (N, N) ndarray
        Value of the sqrt function at `A`

    errest : float
        (if disp == False)

        Frobenius norm of the estimated error, ||err||_F / ||A||_F

    References
    ----------
    .. [1] Edvin Deadman, Nicholas J. Higham, Rui Ralha (2013)
           "Blocked Schur Algorithms for Computing the Matrix Square Root,
           Lecture Notes in Computer Science, 7782. pp. 171-182.

    The blocksize should be at least 1.Failed to find a square root.failed to find the matrix square root
    Matrix square root of an upper triangular matrix.

    This is a helper function for `sqrtm` and `logm`.

    Parameters
    ----------
    T : (N, N) array_like upper triangular
        Matrix whose square root to evaluate
    blocksize : integer, optional
        If the blocksize is not degenerate with respect to the
        size of the input array, then use a blocked algorithm. (Default: 64)

    Returns
    -------
    sqrtm : (N, N) ndarray
        Value of the sqrt function at `T`

    References
    ----------
    .. [1] Edvin Deadman, Nicholas J. Higham, Rui Ralha (2013)
           "Blocked Schur Algorithms for Computing the Matrix Square Root,
           Lecture Notes in Computer Science, 7782. pp. 171-182.

    /usr/lib/python2.7/dist-packages/scipy/linalg/_matfuncs_sqrtm.pyMatrix is singular and may not have a square root.
Matrix square root for general matrices and for upper triangular matrices.

This module exists to avoid cyclic imports.

(   t   Tt	   blocksizet   T_diagt   keep_it_realt   Rt   nt   nblockst   bsmallt   nlarget   blarget   nsmallt   start_stop_pairst   startt   countt   sizet   it   stopt   jt   st   denomt   jstartt   jstopt   istartt   istopt   St   Riit   Rjjt   xt   scalet   infou11u21z11z12z21z22u11itranbIllegal value encountered in the %d term/usr/lib/python2.7/dist-packages/scipy/linalg/_solvers.pyscipy.linalg._solversMatrix R in the algebraic Riccati equation solver is ill-conditionedMatrix A in the algebraic Riccati equation solver is ill-conditionedMatrix equation solver routines
    Solves the disctrete algebraic Riccati equation, or DARE, defined as
    (X = A'XA-(A'XB)(R+B'XB)^-1(B'XA)+Q), directly using a Schur decomposition
    method.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : (M, M) array_like
        Non-singular, square matrix
    b : (M, N) array_like
        Input
    q : (M, M) array_like
        Input
    r : (N, N) array_like
        Non-singular, square matrix

    Returns
    -------
    x : ndarray
        Solution to the continuous Lyapunov equation

    See Also
    --------
    solve_continuous_are : Solves the continuous algebraic Riccati equation

    Notes
    -----
    Method taken from:
    Laub, "A Schur Method for Solving Algebraic Riccati Equations."
    U.S. Energy Research and Development Agency under contract
    ERDA-E(49-18)-2087.
    http://dspace.mit.edu/bitstream/handle/1721.1/1301/R-0859-05666488.pdf

    
    Solves the continuous Lyapunov equation (AX + XA^H = Q) given the values
    of A and Q using the Bartels-Stewart algorithm.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : array_like
        A square matrix

    q : array_like
        Right-hand side square matrix

    Returns
    -------
    x : array_like
        Solution to the continuous Lyapunov equation

    See Also
    --------
    solve_sylvester : computes the solution to the Sylvester equation

    Notes
    -----
    Because the continuous Lyapunov equation is just a special form of the
    Sylvester equation, this solver relies entirely on solve_sylvester for a
    solution.

    
    Solves the Discrete Lyapunov Equation (A'XA-X=-Q) directly.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : (M, M) array_like
        A square matrix

    q : (M, M) array_like
        Right-hand side square matrix

    Returns
    -------
    x : ndarray
        Solution to the continuous Lyapunov equation

    Notes
    -----
    Algorithm is based on a direct analytical solution from:
    Hamilton, James D. Time Series Analysis, Princeton: Princeton University
    Press, 1994.  265.  Print.
    http://www.scribd.com/doc/20577138/Hamilton-1994-Time-Series-Analysis

    
    Computes a solution (X) to the Sylvester equation (AX + XB = Q).

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : (M, M) array_like
        Leading matrix of the Sylvester equation
    b : (N, N) array_like
        Trailing matrix of the Sylvester equation
    q : (M, N) array_like
        Right-hand side

    Returns
    -------
    x : (M, N) ndarray
        The solution to the Sylvester equation.

    Raises
    ------
    LinAlgError
        If solution was not found

    Notes
    -----
    Computes a solution to the Sylvester matrix equation via the Bartels-
    Stewart algorithm.  The A and B matrices first undergo Schur
    decompositions.  The resulting matrices are used to construct an
    alternative Sylvester equation (``RY + YS^T = F``) where the R and S
    matrices are in quasi-triangular form (or, when R, S or F are complex,
    triangular form).  The simplified equation is then solved using
    ``*TRSYL`` from LAPACK directly.

    LAPACK implementation does not contain a proper Sylvester equation solver (TRSYL)
    Solves the continuous algebraic Riccati equation, or CARE, defined
    as (A'X + XA - XBR^-1B'X+Q=0) directly using a Schur decomposition
    method.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : (M, M) array_like
        Input
    b : (M, N) array_like
        Input
    q : (M, M) array_like
        Input
    r : (N, N) array_like
        Non-singular, square matrix

    Returns
    -------
    x : (M, M) ndarray
        Solution to the continuous algebraic Riccati equation

    See Also
    --------
    solve_discrete_are : Solves the discrete algebraic Riccati equation

    Notes
    -----
    Method taken from:
    Laub, "A Schur Method for Solving Algebraic Riccati Equations."
    U.S. Energy Research and Development Agency under contract
    ERDA-E(49-18)-2087.
    http://dspace.mit.edu/bitstream/handle/1721.1/1301/R-0859-05666488.pdf

    )\(?unitdiagpsigma_diagabove_cutoffoverwrite_lu
    Solve the equation `a x = b` for `x`, assuming a is a triangular matrix.

    Parameters
    ----------
    a : (M, M) array_like
        A triangular matrix
    b : (M,) or (M, N) array_like
        Right-hand side matrix in `a x = b`
    lower : boolean
        Use only data contained in the lower triangle of `a`.
        Default is to use upper triangle.
    trans : {0, 1, 2, 'N', 'T', 'C'}, optional
        Type of system to solve:

        ========  =========
        trans     system
        ========  =========
        0 or 'N'  a x  = b
        1 or 'T'  a^T x = b
        2 or 'C'  a^H x = b
        ========  =========
    unit_diagonal : bool, optional
        If True, diagonal elements of `a` are assumed to be 1 and
        will not be referenced.
    overwrite_b : bool, optional
        Allow overwriting data in `b` (may enhance performance)
    check_finite : bool, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : (M,) or (M, N) ndarray
        Solution to the system `a x = b`.  Shape of return matches `b`.

    Raises
    ------
    LinAlgError
        If `a` is singular

    Notes
    -----
    .. versionadded:: 0.9.0

    invalid values for the number of lower and upper diagonals: l+u+1 (%d) does not equal ab.shape[0] (%d)solve:overwrite_a=
    Solve the equation a x = b for x, assuming a is banded matrix.

    The matrix a is stored in `ab` using the matrix diagonal ordered form::

        ab[u + i - j, j] == a[i,j]

    Example of `ab` (shape of a is (6,6), `u` =1, `l` =2)::

        *    a01  a12  a23  a34  a45
        a00  a11  a22  a33  a44  a55
        a10  a21  a32  a43  a54   *
        a20  a31  a42  a53   *    *

    Parameters
    ----------
    (l, u) : (integer, integer)
        Number of non-zero lower and upper diagonals
    ab : (`l` + `u` + 1, M) array_like
        Banded matrix
    b : (M,) or (M, K) array_like
        Right-hand side
    overwrite_ab : boolean, optional
        Discard data in `ab` (may enhance performance)
    overwrite_b : boolean, optional
        Discard data in `b` (may enhance performance)
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : (M,) or (M, K) ndarray
        The solution to the system a x = b.  Returned shape depends on the
        shape of `b`.

    
    Compute the (Moore-Penrose) pseudo-inverse of a matrix.

    Calculate a generalized inverse of a matrix using its
    singular-value decomposition and including all 'large' singular
    values.

    Parameters
    ----------
    a : (M, N) array_like
        Matrix to be pseudo-inverted.
    cond, rcond : float or None
        Cutoff for 'small' singular values.
        Singular values smaller than ``rcond*largest_singular_value``
        are considered zero.
        If None or -1, suitable machine precision is used.
    return_rank : bool, optional
        if True, return the effective rank of the matrix
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    B : (N, M) ndarray
        The pseudo-inverse of matrix `a`.
    rank : int
        The effective rank of the matrix.  Returned if return_rank == True

    Raises
    ------
    LinAlgError
        If SVD computation does not converge.

    Examples
    --------
    >>> a = np.random.randn(9, 6)
    >>> B = linalg.pinv2(a)
    >>> np.allclose(a, dot(a, dot(B, a)))
    True
    >>> np.allclose(B, dot(B, dot(a, B)))
    True

    
    Compute the (Moore-Penrose) pseudo-inverse of a matrix.

    Calculate a generalized inverse of a matrix using a least-squares
    solver.

    Parameters
    ----------
    a : (M, N) array_like
        Matrix to be pseudo-inverted.
    cond, rcond : float, optional
        Cutoff for 'small' singular values in the least-squares solver.
        Singular values smaller than ``rcond * largest_singular_value``
        are considered zero.
    return_rank : bool, optional
        if True, return the effective rank of the matrix
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    B : (N, M) ndarray
        The pseudo-inverse of matrix `a`.
    rank : int
        The effective rank of the matrix.  Returned if return_rank == True

    Raises
    ------
    LinAlgError
        If computation does not converge.

    Examples
    --------
    >>> a = np.random.randn(9, 6)
    >>> B = linalg.pinv(a)
    >>> np.allclose(a, dot(a, dot(B, a)))
    True
    >>> np.allclose(B, dot(B, dot(a, B)))
    True

    solve:overwrite_b=
    Compute the determinant of a matrix

    The determinant of a square matrix is a value derived arithmetically
    from the coefficients of the matrix.

    The determinant for a 3x3 matrix, for example, is computed as follows::

        a    b    c
        d    e    f = A
        g    h    i

        det(A) = a*e*i + b*f*g + c*d*h - c*e*g - b*d*i - a*f*h

    Parameters
    ----------
    a : (M, M) array_like
        A square matrix.
    overwrite_a : bool
        Allow overwriting data in a (may enhance performance).
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    det : float or complex
        Determinant of `a`.

    Notes
    -----
    The determinant is computed via LU factorization, LAPACK routine z/dgetrf.

    Examples
    --------
    >>> a = np.array([[1,2,3],[4,5,6],[7,8,9]])
    >>> linalg.det(a)
    0.0
    >>> a = np.array([[0,2,3],[4,5,6],[7,8,9]])
    >>> linalg.det(a)
    3.0

    
    Compute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.

    Calculate a generalized inverse of a Hermitian or real symmetric matrix
    using its eigenvalue decomposition and including all eigenvalues with
    'large' absolute value.

    Parameters
    ----------
    a : (N, N) array_like
        Real symmetric or complex hermetian matrix to be pseudo-inverted
    cond, rcond : float or None
        Cutoff for 'small' eigenvalues.
        Singular values smaller than rcond * largest_eigenvalue are considered
        zero.

        If None or -1, suitable machine precision is used.
    lower : bool
        Whether the pertinent array data is taken from the lower or upper
        triangle of a. (Default: lower)
    return_rank : bool, optional
        if True, return the effective rank of the matrix
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    B : (N, N) ndarray
        The pseudo-inverse of matrix `a`.
    rank : int
        The effective rank of the matrix.  Returned if return_rank == True

    Raises
    ------
    LinAlgError
        If eigenvalue does not converge

    Examples
    --------
    >>> from numpy import *
    >>> a = random.randn(9, 6)
    >>> a = np.dot(a, a.T)
    >>> B = pinvh(a)
    >>> allclose(a, dot(a, dot(B, a)))
    True
    >>> allclose(B, dot(B, dot(a, B)))
    True

    
    Compute the inverse of a matrix.

    Parameters
    ----------
    a : array_like
        Square matrix to be inverted.
    overwrite_a : bool, optional
        Discard data in `a` (may improve performance). Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    ainv : ndarray
        Inverse of the matrix `a`.

    Raises
    ------
    LinAlgError :
        If `a` is singular.
    ValueError :
        If `a` is not square, or not 2-dimensional.

    Examples
    --------
    >>> a = np.array([[1., 2.], [3., 4.]])
    >>> sp.linalg.inv(a)
    array([[-2. ,  1. ],
           [ 1.5, -0.5]])
    >>> np.dot(a, sp.linalg.inv(a))
    array([[ 1.,  0.],
           [ 0.,  1.]])

    
    Solve the equation ``a x = b`` for ``x``.

    Parameters
    ----------
    a : (M, M) array_like
        A square matrix.
    b : (M,) or (M, N) array_like
        Right-hand side matrix in ``a x = b``.
    sym_pos : bool
        Assume `a` is symmetric and positive definite.
    lower : boolean
        Use only data contained in the lower triangle of `a`, if `sym_pos` is
        true.  Default is to use upper triangle.
    overwrite_a : bool
        Allow overwriting data in `a` (may enhance performance).
        Default is False.
    overwrite_b : bool
        Allow overwriting data in `b` (may enhance performance).
        Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : (M,) or (M, N) ndarray
        Solution to the system ``a x = b``.  Shape of the return matches the
        shape of `b`.

    Raises
    ------
    LinAlgError
        If `a` is singular.

    Examples
    --------
    Given `a` and `b`, solve for `x`:

    >>> a = np.array([[3,2,0],[1,-1,0],[0,5,1]])
    >>> b = np.array([2,4,-1])
    >>> x = linalg.solve(a,b)
    >>> x
    array([ 2., -2.,  9.])
    >>> np.dot(a, x) == b
    array([ True,  True,  True], dtype=bool)

    
    Solve equation a x = b. a is Hermitian positive-definite banded matrix.

    The matrix a is stored in `ab` either in lower diagonal or upper
    diagonal ordered form:

        ab[u + i - j, j] == a[i,j]        (if upper form; i <= j)
        ab[    i - j, j] == a[i,j]        (if lower form; i >= j)

    Example of `ab` (shape of a is (6,6), `u` =2)::

        upper form:
        *   *   a02 a13 a24 a35
        *   a01 a12 a23 a34 a45
        a00 a11 a22 a33 a44 a55

        lower form:
        a00 a11 a22 a33 a44 a55
        a10 a21 a32 a43 a54 *
        a20 a31 a42 a53 *   *

    Cells marked with * are not used.

    Parameters
    ----------
    ab : (`u` + 1, M) array_like
        Banded matrix
    b : (M,) or (M, K) array_like
        Right-hand side
    overwrite_ab : bool, optional
        Discard data in `ab` (may enhance performance)
    overwrite_b : bool, optional
        Discard data in `b` (may enhance performance)
    lower : bool, optional
        Is the matrix in the lower form. (Default is upper form)
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : (M,) or (M, K) ndarray
        The solution to the system a x = b.  Shape of return matches shape
        of `b`.

    
    Compute least-squares solution to equation Ax = b.

    Compute a vector x such that the 2-norm ``|b - A x|`` is minimized.

    Parameters
    ----------
    a : (M, N) array_like
        Left hand side matrix (2-D array).
    b : (M,) or (M, K) array_like
        Right hand side matrix or vector (1-D or 2-D array).
    cond : float, optional
        Cutoff for 'small' singular values; used to determine effective
        rank of a. Singular values smaller than
        ``rcond * largest_singular_value`` are considered zero.
    overwrite_a : bool, optional
        Discard data in `a` (may enhance performance). Default is False.
    overwrite_b : bool, optional
        Discard data in `b` (may enhance performance). Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : (N,) or (N, K) ndarray
        Least-squares solution.  Return shape matches shape of `b`.
    residues : () or (1,) or (K,) ndarray
        Sums of residues, squared 2-norm for each column in ``b - a x``.
        If rank of matrix a is < N or > M this is an empty array.
        If b was 1-D, this is an (1,) shape array, otherwise the shape is (K,).
    rank : int
        Effective rank of matrix `a`.
    s : (min(M,N),) ndarray
        Singular values of `a`. The condition number of a is
        ``abs(s[0]/s[-1])``.

    Raises
    ------
    LinAlgError :
        If computation does not converge.


    See Also
    --------
    optimize.nnls : linear least squares with non-negativity constraint

    shapes of ab and b are not compatible.illegal value in %d-th argument of internal det.getrfillegal value in %d-th argument of internal pbsv/usr/lib/python2.7/dist-packages/scipy/linalg/basic.pyillegal value in %d-th argument of internal getrf|getrisingular matrix: resolution failed at diagonal %sillegal value in %d-th argument of internal gbsvillegal value in %d-th argument of internal trtrsillegal value in %d-th argument of internal gelss(   t   at   bt   condt   overwrite_at   overwrite_bt   check_finitet   a1t   b1t   mt   nt   nrhst   gelsst   b2t   workt   lworkt   vt   xt   st   rankt   infot   residst   x1{s   ddotus   ddots   sdotus   sdots   znrm2s   dznrm2s   cdots   cdotcs   zgers   zgercs   sdotcs   sdots   zdots   zdotcs   ddotcs   ddots   cgers   cgercs   cnrm2s   scnrm20scipy.linalg._fblas
Low-level BLAS functions
========================

This module contains low-level functions from the BLAS library.

.. versionadded:: 0.12.0

.. warning::

   These functions do little to no error checking.
   It is possible to cause crashes by mis-using them,
   so prefer using the higher-level routines in `scipy.linalg`.

Finding functions
=================

.. autosummary::
   :toctree: generated/

   get_blas_funcs
   find_best_blas_type

BLAS Level 1 functions
======================

.. autosummary::
   :toctree: generated/

    caxpy
    ccopy
    cdotc
    cdotu
    crotg
    cscal
    csrot
    csscal
    cswap
    dasum
    daxpy
    dcopy
    ddot
    dnrm2
    drot
    drotg
    drotm
    drotmg
    dscal
    dswap
    dzasum
    dznrm2
    icamax
    idamax
    isamax
    izamax
    sasum
    saxpy
    scasum
    scnrm2
    scopy
    sdot
    snrm2
    srot
    srotg
    srotm
    srotmg
    sscal
    sswap
    zaxpy
    zcopy
    zdotc
    zdotu
    zdrot
    zdscal
    zrotg
    zscal
    zswap

BLAS Level 2 functions
======================

.. autosummary::
   :toctree: generated/

    cgemv
    cgerc
    cgeru
    chemv
    ctrmv
    dgemv
    dger
    dsymv
    dtrmv
    sgemv
    sger
    ssymv
    strmv
    zgemv
    zgerc
    zgeru
    zhemv
    ztrmv

BLAS Level 3 functions
======================

.. autosummary::
   :toctree: generated/

    cgemm
    chemm
    cherk
    cher2k
    csymm
    csyrk
    csyr2k
    dgemm
    dsymm
    dsyrk
    dsyr2k
    sgemm
    ssymm
    ssyrk
    ssyr2k
    zgemm
    zhemm
    zherk
    zher2k
    zsymm
    zsyrk
    zsyr2k


    Return available BLAS/LAPACK functions.

    Used also in lapack.py. See get_blas_funcs for docstring.
    scipy.linalg.blas.cblas%s function %s could not be foundReturn available BLAS function objects from names.

    Arrays are used to determine the optimal prefix of BLAS routines.

    Parameters
    ----------
    names : str or sequence of str
        Name(s) of BLAS functions without type prefix.

    arrays : sequence of ndarrays, optional
        Arrays can be given to determine optimal prefix of BLAS
        routines. If not given, double-precision routines will be
        used, otherwise the most generic type in arrays will be used.

    dtype : str or dtype, optional
        Data-type specifier. Not used if `arrays` is non-empty.


    Returns
    -------
    funcs : list
        List containing the found function(s).


    Notes
    -----
    This routine automatically chooses between Fortran/C
    interfaces. Fortran code is used whenever possible for arrays with
    column major order. In all other cases, C code is preferred.

    In BLAS, the naming convention is that all functions start with a
    type prefix, which depends on the type of the principal
    matrix. These can be one of {'s', 'd', 'c', 'z'} for the numpy
    types {float32, float64, complex64, complex128} respectively.
    The code and the dtype are stored in attributes `typecode` and `dtype`
    of the returned functions.
    scipy.linalg.blas.fblas/usr/lib/python2.7/dist-packages/scipy/linalg/blas.pyFind best-matching BLAS/LAPACK type.

    Arrays are used to determine the optimal prefix of BLAS routines.

    Parameters
    ----------
    arrays : sequence of ndarrays, optional
        Arrays can be given to determine optimal prefix of BLAS
        routines. If not given, double-precision routines will be
        used, otherwise the most generic type in arrays will be used.
    dtype : str or dtype, optional
        Data-type specifier. Not used if `arrays` is non-empty.

    Returns
    -------
    prefix : str
        BLAS/LAPACK prefix character.
    dtype : dtype
        Inferred Numpy data type.
    prefer_fortran : bool
        Whether to prefer Fortran order routines over C order.

    (   t   namest   arrayst   dtypet   lib_namet   fmodulet   cmodulet   fmodule_namet   cmodule_namet   aliast   funcst   unpackt   module1t   module2t   prefixt   prefer_fortrant   it   namet	   func_namet   funct   module_namefFGFDjobzmmaxpivscaleonly_realThe eigenvalue range specified is not valid.
Valid range is [%s,%s]eig algorithm did not converge (only eigenvalues with order >= %d have converged)the leading minor of order %i of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed./usr/lib/python2.7/dist-packages/scipy/linalg/decomp.pyexpected two-dimensional arrayillegal value in %d-th argument of internal geevinvalid argument for selectillegal value in %d-th argument of internal gebal (hessenberg)a and b must have the same shape
    Solve real symmetric or complex hermitian band matrix eigenvalue problem.

    Find eigenvalues w and optionally right eigenvectors v of a::

        a v[:,i] = w[i] v[:,i]
        v.H v    = identity

    The matrix a is stored in a_band either in lower diagonal or upper
    diagonal ordered form:

        a_band[u + i - j, j] == a[i,j]        (if upper form; i <= j)
        a_band[    i - j, j] == a[i,j]        (if lower form; i >= j)

    where u is the number of bands above the diagonal.

    Example of a_band (shape of a is (6,6), u=2)::

        upper form:
        *   *   a02 a13 a24 a35
        *   a01 a12 a23 a34 a45
        a00 a11 a22 a33 a44 a55

        lower form:
        a00 a11 a22 a33 a44 a55
        a10 a21 a32 a43 a54 *
        a20 a31 a42 a53 *   *

    Cells marked with * are not used.

    Parameters
    ----------
    a_band : (u+1, M) array_like
        The bands of the M by M matrix a.
    lower : bool, optional
        Is the matrix in the lower form. (Default is upper form)
    eigvals_only : bool, optional
        Compute only the eigenvalues and no eigenvectors.
        (Default: calculate also eigenvectors)
    overwrite_a_band : bool, optional
        Discard data in a_band (may enhance performance)
    select : {'a', 'v', 'i'}, optional
        Which eigenvalues to calculate

        ======  ========================================
        select  calculated
        ======  ========================================
        'a'     All eigenvalues
        'v'     Eigenvalues in the interval (min, max]
        'i'     Eigenvalues with indices min <= i <= max
        ======  ========================================
    select_range : (min, max), optional
        Range of selected eigenvalues
    max_ev : int, optional
        For select=='v', maximum number of eigenvalues expected.
        For other values of select, has no meaning.

        In doubt, leave this parameter untouched.

    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (M,) ndarray
        The eigenvalues, in ascending order, each repeated according to its
        multiplicity.
    v : (M, M) float or complex ndarray
        The normalized eigenvector corresponding to the eigenvalue w[i] is
        the column v[:,i].

    Raises LinAlgError if eigenvalue computation does not converge

    illegal value in %d-th argument of internal gehrd (hessenberg)
    Solve an ordinary or generalized eigenvalue problem for a complex
    Hermitian or real symmetric matrix.

    Find eigenvalues w and optionally eigenvectors v of matrix `a`, where
    `b` is positive definite::

                      a v[:,i] = w[i] b v[:,i]
        v[i,:].conj() a v[:,i] = w[i]
        v[i,:].conj() b v[:,i] = 1

    Parameters
    ----------
    a : (M, M) array_like
        A complex Hermitian or real symmetric matrix whose eigenvalues and
        eigenvectors will be computed.
    b : (M, M) array_like, optional
        A complex Hermitian or real symmetric definite positive matrix in.
        If omitted, identity matrix is assumed.
    lower : bool, optional
        Whether the pertinent array data is taken from the lower or upper
        triangle of `a`. (Default: lower)
    eigvals_only : bool, optional
        Whether to calculate only eigenvalues and no eigenvectors.
        (Default: both are calculated)
    turbo : bool, optional
        Use divide and conquer algorithm (faster but expensive in memory,
        only for generalized eigenvalue problem and if eigvals=None)
    eigvals : tuple (lo, hi), optional
        Indexes of the smallest and largest (in ascending order) eigenvalues
        and corresponding eigenvectors to be returned: 0 <= lo <= hi <= M-1.
        If omitted, all eigenvalues and eigenvectors are returned.
    type : int, optional
        Specifies the problem type to be solved:

           type = 1: a   v[:,i] = w[i] b v[:,i]

           type = 2: a b v[:,i] = w[i]   v[:,i]

           type = 3: b a v[:,i] = w[i]   v[:,i]
    overwrite_a : bool, optional
        Whether to overwrite data in `a` (may improve performance)
    overwrite_b : bool, optional
        Whether to overwrite data in `b` (may improve performance)
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (N,) float ndarray
        The N (1<=N<=M) selected eigenvalues, in ascending order, each
        repeated according to its multiplicity.
    v : (M, N) complex ndarray
        (if eigvals_only == False)

        The normalized selected eigenvector corresponding to the
        eigenvalue w[i] is the column v[:,i].

        Normalization:

            type 1 and 3: v.conj() a      v  = w

            type 2: inv(v).conj() a  inv(v) = w

            type = 1 or 2: v.conj() b      v  = I

            type = 3: v.conj() inv(b) v  = I

    Raises
    ------
    LinAlgError :
        If eigenvalue computation does not converge,
        an error occurred, or b matrix is not definite positive. Note that
        if input matrices are not symmetric or hermitian, no error is reported
        but results will be wrong.

    See Also
    --------
    eig : eigenvalues and right eigenvectors for non-symmetric arrays

    
    Compute Hessenberg form of a matrix.

    The Hessenberg decomposition is::

        A = Q H Q^H

    where `Q` is unitary/orthogonal and `H` has only zero elements below
    the first sub-diagonal.

    Parameters
    ----------
    a : (M, M) array_like
        Matrix to bring into Hessenberg form.
    calc_q : bool, optional
        Whether to compute the transformation matrix.  Default is False.
    overwrite_a : bool, optional
        Whether to overwrite `a`; may improve performance.
        Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    H : (M, M) ndarray
        Hessenberg form of `a`.
    Q : (M, M) ndarray
        Unitary/orthogonal similarity transformation matrix ``A = Q H Q^H``.
        Only returned if ``calc_q=True``.

    wrong b dimensions %s, should be %sscipy.linalg.decompillegal value in %i-th argument of internal fortran routine.internal fortran routine failed to converge: %i off-diagonal elements of an intermediate tridiagonal form did not converge to zero.
    Solve real symmetric or complex hermitian band matrix eigenvalue problem.

    Find eigenvalues w of a::

        a v[:,i] = w[i] v[:,i]
        v.H v    = identity

    The matrix a is stored in a_band either in lower diagonal or upper
    diagonal ordered form:

        a_band[u + i - j, j] == a[i,j]        (if upper form; i <= j)
        a_band[    i - j, j] == a[i,j]        (if lower form; i >= j)

    where u is the number of bands above the diagonal.

    Example of a_band (shape of a is (6,6), u=2)::

        upper form:
        *   *   a02 a13 a24 a35
        *   a01 a12 a23 a34 a45
        a00 a11 a22 a33 a44 a55

        lower form:
        a00 a11 a22 a33 a44 a55
        a10 a21 a32 a43 a54 *
        a20 a31 a42 a53 *   *

    Cells marked with * are not used.

    Parameters
    ----------
    a_band : (u+1, M) array_like
        The bands of the M by M matrix a.
    lower : boolean
        Is the matrix in the lower form. (Default is upper form)
    overwrite_a_band:
        Discard data in a_band (may enhance performance)
    select : {'a', 'v', 'i'}
        Which eigenvalues to calculate

        ======  ========================================
        select  calculated
        ======  ========================================
        'a'     All eigenvalues
        'v'     Eigenvalues in the interval (min, max]
        'i'     Eigenvalues with indices min <= i <= max
        ======  ========================================
    select_range : (min, max)
        Range of selected eigenvalues
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (M,) ndarray
        The eigenvalues, in ascending order, each repeated according to its
        multiplicity.

    Raises LinAlgError if eigenvalue computation does not converge

    See Also
    --------
    eig_banded : eigenvalues and right eigenvectors for symmetric/Hermitian
        band matrices
    eigvals : eigenvalues of general arrays
    eigh : eigenvalues and right eigenvectors for symmetric/Hermitian arrays
    eig : eigenvalues and right eigenvectors for non-symmetric arrays

    unrecoverable internal error.select_range out of bounds
    Solve an ordinary or generalized eigenvalue problem for a complex
    Hermitian or real symmetric matrix.

    Find eigenvalues w of matrix a, where b is positive definite::

                      a v[:,i] = w[i] b v[:,i]
        v[i,:].conj() a v[:,i] = w[i]
        v[i,:].conj() b v[:,i] = 1


    Parameters
    ----------
    a : (M, M) array_like
        A complex Hermitian or real symmetric matrix whose eigenvalues and
        eigenvectors will be computed.
    b : (M, M) array_like, optional
        A complex Hermitian or real symmetric definite positive matrix in.
        If omitted, identity matrix is assumed.
    lower : bool, optional
        Whether the pertinent array data is taken from the lower or upper
        triangle of `a`. (Default: lower)
    turbo : bool, optional
        Use divide and conquer algorithm (faster but expensive in memory,
        only for generalized eigenvalue problem and if eigvals=None)
    eigvals : tuple (lo, hi), optional
        Indexes of the smallest and largest (in ascending order) eigenvalues
        and corresponding eigenvectors to be returned: 0 <= lo < hi <= M-1.
        If omitted, all eigenvalues and eigenvectors are returned.
    type : integer, optional
        Specifies the problem type to be solved:

           type = 1: a   v[:,i] = w[i] b v[:,i]

           type = 2: a b v[:,i] = w[i]   v[:,i]

           type = 3: b a v[:,i] = w[i]   v[:,i]
    overwrite_a : bool, optional
        Whether to overwrite data in `a` (may improve performance)
    overwrite_b : bool, optional
        Whether to overwrite data in `b` (may improve performance)
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (N,) float ndarray
        The N (1<=N<=M) selected eigenvalues, in ascending order, each
        repeated according to its multiplicity.

    Raises
    ------
    LinAlgError :
        If eigenvalue computation does not converge,
        an error occurred, or b matrix is not definite positive. Note that
        if input matrices are not symmetric or hermitian, no error is reported
        but results will be wrong.

    See Also
    --------
    eigvals : eigenvalues of general arrays
    eigh : eigenvalues and right eigenvectors for symmetric/Hermitian arrays
    eig : eigenvalues and right eigenvectors for non-symmetric arrays

    
    Solve an ordinary or generalized eigenvalue problem of a square matrix.

    Find eigenvalues w and right or left eigenvectors of a general matrix::

        a   vr[:,i] = w[i]        b   vr[:,i]
        a.H vl[:,i] = w[i].conj() b.H vl[:,i]

    where ``.H`` is the Hermitian conjugation.

    Parameters
    ----------
    a : (M, M) array_like
        A complex or real matrix whose eigenvalues and eigenvectors
        will be computed.
    b : (M, M) array_like, optional
        Right-hand side matrix in a generalized eigenvalue problem.
        Default is None, identity matrix is assumed.
    left : bool, optional
        Whether to calculate and return left eigenvectors.  Default is False.
    right : bool, optional
        Whether to calculate and return right eigenvectors.  Default is True.
    overwrite_a : bool, optional
        Whether to overwrite `a`; may improve performance.  Default is False.
    overwrite_b : bool, optional
        Whether to overwrite `b`; may improve performance.  Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (M,) double or complex ndarray
        The eigenvalues, each repeated according to its multiplicity.
    vl : (M, M) double or complex ndarray
        The normalized left eigenvector corresponding to the eigenvalue
        ``w[i]`` is the column v[:,i]. Only returned if ``left=True``.
    vr : (M, M) double or complex ndarray
        The normalized right eigenvector corresponding to the eigenvalue
        ``w[i]`` is the column ``vr[:,i]``.  Only returned if ``right=True``.

    Raises
    ------
    LinAlgError
        If eigenvalue computation does not converge.

    See Also
    --------
    eigh : Eigenvalues and right eigenvectors for symmetric/Hermitian arrays.

    generalized eig algorithm did not converge (info=%d)
    Produce complex-valued eigenvectors from LAPACK DGGEV real-valued output
    the eigenvectors %s failed to converge.illegal value in %d-th argument of internal ggev
    Compute eigenvalues from an ordinary or generalized eigenvalue problem.

    Find eigenvalues of a general matrix::

        a   vr[:,i] = w[i]        b   vr[:,i]

    Parameters
    ----------
    a : (M, M) array_like
        A complex or real matrix whose eigenvalues and eigenvectors
        will be computed.
    b : (M, M) array_like, optional
        Right-hand side matrix in a generalized eigenvalue problem.
        If omitted, identity matrix is assumed.
    overwrite_a : boolean, optional
        Whether to overwrite data in a (may improve performance)
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    w : (M,) double or complex ndarray
        The eigenvalues, each repeated according to its multiplicity,
        but not in any specific order.

    Raises
    ------
    LinAlgError
        If eigenvalue computation does not converge

    See Also
    --------
    eigvalsh : eigenvalues of symmetric or Hermitian arrays,
    eig : eigenvalues and right eigenvectors of general arrays.
    eigh : eigenvalues and eigenvectors of symmetric/Hermitian arrays.

    (   t   at   calc_qt   overwrite_at   check_finitet   a1t   gehrdt   gebalt   bat   lot   hit   pivscalet   infot   nt   lworkt   hqt   taut   it   typecodet   gert   gemmt   qt   vt   h(   t   at   bt   lowert   eigvals_onlyt   overwrite_at   overwrite_bt   turbot   eigvalst   typet   check_finitet   a1t   cplxt   b1t   _jobt   lot   hit   uplot   pfxt   evrt   wt   vt   infot   w_tott   gvxt   ifailt   gvdt   gv(   t   a1t   b1t   leftt   rightt   overwrite_at   overwrite_bt   ggevt   cvlt   cvrt   rest   lworkt   alphat   betat   vlt   vrt   workt   infot   wt   alphart   alphait	   only_realt   tt   i(   t   at   bt   leftt   rightt   overwrite_at   overwrite_bt   check_finitet   a1t   b1t   geevt
   compute_vlt
   compute_vrt   lworkt   wt   vlt   vrt   infot   wrt   wit   tt	   only_real(   t   a_bandt   lowert   eigvals_onlyt   overwrite_a_bandt   selectt   select_ranget   max_evt   check_finitet   a1t   bevdt   internal_namet   wt   vt   infot   vlt   vut   ilt   iut   lamcht   abstolt   bevxt   mt   ifail
    Compute the Cholesky decomposition of a matrix, to use in cho_solve

    Returns a matrix containing the Cholesky decomposition,
    ``A = L L*`` or ``A = U* U`` of a Hermitian positive-definite matrix `a`.
    The return value can be directly used as the first parameter to cho_solve.

    .. warning::
        The returned matrix also contains random data in the entries not
        used by the Cholesky decomposition. If you need to zero these
        entries, use the function `cholesky` instead.

    Parameters
    ----------
    a : (M, M) array_like
        Matrix to be decomposed
    lower : boolean
        Whether to compute the upper or lower triangular Cholesky factorization
        (Default: upper-triangular)
    overwrite_a : boolean
        Whether to overwrite data in a (may improve performance)
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    c : (M, M) ndarray
        Matrix whose upper or lower triangle contains the Cholesky factor
        of `a`. Other parts of the matrix contain random data.
    lower : boolean
        Flag indicating whether the factor is in the lower or upper triangle

    Raises
    ------
    LinAlgError
        Raised if decomposition fails.

    See also
    --------
    cho_solve : Solve a linear set equations using the Cholesky factorization
                of a matrix.

    Solve the linear equations A x = b, given the Cholesky factorization of A.

    Parameters
    ----------
    (c, lower) : tuple, (array, bool)
        Cholesky factorization of a, as given by cho_factor
    b : array
        Right-hand side
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : array
        The solution to the system A x = b

    See also
    --------
    cho_factor : Cholesky factorization of a matrix

    Solve the linear equations A x = b, given the Cholesky factorization of A.

    Parameters
    ----------
    (cb, lower) : tuple, (array, bool)
        `cb` is the Cholesky factorization of A, as given by cholesky_banded.
        `lower` must be the same value that was given to cholesky_banded.
    b : array
        Right-hand side
    overwrite_b : bool
        If True, the function will overwrite the values in `b`.
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : array
        The solution to the system A x = b

    See also
    --------
    cholesky_banded : Cholesky factorization of a banded matrix

    Notes
    -----

    .. versionadded:: 0.8.0

    illegal value in %d-th argument of internal pbtrs
    Cholesky decompose a banded Hermitian positive-definite matrix

    The matrix a is stored in ab either in lower diagonal or upper
    diagonal ordered form:

        ab[u + i - j, j] == a[i,j]        (if upper form; i <= j)
        ab[    i - j, j] == a[i,j]        (if lower form; i >= j)

    Example of ab (shape of a is (6,6), u=2)::

        upper form:
        *   *   a02 a13 a24 a35
        *   a01 a12 a23 a34 a45
        a00 a11 a22 a33 a44 a55

        lower form:
        a00 a11 a22 a33 a44 a55
        a10 a21 a32 a43 a54 *
        a20 a31 a42 a53 *   *

    Parameters
    ----------
    ab : (u + 1, M) array_like
        Banded matrix
    overwrite_ab : boolean
        Discard data in ab (may enhance performance)
    lower : boolean
        Is the matrix in the lower form. (Default is upper form)
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    c : (u + 1, M) ndarray
        Cholesky factorization of a, in the same banded format as ab

    Cholesky decomposition functions.The factored matrix c is not square./usr/lib/python2.7/dist-packages/scipy/linalg/decomp_cholesky.pyillegal value in %d-th argument of internal potrfCommon code for cholesky() and cho_factor().shapes of cb and b are not compatible.scipy.linalg.decomp_choleskyillegal value in %d-th argument of internal pbtrf
    Compute the Cholesky decomposition of a matrix.

    Returns the Cholesky decomposition, :math:`A = L L^*` or
    :math:`A = U^* U` of a Hermitian positive-definite matrix A.

    Parameters
    ----------
    a : (M, M) array_like
        Matrix to be decomposed
    lower : bool
        Whether to compute the upper or lower triangular Cholesky
        factorization.  Default is upper-triangular.
    overwrite_a : bool
        Whether to overwrite data in `a` (may improve performance).
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    c : (M, M) ndarray
        Upper- or lower-triangular Cholesky factor of `a`.

    Raises
    ------
    LinAlgError : if decomposition fails.

    Examples
    --------
    >>> from scipy import array, linalg, dot
    >>> a = array([[1,-2j],[2j,5]])
    >>> L = linalg.cholesky(a, lower=True)
    >>> L
    array([[ 1.+0.j,  0.+0.j],
           [ 0.+2.j,  1.+0.j]])
    >>> dot(L, L.T.conj())
    array([[ 1.+0.j,  0.-2.j],
           [ 0.+2.j,  5.+0.j]])

    illegal value in %d-th argument of internal potrsillegal value in %d-th argument of internal lu.getrf
    Compute pivoted LU decompostion of a matrix.

    The decomposition is::

        A = P L U

    where P is a permutation matrix, L lower triangular with unit
    diagonal elements, and U upper triangular.

    Parameters
    ----------
    a : (M, N) array_like
        Array to decompose
    permute_l : bool
        Perform the multiplication P*L  (Default: do not permute)
    overwrite_a : bool
        Whether to overwrite data in a (may improve performance)
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    **(If permute_l == False)**

    p : (M, M) ndarray
        Permutation matrix
    l : (M, K) ndarray
        Lower triangular or trapezoidal matrix with unit diagonal.
        K = min(M, N)
    u : (K, N) ndarray
        Upper triangular or trapezoidal matrix

    **(If permute_l == True)**

    pl : (M, K) ndarray
        Permuted L matrix.
        K = min(M, N)
    u : (K, N) ndarray
        Upper triangular or trapezoidal matrix

    Notes
    -----
    This is a LU factorization routine written for Scipy.

    scipy.linalg.decomp_luillegal value in %d-th argument of internal getrf (lu_factor)LU decomposition functions.Solve an equation system, a x = b, given the LU factorization of a

    Parameters
    ----------
    (lu, piv)
        Factorization of the coefficient matrix a, as given by lu_factor
    b : array
        Right-hand side
    trans : {0, 1, 2}
        Type of system to solve:

        =====  =========
        trans  system
        =====  =========
        0      a x   = b
        1      a^T x = b
        2      a^H x = b
        =====  =========
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    x : array
        Solution to the system

    See also
    --------
    lu_factor : LU factorize a matrix

    /usr/lib/python2.7/dist-packages/scipy/linalg/decomp_lu.pyDiagonal number %d is exactly zero. Singular matrix.
    Compute pivoted LU decomposition of a matrix.

    The decomposition is::

        A = P L U

    where P is a permutation matrix, L lower triangular with unit
    diagonal elements, and U upper triangular.

    Parameters
    ----------
    a : (M, M) array_like
        Matrix to decompose
    overwrite_a : boolean
        Whether to overwrite data in A (may increase performance)
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    lu : (N, N) ndarray
        Matrix containing U in its upper triangle, and L in its lower triangle.
        The unit diagonal elements of L are not stored.
    piv : (N,) ndarray
        Pivot indices representing the permutation matrix P:
        row i of matrix was interchanged with row piv[i].

    See also
    --------
    lu_solve : solve an equation system using the LU factorization of a matrix

    Notes
    -----
    This is a wrapper to the ``*GETRF`` routines from LAPACK.

    qqr
    Compute QR decomposition of a matrix.

    Calculate the decomposition ``A = Q R`` where Q is unitary/orthogonal
    and R upper triangular.

    Parameters
    ----------
    a : (M, N) array_like
        Matrix to be decomposed
    overwrite_a : bool, optional
        Whether data in a is overwritten (may improve performance)
    lwork : int, optional
        Work array size, lwork >= a.shape[1]. If None or -1, an optimal size
        is computed.
    mode : {'full', 'r', 'economic', 'raw'}, optional
        Determines what information is to be returned: either both Q and R
        ('full', default), only R ('r') or both Q and R but computed in
        economy-size ('economic', see Notes). The final option 'raw'
        (added in Scipy 0.11) makes the function return two matrices
        (Q, TAU) in the internal format used by LAPACK.
    pivoting : bool, optional
        Whether or not factorization should include pivoting for rank-revealing
        qr decomposition. If pivoting, compute the decomposition
        ``A P = Q R`` as above, but where P is chosen such that the diagonal
        of R is non-increasing.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    Q : float or complex ndarray
        Of shape (M, M), or (M, K) for ``mode='economic'``.  Not returned
        if ``mode='r'``.
    R : float or complex ndarray
        Of shape (M, N), or (K, N) for ``mode='economic'``.  ``K = min(M, N)``.
    P : int ndarray
        Of shape (N,) for ``pivoting=True``. Not returned if
        ``pivoting=False``.

    Raises
    ------
    LinAlgError
        Raised if decomposition fails

    Notes
    -----
    This is an interface to the LAPACK routines dgeqrf, zgeqrf,
    dorgqr, zungqr, dgeqp3, and zgeqp3.

    If ``mode=economic``, the shapes of Q and R are (M, K) and (K, N) instead
    of (M,M) and (M,N), with ``K=min(M,N)``.

    Examples
    --------
    >>> from scipy import random, linalg, dot, diag, all, allclose
    >>> a = random.randn(9, 6)

    >>> q, r = linalg.qr(a)
    >>> allclose(a, np.dot(q, r))
    True
    >>> q.shape, r.shape
    ((9, 9), (9, 6))

    >>> r2 = linalg.qr(a, mode='r')
    >>> allclose(r, r2)
    True

    >>> q3, r3 = linalg.qr(a, mode='economic')
    >>> q3.shape, r3.shape
    ((9, 6), (6, 6))

    >>> q4, r4, p4 = linalg.qr(a, pivoting=True)
    >>> d = abs(diag(r4))
    >>> all(d[1:] <= d[:-1])
    True
    >>> allclose(a[:, p4], dot(q4, r4))
    True
    >>> q4.shape, r4.shape, p4.shape
    ((9, 9), (9, 6), (6,))

    >>> q5, r5, p5 = linalg.qr(a, mode='economic', pivoting=True)
    >>> q5.shape, r5.shape, p5.shape
    ((9, 6), (6, 6), (6,))

    Mode argument should be one of ['full', 'r', 'economic', 'raw']
    Compute RQ decomposition of a square real matrix.

    Calculate the decomposition ``A = R Q`` where ``Q`` is
    unitary/orthogonal and ``R`` upper triangular.

    Parameters
    ----------
    a : array, shape (M, M)
        Matrix to be decomposed
    overwrite_a : bool, optional
        Whether data in a is overwritten (may improve performance)
    lwork : int, optional
        Work array size, lwork >= a.shape[1]. If None or -1, an optimal size
        is computed.
    mode : {'full', 'r', 'economic'}, optional
        Determines what information is to be returned: either both Q and R
        ('full', default), only R ('r') or both Q and R but computed in
        economy-size ('economic', see Notes).
    check_finite : bool, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    R : float array, shape (M, N)
        Upper triangular
    Q : float or complex array, shape (M, M)
        Unitary/orthogonal

    Raises
    ------
    LinAlgError
        If decomposition fails.

    Examples
    --------
    >>> from scipy import linalg
    >>> from numpy import random, dot, allclose
    >>> a = random.randn(6, 9)
    >>> r, q = linalg.rq(a)
    >>> allclose(a, dot(r, q))
    True
    >>> r.shape, q.shape
    ((6, 9), (9, 9))
    >>> r2 = linalg.rq(a, mode='r')
    >>> allclose(r, r2)
    True
    >>> r3, q3 = linalg.rq(a, mode='economic')
    >>> r3.shape, q3.shape
    ((6, 6), (6, 9))

    /usr/lib/python2.7/dist-packages/scipy/linalg/decomp_qr.pyCall a LAPACK routine, determining lwork automatically and handling
    error return valuesillegal value in %d-th argument of internal gerqfobjects are not alignedgormqr/gunmqrMode argument should be one of ['left', 'right']gorgqr/gungqr
    Calculate the QR decomposition and multiply Q with a matrix.

    Calculate the decomposition ``A = Q R`` where Q is unitary/orthogonal
    and R upper triangular. Multiply Q with a vector or a matrix c.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    a : ndarray, shape (M, N)
        Matrix to be decomposed
    c : ndarray, one- or two-dimensional
        calculate the product of c and q, depending on the mode:
    mode : {'left', 'right'}, optional
        ``dot(Q, c)`` is returned if mode is 'left',
        ``dot(c, Q)`` is returned if mode is 'right'.
        The shape of c must be appropriate for the matrix multiplications,
        if mode is 'left', ``min(a.shape) == c.shape[0]``,
        if mode is 'right', ``a.shape[0] == c.shape[1]``.
    pivoting : bool, optional
        Whether or not factorization should include pivoting for rank-revealing
        qr decomposition, see the documentation of qr.
    conjugate : bool, optional
        Whether Q should be complex-conjugated. This might be faster
        than explicit conjugation.
    overwrite_a : bool, optional
        Whether data in a is overwritten (may improve performance)
    overwrite_c : bool, optional
        Whether data in c is overwritten (may improve performance).
        If this is used, c must be big enough to keep the result,
        i.e. c.shape[0] = a.shape[0] if mode is 'left'.


    Returns
    -------
    CQ : float or complex ndarray
        the product of Q and c, as defined in mode
    R : float or complex ndarray
        Of shape (K, N), ``K = min(M, N)``.
    P : ndarray of ints
        Of shape (N,) for ``pivoting=True``.
        Not returned if ``pivoting=False``.

    Raises
    ------
    LinAlgError
        Raised if decomposition fails

    Notes
    -----
    This is an interface to the LAPACK routines dgeqrf, zgeqrf,
    dormqr, zunmqr, dgeqp3, and zgeqp3.

    scipy.linalg.decomp_qrexpected 2D arrayQR decomposition functions.Mode argument should be one of ['full', 'r', 'economic']illegal value in %d-th argument of internal orgrq(   t   at   overwrite_at   lworkt   modet   pivotingt   check_finitet   a1t   Mt   Nt   geqp3t   qrt   jpvtt   taut   geqrft   Rt   Rjt
   gor_un_gqrt   Qt   tt   qqrSchur form not found.  Possibly ill-conditioned.Eigenvalues could not be separated for reordering.
    Convert real Schur form to complex Schur form.

    Convert a quasi-diagonal real-valued Schur form to the upper triangular
    complex-valued Schur form.

    Parameters
    ----------
    T : (M, M) array_like
        Real Schur form of the original matrix
    Z : (M, M) array_like
        Schur transformation matrix
    check_finite : boolean, optional
        Whether to check that the input matrices contain only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    T : (M, M) ndarray
        Complex Schur form of the original matrix
    Z : (M, M) ndarray
        Schur transformation matrix corresponding to the complex form

    See also
    --------
    schur : Schur decompose a matrix

    Leading eigenvalues do not satisfy sort condition.
    Compute Schur decomposition of a matrix.

    The Schur decomposition is::

        A = Z T Z^H

    where Z is unitary and T is either upper-triangular, or for real
    Schur decomposition (output='real'), quasi-upper triangular.  In
    the quasi-triangular form, 2x2 blocks describing complex-valued
    eigenvalue pairs may extrude from the diagonal.

    Parameters
    ----------
    a : (M, M) array_like
        Matrix to decompose
    output : {'real', 'complex'}, optional
        Construct the real or complex Schur decomposition (for real matrices).
    lwork : int, optional
        Work array size. If None or -1, it is automatically computed.
    overwrite_a : bool, optional
        Whether to overwrite data in a (may improve performance).
    sort : {None, callable, 'lhp', 'rhp', 'iuc', 'ouc'}, optional
        Specifies whether the upper eigenvalues should be sorted.  A callable
        may be passed that, given a eigenvalue, returns a boolean denoting
        whether the eigenvalue should be sorted to the top-left (True).
        Alternatively, string parameters may be used::

            'lhp'   Left-hand plane (x.real < 0.0)
            'rhp'   Right-hand plane (x.real > 0.0)
            'iuc'   Inside the unit circle (x*x.conjugate() <= 1.0)
            'ouc'   Outside the unit circle (x*x.conjugate() > 1.0)

        Defaults to None (no sorting).
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    T : (M, M) ndarray
        Schur form of A. It is real-valued for the real Schur decomposition.
    Z : (M, M) ndarray
        An unitary Schur transformation matrix for A.
        It is real-valued for the real Schur decomposition.
    sdim : int
        If and only if sorting was requested, a third return value will
        contain the number of eigenvalues satisfying the sort condition.

    Raises
    ------
    LinAlgError
        Error raised under three conditions:

        1. The algorithm failed due to a failure of the QR algorithm to
           compute all eigenvalues
        2. If eigenvalue sorting was requested, the eigenvalues could not be
           reordered due to a failure to separate eigenvalues, usually because
           of poor conditioning
        3. If eigenvalue sorting was requested, roundoff errors caused the
           leading eigenvalues to no longer satisfy the sorting condition

    See also
    --------
    rsf2csf : Convert real Schur form to complex Schur form

    Schur decomposition functions.matrix must be square./usr/lib/python2.7/dist-packages/scipy/linalg/decomp_schur.pymatrices must be same dimension.illegal value in %d-th argument of internal gees(   t   Tt   Zt   check_finitet   Nt   arrt   tt   conjt   dott   r_t   transpt   mt   kt   mut   rt   ct   st   Gt   Gct   jt   iMorN
    Construct the sigma matrix in SVD from singular values and size M, N.

    Parameters
    ----------
    s : (M,) or (N,) array_like
        Singular values
    M : int
        Size of the matrix whose singular values are `s`.
    N : int
        Size of the matrix whose singular values are `s`.

    Returns
    -------
    S : (M, N) ndarray
        The S-matrix in the singular value decomposition

    illegal value in %d-th argument of internal gesdd
    Construct an orthonormal basis for the range of A using SVD

    Parameters
    ----------
    A : (M, N) ndarray
        Input array

    Returns
    -------
    Q : (M, K) ndarray
        Orthonormal basis for the range of A.
        K = effective rank of A, as determined by automatic cutoff

    See also
    --------
    svd : Singular value decomposition of a matrix

    /usr/lib/python2.7/dist-packages/scipy/linalg/decomp_svd.py
    Singular Value Decomposition.

    Factorizes the matrix a into two unitary matrices U and Vh, and
    a 1-D array s of singular values (real, non-negative) such that
    ``a == U*S*Vh``, where S is a suitably shaped matrix of zeros with
    main diagonal s.

    Parameters
    ----------
    a : (M, N) array_like
        Matrix to decompose.
    full_matrices : bool, optional
        If True, `U` and `Vh` are of shape ``(M,M)``, ``(N,N)``.
        If False, the shapes are ``(M,K)`` and ``(K,N)``, where
        ``K = min(M,N)``.
    compute_uv : bool, optional
        Whether to compute also `U` and `Vh` in addition to `s`.
        Default is True.
    overwrite_a : bool, optional
        Whether to overwrite `a`; may improve performance.
        Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    U : ndarray
        Unitary matrix having left singular vectors as columns.
        Of shape ``(M,M)`` or ``(M,K)``, depending on `full_matrices`.
    s : ndarray
        The singular values, sorted in non-increasing order.
        Of shape (K,), with ``K = min(M, N)``.
    Vh : ndarray
        Unitary matrix having right singular vectors as rows.
        Of shape ``(N,N)`` or ``(K,N)`` depending on `full_matrices`.

    For ``compute_uv = False``, only `s` is returned.

    Raises
    ------
    LinAlgError
        If SVD computation does not converge.

    See also
    --------
    svdvals : Compute singular values of a matrix.
    diagsvd : Construct the Sigma matrix, given the vector s.

    Examples
    --------
    >>> from scipy import linalg
    >>> a = np.random.randn(9, 6) + 1.j*np.random.randn(9, 6)
    >>> U, s, Vh = linalg.svd(a)
    >>> U.shape, Vh.shape, s.shape
    ((9, 9), (6, 6), (6,))

    >>> U, s, Vh = linalg.svd(a, full_matrices=False)
    >>> U.shape, Vh.shape, s.shape
    ((9, 6), (6, 6), (6,))
    >>> S = linalg.diagsvd(s, 6, 6)
    >>> np.allclose(a, np.dot(U, np.dot(S, Vh)))
    True

    >>> s2 = linalg.svd(a, compute_uv=False)
    >>> np.allclose(s, s2)
    True

    Length of s must be M or N.scipy.linalg.decomp_svd
    Compute singular values of a matrix.

    Parameters
    ----------
    a : (M, N) array_like
        Matrix to decompose.
    overwrite_a : bool, optional
        Whether to overwrite `a`; may improve performance.
        Default is False.
    check_finite : boolean, optional
        Whether to check that the input matrix contains only finite numbers.
        Disabling may give a performance gain, but may result in problems
        (crashes, non-termination) if the inputs do contain infinities or NaNs.

    Returns
    -------
    s : (min(M, N),) ndarray
        The singular values, sorted in decreasing order.

    Raises
    ------
    LinAlgError
        If SVD computation does not converge.

    See also
    --------
    svd : Compute the full singular value decomposition of a matrix.
    diagsvd : Construct the Sigma matrix, given the vector s.

    SVD decomposition functions.scipy.linalg.flinalg/usr/lib/python2.7/dist-packages/scipy/linalg/flinalg.pyReturn optimal available _flinalg function objects with
    names. arrays are used to determine optimal prefix.corgqrcorgrqcormqrcungqrcungrqcunmqrzorgqrzorgrqzormqrzungrqfind_best_lapack_type
Low-level LAPACK functions
==========================

This module contains low-level functions from the LAPACK library.

.. versionadded:: 0.12.0

.. warning::

   These functions do little to no error checking.
   It is possible to cause crashes by mis-using them,
   so prefer using the higher-level routines in `scipy.linalg`.

Finding functions
=================

.. autosummary::

   get_lapack_funcs

All functions
=============

.. autosummary::
   :toctree: generated/

   cgbsv
   cgbtrf
   cgbtrs
   cgebal
   cgees
   cgeev
   cgegv
   cgehrd
   cgelss
   cgeqp3
   cgeqrf
   cgerqf
   cgesdd
   cgesv
   cgetrf
   cgetri
   cgetrs
   cgges
   cggev
   chbevd
   chbevx
   cheev
   cheevd
   cheevr
   chegv
   chegvd
   chegvx
   claswp
   clauum
   cpbsv
   cpbtrf
   cpbtrs
   cposv
   cpotrf
   cpotri
   cpotrs
   ctrsyl
   ctrtri
   ctrtrs
   cungqr
   cungrq
   cunmqr
   dgbsv
   dgbtrf
   dgbtrs
   dgebal
   dgees
   dgeev
   dgegv
   dgehrd
   dgelss
   dgeqp3
   dgeqrf
   dgerqf
   dgesdd
   dgesv
   dgetrf
   dgetri
   dgetrs
   dgges
   dggev
   dlamch
   dlaswp
   dlauum
   dorgqr
   dorgrq
   dormqr
   dpbsv
   dpbtrf
   dpbtrs
   dposv
   dpotrf
   dpotri
   dpotrs
   dsbev
   dsbevd
   dsbevx
   dsyev
   dsyevd
   dsyevr
   dsygv
   dsygvd
   dsygvx
   dtrsyl
   dtrtri
   dtrtrs
   sgbsv
   sgbtrf
   sgbtrs
   sgebal
   sgees
   sgeev
   sgegv
   sgehrd
   sgelss
   sgeqp3
   sgeqrf
   sgerqf
   sgesdd
   sgesv
   sgetrf
   sgetri
   sgetrs
   sgges
   sggev
   slamch
   slaswp
   slauum
   sorgqr
   sorgrq
   sormqr
   spbsv
   spbtrf
   spbtrs
   sposv
   spotrf
   spotri
   spotrs
   ssbev
   ssbevd
   ssbevx
   ssyev
   ssyevd
   ssyevr
   ssygv
   ssygvd
   ssygvx
   strsyl
   strtri
   strtrs
   zgbsv
   zgbtrf
   zgbtrs
   zgebal
   zgees
   zgeev
   zgegv
   zgehrd
   zgelss
   zgeqp3
   zgeqrf
   zgerqf
   zgesdd
   zgesv
   zgetrf
   zgetri
   zgetrs
   zgges
   zggev
   zhbevd
   zhbevx
   zheev
   zheevd
   zheevr
   zhegv
   zhegvd
   zhegvx
   zlaswp
   zlauum
   zpbsv
   zpbtrf
   zpbtrs
   zposv
   zpotrf
   zpotri
   zpotrs
   ztrsyl
   ztrtri
   ztrtrs
   zungqr
   zungrq
   zunmqr

scipy.linalg.blas.flapack/usr/lib/python2.7/dist-packages/scipy/linalg/lapack.pyReturn available LAPACK function objects from names.

    Arrays are used to determine the optimal prefix of LAPACK routines.

    Parameters
    ----------
    names : str or sequence of str
        Name(s) of LAPACK functions without type prefix.

    arrays : sequence of ndarrays, optional
        Arrays can be given to determine optimal prefix of LAPACK
        routines. If not given, double-precision routines will be
        used, otherwise the most generic type in arrays will be used.

    dtype : str or dtype, optional
        Data-type specifier. Not used if `arrays` is non-empty.


    Returns
    -------
    funcs : list
        List containing the found function(s).


    Notes
    -----
    This routine automatically chooses between Fortran/C
    interfaces. Fortran code is used whenever possible for arrays with
    column major order. In all other cases, C code is preferred.

    In LAPACK, the naming convention is that all functions start with a
    type prefix, which depends on the type of the principal
    matrix. These can be one of {'s', 'd', 'c', 'z'} for the numpy
    types {float32, float64, complex64, complex128} respectevely, and
    are stored in attribute `typecode` of the returned functions.
    scipy.linalg._flapackscipy.linalg.blas.clapack/usr/lib/python2.7/dist-packages/scipy/linalg/linalg_version.pyscipy.linalg.linalg_versionc__builtin__
complex
G        G      R.c__builtin__
complex
G        G      R.iS0vriexpm2expm3max_svrounded_sign
    Compute the matrix exponential using Pade approximation.

    Parameters
    ----------
    A : (N, N) array_like or sparse matrix
        Matrix to be exponentiated.

    Returns
    -------
    expm : (N, N) ndarray
        Matrix exponential of `A`.

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2009)
           "A New Scaling and Squaring Algorithm for the Matrix Exponential."
           SIAM Journal on Matrix Analysis and Applications.
           31 (3). pp. 970-989. ISSN 1095-7162

    signm result may be inaccurate, approximate err =
    Compute the matrix exponential using Taylor series.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix to be exponentiated
    q : int
        Order of the Taylor series used is `q-1`

    Returns
    -------
    expm3 : (N, N) ndarray
        Matrix exponential of `A`

    
    Compute the hyperbolic matrix cosine.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array.

    Returns
    -------
    coshm : (N, N) ndarray
        Hyperbolic matrix cosine of `A`

    funm result may be inaccurate, approximate err =
    Matrix sign function.

    Extension of the scalar sign(x) to matrices.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix at which to evaluate the sign function
    disp : bool, optional
        Print warning if error in the result is estimated large
        instead of returning estimated error. (Default: True)

    Returns
    -------
    signm : (N, N) ndarray
        Value of the sign function at `A`
    errest : float
        (if disp == False)

        1-norm of the estimated error, ||err||_1 / ||A||_1

    Examples
    --------
    >>> from scipy.linalg import signm, eigvals
    >>> a = [[1,2,3], [1,2,1], [1,1,1]]
    >>> eigvals(a)
    array([ 4.12488542+0.j, -0.76155718+0.j,  0.63667176+0.j])
    >>> eigvals(signm(a))
    array([-1.+0.j,  1.+0.j,  1.+0.j])

    
    Wraps asarray with the extra requirement that the input be a square matrix.

    The motivation is that the matfuncs module has real functions that have
    been lifted to square matrix functions.

    Parameters
    ----------
    A : array_like
        A square matrix.

    Returns
    -------
    out : ndarray
        An ndarray copy or view or other representation of A.

    argument q=... in scipy.linalg.expm is deprecated./usr/lib/python2.7/dist-packages/scipy/linalg/matfuncs.py
    Return either B or the real part of B, depending on properties of A and B.

    The motivation is that B has been computed as a complicated function of A,
    and B may be perturbed by negligible imaginary components.
    If A is real and B is complex with small imaginary components,
    then return a real copy of B.  The assumption in that case would be that
    the imaginary components of B are numerical artifacts.

    Parameters
    ----------
    A : ndarray
        Input array whose type is to be checked as real vs. complex.
    B : ndarray
        Array to be returned, possibly without its imaginary part.
    tol : float
        Absolute tolerance.

    Returns
    -------
    out : real or complex array
        Either the input array B or only the real part of the input array B.

    
    Compute the matrix sine.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array.

    Returns
    -------
    sinm : (N, N) ndarray
        Matrix cosine of `A`

    expected square array_like input
    Compute the hyperbolic matrix sine.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array.

    Returns
    -------
    sinhm : (N, N) ndarray
        Hyperbolic matrix sine of `A`

    
    Compute the matrix tangent.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array.

    Returns
    -------
    tanm : (N, N) ndarray
        Matrix tangent of `A`

    
    Compute the hyperbolic matrix tangent.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array

    Returns
    -------
    tanhm : (N, N) ndarray
        Hyperbolic matrix tangent of `A`

    logm result may be inaccurate, approximate err =
    Compute the matrix cosine.

    This routine uses expm to compute the matrix exponentials.

    Parameters
    ----------
    A : (N, N) array_like
        Input array

    Returns
    -------
    cosm : (N, N) ndarray
        Matrix cosine of A

    
    Compute the matrix exponential using eigenvalue decomposition.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix to be exponentiated

    Returns
    -------
    expm2 : (N, N) ndarray
        Matrix exponential of `A`

    
    Evaluate a matrix function specified by a callable.

    Returns the value of matrix-valued function ``f`` at `A`. The
    function ``f`` is an extension of the scalar-valued function `func`
    to matrices.

    Parameters
    ----------
    A : (N, N) array_like
        Matrix at which to evaluate the function
    func : callable
        Callable object that evaluates a scalar function f.
        Must be vectorized (eg. using vectorize).
    disp : bool, optional
        Print warning if error in the result is estimated large
        instead of returning estimated error. (Default: True)

    Returns
    -------
    funm : (N, N) ndarray
        Value of the matrix function specified by func evaluated at `A`
    errest : float
        (if disp == False)

        1-norm of the estimated error, ||err||_1 / ||A||_1

    
    Compute matrix logarithm.

    The matrix logarithm is the inverse of
    expm: expm(logm(`A`)) == `A`

    Parameters
    ----------
    A : (N, N) array_like
        Matrix whose logarithm to evaluate
    disp : bool, optional
        Print warning if error in the result is estimated large
        instead of returning estimated error. (Default: True)

    Returns
    -------
    logm : (N, N) ndarray
        Matrix logarithm of `A`
    errest : float
        (if disp == False)

        1-norm of the estimated error, ||err||_1 / ||A||_1

    (d   i    i   i   i   i   i   i   i   i   i	   i
   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i   i    i!   i"   i#   i$   i%   i&   i'   i(   i)   i*   i+   i,   i-   i.   i/   i0   i1   i2   i3   i4   i5   i6   i7   i8   i9   i:   i;   i<   i=   i>   i?   i@   iA   iB   iC   iD   iE   iF   iG   iH   iI   iJ   iK   iL   iM   iN   iO   iP   iQ   iR   iS   iT   iU   iV   iW   iX   iY   iZ   i[   i\   i]   i^   i_   i`   ia   ib   ic   
    Matrix or vector norm.

    This function is able to return one of seven different matrix norms,
    or one of an infinite number of vector norms (described below), depending
    on the value of the ``ord`` parameter.

    Parameters
    ----------
    x : (M,) or (M, N) array_like
        Input array.
    ord : {non-zero int, inf, -inf, 'fro'}, optional
        Order of the norm (see table under ``Notes``). inf means numpy's
        `inf` object.

    Returns
    -------
    norm : float
        Norm of the matrix or vector.

    Notes
    -----
    For values of ``ord <= 0``, the result is, strictly speaking, not a
    mathematical 'norm', but it may still be useful for various numerical
    purposes.

    The following norms can be calculated:

    =====  ============================  ==========================
    ord    norm for matrices             norm for vectors
    =====  ============================  ==========================
    None   Frobenius norm                2-norm
    'fro'  Frobenius norm                --
    inf    max(sum(abs(x), axis=1))      max(abs(x))
    -inf   min(sum(abs(x), axis=1))      min(abs(x))
    0      --                            sum(x != 0)
    1      max(sum(abs(x), axis=0))      as below
    -1     min(sum(abs(x), axis=0))      as below
    2      2-norm (largest sing. value)  as below
    -2     smallest singular value       as below
    other  --                            sum(abs(x)**ord)**(1./ord)
    =====  ============================  ==========================

    The Frobenius norm is given by [1]_:

        :math:`||A||_F = [\sum_{i,j} abs(a_{i,j})^2]^{1/2}`

    References
    ----------
    .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,
           Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15

    Examples
    --------
    >>> from scipy.linalg import norm
    >>> a = np.arange(9) - 4
    >>> a
    array([-4, -3, -2, -1,  0,  1,  2,  3,  4])
    >>> b = a.reshape((3, 3))
    >>> b
    array([[-4, -3, -2],
           [-1,  0,  1],
           [ 2,  3,  4]])

    >>> norm(a)
    7.745966692414834
    >>> norm(b)
    7.745966692414834
    >>> norm(b, 'fro')
    7.745966692414834
    >>> norm(a, np.inf)
    4
    >>> norm(b, np.inf)
    9
    >>> norm(a, -np.inf)
    0
    >>> norm(b, -np.inf)
    2

    >>> norm(a, 1)
    20
    >>> norm(b, 1)
    7
    >>> norm(a, -1)
    -4.6566128774142013e-010
    >>> norm(b, -1)
    6
    >>> norm(a, 2)
    7.745966692414834
    >>> norm(b, 2)
    7.3484692283495345

    >>> norm(a, -2)
    nan
    >>> norm(b, -2)
    1.8570331885190563e-016
    >>> norm(a, 3)
    5.8480354764257312
    >>> norm(a, -3)
    nan

    /usr/lib/python2.7/dist-packages/scipy/linalg/misc.py
    Strict check for `arr` not sharing any data with `original`,
    under the assumption that arr = asarray(original)

    c__builtin__
complex
G        G       R.lg2sqrtnomegasall_matfirst_rowThe first coefficient in `a` must not be zero.
    Make a copy of a matrix with elements below the k-th diagonal zeroed.

    Parameters
    ----------
    m : array_like
        Matrix whose elements to return
    k : int, optional
        Diagonal below which to zero elements.
        `k` == 0 is the main diagonal, `k` < 0 subdiagonal and
        `k` > 0 superdiagonal.

    Returns
    -------
    triu : ndarray
        Return matrix with zeroed elements below the k-th diagonal and has
        same shape and type as `m`.

    Examples
    --------
    >>> from scipy.linalg import triu
    >>> triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)
    array([[ 1,  2,  3],
           [ 4,  5,  6],
           [ 0,  8,  9],
           [ 0,  0, 12]])

    Incorrect shape for s.  s must be one-dimensional
    Create a Hilbert matrix of order `n`.

    Returns the `n` by `n` array with entries `h[i,j] = 1 / (i + j + 1)`.

    Parameters
    ----------
    n : int
        The size of the array to create.

    Returns
    -------
    h : (n, n) ndarray
        The Hilbert matrix.

    See Also
    --------
    invhilbert : Compute the inverse of a Hilbert matrix.

    Notes
    -----
    .. versionadded:: 0.10.0

    Examples
    --------
    >>> from scipy.linalg import hilbert
    >>> hilbert(3)
    array([[ 1.        ,  0.5       ,  0.33333333],
           [ 0.5       ,  0.33333333,  0.25      ],
           [ 0.33333333,  0.25      ,  0.2       ]])

    
    Returns the n x n Pascal matrix.

    The Pascal matrix is a matrix containing the binomial coefficients as
    its elements.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    n : int
        The size of the matrix to create; that is, the result is an n x n
        matrix.
    kind : str, optional
        Must be one of 'symmetric', 'lower', or 'upper'.
        Default is 'symmetric'.
    exact : bool, optional
        If `exact` is True, the result is either an array of type
        numpy.uint64 (if n <= 35) or an object array of Python long integers.
        If `exact` is False, the coefficients in the matrix are computed using
        `scipy.special.comb` with `exact=False`.  The result will be a floating
        point array, and the values in the array will not be the exact
        coefficients, but this version is much faster than `exact=True`.

    Returns
    -------
    p : (n, n) ndarray
        The Pascal matrix.

    Notes
    -----
    See http://en.wikipedia.org/wiki/Pascal_matrix for more information
    about Pascal matrices.

    Examples
    --------
    >>> from scipy.linalg import pascal
    >>> pascal(4)
    array([[ 1,  1,  1,  1],
           [ 1,  2,  3,  4],
           [ 1,  3,  6, 10],
           [ 1,  4, 10, 20]], dtype=uint64)
    >>> pascal(4, kind='lower')
    array([[1, 0, 0, 0],
           [1, 1, 0, 0],
           [1, 2, 1, 0],
           [1, 3, 3, 1]], dtype=uint64)
    >>> pascal(50)[-1, -1]
    25477612258980856902730428600L
    >>> from scipy.special import comb
    >>> comb(98, 49, exact=True)
    25477612258980856902730428600L

    
    Construct a Toeplitz matrix.

    The Toeplitz matrix has constant diagonals, with c as its first column
    and r as its first row.  If r is not given, ``r == conjugate(c)`` is
    assumed.

    Parameters
    ----------
    c : array_like
        First column of the matrix.  Whatever the actual shape of `c`, it
        will be converted to a 1-D array.
    r : array_like
        First row of the matrix. If None, ``r = conjugate(c)`` is assumed;
        in this case, if c[0] is real, the result is a Hermitian matrix.
        r[0] is ignored; the first row of the returned matrix is
        ``[c[0], r[1:]]``.  Whatever the actual shape of `r`, it will be
        converted to a 1-D array.

    Returns
    -------
    A : (len(c), len(r)) ndarray
        The Toeplitz matrix. Dtype is the same as ``(c[0] + r[0]).dtype``.

    See also
    --------
    circulant : circulant matrix
    hankel : Hankel matrix

    Notes
    -----
    The behavior when `c` or `r` is a scalar, or when `c` is complex and
    `r` is None, was changed in version 0.8.0.  The behavior in previous
    versions was undocumented and is no longer supported.

    Examples
    --------
    >>> from scipy.linalg import toeplitz
    >>> toeplitz([1,2,3], [1,4,5,6])
    array([[1, 4, 5, 6],
           [2, 1, 4, 5],
           [3, 2, 1, 4]])
    >>> toeplitz([1.0, 2+3j, 4-1j])
    array([[ 1.+0.j,  2.-3.j,  4.+1.j],
           [ 2.+3.j,  1.+0.j,  2.-3.j],
           [ 4.-1.j,  2.+3.j,  1.+0.j]])

    
    Construct a circulant matrix.

    Parameters
    ----------
    c : (N,) array_like
        1-D array, the first column of the matrix.

    Returns
    -------
    A : (N, N) ndarray
        A circulant matrix whose first column is `c`.

    See also
    --------
    toeplitz : Toeplitz matrix
    hankel : Hankel matrix

    Notes
    -----
    .. versionadded:: 0.8.0

    Examples
    --------
    >>> from scipy.linalg import circulant
    >>> circulant([1, 2, 3])
    array([[1, 3, 2],
           [2, 1, 3],
           [3, 2, 1]])

    The length of `a` must be at least 2.
    Construct a Hankel matrix.

    The Hankel matrix has constant anti-diagonals, with `c` as its
    first column and `r` as its last row.  If `r` is not given, then
    `r = zeros_like(c)` is assumed.

    Parameters
    ----------
    c : array_like
        First column of the matrix.  Whatever the actual shape of `c`, it
        will be converted to a 1-D array.
    r : array_like
        Last row of the matrix. If None, ``r = zeros_like(c)`` is assumed.
        r[0] is ignored; the last row of the returned matrix is
        ``[c[-1], r[1:]]``.  Whatever the actual shape of `r`, it will be
        converted to a 1-D array.

    Returns
    -------
    A : (len(c), len(r)) ndarray
        The Hankel matrix. Dtype is the same as ``(c[0] + r[0]).dtype``.

    See also
    --------
    toeplitz : Toeplitz matrix
    circulant : circulant matrix

    Examples
    --------
    >>> from scipy.linalg import hankel
    >>> hankel([1, 17, 99])
    array([[ 1, 17, 99],
           [17, 99,  0],
           [99,  0,  0]])
    >>> hankel([1,2,3,4], [4,7,7,8,9])
    array([[1, 2, 3, 4, 7],
           [2, 3, 4, 7, 7],
           [3, 4, 7, 7, 8],
           [4, 7, 7, 8, 9]])

    
    Construct a Hadamard matrix.

    Constructs an n-by-n Hadamard matrix, using Sylvester's
    construction.  `n` must be a power of 2.

    Parameters
    ----------
    n : int
        The order of the matrix.  `n` must be a power of 2.
    dtype : numpy dtype
        The data type of the array to be constructed.

    Returns
    -------
    H : (n, n) ndarray
        The Hadamard matrix.

    Notes
    -----
    .. versionadded:: 0.8.0

    Examples
    --------
    >>> from scipy.linalg import hadamard
    >>> hadamard(2, dtype=complex)
    array([[ 1.+0.j,  1.+0.j],
           [ 1.+0.j, -1.-0.j]])
    >>> hadamard(4)
    array([[ 1,  1,  1,  1],
           [ 1, -1,  1, -1],
           [ 1,  1, -1, -1],
           [ 1, -1, -1,  1]])

    The length of s must be at least 1.arguments in the following positions have dimension greater than 2: %s
    Create a block diagonal matrix from provided arrays.

    Given the inputs `A`, `B` and `C`, the output will have these
    arrays arranged on the diagonal::

        [[A, 0, 0],
         [0, B, 0],
         [0, 0, C]]

    Parameters
    ----------
    A, B, C, ... : array_like, up to 2-D
        Input arrays.  A 1-D array or array_like sequence of length `n`is
        treated as a 2-D array with shape ``(1,n)``.

    Returns
    -------
    D : ndarray
        Array with `A`, `B`, `C`, ... on the diagonal.  `D` has the
        same dtype as `A`.

    Notes
    -----
    If all the input arrays are square, the output is known as a
    block diagonal matrix.

    Examples
    --------
    >>> from scipy.linalg import block_diag
    >>> A = [[1, 0],
    ...      [0, 1]]
    >>> B = [[3, 4, 5],
    ...      [6, 7, 8]]
    >>> C = [[7]]
    >>> block_diag(A, B, C)
    [[1 0 0 0 0 0]
     [0 1 0 0 0 0]
     [0 0 3 4 5 0]
     [0 0 6 7 8 0]
     [0 0 0 0 0 7]]
    >>> block_diag(1.0, [2, 3], [[4, 5], [6, 7]])
    array([[ 1.,  0.,  0.,  0.,  0.],
           [ 0.,  2.,  3.,  0.,  0.],
           [ 0.,  0.,  0.,  4.,  5.],
           [ 0.,  0.,  0.,  6.,  7.]])

    Incorrect lengths for f and s.  The length of s must be one less than the length of f.scipy.linalg.special_matrices
    Create a Leslie matrix.

    Given the length n array of fecundity coefficients `f` and the length
    n-1 array of survival coefficents `s`, return the associated Leslie matrix.

    Parameters
    ----------
    f : (N,) array_like
        The "fecundity" coefficients.
    s : (N-1,) array_like
        The "survival" coefficients, has to be 1-D.  The length of `s`
        must be one less than the length of `f`, and it must be at least 1.

    Returns
    -------
    L : (N, N) ndarray
        The array is zero except for the first row,
        which is `f`, and the first sub-diagonal, which is `s`.
        The data-type of the array will be the data-type of ``f[0]+s[0]``.

    Notes
    -----
    .. versionadded:: 0.8.0

    The Leslie matrix is used to model discrete-time, age-structured
    population growth [1]_ [2]_. In a population with `n` age classes, two sets
    of parameters define a Leslie matrix: the `n` "fecundity coefficients",
    which give the number of offspring per-capita produced by each age
    class, and the `n` - 1 "survival coefficients", which give the
    per-capita survival rate of each age class.

    References
    ----------
    .. [1] P. H. Leslie, On the use of matrices in certain population
           mathematics, Biometrika, Vol. 33, No. 3, 183--212 (Nov. 1945)
    .. [2] P. H. Leslie, Some further notes on the use of matrices in
           population mathematics, Biometrika, Vol. 35, No. 3/4, 213--245
           (Dec. 1948)

    Examples
    --------
    >>> from scipy.linalg import leslie
    >>> leslie([0.1, 2.0, 1.0, 0.1], [0.2, 0.8, 0.7])
    array([[ 0.1,  2. ,  1. ,  0.1],
           [ 0.2,  0. ,  0. ,  0. ],
           [ 0. ,  0.8,  0. ,  0. ],
           [ 0. ,  0. ,  0.7,  0. ]])

    
    Kronecker product.

    The result is the block matrix::

        a[0,0]*b    a[0,1]*b  ... a[0,-1]*b
        a[1,0]*b    a[1,1]*b  ... a[1,-1]*b
        ...
        a[-1,0]*b   a[-1,1]*b ... a[-1,-1]*b

    Parameters
    ----------
    a : (M, N) ndarray
        Input array
    b : (P, Q) ndarray
        Input array

    Returns
    -------
    A : (M*P, N*Q) ndarray
        Kronecker product of `a` and `b`.

    Examples
    --------
    >>> from numpy import array
    >>> from scipy.linalg import kron
    >>> kron(array([[1,2],[3,4]]), array([[1,1,1]]))
    array([[1, 1, 1, 2, 2, 2],
           [3, 3, 3, 4, 4, 4]])

    scale must be None, 'sqrtn', or 'n'; %r is not valid.kind must be 'symmetric', 'lower', or 'upper'
    Create a companion matrix.

    Create the companion matrix [1]_ associated with the polynomial whose
    coefficients are given in `a`.

    Parameters
    ----------
    a : (N,) array_like
        1-D array of polynomial coefficients.  The length of `a` must be
        at least two, and ``a[0]`` must not be zero.

    Returns
    -------
    c : (N-1, N-1) ndarray
        The first row of `c` is ``-a[1:]/a[0]``, and the first
        sub-diagonal is all ones.  The data-type of the array is the same
        as the data-type of ``1.0*a[0]``.

    Raises
    ------
    ValueError
        If any of the following are true: a) ``a.ndim != 1``;
        b) ``a.size < 2``; c) ``a[0] == 0``.

    Notes
    -----
    .. versionadded:: 0.8.0

    References
    ----------
    .. [1] R. A. Horn & C. R. Johnson, *Matrix Analysis*.  Cambridge, UK:
        Cambridge University Press, 1999, pp. 146-7.

    Examples
    --------
    >>> from scipy.linalg import companion
    >>> companion([1, -10, 31, -30])
    array([[ 10., -31.,  30.],
           [  1.,   0.,   0.],
           [  0.,   1.,   0.]])

    /usr/lib/python2.7/dist-packages/scipy/linalg/special_matrices.py
    Construct (N, M) matrix filled with ones at and below the k-th diagonal.

    The matrix has A[i,j] == 1 for i <= j + k

    Parameters
    ----------
    N : integer
        The size of the first dimension of the matrix.
    M : integer or None
        The size of the second dimension of the matrix. If `M` is None,
        `M = N` is assumed.
    k : integer
        Number of subdiagonal below which matrix is filled with ones.
        `k` = 0 is the main diagonal, `k` < 0 subdiagonal and `k` > 0
        superdiagonal.
    dtype : dtype
        Data type of the matrix.

    Returns
    -------
    tri : (N, M) ndarray
        Tri matrix.

    Examples
    --------
    >>> from scipy.linalg import tri
    >>> tri(3, 5, 2, dtype=int)
    array([[1, 1, 1, 0, 0],
           [1, 1, 1, 1, 0],
           [1, 1, 1, 1, 1]])
    >>> tri(3, 5, -1, dtype=int)
    array([[0, 0, 0, 0, 0],
           [1, 0, 0, 0, 0],
           [1, 1, 0, 0, 0]])

    
    Compute the inverse of the Hilbert matrix of order `n`.

    The entries in the inverse of a Hilbert matrix are integers.  When `n`
    is greater than 14, some entries in the inverse exceed the upper limit
    of 64 bit integers.  The `exact` argument provides two options for
    dealing with these large integers.

    Parameters
    ----------
    n : int
        The order of the Hilbert matrix.
    exact : bool
        If False, the data type of the array that is returned is np.float64,
        and the array is an approximation of the inverse.
        If True, the array is the exact integer inverse array.  To represent
        the exact inverse when n > 14, the returned array is an object array
        of long integers.  For n <= 14, the exact inverse is returned as an
        array with data type np.int64.

    Returns
    -------
    invh : (n, n) ndarray
        The data type of the array is np.float64 if `exact` is False.
        If `exact` is True, the data type is either np.int64 (for n <= 14)
        or object (for n > 14).  In the latter case, the objects in the
        array will be long integers.

    See Also
    --------
    hilbert : Create a Hilbert matrix.

    Notes
    -----
    .. versionadded:: 0.10.0

    Examples
    --------
    >>> from scipy.linalg import invhilbert
    >>> invhilbert(4)
    array([[   16.,  -120.,   240.,  -140.],
           [ -120.,  1200., -2700.,  1680.],
           [  240., -2700.,  6480., -4200.],
           [ -140.,  1680., -4200.,  2800.]])
    >>> invhilbert(4, exact=True)
    array([[   16,  -120,   240,  -140],
           [ -120,  1200, -2700,  1680],
           [  240, -2700,  6480, -4200],
           [ -140,  1680, -4200,  2800]], dtype=int64)
    >>> invhilbert(16)[7,7]
    4.2475099528537506e+19
    >>> invhilbert(16, exact=True)[7,7]
    42475099528537378560L

    Incorrect shape for f.  f must be one-dimensionalIncorrect shape for `a`.  `a` must be one-dimensional.
    Make a copy of a matrix with elements above the k-th diagonal zeroed.

    Parameters
    ----------
    m : array_like
        Matrix whose elements to return
    k : integer
        Diagonal above which to zero elements.
        `k` == 0 is the main diagonal, `k` < 0 subdiagonal and
        `k` > 0 superdiagonal.

    Returns
    -------
    tril : ndarray
        Return is the same shape and type as `m`.

    Examples
    --------
    >>> from scipy.linalg import tril
    >>> tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)
    array([[ 0,  0,  0],
           [ 4,  0,  0],
           [ 7,  8,  0],
           [10, 11, 12]])

    
    Discrete Fourier transform matrix.

    Create the matrix that computes the discrete Fourier transform of a
    sequence [1]_.  The n-th primitive root of unity used to generate the
    matrix is exp(-2*pi*i/n), where i = sqrt(-1).

    Parameters
    ----------
    n : int
        Size the matrix to create.
    scale : str, optional
        Must be None, 'sqrtn', or 'n'.
        If `scale` is 'sqrtn', the matrix is divided by `sqrt(n)`.
        If `scale` is 'n', the matrix is divided by `n`.
        If `scale` is None (the default), the matrix is not normalized, and the
        return value is simply the Vandermonde matrix of the roots of unity.

    Returns
    -------
    m : (n, n) ndarray
        The DFT matrix.

    Notes
    -----
    When `scale` is None, multiplying a vector by the matrix returned by
    `dft` is mathematically equivalent to (but much less efficient than)
    the calculation performed by `scipy.fftpack.fft`.

    .. versionadded:: 0.14.0

    References
    ----------
    .. [1] "DFT matrix", http://en.wikipedia.org/wiki/DFT_matrix

    Examples
    --------
    >>> np.set_printoptions(precision=5, suppress=True)
    >>> x = np.array([1, 2, 3, 0, 3, 2, 1, 0])
    >>> m = dft(8)
    >>> m.dot(x)   # Comute the DFT of x
    array([ 12.+0.j,  -2.-2.j,   0.-4.j,  -2.+2.j,   4.+0.j,  -2.-2.j,
            -0.+4.j,  -2.+2.j])

    Verify that ``m.dot(x)`` is the same as ``fft(x)``.

    >>> from scipy.fftpack import fft
    >>> fft(x)     # Same result as m.dot(x)
    array([ 12.+0.j,  -2.-2.j,   0.-4.j,  -2.+2.j,   4.+0.j,  -2.-2.j,
             0.+4.j,  -2.+2.j])
    n must be an positive integer, and n must be a power of 2
==========================================
Miscellaneous routines (:mod:`scipy.misc`)
==========================================

.. currentmodule:: scipy.misc

Various utilities that don't have another home.

Note that the Python Imaging Library (PIL) is not a dependency
of SciPy and therefore the `pilutil` module is not available on
systems that don't have PIL installed.

.. autosummary::
   :toctree: generated/

   bytescale - Byte scales an array (image)
   central_diff_weights - Weights for an n-point central m-th derivative
   comb - Combinations of N things taken k at a time, "N choose k" (imported from scipy.special)
   derivative - Find the n-th derivative of a function at a point
   factorial  - The factorial function, n! = special.gamma(n+1) (imported from scipy.special)
   factorial2 - Double factorial, (n!)! (imported from scipy.special)
   factorialk - (...((n!)!)!...)! where there are k '!' (imported from scipy.special)
   fromimage - Return a copy of a PIL image as a numpy array
   imfilter - Simple filtering of an image
   imread - Read an image file from a filename
   imresize - Resize an image
   imrotate - Rotate an image counter-clockwise
   imsave - Save an array to an image file
   imshow - Simple showing of an image through an external viewer
   info - Get help information for a function, class, or module
   lena - Get classic image processing example image Lena
   logsumexp - Compute the log of the sum of exponentials of input elements
   pade - Pade approximation to function as the ratio of two polynomials
   toimage - Takes a numpy array and returns a PIL image
   who - Print the Numpy arrays in the given dictionary

/usr/lib/python2.7/dist-packages/scipy/misc/__init__.pyQ?zG?Q?     f@     @@     @       
    Get a 1024 x 768, color image of a raccoon face.

    raccoon-procyon-lotor.jpg at http://www.public-domain-image.com

    Parameters
    ----------
    gray : bool, optional
        If True then return color image, otherwise return an 8-bit gray-scale

    Returns
    -------
    face : ndarray
        image of a racoon face

    Examples
    --------
    >>> import scipy.misc
    >>> face = scipy.misc.face()
    >>> face.shape
    (768, 1024, 3)
    >>> face.max()
    230
    >>> face.dtype
    dtype('uint8')

    >>> import matplotlib.pyplot as plt
    >>> plt.gray()
    >>> plt.imshow(face)
    >>> plt.show()

    lena.datscipy.misc.common
    Return Pade approximation to a polynomial as the ratio of two polynomials.

    Parameters
    ----------
    an : (N,) array_like
        Taylor series coefficients.
    m : int
        The order of the returned approximating polynomials.

    Returns
    -------
    p, q : Polynomial class
        The pade approximation of the polynomial defined by `an` is
        `p(x)/q(x)`.

    Examples
    --------
    >>> from scipy import misc
    >>> e_exp = [1.0, 1.0, 1.0/2.0, 1.0/6.0, 1.0/24.0, 1.0/120.0]
    >>> p, q = misc.pade(e_exp, 2)

    >>> e_exp.reverse()
    >>> e_poly = np.poly1d(e_exp)

    Compare ``e_poly(x)`` and the pade approximation ``p(x)/q(x)``

    >>> e_poly(1)
    2.7166666666666668

    >>> p(1)/q(1)
    2.7179487179487181

    
    Get classic image processing example image, Lena, at 8-bit grayscale
    bit-depth, 512 x 512 size.

    Parameters
    ----------
    None

    Returns
    -------
    lena : ndarray
        Lena image

    Examples
    --------
    >>> import scipy.misc
    >>> lena = scipy.misc.lena()
    >>> lena.shape
    (512, 512)
    >>> lena.max()
    245
    >>> lena.dtype
    dtype('int32')

    >>> import matplotlib.pyplot as plt
    >>> plt.gray()
    >>> plt.imshow(lena)
    >>> plt.show()

    'order' (the number of points used to compute the derivative), must be at least the derivative order 'n' + 1.The number of points must be odd.
    Find the n-th derivative of a function at a point.

    Given a function, use a central difference formula with spacing `dx` to
    compute the `n`-th derivative at `x0`.

    Parameters
    ----------
    func : function
        Input function.
    x0 : float
        The point at which `n`-th derivative is found.
    dx : int, optional
        Spacing.
    n : int, optional
        Order of the derivative. Default is 1.
    args : tuple, optional
        Arguments
    order : int, optional
        Number of points to use, must be odd.

    Notes
    -----
    Decreasing the step size too small can result in round-off error.

    Examples
    --------
    >>> def f(x):
    ...     return x**3 + x**2
    ...
    >>> derivative(f, 1.0, dx=1e-6)
    4.9999999999217337

    /usr/lib/python2.7/dist-packages/scipy/misc/common.py'order' (the number of points used to compute the derivative) must be odd.face.datCompute the log of the sum of exponentials of input elements.

    Parameters
    ----------
    a : array_like
        Input array.
    axis : int, optional
        Axis over which the sum is taken. By default `axis` is None,
        and all elements are summed.

        .. versionadded:: 0.11.0
    b : array-like, optional
        Scaling factor for exp(`a`) must be of the same shape as `a` or
        broadcastable to `a`.

        .. versionadded:: 0.12.0

    Returns
    -------
    res : ndarray
        The result, ``np.log(np.sum(np.exp(a)))`` calculated in a numerically
        more stable way. If `b` is given then ``np.log(np.sum(b*np.exp(a)))``
        is returned.

    See Also
    --------
    numpy.logaddexp, numpy.logaddexp2

    Notes
    -----
    Numpy has a logaddexp function which is very similar to `logsumexp`, but
    only handles two arguments. `logaddexp.reduce` is similar to this
    function, but may be less stable.

    Examples
    --------
    >>> from scipy.misc import logsumexp
    >>> a = np.arange(10)
    >>> np.log(np.sum(np.exp(a)))
    9.4586297444267107
    >>> logsumexp(a)
    9.4586297444267107

    With weights

    >>> a = np.arange(10)
    >>> b = np.arange(10, 0, -1)
    >>> logsumexp(a, b=b)
    9.9170178533034665
    >>> np.log(np.sum(b*np.exp(a)))
    9.9170178533034647
    Number of points must be at least the derivative order + 1.
    Return weights for an Np-point central derivative.

    Assumes equally-spaced function points.

    If weights are in the vector w, then
    derivative is w[0] * f(x-ho*dx) + ... + w[-1] * f(x+h0*dx)

    Parameters
    ----------
    Np : int
        Number of points for the central derivative.
    ndiv : int, optional
        Number of divisions.  Default is 1.

    Notes
    -----
    Can be inaccurate for large number of points.

    Order of q <m> must be smaller than len(an)-1.ascent.dat
    Get an 8-bit grayscale bit-depth, 512 x 512 derived image for easy use in demos

    The image is derived from accent-to-the-top.jpg at
    http://www.public-domain-image.com/people-public-domain-images-pictures/

    Parameters
    ----------
    None

    Returns
    -------
    ascent : ndarray
       convenient image to use for testing and demonstration

    Examples
    --------
    >>> import scipy.misc
    >>> ascent = scipy.misc.ascent()
    >>> ascent.shape
    (512, 512)
    >>> ascent.max()
    255

    >>> import matplotlib.pyplot as plt
    >>> plt.gray()
    >>> plt.imshow(ascent)
    >>> plt.show()

    
Functions which are common and require SciPy Base and Level 1 SciPy
(special, linalg)
filldoccls_docstringinherit_docstring_from Set docstring to minimum indent for all lines, including first

    >>> unindent_string(' two')
    'two'
    >>> unindent_string('  two\n   three')
    'two\n three'
     Unindent all strings in a docdict  Minimum indent for all lines in line list

    >>> lines = [' one', '  two', '   three']
    >>> indentcount_lines(lines)
    1
    >>> lines = []
    >>> indentcount_lines(lines)
    0
    >>> lines = [' one']
    >>> indentcount_lines(lines)
    1
    >>> indentcount_lines(['    '])
    0
    
    This decorator modifies the decorated function's docstring by
    replacing occurrences of '%(super)s' with the docstring of the
    method of the same name from the class `cls`.

    If the decorated method has no docstring, it is simply given the
    docstring of `cls`s method.

    Parameters
    ----------
    cls : Python class or instance
        A class with a method with the same name as the decorated method.
        The docstring of the method in this class replaces '%(super)s' in the
        docstring of the decorated method.

    Returns
    -------
    f : function
        The decorator function that modifies the __doc__ attribute
        of its argument.

    Examples
    --------
    In the following, the docstring for Bar.func created using the
    docstring of `Foo.func`.

    >>> class Foo(object):
    ...     def func(self):
    ...         '''Do something useful.'''
    ...         return
    ...
    >>> class Bar(Foo):
    ...     @inherit_docstring_from(Foo)
    ...     def func(self):
    ...         '''%(super)s
    ...         Do it fast.
    ...         '''
    ...         return
    ...
    >>> b = Bar()
    >>> b.func.__doc__
    'Do something useful.
        Do it fast.
        '

     Utilities to allow inserting docstring fragments for common
parameters into function and method docstringsscipy.misc.doccer Fill a function docstring from variables in dictionary

    Adapt the indent of the inserted docs

    Parameters
    ----------
    docstring : string
        docstring from function, possibly with dict formatting strings
    docdict : dict
        dictionary with keys that match the dict formatting strings
        and values that are docstring fragments to be inserted.  The
        indentation of the inserted docstrings is set to match the
        minimum indentation of the ``docstring`` by adding this
        indentation to all lines of the inserted string, except the
        first

    Returns
    -------
    outstring : string
        string with requested ``docdict`` strings inserted

    Examples
    --------
    >>> docformat(' Test string with %(value)s', {'value':'inserted value'})
    ' Test string with inserted value'
    >>> docstring = 'First line\n    Second line\n    %(value)s'
    >>> inserted_string = "indented\nstring"
    >>> docdict = {'value': inserted_string}
    >>> docformat(docstring, docdict)
    'First line\n    Second line\n    indented\n    string'
     Return docstring decorator using docdict variable dictionary

    Parameters
    ----------
    docdict : dictionary
        dictionary containing name, docstring fragment pairs
    unindent_params : {False, True}, boolean, optional
        If True, strip common indentation from all parameters in
        docdict

    Returns
    -------
    decfunc : function
        decorator that applies dictionary to input function docstring

    /usr/lib/python2.7/dist-packages/scipy/misc/doccer.py<N\?imnew_tdictdata32embosssharpenbytedatafind_edgessmooth_moreedge_enhanceedge_enhance_moreSCIPY_PIL_IMAGE_VIEWER
    Read an image from a file as an array.

    Parameters
    ----------
    name : str or file object
        The file name or file object to be read.
    flatten : bool, optional
        If True, flattens the color layers into a single gray-scale layer.

    Returns
    -------
    imread : ndarray
        The array obtained by reading image from file `imfile`.

    Notes
    -----
    The image is flattened by calling convert('F') on
    the resulting image object.

    Input is not a PIL image.Unknown filter type.'arr' does not have a suitable array shape for any mode.
    Simple showing of an image through an external viewer.

    Uses the image viewer specified by the environment variable
    SCIPY_PIL_IMAGE_VIEWER, or if that is not defined then `see`,
    to view a temporary file generated from array data.

    Parameters
    ----------
    arr : ndarray
        Array of image data to show.

    Returns
    -------
    None

    Examples
    --------
    >>> a = np.tile(np.arange(255), (255,1))
    >>> from scipy import misc
    >>> misc.pilutil.imshow(a)

    
    Save an array as an image.

    Parameters
    ----------
    name : str or file object
        Output file name or file object.
    arr : ndarray, MxN or MxNx3 or MxNx4
        Array containing image values.  If the shape is ``MxN``, the array
        represents a grey-level image.  Shape ``MxNx3`` stores the red, green
        and blue bands along the last dimension.  An alpha layer may be
        included, specified as the last colour band of an ``MxNx4`` array.
    format : str
        Image format. If omitted, the format to use is determined from the 
        file name extension. If a file object was used instead of a file name,
        this parameter should always be used.

    Examples
    --------
    Construct an array of gradient intensity values and save to file:

    >>> x = np.zeros((255, 255))
    >>> x = np.zeros((255, 255), dtype=np.uint8)
    >>> x[:] = np.arange(255)
    >>> imsave('/tmp/gradient.png', x)

    Construct an array with three colour bands (R, G, B) and store to file:

    >>> rgb = np.zeros((255, 255, 3), dtype=np.uint8)
    >>> rgb[..., 0] = np.arange(255)
    >>> rgb[..., 1] = 55
    >>> rgb[..., 2] = 1 - np.arange(255)
    >>> imsave('/tmp/rgb_gradient.png', rgb)

    `high` should be larger than `low`.Error saving temporary image data.`cmax` should be larger than `cmin`.Could not execute image viewer.
    Resize an image.

    Parameters
    ----------
    arr : ndarray
        The array of image to be resized.

    size : int, float or tuple
        * int   - Percentage of current size.
        * float - Fraction of current size.
        * tuple - Size of the output image.

    interp : str
        Interpolation to use for re-sizing ('nearest', 'bilinear', 'bicubic'
        or 'cubic').

    mode : str
        The PIL image mode ('P', 'L', etc.).

    Returns
    -------
    imresize : ndarray
        The resized array of image.

    Could not find channel dimension.
A collection of image utilities using the Python Imaging Library (PIL).

Note that PIL is not a dependency of SciPy and this module is not
available on systems that don't have PIL installed.


    Rotate an image counter-clockwise by angle degrees.

    Parameters
    ----------
    arr : ndarray
        Input array of image to be rotated.
    angle : float
        The angle of rotation.
    interp : str, optional
        Interpolation

        - 'nearest' :  for nearest neighbor
        - 'bilinear' : for bilinear
        - 'cubic' : cubic
        - 'bicubic' : for bicubic

    Returns
    -------
    imrotate : ndarray
        The rotated array of image.

    Mode is unknown or incompatible with input array shape.Invalid array shape for mode.
    Simple filtering of an image.

    Parameters
    ----------
    arr : ndarray
        The array of Image in which the filter is to be applied.
    ftype : str
        The filter that has to be applied. Legal values are:
        'blur', 'contour', 'detail', 'edge_enhance', 'edge_enhance_more',
        'emboss', 'find_edges', 'smooth', 'smooth_more', 'sharpen'.

    Returns
    -------
    imfilter : ndarray
        The array with filter applied.

    Raises
    ------
    ValueError
        *Unknown filter type.*  If the filter you are trying
        to apply is unsupported.

    scipy.misc.pilutilTakes a numpy array and returns a PIL image.

    The mode of the PIL image depends on the array shape and the `pal` and
    `mode` keywords.

    For 2-D arrays, if `pal` is a valid (N,3) byte-array giving the RGB values
    (from 0 to 255) then ``mode='P'``, otherwise ``mode='L'``, unless mode
    is given as 'F' or 'I' in which case a float and/or integer array is made.

    Notes
    -----
    For 3-D arrays, the `channel_axis` argument tells which dimension of the
    array holds the channel data.

    For 3-D arrays if one of the dimensions is 3, the mode is 'RGB'
    by default or 'YCbCr' if selected.

    The numpy array must be either 2 dimensional or 3 dimensional.

    
    Return a copy of a PIL image as a numpy array.

    Parameters
    ----------
    im : PIL image
        Input image.
    flatten : bool
        If true, convert the output to grey-scale.

    Returns
    -------
    fromimage : ndarray
        The different colour bands/channels are stored in the
        third dimension, such that a grey-image is MxN, an
        RGB-image MxNx3 and an RGBA-image MxNx4.

    
    Byte scales an array (image).

    Byte scaling means converting the input image to uint8 dtype and scaling
    the range to ``(low, high)`` (default 0-255).
    If the input image already has dtype uint8, no scaling is done.

    Parameters
    ----------
    data : ndarray
        PIL image data array.
    cmin : scalar, optional
        Bias scaling of small values. Default is ``data.min()``.
    cmax : scalar, optional
        Bias scaling of large values. Default is ``data.max()``.
    high : scalar, optional
        Scale max value to `high`.  Default is 255.
    low : scalar, optional
        Scale min value to `low`.  Default is 0.

    Returns
    -------
    img_array : uint8 ndarray
        The byte-scaled array.

    Examples
    --------
    >>> img = array([[ 91.06794177,   3.39058326,  84.4221549 ],
                     [ 73.88003259,  80.91433048,   4.88878881],
                     [ 51.53875334,  34.45808177,  27.5873488 ]])
    >>> bytescale(img)
    array([[255,   0, 236],
           [205, 225,   4],
           [140,  90,  70]], dtype=uint8)
    >>> bytescale(img, high=200, low=100)
    array([[200, 100, 192],
           [180, 188, 102],
           [155, 135, 128]], dtype=uint8)
    >>> bytescale(img, cmin=0, cmax=255)
    array([[91,  3, 84],
           [74, 81,  5],
           [52, 34, 28]], dtype=uint8)

    Cannot convert a complex-valued array.Channel axis dimension is not valid./usr/lib/python2.7/dist-packages/scipy/misc/pilutil.py/usr/lib/python2.7/dist-packages/scipy/sparse/usr/lib/python2.7/dist-packages/scipy/sparse/__init__.py
=====================================
Sparse matrices (:mod:`scipy.sparse`)
=====================================

.. currentmodule:: scipy.sparse

SciPy 2-D sparse matrix package for numeric data.

Contents
========

Sparse matrix classes
---------------------

.. autosummary::
   :toctree: generated/

   bsr_matrix - Block Sparse Row matrix
   coo_matrix - A sparse matrix in COOrdinate format
   csc_matrix - Compressed Sparse Column matrix
   csr_matrix - Compressed Sparse Row matrix
   dia_matrix - Sparse matrix with DIAgonal storage
   dok_matrix - Dictionary Of Keys based sparse matrix
   lil_matrix - Row-based linked list sparse matrix

Functions
---------

Building sparse matrices:

.. autosummary::
   :toctree: generated/

   eye - Sparse MxN matrix whose k-th diagonal is all ones
   identity - Identity matrix in sparse format
   kron - kronecker product of two sparse matrices
   kronsum - kronecker sum of sparse matrices
   diags - Return a sparse matrix from diagonals
   spdiags - Return a sparse matrix from diagonals
   block_diag - Build a block diagonal sparse matrix
   tril - Lower triangular portion of a matrix in sparse format
   triu - Upper triangular portion of a matrix in sparse format
   bmat - Build a sparse matrix from sparse sub-blocks
   hstack - Stack sparse matrices horizontally (column wise)
   vstack - Stack sparse matrices vertically (row wise)
   rand - Random values in a given shape

Identifying sparse matrices:

.. autosummary::
   :toctree: generated/

   issparse
   isspmatrix
   isspmatrix_csc
   isspmatrix_csr
   isspmatrix_bsr
   isspmatrix_lil
   isspmatrix_dok
   isspmatrix_coo
   isspmatrix_dia

Submodules
----------

.. autosummary::
   :toctree: generated/

   csgraph - Compressed sparse graph routines
   linalg - sparse linear algebra routines

Exceptions
----------

.. autosummary::
   :toctree: generated/

   SparseEfficiencyWarning
   SparseWarning


Usage information
=================

There are seven available sparse matrix types:

    1. csc_matrix: Compressed Sparse Column format
    2. csr_matrix: Compressed Sparse Row format
    3. bsr_matrix: Block Sparse Row format
    4. lil_matrix: List of Lists format
    5. dok_matrix: Dictionary of Keys format
    6. coo_matrix: COOrdinate format (aka IJV, triplet format)
    7. dia_matrix: DIAgonal format

To construct a matrix efficiently, use either dok_matrix or lil_matrix.
The lil_matrix class supports basic slicing and fancy
indexing with a similar syntax to NumPy arrays.  As illustrated below,
the COO format may also be used to efficiently construct matrices.

To perform manipulations such as multiplication or inversion, first
convert the matrix to either CSC or CSR format. The lil_matrix format is
row-based, so conversion to CSR is efficient, whereas conversion to CSC
is less so.

All conversions among the CSR, CSC, and COO formats are efficient,
linear-time operations.

Matrix vector product
---------------------
To do a vector product between a sparse matrix and a vector simply use
the matrix `dot` method, as described in its docstring:

>>> import numpy as np
>>> from scipy.sparse import csr_matrix
>>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])
>>> v = np.array([1, 0, -1])
>>> A.dot(v)
array([ 1, -3, -1], dtype=int64)

.. warning:: As of NumPy 1.7, `np.dot` is not aware of sparse matrices,
  therefore using it will result on unexpected results or errors.
  The corresponding dense matrix should be obtained first instead:

  >>> np.dot(A.todense(), v)
  matrix([[ 1, -3, -1]], dtype=int64)

  but then all the performance advantages would be lost.
  Notice that it returned a matrix, because `todense` returns a matrix.

The CSR format is specially suitable for fast matrix vector products.

Example 1
---------
Construct a 1000x1000 lil_matrix and add some values to it:

>>> from scipy.sparse import lil_matrix
>>> from scipy.sparse.linalg import spsolve
>>> from numpy.linalg import solve, norm
>>> from numpy.random import rand

>>> A = lil_matrix((1000, 1000))
>>> A[0, :100] = rand(100)
>>> A[1, 100:200] = A[0, :100]
>>> A.setdiag(rand(1000))

Now convert it to CSR format and solve A x = b for x:

>>> A = A.tocsr()
>>> b = rand(1000)
>>> x = spsolve(A, b)

Convert it to a dense matrix and solve, and check that the result
is the same:

>>> x_ = solve(A.todense(), b)

Now we can compute norm of the error with:

>>> err = norm(x-x_)
>>> err < 1e-10
True

It should be small :)


Example 2
---------

Construct a matrix in COO format:

>>> from scipy import sparse
>>> from numpy import array
>>> I = array([0,3,1,0])
>>> J = array([0,3,1,2])
>>> V = array([4,5,7,9])
>>> A = sparse.coo_matrix((V,(I,J)),shape=(4,4))

Notice that the indices do not need to be sorted.

Duplicate (i,j) entries are summed when converting to CSR or CSC.

>>> I = array([0,0,1,3,1,0,0])
>>> J = array([0,2,1,3,1,0,0])
>>> V = array([1,1,1,1,1,1,1])
>>> B = sparse.coo_matrix((V,(I,J)),shape=(4,4)).tocsr()

This is useful for constructing finite-element stiffness and mass matrices.

Further Details
---------------

CSR column indices are not necessarily sorted.  Likewise for CSC row
indices.  Use the .sorted_indices() and .sort_indices() methods when
sorted indices are required (e.g. when passing data to other libraries).

333333$@fp_typenz_mask__bool__fp_typeswith_self__nonzero__getmaxprintcol_selectorrow_selectorscalar_dtypewithout_self__numpy_ufunc__SparseFormatWarning_spmatrix__iterator{s   dok[   i   s   Dictionary Of Keyss   nsk[   i   s   Nonsymmetric SKylines   lil[   i   s   LInked Lists   dod[   i   s   Dictionary of Dictionariess   csr[   i   s   Compressed Sparse Rows   msr[   i   s   Modified compressed Sparse Rows   bsr[   i
   s   Block Sparse Rows   dia[   i	   s   DIAgonals   lba[   i   s   Linpack BAndeds   vbr[   i   s   Variable Block Rows   und[   i   s	   Undefineds   sss[   i   s   Symmetric Sparse Skylines   ssk[   i   s   Symmetric SKylines   csc[   i    s   Compressed Sparse Columns   uss[   i   s   Unsymmetric Sparse Skylines   jad[   i   s   JAgged Diagonals   egd[   i   s#   Ellpack-itpack Generalized Diagonals   msc[   i   s!   Modified compressed Sparse Columns   coo[   i   s
   COOrdinates   bsc[   i   s   Block Sparse Column0  %s	%sBase class for sparse matricesReturns a copy of column j of the matrix, as an (m x 1) sparse
        matrix (column vector).
        
  :	:
nnz not definedReturn this matrix in a given sparse format

        Parameters
        ----------
        format : {string, None}
            desired sparse matrix format
                - None for no format conversion
                - "csr" for csr_matrix format
                - "csc" for csc_matrix format
                - "lil" for lil_matrix format
                - "dok" for dok_matrix format and so on

        order cannot be specified if out is not Noneout array must be same dtype and shape as sparse matrixsparse matrix length is ambiguous; use getnnz() or shape[0]Average the matrix over the given axis.  If the axis is None,
        average over both rows and columns, returning a scalar.
        
        Set diagonal or off-diagonal elements of the array.

        Parameters
        ----------
        values : array_like
            New values of the diagonal elements.

            Values may have any length.  If the diagonal is longer than values,
            then the remaining diagonal entries will not be set.  If values if
            longer than the diagonal, then the remaining values are ignored.

            If a scalar value is given, all of the diagonal is set to it.

        k : int, optional
            Which off-diagonal to set, corresponding to elements a[i,i+k].
            Default: 0 (the main diagonal).

        The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().could not interpret dimensionsPoint-wise multiplication by another matrix
        interpret other and call one of the following

        self._mul_scalar()
        self._mul_vector()
        self._mul_multivector()
        self._mul_sparse_matrix()
        
        Return a dense ndarray representation of this matrix.

        Parameters
        ----------
        order : {'C', 'F'}, optional
            Whether to store multi-dimensional data in C (row-major)
            or Fortran (column-major) order in memory. The default
            is 'None', indicating the NumPy default of C-ordered.
            Cannot be specified in conjunction with the `out`
            argument.

        out : ndarray, 2-dimensional, optional
            If specified, uses this array as the output buffer
            instead of allocating a new array to return. The provided
            array must have the same shape and dtype as the sparse
            matrix on which you are calling the method. For most
            sparse types, `out` is required to be memory contiguous
            (either C or Fortran ordered).

        Returns
        -------
        arr : ndarray, 2-dimensional
            An array with the same shape and containing the same
            data represented by the sparse matrix, with the requested
            memory order. If `out` was passed, the same object is
            returned after being modified in-place to contain the
            appropriate values.
        Ordinary dot product

        Examples
        --------
        >>> import numpy as np
        >>> from scipy.sparse import csr_matrix
        >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])
        >>> v = np.array([1, 0, -1])
        >>> A.dot(v)
        array([ 1, -3, -1], dtype=int64)

        cannot upcast [%s] to a floating point format/usr/lib/python2.7/dist-packages/scipy/sparse/base.pyThis class is not intended to be instantiated directly.Upcast matrix to a floating point format (if necessary)exponent must be >= 0<%dx%d sparse matrix of type '%s'
	with %d stored elements in %s format>
        Return a dense matrix representation of this matrix.

        Parameters
        ----------
        order : {'C', 'F'}, optional
            Whether to store multi-dimensional data in C (row-major)
            or Fortran (column-major) order in memory. The default
            is 'None', indicating the NumPy default of C-ordered.
            Cannot be specified in conjunction with the `out`
            argument.

        out : ndarray, 2-dimensional, optional
            If specified, uses this array (or `numpy.matrix`) as the
            output buffer instead of allocating a new array to
            return. The provided array must have the same shape and
            dtype as the sparse matrix on which you are calling the
            method.

        Returns
        -------
        arr : numpy.matrix, 2-dimensional
            A NumPy matrix object with the same shape and containing
            the same data represented by the sparse matrix, with the
            requested memory order. If `out` was passed and was an
            array (rather than a `numpy.matrix`), it will be filled
            with the appropriate values and returned wrapped in a
            `numpy.matrix` object that shares the same memory.
        matrix is not squarenonzero indices

        Returns a tuple of arrays (row,col) containing the indices
        of the non-zero elements of the matrix.

        Examples
        --------
        >>> from scipy.sparse import csr_matrix
        >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])
        >>> A.nonzero()
        (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))

         This class provides a base class for all sparse matrices.  It
    cannot be instantiated.  Most of the work is provided by subclasses.
    Method for compatibility with NumPy's ufuncs and dot
        functions.
        Returns a copy of row i of the matrix, as a (1 x n) sparse
        matrix (row vector).
        NBLKbnnzin_shapemax_bnnzactual_bnnzindptr_diffbsr_diagonal_get_blocksizenonzero_blocksindptr_diff_limitedcolumn index values must be < %d (now max %d)Convert this matrix to COOrdinate format.

        When copy=False the data array will be shared between
        this matrix and the resultant coo_matrix.
        data should be 3-DBlock Sparse Row matrix

    This can be instantiated in several ways:
        bsr_matrix(D, [blocksize=(R,C)])
            where D is a dense matrix or 2-D ndarray.

        bsr_matrix(S, [blocksize=(R,C)])
            with another sparse matrix S (equivalent to S.tobsr())

        bsr_matrix((M, N), [blocksize=(R,C), dtype])
            to construct an empty matrix with shape (M, N)
            dtype is optional, defaulting to dtype='d'.

        bsr_matrix((data, ij), [blocksize=(R,C), shape=(M, N)])
            where ``data`` and ``ij`` satisfy ``a[ij[0, k], ij[1, k]] = data[k]``

        bsr_matrix((data, indices, indptr), [shape=(M, N)])
            is the standard BSR representation where the block column
            indices for row i are stored in ``indices[indptr[i]:indptr[i+1]]``
            and their corresponding block values are stored in
            ``data[ indptr[i]: indptr[i+1] ]``.  If the shape parameter is not
            supplied, the matrix dimensions are inferred from the index arrays.

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        Data array of the matrix
    indices
        BSR format index array
    indptr
        BSR format index pointer array
    blocksize
        Block size of the matrix
    has_sorted_indices
        Whether indices are sorted

    Notes
    -----
    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    **Summary of BSR format**

    The Block Compressed Row (BSR) format is very similar to the Compressed
    Sparse Row (CSR) format.  BSR is appropriate for sparse matrices with dense
    sub matrices like the last example below.  Block matrices often arise in
    vector-valued finite element discretizations.  In such cases, BSR is
    considerably more efficient than CSR and CSC for many sparse arithmetic
    operations.

    **Blocksize**

    The blocksize (R,C) must evenly divide the shape of the matrix (M,N).
    That is, R and C must satisfy the relationship ``M % R = 0`` and
    ``N % C = 0``.

    If no blocksize is specified, a simple heuristic is applied to determine
    an appropriate blocksize.

    Examples
    --------
    >>> from scipy.sparse import bsr_matrix
    >>> bsr_matrix((3,4), dtype=np.int8).todense()
    matrix([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]], dtype=int8)

    >>> row = np.array([0,0,1,2,2,2])
    >>> col = np.array([0,2,2,0,1,2])
    >>> data = np.array([1,2,3,4,5,6])
    >>> bsr_matrix((data, (row,col)), shape=(3,3)).todense()
    matrix([[1, 0, 2],
            [0, 0, 3],
            [4, 5, 6]])

    >>> indptr = np.array([0,2,3,6])
    >>> indices = np.array([0,2,2,0,1,2])
    >>> data = np.array([1,2,3,4,5,6]).repeat(4).reshape(6,2,2)
    >>> bsr_matrix((data,indices,indptr), shape=(6,6)).todense()
    matrix([[1, 1, 0, 0, 2, 2],
            [1, 1, 0, 0, 2, 2],
            [0, 0, 0, 0, 3, 3],
            [0, 0, 0, 0, 3, 3],
            [4, 4, 5, 5, 6, 6],
            [4, 4, 5, 5, 6, 6]])

    invalid blocksize=%sindices, and indptr should be 1-Dunrecognized bsr_matrix constructor usageMatrix too big to convertdata array has too few elements Remove empty space after all non-zero elements.
        shape must be multiple of blocksizeCompressed Block Sparse Row matrix formatscipy.sparse.bsrneed to infer shape/usr/lib/python2.7/dist-packages/scipy/sparse/bsr.pyindices array has too few elements<%dx%d sparse matrix of type '%s'
	with %d stored elements (blocksize = %dx%d) in %s format>Apply the binary operation fn to two sparse matrices.column index values must be >= 0check whether the matrix format is valid

            *Parameters*:
                full_check:
                    True  - rigorous check, O(N) operations : default
                    False - basic check, O(1) operations

        _plus_maxnnz_eldiv__elmul__minus_all_true_set_manyn_samplesother_arr_get_sliceactual_nnzmajor_axismajor_name_inequalityminor_shape__get_sorted__set_sorted_insert_manyself_as_bool_copy_with_const_maximum_minimumcsr_sort_indicescsr_sample_offsetscsr_sum_duplicates_has_sorted_indicescsr_eliminate_zeroshas_canonical_format_has_canonical_format_cs_matrix__get_sorted_cs_matrix__set_sortedcsr_has_sorted_indicescsr_has_canonical_format__get_has_canonical_format__set_has_canonical_formatbase matrix class for compressed row and column oriented matricesComparing a sparse matrix with a scalar greater than zero using <= is inefficient, try using > instead.apply the binary operation fn to two sparse matrices.data, indices, and indptr should be 1-DComparing sparse matrices using >= and <= is inefficient, using <, >, or !=, instead.slice width must be >= 1 >= and <= don't work with 0.Comparing a sparse matrix with a scalar less than zero using > is inefficient, try using <= instead.Comparing sparse matrices using == is inefficient, try using != instead.scipy.sparse.compressedEliminate duplicate matrix entries by adding them together

        The is an *in place* operation
        index out of bounds: 0<=%d<%d, 0<=%d<%d, %d<%dDetermine whether the matrix has sorted indices

        Returns
            - True: if the indices of the matrix are in sorted order
            - False: otherwise

        Comparing a sparse matrix with a scalar greater than zero using < is inefficient, try using >= instead.Remove zero entries from the matrix

        The is an *in place* operation
        Copy data, with all nonzeros replaced with constant for binopt

        Adopts the dtype of const to avoid removing sign or magnitude before
        comparison.

        Warning: does not make a copy of indices and indptr
        adding a nonzero scalar to a sparse matrix is not supportedTaking maximum (minimum) with > 0 (< 0) number results to a dense matrix.Base class for sparse matrix formats using compressed storage.Comparing a sparse matrix with 0 using == is inefficient, try using != instead.Determine whether the matrix has sorted indices and no duplicates

        Returns
            - True: if the above applies
            - False: otherwise

        has_canonical_format implies has_sorted_indices, so if the latter flag
        is False, so will the former be; if the former is found True, the
        latter flag is also set.
        %s index values must be >= 0Operands not compatible.Changing the sparsity structure of a %s_matrix is expensive. lil_matrix is more efficient.Reduce nonzeros with a ufunc over the minor axis when non-empty

        Warning: this does not call sum_duplicates()

        Returns
        -------
        major_index : array of ints
            Major indices where nonzero

        value : array of self.dtype
            Reduce result for nonzeros in each major_index
        data array has fewer than nnz elementsReturn a COOrdinate representation of this matrix

        When copy=False the index and data arrays are not copied.
        Point-wise multiplication by another matrix, vector, or
        scalar.
        
        Divide this matrix by a second sparse matrix.
        unrecognized %s_matrix constructor usage/usr/lib/python2.7/dist-packages/scipy/sparse/compressed.pySets value at each (i, j) to x

        Here (i,j) index major and minor respectively.
        indices array has fewer than nnz elementsindex (%d) out of range (>= %d)%s index values must be < %dindex (%d) out of range (< -%d)check whether the matrix format is valid

        Parameters
        ==========

            - full_check : {bool}
                - True  - rigorous check, O(N) operations : default
                - False - basic check, O(1) operations

        Operands could not be compared.Comparing a sparse matrix with a nonzero scalar using != is inefficient, try using == instead.take the member variables of other and assign them to selfReturns a copy of the elements
            [i, start:stop:string] for row-oriented matrices
            [start:stop:string, i] for column-oriented matrices
        Return a copy of this matrix with sorted indices
        inconsistent shapesInserts new nonzero at each (i, j) with value x

        Here (i,j) index major and minor respectively.
        i, j and x must be non-empty, 1d arrays.
        Inserts each major group (e.g. all entries per row) at a time.
        Maintains has_sorted_indices property.
        Modifies i, j, x in place.
        Comparing a sparse matrix with a scalar less than zero using >= is inefficient, try using < instead.(   t   selft   it   jt   xt   ordert   do_sortt	   idx_dtypet   indices_partst
   data_partst   uit	   ui_indptrt   new_nnzst   prevt   ct   iit   jst   jet   startt   stopt   ujt	   uj_indptrt   nnzs_cs_matrix__get_has_canonical_format_cs_matrix__set_has_canonical_formatRQ??mlow
    Build a block diagonal sparse matrix from provided matrices.

    .. versionadded:: 0.11.0

    Parameters
    ----------
    A, B, ... : sequence of matrices
        Input matrices.
    format : str, optional
        The sparse format of the result (e.g. "csr").  If not given, the matrix
        is returned in "coo" format.
    dtype : dtype specifier, optional
        The data-type of the output matrix.  If not given, the dtype is
        determined from that of `blocks`.

    Returns
    -------
    res : sparse matrix

    See Also
    --------
    bmat, diags

    Examples
    --------
    >>> A = coo_matrix([[1, 2], [3, 4]])
    >>> B = coo_matrix([[5], [6]])
    >>> C = coo_matrix([[7]])
    >>> block_diag((A, B, C)).todense()
    matrix([[1, 2, 0, 0],
            [3, 4, 0, 0],
            [0, 0, 5, 0],
            [0, 0, 6, 0],
            [0, 0, 0, 7]])

    A is not square
    Return a sparse matrix from diagonals.

    Parameters
    ----------
    data   : array_like
        matrix diagonals stored row-wise
    diags  : diagonals to set
        - k = 0  the main diagonal
        - k > 0  the k-th upper diagonal
        - k < 0  the k-th lower diagonal
    m, n : int
        shape of the result
    format : format of the result (e.g. "csr")
        By default (format=None) an appropriate sparse matrix
        format is returned.  This choice is subject to change.

    See Also
    --------
    diags : more convenient form of this function
    dia_matrix : the sparse DIAgonal format.

    Examples
    --------
    >>> data = array([[1,2,3,4],[1,2,3,4],[1,2,3,4]])
    >>> diags = array([0,-1,2])
    >>> spdiags(data, diags, 4, 4).todense()
    matrix([[1, 0, 3, 0],
            [1, 2, 0, 4],
            [0, 2, 3, 0],
            [0, 0, 3, 4]])

    blocks[%d,:] is all None
    Stack sparse matrices horizontally (column wise)

    Parameters
    ----------
    blocks
        sequence of sparse matrices with compatible shapes
    format : string
        sparse format of the result (e.g. "csr")
        by default an appropriate sparse matrix format is returned.
        This choice is subject to change.

    See Also
    --------
    vstack : stack sparse matrices vertically (row wise)

    Examples
    --------
    >>> from scipy.sparse import coo_matrix, hstack
    >>> A = coo_matrix([[1,2],[3,4]])
    >>> B = coo_matrix([[5],[6]])
    >>> hstack( [A,B] ).todense()
    matrix([[1, 2, 5],
            [3, 4, 6]])

    type %s not supportedkronecker sum of sparse matrices A and B

    Kronecker sum of two sparse matrices is a sum of two Kronecker
    products kron(I_n,A) + kron(B,I_m) where A has shape (m,m)
    and B has shape (n,n) and I_m and I_n are identity matrices
    of shape (m,m) and (n,n) respectively.

    Parameters
    ----------
    A
        square matrix
    B
        square matrix
    format : string
        format of the result (e.g. "csr")

    Returns
    -------
    kronecker sum in a sparse matrix format

    Examples
    --------


    blocks[:,%d] has incompatible column dimensionsIdentity matrix in sparse format

    Returns an identity matrix with shape (n,n) using a given
    sparse format and dtype.

    Parameters
    ----------
    n : integer
        Shape of the identity matrix.
    dtype :
        Data type of the matrix
    format : string
        Sparse format of the result, e.g. format="csr", etc.

    Examples
    --------
    >>> identity(3).todense()
    matrix([[ 1.,  0.,  0.],
            [ 0.,  1.,  0.],
            [ 0.,  0.,  1.]])
    >>> identity(3, dtype='int8', format='dia')
    <3x3 sparse matrix of type '<type 'numpy.int8'>'
            with 3 stored elements (1 diagonals) in DIAgonal format>

    density expected to be 0 <= density <= 1blocks must be 2-Dincompatible dimensions for axis %d
    Stack sparse matrices vertically (row wise)

    Parameters
    ----------
    blocks
        sequence of sparse matrices with compatible shapes
    format : string
        sparse format of the result (e.g. "csr")
        by default an appropriate sparse matrix format is returned.
        This choice is subject to change.

    See Also
    --------
    hstack : stack sparse matrices horizontally (column wise)

    Examples
    --------
    >>> from scipy.sparse import coo_matrix, vstack
    >>> A = coo_matrix([[1,2],[3,4]])
    >>> B = coo_matrix([[5,6]])
    >>> vstack( [A,B] ).todense()
    matrix([[1, 2],
            [3, 4],
            [5, 6]])

    Generate a sparse matrix of the given shape and density with uniformly
    distributed values.

    Parameters
    ----------
    m, n : int
        shape of the matrix
    density : real
        density of the generated matrix: density equal to one means a full
        matrix, density of 0 means a matrix with no non-zero items.
    format : str
        sparse matrix format.
    dtype : dtype
        type of the returned matrix values.
    random_state : {numpy.random.RandomState, int}, optional
        Random number generator or random seed. If not given, the singleton
        numpy.random will be used.

    Notes
    -----
    Only float types are supported for now.
    blocks[%d,:] has incompatible row dimensionsFunctions to construct sparse matrices

    Stacking fast path for CSR/CSC matrices
    (i) vstack for CSR, (ii) hstack for CSC.
    Trying to generate a random sparse matrix such as the product of dimensions is
greater than %d - this is not supported on this machine
blocks[:,%d] is all NoneB is not squareDiagonal length (index %d: %d at offset %d) does not agree with matrix size (%d, %d).
    Construct a sparse matrix from diagonals.

    .. versionadded:: 0.11

    Parameters
    ----------
    diagonals : sequence of array_like
        Sequence of arrays containing the matrix diagonals,
        corresponding to `offsets`.
    offsets  : sequence of int
        Diagonals to set:
          - k = 0  the main diagonal
          - k > 0  the k-th upper diagonal
          - k < 0  the k-th lower diagonal
    shape : tuple of int, optional
        Shape of the result. If omitted, a square matrix large enough
        to contain the diagonals is returned.
    format : {"dia", "csr", "csc", "lil", ...}, optional
        Matrix format of the result.  By default (format=None) an
        appropriate sparse matrix format is returned.  This choice is
        subject to change.
    dtype : dtype, optional
        Data type of the matrix.

    See Also
    --------
    spdiags : construct matrix from diagonals

    Notes
    -----
    This function differs from `spdiags` in the way it handles
    off-diagonals.

    The result from `diags` is the sparse equivalent of::

        np.diag(diagonals[0], offsets[0])
        + ...
        + np.diag(diagonals[k], offsets[k])

    Repeated diagonal offsets are disallowed.

    Examples
    --------
    >>> diagonals = [[1,2,3,4], [1,2,3], [1,2]]
    >>> diags(diagonals, [0, -1, 2]).todense()
    matrix([[1, 0, 1, 0],
            [1, 2, 0, 2],
            [0, 2, 3, 0],
            [0, 0, 3, 4]])

    Broadcasting of scalars is supported (but shape needs to be
    specified):

    >>> diags([1, -2, 1], [-1, 0, 1], shape=(4, 4)).todense()
    matrix([[-2.,  1.,  0.,  0.],
            [ 1., -2.,  1.,  0.],
            [ 0.,  1., -2.,  1.],
            [ 0.,  0.,  1., -2.]])


    If only one diagonal is wanted (as in `numpy.diag`), the following
    works as well:

    >>> diags([1, 2, 3], 1).todense()
    matrix([[ 0.,  1.,  0.,  0.],
            [ 0.,  0.,  2.,  0.],
            [ 0.,  0.,  0.,  3.],
            [ 0.,  0.,  0.,  0.]])
    
    Build a sparse matrix from sparse sub-blocks

    Parameters
    ----------
    blocks : array_like
        Grid of sparse matrices with compatible shapes.
        An entry of None implies an all-zero matrix.
    format : {'bsr', 'coo', 'csc', 'csr', 'dia', 'dok', 'lil'}, optional
        The sparse format of the result (e.g. "csr").  By default an
        appropriate sparse matrix format is returned.
        This choice is subject to change.
    dtype : dtype specifier, optional
        The data-type of the output matrix.  If not given, the dtype is
        determined from that of `blocks`.

    Returns
    -------
    bmat : sparse matrix

    See Also
    --------
    block_diag, diags

    Examples
    --------
    >>> from scipy.sparse import coo_matrix, bmat
    >>> A = coo_matrix([[1,2],[3,4]])
    >>> B = coo_matrix([[5],[6]])
    >>> C = coo_matrix([[7]])
    >>> bmat( [[A,B],[None,C]] ).todense()
    matrix([[1, 2, 5],
            [3, 4, 6],
            [0, 0, 7]])

    >>> bmat( [[A,None],[None,C]] ).todense()
    matrix([[1, 2, 0],
            [3, 4, 0],
            [0, 0, 7]])

    Different number of diagonals and offsets.Offset %d (index %d) out of bounds/usr/lib/python2.7/dist-packages/scipy/sparse/construct.pykronecker product of sparse matrices A and B

    Parameters
    ----------
    A : sparse or dense matrix
        first matrix of the product
    B : sparse or dense matrix
        second matrix of the product
    format : string
        format of the result (e.g. "csr")

    Returns
    -------
    kronecker product in a sparse matrix format


    Examples
    --------
    >>> A = csr_matrix(array([[0,2],[5,0]]))
    >>> B = csr_matrix(array([[1,2],[3,4]]))
    >>> kron(A,B).todense()
    matrix([[ 0,  0,  2,  4],
            [ 0,  0,  6,  8],
            [ 5, 10,  0,  0],
            [15, 20,  0,  0]])

    >>> kron(A,[[1,2],[3,4]]).todense()
    matrix([[ 0,  0,  2,  4],
            [ 0,  0,  6,  8],
            [ 5, 10,  0,  0],
            [15, 20,  0,  0]])

    Sparse matrix with ones on diagonal

    Returns a sparse (m x n) matrix where the k-th diagonal
    is all ones and everything else is zeros.

    Parameters
    ----------
    n : integer
        Number of rows in the matrix.
    m : integer, optional
        Number of columns. Default: n
    k : integer, optional
        Diagonal to place ones on. Default: 0 (main diagonal)
    dtype :
        Data type of the matrix
    format : string
        Sparse format of the result, e.g. format="csr", etc.

    Examples
    --------
    >>> from scipy import sparse
    >>> sparse.eye(3).todense()
    matrix([[ 1.,  0.,  0.],
            [ 0.,  1.,  0.],
            [ 0.,  0.,  1.]])
    >>> sparse.eye(3, dtype=np.int8)
    <3x3 sparse matrix of type '<type 'numpy.int8'>'
        with 3 stored elements (1 diagonals) in DIAgonal format>

     A sparse matrix in COOrdinate or 'triplet' formatcannot infer dimensions from zero sized index arrayscoo_matrix(None, shape=(M,N)) is deprecated, use coo_matrix( (M,N) ) insteadReturn a copy of this matrix in Compressed Sparse Row format

        Duplicate entries will be summed together.

        Examples
        --------
        >>> from numpy import array
        >>> from scipy.sparse import coo_matrix
        >>> row  = array([0,0,1,3,1,0,0])
        >>> col  = array([0,2,1,3,1,0,0])
        >>> data = array([1,1,1,1,1,1,1])
        >>> A = coo_matrix( (data,(row,col)), shape=(4,4)).tocsr()
        >>> A.todense()
        matrix([[3, 0, 1, 0],
                [0, 2, 0, 0],
                [0, 0, 0, 0],
                [0, 0, 0, 1]])

        /usr/lib/python2.7/dist-packages/scipy/sparse/coo.pyrow, column, and data array must all be the same lengthnegative row index foundOutput array must be C or F contiguousrow, column, and data arrays must be 1-D
    A sparse matrix in COOrdinate format.

    Also known as the 'ijv' or 'triplet' format.

    This can be instantiated in several ways:
        coo_matrix(D)
            with a dense matrix D

        coo_matrix(S)
            with another sparse matrix S (equivalent to S.tocoo())

        coo_matrix((M, N), [dtype])
            to construct an empty matrix with shape (M, N)
            dtype is optional, defaulting to dtype='d'.

        coo_matrix((data, (i, j)), [shape=(M, N)])
            to construct from three arrays:
                1. data[:]   the entries of the matrix, in any order
                2. i[:]      the row indices of the matrix entries
                3. j[:]      the column indices of the matrix entries

            Where ``A[i[k], j[k]] = data[k]``.  When shape is not
            specified, it is inferred from the index arrays

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        COO format data array of the matrix
    row
        COO format row index array of the matrix
    col
        COO format column index array of the matrix

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Advantages of the COO format
        - facilitates fast conversion among sparse formats
        - permits duplicate entries (see example)
        - very fast conversion to and from CSR/CSC formats

    Disadvantages of the COO format
        - does not directly support:
            + arithmetic operations
            + slicing

    Intended Usage
        - COO is a fast format for constructing sparse matrices
        - Once a matrix has been constructed, convert to CSR or
          CSC format for fast arithmetic and matrix vector operations
        - By default when converting to CSR or CSC format, duplicate (i,j)
          entries will be summed together.  This facilitates efficient
          construction of finite element matrices and the like. (see example)

    Examples
    --------
    >>> from scipy.sparse import coo_matrix
    >>> coo_matrix((3,4), dtype=np.int8).todense()
    matrix([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]], dtype=int8)

    >>> row  = np.array([0,3,1,0])
    >>> col  = np.array([0,3,1,2])
    >>> data = np.array([4,5,7,9])
    >>> coo_matrix((data,(row,col)), shape=(4,4)).todense()
    matrix([[4, 0, 9, 0],
            [0, 7, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 5]])

    >>> # example with duplicates
    >>> row  = np.array([0,0,1,3,1,0,0])
    >>> col  = np.array([0,2,1,3,1,0,0])
    >>> data = np.array([1,1,1,1,1,1,1])
    >>> coo_matrix((data, (row,col)), shape=(4,4)).todense()
    matrix([[3, 0, 1, 0],
            [0, 2, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 1]])

    Return a copy of this matrix in Compressed Sparse Column format

        Duplicate entries will be summed together.

        Examples
        --------
        >>> from numpy import array
        >>> from scipy.sparse import coo_matrix
        >>> row  = array([0,0,1,3,1,0,0])
        >>> col  = array([0,2,1,3,1,0,0])
        >>> data = array([1,1,1,1,1,1,1])
        >>> A = coo_matrix( (data,(row,col)), shape=(4,4)).tocsc()
        >>> A.todense()
        matrix([[3, 0, 1, 0],
                [0, 2, 0, 0],
                [0, 0, 0, 0],
                [0, 0, 0, 1]])

        row index array has non-integer dtype (%s)  dimensions not understoodnegative column index foundcolumn index exceeds matrix dimensionsscipy.sparse.coo Checks data structure for consistency Returns a matrix with the same sparsity structure as self,
        but with different data.  By default the index arrays
        (i.e. .row and .col) are copied.
        expected dimension <= 2 array or matrixrow index exceeds matrix dimensionscol index array has non-integer dtype (%s) /usr/lib/python2.7/dist-packages/scipy/sparse/csc.py
    Compressed Sparse Column matrix

    This can be instantiated in several ways:

        csc_matrix(D)
            with a dense matrix or rank-2 ndarray D

        csc_matrix(S)
            with another sparse matrix S (equivalent to S.tocsc())

        csc_matrix((M, N), [dtype])
            to construct an empty matrix with shape (M, N)
            dtype is optional, defaulting to dtype='d'.

        csc_matrix((data, ij), [shape=(M, N)])
            where ``data`` and ``ij`` satisfy the relationship
            ``a[ij[0, k], ij[1, k]] = data[k]``

        csc_matrix((data, indices, indptr), [shape=(M, N)])
            is the standard CSC representation where the row indices for
            column i are stored in ``indices[indptr[i]:indptr[i+1]]``
            and their corresponding values are stored in
            ``data[indptr[i]:indptr[i+1]]``.  If the shape parameter is
            not supplied, the matrix dimensions are inferred from
            the index arrays.

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        Data array of the matrix
    indices
        CSC format index array
    indptr
        CSC format index pointer array
    has_sorted_indices
        Whether indices are sorted

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Advantages of the CSC format
        - efficient arithmetic operations CSC + CSC, CSC * CSC, etc.
        - efficient column slicing
        - fast matrix vector products (CSR, BSR may be faster)

    Disadvantages of the CSC format
      - slow row slicing operations (consider CSR)
      - changes to the sparsity structure are expensive (consider LIL or DOK)


    Examples
    --------

    >>> from scipy.sparse import *
    >>> from scipy import *
    >>> csc_matrix( (3,4), dtype=int8 ).todense()
    matrix([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]], dtype=int8)

    >>> row = array([0,2,2,0,1,2])
    >>> col = array([0,0,1,2,2,2])
    >>> data = array([1,2,3,4,5,6])
    >>> csc_matrix( (data,(row,col)), shape=(3,3) ).todense()
    matrix([[1, 0, 4],
            [0, 0, 5],
            [2, 3, 6]])

    >>> indptr = array([0,2,3,6])
    >>> indices = array([0,2,2,0,1,2])
    >>> data = array([1,2,3,4,5,6])
    >>> csc_matrix( (data,indices,indptr), shape=(3,3) ).todense()
    matrix([[1, 0, 4],
            [0, 0, 5],
            [2, 3, 6]])

    Returns a copy of column i of the matrix, as a (m x 1)
        CSC matrix (column vector).
        Compressed Sparse Column matrix formatscipy.sparse.cscjohnsondijkstra_traversalbellman_fordshortest_path_shortest_pathfloyd_warshallcsgraph_to_densedepth_first_treereconstruct_pathdepth_first_orderNegativeCycleError_min_spanning_treebreadth_first_treecsgraph_from_densebreadth_first_ordercsgraph_from_maskedconnected_componentsconstruct_dist_matrixminimum_spanning_treecsgraph_masked_from_denseIn the future, use csgraph.connected_components. Note that this new function has a slightly different interface: see the docstring for more information.[   s   cs_graph_componentss   connected_componentss	   laplacians   shortest_paths   floyd_warshalls   dijkstras   bellman_fords   johnsons   breadth_first_orders   depth_first_orders   breadth_first_trees   depth_first_trees   minimum_spanning_trees   construct_dist_matrixs   reconstruct_paths   csgraph_from_denses   csgraph_masked_from_denses   csgraph_to_denses   csgraph_to_maskeds   NegativeCycleError
==============================================================
Compressed Sparse Graph Routines (:mod:`scipy.sparse.csgraph`)
==============================================================

.. currentmodule:: scipy.sparse.csgraph

Fast graph algorithms based on sparse matrix representations.

Contents
========

.. autosummary::
   :toctree: generated/

   connected_components -- determine connected components of a graph
   laplacian -- compute the laplacian of a graph
   shortest_path -- compute the shortest path between points on a positive graph
   dijkstra -- use Dijkstra's algorithm for shortest path
   floyd_warshall -- use the Floyd-Warshall algorithm for shortest path
   bellman_ford -- use the Bellman-Ford algorithm for shortest path
   johnson -- use Johnson's algorithm for shortest path
   breadth_first_order -- compute a breadth-first order of nodes
   depth_first_order -- compute a depth-first order of nodes
   breadth_first_tree -- construct the breadth-first tree from a given node
   depth_first_tree -- construct a depth-first tree from a given node
   minimum_spanning_tree -- construct the minimum spanning tree of a graph

Graph Representations
=====================
This module uses graphs which are stored in a matrix format.  A
graph with N nodes can be represented by an (N x N) adjacency matrix G.
If there is a connection from node i to node j, then G[i, j] = w, where
w is the weight of the connection.  For nodes i and j which are
not connected, the value depends on the representation:

- for dense array representations, non-edges are represented by
  G[i, j] = 0, infinity, or NaN.

- for dense masked representations (of type np.ma.MaskedArray), non-edges
  are represented by masked values.  This can be useful when graphs with
  zero-weight edges are desired.

- for sparse array representations, non-edges are represented by
  non-entries in the matrix.  This sort of sparse representation also
  allows for edges with zero weights.

As a concrete example, imagine that you would like to represent the following
undirected graph::

              G

             (0)
            /   \
           1     2
          /       \
        (2)       (1)

This graph has three nodes, where node 0 and 1 are connected by an edge of
weight 2, and nodes 0 and 2 are connected by an edge of weight 1.
We can construct the dense, masked, and sparse representations as follows,
keeping in mind that an undirected graph is represented by a symmetric matrix::

    >>> G_dense = np.array([[0, 2, 1],
    ...                     [2, 0, 0],
    ...                     [1, 0, 0]])
    >>> G_masked = np.ma.masked_values(G_dense, 0)
    >>> from scipy.sparse import csr_matrix
    >>> G_sparse = csr_matrix(G_dense)

This becomes more difficult when zero edges are significant.  For example,
consider the situation when we slightly modify the above graph::

             G2

             (0)
            /   \
           0     2
          /       \
        (2)       (1)

This is identical to the previous graph, except nodes 0 and 2 are connected
by an edge of zero weight.  In this case, the dense representation above
leads to ambiguities: how can non-edges be represented if zero is a meaningful
value?  In this case, either a masked or sparse representation must be used
to eliminate the ambiguity::

    >>> G2_data = np.array([[np.inf, 2,      0     ],
    ...                     [2,      np.inf, np.inf],
    ...                     [0,      np.inf, np.inf]])
    >>> G2_masked = np.ma.masked_invalid(G2_data)
    >>> from scipy.sparse.csgraph import csgraph_from_dense
    >>> # G2_sparse = csr_matrix(G2_data) would give the wrong result
    >>> G2_sparse = csgraph_from_dense(G2_data, null_value=np.inf)
    >>> G2_sparse.data
    array([ 2.,  0.,  2.,  0.])

Here we have used a utility routine from the csgraph submodule in order to
convert the dense representation to a sparse representation which can be
understood by the algorithms in submodule.  By viewing the data array, we
can see that the zero values are explicitly encoded in the graph.

Directed vs. Undirected
-----------------------
Matrices may represent either directed or undirected graphs.  This is
specified throughout the csgraph module by a boolean keyword.  Graphs are
assumed to be directed by default. In a directed graph, traversal from node
i to node j can be accomplished over the edge G[i, j], but not the edge
G[j, i].  In a non-directed graph, traversal from node i to node j can be
accomplished over either G[i, j] or G[j, i].  If both edges are not null,
and the two have unequal weights, then the smaller of the two is used.
Note that a symmetric matrix will represent an undirected graph, regardless
of whether the 'directed' keyword is set to True or False.  In this case,
using ``directed=True`` generally leads to more efficient computation.

The routines in this module accept as input either scipy.sparse representations
(csr, csc, or lil format), masked representations, or dense representations
with non-edges indicated by zeros, infinities, and NaN entries.
/usr/lib/python2.7/dist-packages/scipy/sparse/csgraph/usr/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.pyx must be a symmetric square matrix!(has shape %s)
    Determine connected components of a graph stored as a compressed
    sparse row or column matrix.

    For speed reasons, the symmetry of the matrix x is not checked. A
    nonzero at index `(i, j)` means that node `i` is connected to node
    `j` by an edge. The number of rows/columns of the matrix thus
    corresponds to the number of nodes in the graph.

    Parameters
    -----------
    x : array_like or sparse matrix, 2 dimensions
        The adjacency matrix of the graph. Only the upper triangular part
        is used.

    Returns
    --------
    n_comp : int
        The number of connected components.
    label : ndarray (ints, 1 dimension):
        The label array of each connected component (-2 is used to
        indicate empty rows in the matrix: 0 everywhere, including
        diagonal). This array has the length of the number of nodes,
        i.e. one label for each node of the graph. Nodes having the same
        label belong to the same connected component.

    Notes
    ------
    The matrix is assumed to be symmetric and the upper triangular part
    of the matrix is used. The matrix is converted to a CSR matrix unless
    it is already a CSR.

    Examples
    --------
    >>> from scipy.sparse.csgraph import connected_components
    >>> D = np.eye(4)
    >>> D[0,1] = D[1,0] = 1
    >>> cs_graph_components(D)
    (3, array([0, 0, 1, 2]))
    >>> from scipy.sparse import dok_matrix
    >>> cs_graph_components(dok_matrix(D))
    (3, array([0, 0, 1, 2]))

    /usr/lib/python2.7/dist-packages/scipy/sparse/csgraph/_components.pyscipy.sparse._sparsetoolsscipy.sparse.csgraph._componentsnew_colnew_rowdiag_idxdiagonal_holesscipy.sparse.csgraph._laplaciancsgraph must be a square matrix or array/usr/lib/python2.7/dist-packages/scipy/sparse/csgraph/_laplacian.py Return the Laplacian matrix of a directed graph.

    For non-symmetric graphs the out-degree is used in the computation.

    Parameters
    ----------
    csgraph : array_like or sparse matrix, 2 dimensions
        compressed-sparse graph, with shape (N, N).
    normed : bool, optional
        If True, then compute normalized Laplacian.
    return_diag : bool, optional
        If True, then return diagonal as well as laplacian.

    Returns
    -------
    lap : ndarray
        The N x N laplacian matrix of graph.
    diag : ndarray
        The length-N diagonal of the laplacian matrix.
        diag is returned only if return_diag is True.

    Notes
    -----
    The Laplacian matrix of a graph is sometimes referred to as the
    "Kirchoff matrix" or the "admittance matrix", and is useful in many
    parts of spectral graph theory.  In particular, the eigen-decomposition
    of the laplacian matrix can give insight into many properties of the graph.

    For non-symmetric directed graphs, the laplacian is computed using the
    out-degree of each node.

    Examples
    --------
    >>> from scipy.sparse import csgraph
    >>> G = np.arange(5) * np.arange(5)[:, np.newaxis]
    >>> G
    array([[ 0,  0,  0,  0,  0],
           [ 0,  1,  2,  3,  4],
           [ 0,  2,  4,  6,  8],
           [ 0,  3,  6,  9, 12],
           [ 0,  4,  8, 12, 16]])
    >>> csgraph.laplacian(G, normed=False)
    array([[  0,   0,   0,   0,   0],
           [  0,   9,  -2,  -3,  -4],
           [  0,  -2,  16,  -6,  -8],
           [  0,  -3,  -6,  21, -12],
           [  0,  -4,  -8, -12,  24]])
    
Laplacian of a compressed-sparse graph
blksmax_indxrow_datarow_indptrnum_samplesrow_indices_get_row_slice/usr/lib/python2.7/dist-packages/scipy/sparse/csr.pyReturns a copy of column i of the matrix, as a (m x 1)
        CSR matrix (column vector).
        index out of bounds: 0 <= %d <= %d, 0 <= %d <= %d, %d <= %dexpected slice or scalarnumber of row and column indices differReturns a copy of row self[i, cslice]
        Return a sparse matrix P so that P*self implements
            slicing of the form self[[1,2,3],:]
            
    Compressed Sparse Row matrix

    This can be instantiated in several ways:
        csr_matrix(D)
            with a dense matrix or rank-2 ndarray D

        csr_matrix(S)
            with another sparse matrix S (equivalent to S.tocsr())

        csr_matrix((M, N), [dtype])
            to construct an empty matrix with shape (M, N)
            dtype is optional, defaulting to dtype='d'.

        csr_matrix((data, ij), [shape=(M, N)])
            where ``data`` and ``ij`` satisfy the relationship
            ``a[ij[0, k], ij[1, k]] = data[k]``

        csr_matrix((data, indices, indptr), [shape=(M, N)])
            is the standard CSR representation where the column indices for
            row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their
            corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.
            If the shape parameter is not supplied, the matrix dimensions
            are inferred from the index arrays.

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        CSR format data array of the matrix
    indices
        CSR format index array of the matrix
    indptr
        CSR format index pointer array of the matrix
    has_sorted_indices
        Whether indices are sorted

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Advantages of the CSR format
      - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.
      - efficient row slicing
      - fast matrix vector products

    Disadvantages of the CSR format
      - slow column slicing operations (consider CSC)
      - changes to the sparsity structure are expensive (consider LIL or DOK)

    Examples
    --------

    >>> from scipy.sparse import *
    >>> from scipy import *
    >>> csr_matrix( (3,4), dtype=int8 ).todense()
    matrix([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]], dtype=int8)

    >>> row = array([0,0,1,2,2,2])
    >>> col = array([0,2,2,0,1,2])
    >>> data = array([1,2,3,4,5,6])
    >>> csr_matrix( (data,(row,col)), shape=(3,3) ).todense()
    matrix([[1, 0, 2],
            [0, 0, 3],
            [4, 5, 6]])

    >>> indptr = array([0,2,3,6])
    >>> indices = array([0,2,2,0,1,2])
    >>> data = array([1,2,3,4,5,6])
    >>> csr_matrix( (data,indices,indptr), shape=(3,3) ).todense()
    matrix([[1, 0, 2],
            [0, 0, 3],
            [4, 5, 6]])

    invalid blocksize %sCompressed Sparse Row matrix formatnot_full_set_dtype_min_or_max_min_or_max_axisinvalid axis, use 0 for rows, or 1 for columnsMaximum of the elements of this matrix.

        This takes all elements into account, not just the non-zero ones.

        Returns
        -------
        amax : self.dtype
            Maximum element.
        zero-size array to reduction operationBase class for sparse matrice with a .data attribute

    subclasses must provide a _with_data() method that
    creates a new matrix with the same sparsity pattern
    as self but with a different data array

Element-wise %s.

See numpy.%s for more information.Mixin for min and max methods.

    These are not implemented for dia_matrix, hence the separate class.
    /usr/lib/python2.7/dist-packages/scipy/sparse/data.pyscipy.sparse.dataMinimum of the elements of this matrix.

        This takes all elements into account, not just the non-zero ones.

        Returns
        -------
        amin : self.dtype
            Minimum element.
        len_datanum_datamin_index_mul_multimatrixnumber of diagonals (%d) does not match the number of offsets (%d)Sparse matrix with DIAgonal storage

    This can be instantiated in several ways:
        dia_matrix(D)
            with a dense matrix

        dia_matrix(S)
            with another sparse matrix S (equivalent to S.todia())

        dia_matrix((M, N), [dtype])
            to construct an empty matrix with shape (M, N),
            dtype is optional, defaulting to dtype='d'.

        dia_matrix((data, offsets), shape=(M, N))
            where the ``data[k,:]`` stores the diagonal entries for
            diagonal ``offsets[k]`` (See example below)

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        DIA format data array of the matrix
    offsets
        DIA format offset array of the matrix

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Examples
    --------

    >>> from scipy.sparse import *
    >>> from scipy import *
    >>> dia_matrix( (3,4), dtype=int8).todense()
    matrix([[0, 0, 0, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]], dtype=int8)

    >>> data = array([[1,2,3,4]]).repeat(3,axis=0)
    >>> offsets = array([0,-1,2])
    >>> dia_matrix( (data,offsets), shape=(4,4)).todense()
    matrix([[1, 0, 3, 0],
            [1, 2, 0, 4],
            [0, 2, 3, 0],
            [0, 0, 3, 4]])

    offsets array must have rank 1data array must have rank 2/usr/lib/python2.7/dist-packages/scipy/sparse/dia.pynumber of nonzero values

        explicit zero values are included in this number
        scipy.sparse.diaexpected a shape argumentReturns a matrix with the same sparsity structure as self,
        but with different data.  By default the structure arrays are copied.
        unrecognized form for dia_matrix constructor<%dx%d sparse matrix of type '%s'
	with %d stored elements (%d diagonals) in %s format>Sparse DIAgonal formatoffset array contains duplicate valuesaiji_seqj_seqi_stopj_stopzeroesj_sliceconjtransp_is_sequenceisSequenceType_getitem_ranges Return the conjugate transpose
        /usr/lib/python2.7/dist-packages/scipy/sparse/dok.pydimensions must be a 2-tuple of positive integersscipy.sparse.dokindex must be a pair of integersmatrix dimensions are not equal
    Dictionary Of Keys based sparse matrix.

    This is an efficient structure for constructing sparse
    matrices incrementally.

    This can be instantiated in several ways:
        dok_matrix(D)
            with a dense matrix, D

        dok_matrix(S)
            with a sparse matrix, S

        dok_matrix((M,N), [dtype])
            create the matrix with initial shape (M,N)
            dtype is optional, defaulting to dtype='d'

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Allows for efficient O(1) access of individual elements.
    Duplicates are not allowed.
    Can be efficiently converted to a coo_matrix once constructed.

    Examples
    --------
    >>> from scipy.sparse import *
    >>> from scipy import *
    >>> S = dok_matrix((5,5), dtype=float32)
    >>> for i in range(5):
    >>>     for j in range(5):
    >>>         S[i,j] = i+j # Update element

     Return a copy of this matrix in COOrdinate formatReturns a copy of column j of the matrix as a (m x 1)
        DOK matrix.
        If key=(i,j) is a pair of integers, return the corresponding
        element.  If either i or j is a slice or sequence, return a new sparse
        matrix with just these elements.
        expected rank <=2 dense array or matrix Return the transpose
        Force x to a list.Product of a list of numbers; ~40x faster vs np.prod for Python tuplesThis overrides the dict.get method, providing type checking
        but otherwise equivalent functionality.
        Returns a copy of row i of the matrix as a (1 x n)
        DOK matrix.
         Resize the matrix in-place to dimensions given by 'shape'.

        Any non-zero elements that lie outside the new shape are removed.
         Return a copy of this matrix in Compressed Sparse Row formatindex (%d) out of range -%d to %d)data type not understoodDictionary Of Keys based matrix(   t   selft   indext   it   jt	   i_intliket	   j_intliket   i_slicet   j_slicet	   i_indicest	   j_indicest   i_seqt   j_seqt   newshapet   newsizet   min_it   min_jt   newdokt   at   bt   v/usr/lib/python2.7/dist-packages/scipy/sparse/extract.pyFunctions to extract parts of sparse matrices
scipy.sparse.extractReturn the upper triangular portion of a matrix in sparse format

    Returns the elements on or above the k-th diagonal of the matrix A.
        - k = 0 corresponds to the main diagonal
        - k > 0 is above the main diagonal
        - k < 0 is below the main diagonal

    Parameters
    ----------
    A : dense or sparse matrix
        Matrix whose upper trianglar portion is desired.
    k : integer : optional
        The bottom-most diagonal of the upper triangle.
    format : string
        Sparse format of the result, e.g. format="csr", etc.

    Returns
    -------
    L : sparse matrix
        Upper triangular portion of A in sparse format.

    See Also
    --------
    tril : lower triangle in sparse format

    Examples
    --------
    >>> from scipy.sparse import csr_matrix
    >>> A = csr_matrix( [[1,2,0,0,3],[4,5,0,6,7],[0,0,8,9,0]], dtype='int32' )
    >>> A.todense()
    matrix([[1, 2, 0, 0, 3],
            [4, 5, 0, 6, 7],
            [0, 0, 8, 9, 0]])
    >>> triu(A).todense()
    matrix([[1, 2, 0, 0, 3],
            [0, 5, 0, 6, 7],
            [0, 0, 8, 9, 0]])
    >>> triu(A).nnz
    8
    >>> triu(A, k=1).todense()
    matrix([[0, 2, 0, 0, 3],
            [0, 0, 0, 6, 7],
            [0, 0, 0, 9, 0]])
    >>> triu(A, k=-1).todense()
    matrix([[1, 2, 0, 0, 3],
            [4, 5, 0, 6, 7],
            [0, 0, 8, 9, 0]])
    >>> triu(A, format='csc')
    <3x5 sparse matrix of type '<type 'numpy.int32'>'
            with 8 stored elements in Compressed Sparse Column format>

    Return the lower triangular portion of a matrix in sparse format

    Returns the elements on or below the k-th diagonal of the matrix A.
        - k = 0 corresponds to the main diagonal
        - k > 0 is above the main diagonal
        - k < 0 is below the main diagonal

    Parameters
    ----------
    A : dense or sparse matrix
        Matrix whose lower trianglar portion is desired.
    k : integer : optional
        The top-most diagonal of the lower triangle.
    format : string
        Sparse format of the result, e.g. format="csr", etc.

    Returns
    -------
    L : sparse matrix
        Lower triangular portion of A in sparse format.

    See Also
    --------
    triu : upper triangle in sparse format

    Examples
    --------
    >>> from scipy.sparse import csr_matrix
    >>> A = csr_matrix( [[1,2,0,0,3],[4,5,0,6,7],[0,0,8,9,0]], dtype='int32' )
    >>> A.todense()
    matrix([[1, 2, 0, 0, 3],
            [4, 5, 0, 6, 7],
            [0, 0, 8, 9, 0]])
    >>> tril(A).todense()
    matrix([[1, 0, 0, 0, 0],
            [4, 5, 0, 0, 0],
            [0, 0, 8, 0, 0]])
    >>> tril(A).nnz
    4
    >>> tril(A, k=1).todense()
    matrix([[1, 2, 0, 0, 0],
            [4, 5, 0, 0, 0],
            [0, 0, 8, 9, 0]])
    >>> tril(A, k=-1).todense()
    matrix([[0, 0, 0, 0, 0],
            [4, 0, 0, 0, 0],
            [0, 0, 0, 0, 0]])
    >>> tril(A, format='csc')
    <3x5 sparse matrix of type '<type 'numpy.int32'>'
            with 4 stored elements in Compressed Sparse Column format>

    Return the indices and values of the nonzero elements of a matrix

    Parameters
    ----------
    A : dense or sparse matrix
        Matrix whose nonzero elements are desired.

    Returns
    -------
    (I,J,V) : tuple of arrays
        I,J, and V contain the row indices, column indices, and values
        of the nonzero matrix entries.


    Examples
    --------
    >>> from scipy.sparse import csr_matrix
    >>> A = csr_matrix([[7.0, 8.0, 0],[0, 0, 9.0]])
    >>> find(A)
    (array([0, 0, 1], dtype=int32), array([0, 1, 2], dtype=int32), array([ 7.,  8.,  9.]))

    bisectlil_get1getrowviewlil_insertbisect_leftlil_fancy_getlil_fancy_setprepare_index_for_memoryviewscipy.sparse.lilReturn the element(s) index=(i, j), where j may be a slice.
        This always returns a copy for consistency, since slices into
        Python lists return copies.
         Return Compressed Sparse Column format arrays for this matrix.
        /usr/lib/python2.7/dist-packages/scipy/sparse/lil.pyinvalid use of shape parameterTrying to assign a sequence to an item  %s	%s
unsupported matrix typeRow-based linked list sparse matrix

    This is an efficient structure for constructing sparse
    matrices incrementally.

    This can be instantiated in several ways:
        lil_matrix(D)
            with a dense matrix or rank-2 ndarray D

        lil_matrix(S)
            with another sparse matrix S (equivalent to S.tolil())

        lil_matrix((M, N), [dtype])
            to construct an empty matrix with shape (M, N)
            dtype is optional, defaulting to dtype='d'.

    Attributes
    ----------
    dtype : dtype
        Data type of the matrix
    shape : 2-tuple
        Shape of the matrix
    ndim : int
        Number of dimensions (this is always 2)
    nnz
        Number of nonzero elements
    data
        LIL format data array of the matrix
    rows
        LIL format row index array of the matrix

    Notes
    -----

    Sparse matrices can be used in arithmetic operations: they support
    addition, subtraction, multiplication, division, and matrix power.

    Advantages of the LIL format
        - supports flexible slicing
        - changes to the matrix sparsity structure are efficient

    Disadvantages of the LIL format
        - arithmetic operations LIL + LIL are slow (consider CSR or CSC)
        - slow column slicing (consider CSC)
        - slow matrix vector products (consider CSR or CSC)

    Intended Usage
        - LIL is a convenient format for constructing sparse matrices
        - once a matrix has been constructed, convert to CSR or
          CSC format for fast arithmetic and matrix vector operations
        - consider using the COO format when constructing large matrices

    Data Structure
        - An array (``self.rows``) of rows, each of which is a sorted
          list of column indices of non-zero elements.
        - The corresponding nonzero values are stored in similar
          fashion in ``self.data``.


    Returns a view of the 'i'th row (without copying).
        unrecognized lil_matrix constructor usageReturns a copy of the 'i'th row.
         Return Compressed Sparse Row format arrays for this matrix.
        LInked List sparse matrix class
/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/__init__.py
==================================================
Sparse linear algebra (:mod:`scipy.sparse.linalg`)
==================================================

.. currentmodule:: scipy.sparse.linalg

Abstract linear operators
-------------------------

.. autosummary::
   :toctree: generated/

   LinearOperator -- abstract representation of a linear operator
   aslinearoperator -- convert an object to an abstract linear operator

Matrix Operations
-----------------

.. autosummary::
   :toctree: generated/

   inv -- compute the sparse matrix inverse
   expm -- compute the sparse matrix exponential
   expm_multiply -- compute the product of a matrix exponential and a matrix

Matrix norms
------------

.. autosummary::
   :toctree: generated/

   onenormest -- Estimate the 1-norm of a sparse matrix

Solving linear problems
-----------------------

Direct methods for linear equation systems:

.. autosummary::
   :toctree: generated/

   spsolve -- Solve the sparse linear system Ax=b
   factorized -- Pre-factorize matrix to a function solving a linear system

Iterative methods for linear equation systems:

.. autosummary::
   :toctree: generated/

   bicg -- Use BIConjugate Gradient iteration to solve A x = b
   bicgstab -- Use BIConjugate Gradient STABilized iteration to solve A x = b
   cg -- Use Conjugate Gradient iteration to solve A x = b
   cgs -- Use Conjugate Gradient Squared iteration to solve A x = b
   gmres -- Use Generalized Minimal RESidual iteration to solve A x = b
   lgmres -- Solve a matrix equation using the LGMRES algorithm
   minres -- Use MINimum RESidual iteration to solve Ax = b
   qmr -- Use Quasi-Minimal Residual iteration to solve A x = b

Iterative methods for least-squares problems:

.. autosummary::
   :toctree: generated/

   lsqr -- Find the least-squares solution to a sparse linear equation system
   lsmr -- Find the least-squares solution to a sparse linear equation system

Matrix factorizations
---------------------

Eigenvalue problems:

.. autosummary::
   :toctree: generated/

   eigs -- Find k eigenvalues and eigenvectors of the square matrix A
   eigsh -- Find k eigenvalues and eigenvectors of a symmetric matrix
   lobpcg -- Solve symmetric partial eigenproblems with optional preconditioning

Singular values problems:

.. autosummary::
   :toctree: generated/

   svds -- Compute k singular values/vectors for a sparse matrix

Complete or incomplete LU factorizations

.. autosummary::
   :toctree: generated/

   splu -- Compute a LU decomposition for a sparse matrix
   spilu -- Compute an incomplete LU decomposition for a sparse matrix
   SuperLU -- Object representing an LU factorization

Exceptions
----------

.. autosummary::
   :toctree: generated/

   ArpackNoConvergence
   ArpackError

p_lowp_highK_shapeX_shapensamples_A_1_normsqrt_m_maxeffective_dinput_shapeinf_norm_K_p_1linspace_kwargs{i   gM<i   g6m[>i   gYt&>i   gq@H6?i   ga2U0*c?i   g3mJ?i   gtF_?i   g?i	   g?i
   g;On?i   g1Zd?i   g333333?i   g?i   g r?i   gPn?i   gE?i   gn?i   gq=
p?i   g)\(?i   g
p=
?i   gQ?i   gQ?i   gGz @i   g(\@i   gq=
p@i   gQ@i   gzG@i   gp=
@i   g{Gz
@i   gRQ@i#   g@i(   g      @i-   g@i2   g      !@i7   g#@0
    A helper function, for the case q > s and q % s == 0.
    
    Compute the action of the matrix exponential of A on B.

    Parameters
    ----------
    A : transposable linear operator
        The operator whose exponential is of interest.
    B : ndarray
        The matrix or vector to be multiplied by the matrix exponential of A.
    start : scalar, optional
        The starting time point of the sequence.
    stop : scalar, optional
        The end time point of the sequence, unless `endpoint` is set to False.
        In that case, the sequence consists of all but the last of ``num + 1``
        evenly spaced time points, so that `stop` is excluded.
        Note that the step size changes when `endpoint` is False.
    num : int, optional
        Number of time points to use.
    endpoint : bool, optional
        If True, `stop` is the last time point.  Otherwise, it is not included.

    Returns
    -------
    expm_A_B : ndarray
         The result of the action :math:`e^{t_k A} B`.

    Notes
    -----
    The optional arguments defining the sequence of evenly spaced time points
    are compatible with the arguments of `numpy.linspace`.

    The output ndarray shape is somewhat complicated so I explain it here.
    The ndim of the output could be either 1, 2, or 3.
    It would be 1 if you are computing the expm action on a single vector
    at a single time point.
    It would be 2 if you are computing the expm action on a vector
    at multiple time points, or if you are computing the expm action
    on a matrix at a single time point.
    It would be 3 if you want the action on a matrix with multiple
    columns at multiple time points.
    If multiple time points are requested, expm_A_B[0] will always
    be the action of the expm at the first time point,
    regardless of whether the action is on a vector or a matrix.

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2011)
           "Computing the Action of the Matrix Exponential,
           with an Application to Exponential Integrators."
           SIAM Journal on Scientific Computing,
           33 (2). pp. 488-511. ISSN 1064-8275
           http://eprints.ma.man.ac.uk/1591/

    .. [2] Nicholas J. Higham and Awad H. Al-Mohy (2010)
           "Computing Matrix Functions."
           Acta Numerica,
           19. 159-208. ISSN 0962-4929
           http://eprints.ma.man.ac.uk/1451/

    
    A helper function for the _expm_multiply_* functions.

    Parameters
    ----------
    A_1_norm : float
        The precomputed 1-norm of A.
    n0 : int
        Number of columns in the _expm_multiply_* B matrix.
    m_max : int
        A value related to a bound.
    ell : int
        The number of columns used in the 1-norm approximation.
        This is usually taken to be small, maybe between 1 and 5.

    Returns
    -------
    value : bool
        Indicates whether or not the condition has been met.

    Notes
    -----
    This is condition (3.13) in Al-Mohy and Higham (2011).

    at least two time points are required
    A helper function, for the case q > s and q % s > 0.
    
    Compute the action of the matrix exponential at multiple time points.

    Parameters
    ----------
    A : transposable linear operator
        The operator whose exponential is of interest.
    B : ndarray
        The matrix to be multiplied by the matrix exponential of A.
    start : scalar, optional
        The starting time point of the sequence.
    stop : scalar, optional
        The end time point of the sequence, unless `endpoint` is set to False.
        In that case, the sequence consists of all but the last of ``num + 1``
        evenly spaced time points, so that `stop` is excluded.
        Note that the step size changes when `endpoint` is False.
    num : int, optional
        Number of time points to use.
    endpoint : bool, optional
        If True, `stop` is the last time point.  Otherwise, it is not included.
    balance : bool
        Indicates whether or not to apply balancing.
    status_only : bool
        A flag that is set to True for some debugging and testing operations.

    Returns
    -------
    F : ndarray
        :math:`e^{t_k A} B`
    status : int
        An integer status for testing and debugging.

    Notes
    -----
    This is algorithm (5.2) in Al-Mohy and Higham (2011).

    There seems to be a typo, where line 15 of the algorithm should be
    moved to line 6.5 (between lines 6 and 7).

    
    A helper function, for the case q <= s.
    expected B to be like a matrix or a vector
    A helper function for the _expm_multiply_* functions.

    Parameters
    ----------
    norm_info : LazyOperatorNormInfo
        Information about norms of certain linear operators of interest.
    n0 : int
        Number of columns in the _expm_multiply_* B matrix.
    tol : float
        Expected to be
        :math:`2^{-24}` for single precision or
        :math:`2^{-53}` for double precision.
    m_max : int
        A value related to a bound.
    ell : int
        The number of columns used in the 1-norm approximation.
        This is usually taken to be small, maybe between 1 and 5.

    Returns
    -------
    best_m : int
        Related to bounds for error control.
    best_s : int
        Amount of scaling.

    Notes
    -----
    This is code fragment (3.1) in Al-Mohy and Higham (2011).
    The discussion of default values for m_max and ell
    is given between the definitions of equation (3.11)
    and the definition of equation (3.12).

    
    Compute the largest positive integer p such that p*(p-1) <= m_max + 1.

    Do this in a slightly dumb way, but safe and not too slow.

    Parameters
    ----------
    m_max : int
        A count related to bounds.

    the matrices A and B have incompatible shapes
        Lazily estimate d_p(A) ~= || A^p ||^(1/p) where ||.|| is the 1-norm.
        
    Compute the action of the matrix exponential at a single time point.

    Parameters
    ----------
    A : transposable linear operator
        The operator whose exponential is of interest.
    B : ndarray
        The matrix to be multiplied by the matrix exponential of A.
    t : float
        A time point.
    balance : bool
        Indicates whether or not to apply balancing.

    Returns
    -------
    F : ndarray
        :math:`e^{t A} B`

    Notes
    -----
    This is algorithm (3.2) in Al-Mohy and Higham (2011).

    
    A helper function.
    
    A helper function for computing bounds.

    This is equation (3.10).
    It measures cost in terms of the number of required matrix products.

    Parameters
    ----------
    m : int
        A valid key of _theta.
    p : int
        A matrix power.
    norm_info : LazyOperatorNormInfo
        Information about 1-norms of related operators.

    Returns
    -------
    cost_div_m : int
        Required number of matrix products divided by m.

    scipy.sparse.linalg._expm_multiply
        Compute the exact 1-norm.
        
    Information about an operator is lazily computed.

    The information includes the exact 1-norm of the operator,
    in addition to estimates of 1-norms of powers of the operator.
    This uses the notation of Computing the Action (2011).
    This class is specialized enough to probably not be of general interest
    outside of this module.

    
        Lazily compute max(d(p), d(p+1)).
        expected ell to be a positive integerCompute the action of the matrix exponential.
/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/_expm_multiply.py
        Provide the operator and some norm-related information.

        Parameters
        ----------
        A : linear operator
            The operator of interest.
        A_1_norm : float, optional
            The exact 1-norm of A.
        ell : int, optional
            A technical parameter controlling norm estimation quality.

        (   t   At   Bt   startt   stopt   numt   endpointt   balancet   status_onlyt   identt   nt   n0t   u_dt   tolt   mut   linspace_kwargst   samplest   stept   nsamplest   qt   ht   t_0t   t_qt   X_shapet   Xt   tt   A_1_normt   m_start   st   ellt	   norm_info(   t   At   Xt   ht   mut   m_start   st   qt   tolt   dt   jt   rt   input_shapet   K_shapet   Kt   it   Zt   high_pt   effective_dt   kt   Ft   c1t   pt   coefft   inf_norm_K_p_1t   c2(   t   At   Xt   ht   mut   m_start   st   qt   tolt   dt   input_shapet   K_shapet   Kt   it   Zt   high_pt   kt   Ft   c1t   pt   coefft   inf_norm_K_p_1t   c2argmax_jh_i_pairsA_explicitcol_abs_sums_algorithm_2_2at least two iterations are required/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/_onenormest.pyt should be smaller than the order of Ascipy.sparse.linalg._onenormestinvariant (2.3) is violated
    Compute a lower bound of the 1-norm of a sparse matrix.

    .. versionadded:: 0.13.0

    Parameters
    ----------
    A : ndarray or other linear operator
        A linear operator that can be transposed and that can
        produce matrix products.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.
        Larger values take longer and use more memory
        but give more accurate output.
    itmax : int, optional
        Use at most this many iterations.
    compute_v : bool, optional
        Request a norm-maximizing linear operator input vector if True.
    compute_w : bool, optional
        Request a norm-maximizing linear operator output vector if True.

    Returns
    -------
    est : float
        An underestimate of the 1-norm of the sparse matrix.
    v : ndarray, optional
        The vector such that ||Av||_1 == est*||v||_1.
        It can be thought of as an input to the linear operator
        that gives an output with particularly large norm.
    w : ndarray, optional
        The vector Av which has relatively large 1-norm.
        It can be thought of as an output of the linear operator
        that is relatively large in norm compared to the input.

    Notes
    -----
    This is algorithm 2.4 of [1].

    In [2] it is described as follows.
    "This algorithm typically requires the evaluation of
    about 4t matrix-vector products and almost invariably
    produces a norm estimate (which is, in fact, a lower
    bound on the norm) correct to within a factor 3."

    References
    ----------
    .. [1] Nicholas J. Higham and Francoise Tisseur (2000),
           "A Block Algorithm for Matrix 1-Norm Estimation,
           with an Application to 1-Norm Pseudospectra."
           SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201.

    .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009),
           "A new scaling and squaring algorithm for the matrix exponential."
           SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989.

    
    Compute a lower bound of the 1-norm of a sparse matrix.

    Parameters
    ----------
    A : ndarray or other linear operator
        A linear operator that can produce matrix products.
    AT : ndarray or other linear operator
        The transpose of A.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.
    itmax : int, optional
        Use at most this many iterations.

    Returns
    -------
    est : float
        An underestimate of the 1-norm of the sparse matrix.
    v : ndarray, optional
        The vector such that ||Av||_1 == est*||v||_1.
        It can be thought of as an input to the linear operator
        that gives an output with particularly large norm.
    w : ndarray, optional
        The vector Av which has relatively large 1-norm.
        It can be thought of as an output of the linear operator
        that is relatively large in norm compared to the input.
    nmults : int, optional
        The number of matrix products that were computed.
    nresamples : int, optional
        The number of times a parallel column was observed,
        necessitating a re-randomization of the column.

    Notes
    -----
    This is algorithm 2.4.

    unexpected shape invariant (2.2) is violatedexpected the operator to act like a square matrix
    This is Algorithm 2.2.

    Parameters
    ----------
    A : ndarray or other linear operator
        A linear operator that can produce matrix products.
    AT : ndarray or other linear operator
        The transpose of A.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.

    Returns
    -------
    g : sequence
        A non-negative decreasing vector
        such that g[j] is a lower bound for the 1-norm
        of the column of A of jth largest 1-norm.
        The first entry of this vector is therefore a lower bound
        on the 1-norm of the linear operator A.
        This sequence has length t.
    ind : sequence
        The ith entry of ind is the index of the column A whose 1-norm
        is given by g[i].
        This sequence of indices has length t, and its entries are
        chosen from range(n), possibly with repetition,
        where n is the order of the operator A.

    Notes
    -----
    This algorithm is mainly for testing.
    It uses the 'ind' array in a way that is similar to
    its usage in algorithm 2.4.  This algorithm 2.2 may be easier to test,
    so it gives a chance of uncovering bugs related to indexing
    which could have propagated less noticeably to algorithm 2.4.

    internal error: at least one column is requiredexpected conformant vectors with entries in {-1,1}Sparse block 1-norm estimator.
(   t   At   ATt   tt   A_linear_operatort   AT_linear_operatort   nt   Xt   g_prevt   h_prevt   kt   indt   Yt   jt   gt   best_jt   St   Zt   rowt   ht	   h_i_pairs(   t   At   ATt   tt   itmaxt   A_linear_operatort   AT_linear_operatort   nt   nmultst
   nresamplest   Xt   it   ind_histt   est_oldt   St   kt   indt   Yt   jt   magst   estt   best_jt   ind_bestt   wt   S_oldt   Zt   rowt   ht	   h_i_pairst   unused_entriest   used_entriest   v/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/dsolve/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/dsolve/__init__.pyscipy.sparse.linalg.dsolve
Linear Solvers
==============

The default solver is SuperLU (included in the scipy distribution),
which can solve real or complex linear systems in both single and
double precisions.  It is automatically replaced by UMFPACK, if
available.  Note that UMFPACK works in double precision only, so
switch it off by::

    >>> use_solver(useUmfpack=False)

to solve in the single precision. See also use_solver documentation.

Example session::

    >>> from scipy.sparse import csc_matrix, spdiags
    >>> from numpy import array
    >>> from scipy.sparse.linalg import spsolve, use_solver
    >>>
    >>> print "Inverting a sparse linear system:"
    >>> print "The sparse matrix (constructed from diagonals):"
    >>> a = spdiags([[1, 2, 3, 4, 5], [6, 5, 8, 9, 10]], [0, 1], 5, 5)
    >>> b = array([1, 2, 3, 4, 5])
    >>> print "Solve: single precision complex:"
    >>> use_solver( useUmfpack = False )
    >>> a = a.astype('F')
    >>> x = spsolve(a, b)
    >>> print x
    >>> print "Error: ", a*x-b
    >>>
    >>> print "Solve: double precision complex:"
    >>> use_solver( useUmfpack = True )
    >>> a = a.astype('D')
    >>> x = spsolve(a, b)
    >>> print x
    >>> print "Error: ", a*x-b
    >>>
    >>> print "Solve: double precision:"
    >>> a = a.astype('d')
    >>> x = spsolve(a, b)
    >>> print x
    >>> print "Error: ", a*x-b
    >>>
    >>> print "Solve: single precision:"
    >>> use_solver( useUmfpack = False )
    >>> a = a.astype('f')
    >>> x = spsolve(a, b.astype('f'))
    >>> print x
    >>> print "Error: ", a*x-b

perm_cperm_r
    Upper triangular factor as a `scipy.sparse.csc_matrix`.

    .. versionadded:: 0.14.0
    
    Shape of the original matrix as a tuple of ints.
    
    Lower triangular factor with unit diagonal as a
    `scipy.sparse.csc_matrix`.

    .. versionadded:: 0.14.0
    
    Number of nonzero elements in the matrix.
    
    Permutation Pr represented as an array of indices.

    The row permutation matrix can be reconstructed via:

    >>> Pr = np.zeros((n, n))
    >>> Pr[perm_r, np.arange(n)] = 1
    
    Permutation Pc represented as an array of indices.

    The column permutation matrix can be reconstructed via:

    >>> Pc = np.zeros((n, n))
    >>> Pc[np.arange(n), perm_c] = 1
    
    solve(b[, trans])

    Solves linear system of equations with one or several right-hand sides.

    Parameters
    ----------
    b : ndarray, shape (n,) or (n, k)
        Right hand side(s) of equation
    trans : {'N', 'T', 'H'}, optional
        Type of system to solve::
    
            'N':   A   * x == b  (default)
            'T':   A^T * x == b
            'H':   A^H * x == b

        i.e., normal, transposed, and hermitian conjugate.

    Returns
    -------
    x : ndarray, shape b.shape
        Solution vector(s)
    scipy.sparse.linalg.dsolve._superlu
    LU factorization of a sparse matrix.

    Factorization is represented as::

        Pr * A * Pc = L * U

    To construct these `SuperLU` objects, call the `splu` and `spilu`
    functions.

    .. versionadded:: 0.14.0

    Attributes
    ----------
    shape
    nnz
    perm_c
    perm_r
    L
    U

    Methods
    -------
    solve

    Examples
    --------
    The LU decomposition can be used to solve matrix equations. Consider:

    >>> import numpy as np
    >>> from scipy.sparse import csc_matrix, linalg as sla
    >>> A = csc_matrix([[1,2,0,4],[1,0,0,1],[1,0,2,1],[2,2,1,0.]])

    This can be solved for a given right-hand side:

    >>> lu = sla.splu(A)
    >>> b = np.array([1, 2, 3, 4])
    >>> x = lu.solve(b)
    >>> A.dot(x)
    array([ 1.,  2.,  3.,  4.])

    The ``lu`` object also contains an explicit representation of the
    decomposition. The permutations are represented as mappings of
    indices:

    >>> lu.perm_r
    array([0, 2, 1, 3], dtype=int32)
    >>> lu.perm_c
    array([2, 0, 1, 3], dtype=int32)

    The L and U factors are sparse matrices in CSC format:

    >>> lu.L.A
    array([[ 1. ,  0. ,  0. ,  0. ],
           [ 0. ,  1. ,  0. ,  0. ],
           [ 0. ,  0. ,  1. ,  0. ],
           [ 1. ,  0.5,  0.5,  1. ]])
    >>> lu.U.A
    array([[ 2.,  0.,  1.,  4.],
           [ 0.,  2.,  1.,  1.],
           [ 0.,  0.,  1.,  1.],
           [ 0.,  0.,  0., -5.]])

    The permutation matrices can be constructed:

    >>> Pr = csc_matrix((4, 4))
    >>> Pr[lu.perm_r, np.arange(4)] = 1
    >>> Pc = csc_matrix((4, 4))
    >>> Pc[np.arange(4), lu.perm_c] = 1

    We can reassemble the original matrix:

    >>> (Pr.T * (lu.L * lu.U) * Pc.T).A
    array([[ 1.,  2.,  0.,  4.],
           [ 1.,  0.,  0.,  1.],
           [ 1.,  0.,  2.,  1.],
           [ 2.,  2.,  1.,  0.]])
    scipy.sparse.linalg.dsolve._add_newdocs/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/dsolve/_add_newdocs.pyxjgssvRelaxb_vecgstrfColPermPanelSizeUMFPACK_AILU_DropTolILU_DropRuleautoTransposeILU_FillFactorUmfpackContextDiagPivotThreshScikits.umfpack not installed.spsolve requires A be CSC or CSR matrix formatmatrix must be square (has shape %s)
    Return a fuction for solving a sparse linear system, with A pre-factorized.

    Parameters
    ----------
    A : (N, N) array_like
        Input.

    Returns
    -------
    solve : callable
        To solve the linear system of equations given in `A`, the `solve`
        callable should be passed an ndarray of shape (N,).

    Examples
    --------
    >>> A = np.array([[ 3. ,  2. , -1. ],
                      [ 2. , -2. ,  4. ],
                      [-1. ,  0.5, -1. ]])

    >>> solve = factorized( A ) # Makes LU decomposition.

    >>> rhs1 = np.array([1,-2,0])
    >>> x1 = solve( rhs1 ) # Uses the LU factors.
    array([ 1., -2., -2.])

    spsolve requires sparse b be in CSC or CSR matrix formatSolve the sparse linear system Ax=b, where b may be a vector or a matrix.

    Parameters
    ----------
    A : ndarray or sparse matrix
        The square matrix A will be converted into CSC or CSR form
    b : ndarray or sparse matrix
        The matrix or vector representing the right hand side of the equation.
        If a vector, b.size must
    permc_spec : str, optional
        How to permute the columns of the matrix for sparsity preservation.
        (default: 'COLAMD')

        - ``NATURAL``: natural ordering.
        - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.
        - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.
        - ``COLAMD``: approximate minimum degree column ordering
    use_umfpack : bool (optional)
        if True (default) then use umfpack for the solution.  This is
        only referenced if b is a vector.

    Returns
    -------
    x : ndarray or sparse matrix
        the solution of the sparse linear equation.
        If b is a vector, then x is a vector of size A.shape[1]
        If b is a matrix, then x is a matrix of size (A.shape[1], b.shape[1])

    Notes
    -----
    For solving the matrix expression AX = B, this solver assumes the resulting
    matrix X is sparse, as is often the case for very sparse inputs.  If the
    resulting X is dense, the construction of this sparse result will be
    relatively expensive.  In that case, consider converting A to a dense
    matrix and using scipy.linalg.solve or its variants.
    matrix - rhs dimension mismatch (%s - %s)convert matrix data to double, please, using .astype(), or set linsolve.useUmfpack = FalseMatrix is exactly singularcan only factor square matricessplu requires CSC matrix format
    Compute the LU decomposition of a sparse, square matrix.

    Parameters
    ----------
    A : sparse matrix
        Sparse matrix to factorize. Should be in CSR or CSC format.
    permc_spec : str, optional
        How to permute the columns of the matrix for sparsity preservation.
        (default: 'COLAMD')

        - ``NATURAL``: natural ordering.
        - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.
        - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.
        - ``COLAMD``: approximate minimum degree column ordering

    diag_pivot_thresh : float, optional
        Threshold used for a diagonal entry to be an acceptable pivot.
        See SuperLU user's guide for details [SLU]_
    drop_tol : float, optional
        (deprecated) No effect.
    relax : int, optional
        Expert option for customizing the degree of relaxing supernodes.
        See SuperLU user's guide for details [SLU]_
    panel_size : int, optional
        Expert option for customizing the panel size.
        See SuperLU user's guide for details [SLU]_
    options : dict, optional
        Dictionary containing additional expert options to SuperLU.
        See SuperLU user guide [SLU]_ (section 2.4 on the 'Options' argument)
        for more details. For example, you can specify
        ``options=dict(Equil=False, IterRefine='SINGLE'))``
        to turn equilibration off and perform a single iterative refinement.

    Returns
    -------
    invA : scipy.sparse.linalg.SuperLU
        Object, which has a ``solve`` method.

    See also
    --------
    spilu : incomplete LU decomposition

    Notes
    -----
    This function uses the SuperLU library.

    References
    ----------
    .. [SLU] SuperLU http://crd.lbl.gov/~xiaoye/SuperLU/

    
    Valid keyword arguments with defaults (other ignored)::

      useUmfpack = True
      assumeSortedIndices = False

    The default sparse solver is umfpack when available. This can be changed by
    passing useUmfpack = False, which then causes the always present SuperLU
    based solver to be used.

    Umfpack requires a CSR/CSC matrix to have sorted column/row indices. If
    sure that the matrix fulfills this, pass ``assumeSortedIndices=True``
    to gain some speed.

    scikits.umfpackscipy.sparse.linalg.dsolve.linsolve
    Compute an incomplete LU decomposition for a sparse, square matrix.

    The resulting object is an approximation to the inverse of `A`.

    Parameters
    ----------
    A : (N, N) array_like
        Sparse matrix to factorize
    drop_tol : float, optional
        Drop tolerance (0 <= tol <= 1) for an incomplete LU decomposition.
        (default: 1e-4)
    fill_factor : float, optional
        Specifies the fill ratio upper bound (>= 1.0) for ILU. (default: 10)
    drop_rule : str, optional
        Comma-separated string of drop rules to use.
        Available rules: ``basic``, ``prows``, ``column``, ``area``,
        ``secondary``, ``dynamic``, ``interp``. (Default: ``basic,area``)

        See SuperLU documentation for details.
    milu : str, optional
        Which version of modified ILU to use. (Choices: ``silu``,
        ``smilu_1``, ``smilu_2`` (default), ``smilu_3``.)

    Remaining other options
        Same as for `splu`

    Returns
    -------
    invA_approx : scipy.sparse.linalg.SuperLU
        Object, which has a ``solve`` method.

    See also
    --------
    splu : complete LU decomposition

    Notes
    -----
    To improve the better approximation to the inverse, you may need to
    increase `fill_factor` AND decrease `drop_tol`.

    This function uses the SuperLU library.

    /usr/lib/python2.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py(   t   At   bt
   permc_spect   use_umfpackt   b_is_sparset   b_is_vectort   Mt   Nt   b_vect   familyt   umft   xt   flagt   optionst   infot
   Afactsolvet   tempjt   jt   colt   xjt   w/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/__init__.py
Sparse Eigenvalue Solvers
-------------------------

The submodules of sparse.linalg.eigen:
    1. lobpcg: Locally Optimal Block Preconditioned Conjugate Gradient Method

scipy.sparse.linalg.eigen/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/arpack/__init__.py
Eigenvalue solver using iterative methods.

Find k eigenvectors and eigenvalues of a matrix A using the
Arnoldi/Lanczos iterative methods from ARPACK [1]_,[2]_.

These methods are most useful for large sparse matrices.

  - eigs(A,k)
  - eigsh(A,k)

References
----------
.. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/
.. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:
   Solution of Large Scale Eigenvalue Problems by Implicitly Restarted
   Arnoldi Methods. SIAM, Philadelphia, PA, 1998.

scipy.sparse.linalg.eigen.arpackOPaOPbM_luXH_XrvecipntrnaupdneupdsaupdworkdworklcayleyhowmnyiparamishftssigmarworkevysliceBxslicesselectA_matvecbucklingmult_funceigensolvermatvec_XH_X_arpack_solver_arpack_extractextract_infodictiterate_infodictmult_func_M_None_raise_no_convergence{i    s   Normal exit.i   s   Maximum number of iterations taken. All possible eigenvalues of OP has been found. IPARAM(5) returns the number of wanted converged Ritz values.i   sO   No longer an informational error. Deprecated starting with release 2 of ARPACK.i   s   No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. is   N must be positive.is   Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.is&   NEV and WHICH = 'BE' are incompatible.is"   IPARAM(1) must be equal to 0 or 1.is.   IPARAM(7) = 1 and BMAT = 'G' are incompatible.is   IPARAM(7) must be 1,2,3,4.is   Starting vector is zero.is0   Error return from LAPACK eigenvalue calculation;is5   Length of private work array WORKL is not sufficient.is   BMAT must be one of 'I' or 'G'.is8    WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'isR   The maximum number of Arnoldi update iterations allowed must be greater than zero.is)   NCV-NEV >= 2 and less than or equal to N.is   NEV must be positive.0{i    s   Normal exit.i   sR   Maximum number of iterations taken. All possible eigenvalues of OP has been found.i   sO   No longer an informational error. Deprecated starting with release 2 of ARPACK.i   s   No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration. One possibility is to increase the size of NCV relative to NEV. is   N must be positive.is   Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.is'   NEV and WHICH = 'BE' are incompatible. is"   IPARAM(1) must be equal to 0 or 1.is.   IPARAM(7) = 1 and BMAT = 'G' are incompatible.is   IPARAM(7) must be 1,2,3,4,5.is   Starting vector is zero.is`   Error return from trid. eigenvalue calculation; Informational error from LAPACK routine dsteqr .is5   Length of private work array WORKL is not sufficient.is   BMAT must be one of 'I' or 'G'.is4   WHICH must be one of 'LM', 'SM', 'LA', 'SA' or 'BE'.isR   The maximum number of Arnoldi update iterations allowed must be greater than zero.is9   NCV must be greater than NEV and less than or equal to N.is   NEV must be positive.0{i    s   Normal exit.i   sk  The Schur form computed by LAPACK routine csheqr could not be reordered by LAPACK routine ztrsen. Re-enter subroutine zneupd with IPARAM(5)=NCV and increase the size of the array D to have dimension at least dimension NCV and allocate at least NCV columns for Z. NOTE: Not necessary if Z and V share the same space. Please notify the authors if this error occurs.is   N must be positive.is   ZNEUPD got a different count of the number of converged Ritz values than ZNAUPD got.  This indicates the user probably made an error in passing data from ZNAUPD to ZNEUPD or that the data was modified before entering ZNEUPDis;   ZNAUPD did not find any eigenvalues to sufficient accuracy.is1   HOWMNY must be one of 'A' or 'P' if RVEC = .true.is    HOWMNY = 'S' not yet implementedis.   IPARAM(7) = 1 and BMAT = 'G' are incompatible.is   IPARAM(7) must be 1,2,3is^   Error return from calculation of eigenvectors. Informational error from LAPACK routine ztrevc.isL   Error return from LAPACK eigenvalue calculation. This should never happened.is5   Length of private work WORKL array is not sufficient.is   BMAT must be one of 'I' or 'G'.is7   WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'is)   NCV-NEV >= 1 and less than or equal to N.is   NEV must be positive.0{i    s   Normal exit.i   ss  The Schur form computed by LAPACK routine dlahqr could not be reordered by LAPACK routine dtrsen. Re-enter subroutine dneupd  with IPARAM(5)NCV and increase the size of the arrays DR and DI to have dimension at least dimension NCV and allocate at least NCV columns for Z. NOTE: Not necessary if Z and V share the same space. Please notify the authors if this erroroccurs.is   N must be positive.is   DNEUPD got a different count of the number of converged Ritz values than DNAUPD got.  This indicates the user probably made an error in passing data from DNAUPD to DNEUPD or that the data was modified before entering DNEUPDis<   DNAUPD  did not find any eigenvalues to sufficient accuracy.is1   HOWMNY must be one of 'A' or 'P' if RVEC = .true.is    HOWMNY = 'S' not yet implementedis.   IPARAM(7) = 1 and BMAT = 'G' are incompatible.is   IPARAM(7) must be 1,2,3,4.is^   Error return from calculation of eigenvectors. Informational error from LAPACK routine dtrevc.isd   Error return from calculation of a real Schur form. Informational error from LAPACK routine dlahqr .is5   Length of private work WORKL array is not sufficient.is   BMAT must be one of 'I' or 'G'.is7   WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'is)   NCV-NEV >= 2 and less than or equal to N.is   NEV must be positive.0{i    s   Normal exit.is   N must be positive.is   DSEUPD  got a different count of the number of converged Ritz values than DSAUPD  got.  This indicates the user probably made an error in passing data from DSAUPD  to DSEUPD  or that the data was modified before entering  DSEUPD.is    HOWMNY = 'S' not yet implementedis1   HOWMNY must be one of 'A' or 'S' if RVEC = .true.is<   DSAUPD  did not find any eigenvalues to sufficient accuracy.is&   NEV and WHICH = 'BE' are incompatible.is.   IPARAM(7) = 1 and BMAT = 'G' are incompatible.is   IPARAM(7) must be 1,2,3,4,5.is   Starting vector is zero.is]   Error return from trid. eigenvalue calculation; Information error from LAPACK routine dsteqr.is5   Length of private work WORKL array is not sufficient.is   BMAT must be one of 'I' or 'G'.is4   WHICH must be one of 'LM', 'SM', 'LA', 'SA' or 'BE'.is9   NCV must be greater than NEV and less than or equal to N.is   NEV must be positive.0Minv_matvec must be specified for mode=2matvec must be specified for mode in (3,4)ARPACK requested user shifts.  Assure ISHIFT==0Minv_matvec must be specified for mode in (3,4)maxiter must be positive, maxiter=%d
Find a few eigenvectors and eigenvalues of a matrix.


Uses ARPACK: http://www.caam.rice.edu/software/ARPACK/

M_matvec cannot be specified for mode=1which must be one of %sk must be positive, k=%dNo convergence (%d iterations, %d/%d eigenvectors converged)Minv should not be specified with M = None.which='BE' cannot be used with complex matrix Ancv must be k<ncv<=n, ncv=%sOPpart cannot be 'i' if sigma is realOPpart must be one of ('r','i')%s [%s]IPARAM(7) must be 1,2,3.Minv_matvec must be specified for mode=5SNEUPD got a different count of the number of converged Ritz values than SNAUPD got.  This indicates the user probably made an error in passing data from SNAUPD to SNEUPD or that the data was modified before entering SNEUPDARPACK error %d: %smatvec must be specified for mode=1Input matrix is not real-valued.
    SpLuInv:
       helper class to repeatedly solve M*x=b
       using a sparse LU-decopposition of M
    wrong M dimensions %s, should be %sMinv_matvec cannot be specified for mode=1
    ARPACK iteration did not converge

    Attributes
    ----------
    eigenvalues : ndarray
        Partial result. Converged eigenvalues.
    eigenvectors : ndarray
        Partial result. Converged eigenvectors.

    CNEUPD got a different count of the number of converged Ritz values than CNAUPD got.  This indicates the user probably made an error in passing data from CNAUPD to CNEUPD or that the data was modified before entering CNEUPD
    IterOpInv:
       helper class to repeatedly solve [A-sigma*M]*x = b
       using an iterative method
    mode=4 invalid for complex Ak must be less than ndim(A), k=%dexpected square matrix (shape=%s)ncv must be k+1<ncv<=n, ncv=%sMinv_matvec must be specified for mode=4M does not have the same type precision as A. This may adversely affect ARPACK convergencek must be between 1 and ndim(A)-1OPinv should not be specified with sigma = None.mode=%s cannot be used with complex matrix AError in inverting [A-sigma*M]: function %s did not converge (info = %i).Error in inverting M: function %s did not converge (info = %i).matvec must not be specified for mode=3The Schur form computed by LAPACK routine slahqr could not be reordered by LAPACK routine strsen . Re-enter subroutine dneupd  with IPARAM(5)=NCV and increase the size of the arrays DR and DI to have dimension at least dimension NCV and allocate at least NCV columns for Z. NOTE: Not necessary if Z and V share the same space. Please notify the authors if this error occurs.
    Find k eigenvalues and eigenvectors of the square matrix A.

    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem
    for w[i] eigenvalues with corresponding eigenvectors x[i].

    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the
    generalized eigenvalue problem for w[i] eigenvalues
    with corresponding eigenvectors x[i]

    Parameters
    ----------
    A : ndarray, sparse matrix or LinearOperator
        An array, sparse matrix, or LinearOperator representing
        the operation ``A * x``, where A is a real or complex square matrix.
    k : int, optional
        The number of eigenvalues and eigenvectors desired.
        `k` must be smaller than N. It is not possible to compute all
        eigenvectors of a matrix.
    M : ndarray, sparse matrix or LinearOperator, optional
        An array, sparse matrix, or LinearOperator representing
        the operation M*x for the generalized eigenvalue problem
          ``A * x = w * M * x``.
        M must represent a real, symmetric matrix if A is real, and must
        represent a complex, hermitian matrix if A is complex. For best
        results, the data type of M should be the same as that of A.
        Additionally:

            If `sigma` is None, M is positive definite

            If sigma is specified, M is positive semi-definite

        If sigma is None, eigs requires an operator to compute the solution
        of the linear equation ``M * x = b``.  This is done internally via a
        (sparse) LU decomposition for an explicit matrix M, or via an
        iterative solver for a general linear operator.  Alternatively,
        the user can supply the matrix or operator Minv, which gives
        ``x = Minv * b = M^-1 * b``.
    sigma : real or complex, optional
        Find eigenvalues near sigma using shift-invert mode.  This requires
        an operator to compute the solution of the linear system
        ``[A - sigma * M] * x = b``, where M is the identity matrix if
        unspecified. This is computed internally via a (sparse) LU
        decomposition for explicit matrices A & M, or via an iterative
        solver if either A or M is a general linear operator.
        Alternatively, the user can supply the matrix or operator OPinv,
        which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.
        For a real matrix A, shift-invert can either be done in imaginary
        mode or real mode, specified by the parameter OPpart ('r' or 'i').
        Note that when sigma is specified, the keyword 'which' (below)
        refers to the shifted eigenvalues ``w'[i]`` where:

            If A is real and OPpart == 'r' (default),
              ``w'[i] = 1/2 * [1/(w[i]-sigma) + 1/(w[i]-conj(sigma))]``.

            If A is real and OPpart == 'i',
              ``w'[i] = 1/2i * [1/(w[i]-sigma) - 1/(w[i]-conj(sigma))]``.

            If A is complex, ``w'[i] = 1/(w[i]-sigma)``.

    v0 : ndarray, optional
        Starting vector for iteration.
    ncv : int, optional
        The number of Lanczos vectors generated
        `ncv` must be greater than `k`; it is recommended that ``ncv > 2*k``.
    which : str, ['LM' | 'SM' | 'LR' | 'SR' | 'LI' | 'SI'], optional
        Which `k` eigenvectors and eigenvalues to find:

            'LM' : largest magnitude

            'SM' : smallest magnitude

            'LR' : largest real part

            'SR' : smallest real part

            'LI' : largest imaginary part

            'SI' : smallest imaginary part

        When sigma != None, 'which' refers to the shifted eigenvalues w'[i]
        (see discussion in 'sigma', above).  ARPACK is generally better
        at finding large values than small values.  If small eigenvalues are
        desired, consider using shift-invert mode for better performance.
    maxiter : int, optional
        Maximum number of Arnoldi update iterations allowed
    tol : float, optional
        Relative accuracy for eigenvalues (stopping criterion)
        The default value of 0 implies machine precision.
    return_eigenvectors : bool, optional
        Return eigenvectors (True) in addition to eigenvalues
    Minv : ndarray, sparse matrix or LinearOperator, optional
        See notes in M, above.
    OPinv : ndarray, sparse matrix or LinearOperator, optional
        See notes in sigma, above.
    OPpart : {'r' or 'i'}, optional
        See notes in sigma, above

    Returns
    -------
    w : ndarray
        Array of k eigenvalues.
    v : ndarray
        An array of `k` eigenvectors.
        ``v[:, i]`` is the eigenvector corresponding to the eigenvalue w[i].

    Raises
    ------
    ArpackNoConvergence
        When the requested convergence is not obtained.
        The currently converged eigenvalues and eigenvectors can be found
        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception
        object.

    See Also
    --------
    eigsh : eigenvalues and eigenvectors for symmetric matrix A
    svds : singular value decomposition for a matrix A

    Notes
    -----
    This function is a wrapper to the ARPACK [1]_ SNEUPD, DNEUPD, CNEUPD,
    ZNEUPD, functions which use the Implicitly Restarted Arnoldi Method to
    find the eigenvalues and eigenvectors [2]_.

    References
    ----------
    .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/
    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:
       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted
       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.

    Examples
    --------
    Find 6 eigenvectors of the identity matrix:

    >>> id = np.eye(13)
    >>> vals, vecs = sp.sparse.linalg.eigs(id, k=6)
    >>> vals
    array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])
    >>> vecs.shape
    (13, 6)

    OPpart should not be specified with sigma = None or complex AMinv should not be specified when sigma isunrecognized mode '%s'mode=%i not implemented
    LuInv:
       helper class to repeatedly solve M*x=b
       using an LU-decomposition of M
    M_matvec must not be specified for mode=4/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py
    IterInv:
       helper class to repeatedly solve M*x=b
       using an iterative method.
    matrix type must be 'f', 'd', 'F', or 'D'M_matvec must be specified for mode=2OPpart should not be specified with sigma=None or complex A
    ARPACK error
    Parameter which must be one of %sSSEUPD  got a different count of the number of converged Ritz values than SSAUPD  got.  This indicates the user probably made an error in passing data from SSAUPD  to SSEUPD  or that the data was modified before entering  SSEUPD.Compute the largest k singular values/vectors for a sparse matrix.

    Parameters
    ----------
    A : sparse matrix
        Array to compute the SVD on, of shape (M, N)
    k : int, optional
        Number of singular values and vectors to compute.
    ncv : integer, optional
        The number of Lanczos vectors generated
        ncv must be greater than k+1 and smaller than n;
        it is recommended that ncv > 2*k
    tol : float, optional
        Tolerance for singular values. Zero (default) means machine precision.
    which : str, ['LM' | 'SM'], optional
        Which `k` singular values to find:

            - 'LM' : largest singular values
            - 'SM' : smallest singular values

        .. versionadded:: 0.12.0
    v0 : ndarray, optional
        Starting vector for iteration, of length min(A.shape). Should be an
        (approximate) right singular vector if N > M and a right singular vector
        otherwise.

        .. versionadded:: 0.12.0
    maxiter: integer, optional
        Maximum number of iterations.

        .. versionadded:: 0.12.0
    return_singular_vectors : bool, optional
        Return singular vectors (True) in addition to singular values

        .. versionadded:: 0.12.0
    Returns
    -------
    u : ndarray, shape=(M, k)
        Unitary matrix having left singular vectors as columns.
    s : ndarray, shape=(k,)
        The singular values.
    vt : ndarray, shape=(k, N)
        Unitary matrix having right singular vectors as rows.

    Notes
    -----
    This is a naive implementation using ARPACK as an eigensolver
    on A.H * A or A * A.H, depending on which one is more efficient.
    SSAUPD  did not find any eigenvalues to sufficient accuracy.
    Find k eigenvalues and eigenvectors of the real symmetric square matrix
    or complex hermitian matrix A.

    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for
    w[i] eigenvalues with corresponding eigenvectors x[i].

    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the
    generalized eigenvalue problem for w[i] eigenvalues
    with corresponding eigenvectors x[i]

    Parameters
    ----------
    A : An N x N matrix, array, sparse matrix, or LinearOperator representing
        the operation A * x, where A is a real symmetric matrix
        For buckling mode (see below) A must additionally be positive-definite
    k : integer
        The number of eigenvalues and eigenvectors desired.
        `k` must be smaller than N. It is not possible to compute all
        eigenvectors of a matrix.

    Returns
    -------
    w : array
        Array of k eigenvalues
    v : array
        An array representing the `k` eigenvectors.  The column ``v[:, i]`` is
        the eigenvector corresponding to the eigenvalue ``w[i]``.

    Other Parameters
    ----------------
    M : An N x N matrix, array, sparse matrix, or linear operator representing
        the operation M * x for the generalized eigenvalue problem
          ``A * x = w * M * x``.
        M must represent a real, symmetric matrix if A is real, and must
        represent a complex, hermitian matrix if A is complex. For best
        results, the data type of M should be the same as that of A.
        Additionally:

            If sigma is None, M is symmetric positive definite

            If sigma is specified, M is symmetric positive semi-definite

            In buckling mode, M is symmetric indefinite.

        If sigma is None, eigsh requires an operator to compute the solution
        of the linear equation ``M * x = b``. This is done internally via a
        (sparse) LU decomposition for an explicit matrix M, or via an
        iterative solver for a general linear operator.  Alternatively,
        the user can supply the matrix or operator Minv, which gives
        ``x = Minv * b = M^-1 * b``.
    sigma : real
        Find eigenvalues near sigma using shift-invert mode.  This requires
        an operator to compute the solution of the linear system
        `[A - sigma * M] x = b`, where M is the identity matrix if
        unspecified.  This is computed internally via a (sparse) LU
        decomposition for explicit matrices A & M, or via an iterative
        solver if either A or M is a general linear operator.
        Alternatively, the user can supply the matrix or operator OPinv,
        which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.
        Note that when sigma is specified, the keyword 'which' refers to
        the shifted eigenvalues ``w'[i]`` where:

            if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.

            if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.

            if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.

        (see further discussion in 'mode' below)
    v0 : ndarray
        Starting vector for iteration.
    ncv : int
        The number of Lanczos vectors generated ncv must be greater than k and
        smaller than n; it is recommended that ``ncv > 2*k``.
    which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']
        If A is a complex hermitian matrix, 'BE' is invalid.
        Which `k` eigenvectors and eigenvalues to find:

            'LM' : Largest (in magnitude) eigenvalues

            'SM' : Smallest (in magnitude) eigenvalues

            'LA' : Largest (algebraic) eigenvalues

            'SA' : Smallest (algebraic) eigenvalues

            'BE' : Half (k/2) from each end of the spectrum

        When k is odd, return one more (k/2+1) from the high end.
        When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``
        (see discussion in 'sigma', above).  ARPACK is generally better
        at finding large values than small values.  If small eigenvalues are
        desired, consider using shift-invert mode for better performance.
    maxiter : int
        Maximum number of Arnoldi update iterations allowed
    tol : float
        Relative accuracy for eigenvalues (stopping criterion).
        The default value of 0 implies machine precision.
    Minv : N x N matrix, array, sparse matrix, or LinearOperator
        See notes in M, above
    OPinv : N x N matrix, array, sparse matrix, or LinearOperator
        See notes in sigma, above.
    return_eigenvectors : bool
        Return eigenvectors (True) in addition to eigenvalues
    mode : string ['normal' | 'buckling' | 'cayley']
        Specify strategy to use for shift-invert mode.  This argument applies
        only for real-valued A and sigma != None.  For shift-invert mode,
        ARPACK internally solves the eigenvalue problem
        ``OP * x'[i] = w'[i] * B * x'[i]``
        and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]
        into the desired eigenvectors and eigenvalues of the problem
        ``A * x[i] = w[i] * M * x[i]``.
        The modes are as follows:

            'normal' :
                OP = [A - sigma * M]^-1 * M,
                B = M,
                w'[i] = 1 / (w[i] - sigma)

            'buckling' :
                OP = [A - sigma * M]^-1 * A,
                B = A,
                w'[i] = w[i] / (w[i] - sigma)

            'cayley' :
                OP = [A - sigma * M]^-1 * [A + sigma * M],
                B = M,
                w'[i] = (w[i] + sigma) / (w[i] - sigma)

        The choice of mode will affect which eigenvalues are selected by
        the keyword 'which', and can also impact the stability of
        convergence (see [2] for a discussion)

    Raises
    ------
    ArpackNoConvergence
        When the requested convergence is not obtained.

        The currently converged eigenvalues and eigenvectors can be found
        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception
        object.

    See Also
    --------
    eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A
    svds : singular value decomposition for a matrix A

    Notes
    -----
    This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD
    functions which use the Implicitly Restarted Lanczos Method to
    find the eigenvalues and eigenvectors [2]_.

    References
    ----------
    .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/
    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:
       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted
       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.

    Examples
    --------
    >>> id = np.eye(13)
    >>> vals, vecs = sp.sparse.linalg.eigsh(id, k=6)
    >>> vals
    array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])
    >>> vecs.shape
    (13, 6)

    k must be less than ndim(A)-1, k=%dscipy.sparse.linalg.eigen.arpack.arpackk=%d must be between 1 and ndim(A)-1=%dCNAUPD did not find any eigenvalues to sufficient accuracy.Minv_matvec must be specified for mode=3SNAUPD did not find any eigenvalues to sufficient accuracy.(   t   At   kt   Mt   sigmat   whicht   v0t   ncvt   maxitert   tolt   return_eigenvectorst   Minvt   OPinvt   modet   rett   warningst   nt   matvect   M_matvect   Minv_matvect   params(   t   selft   return_eigenvectorst   kt   nt   ierrt   howmnyt   sselectt   sigmart   sigmait   workevt   drt   dit   zrt	   nreturnedt   dt   zt   it   rdt   indt   k_ok(   t   At   kt   Mt   sigmat   whicht   v0t   ncvt   maxitert   tolt   return_eigenvectorst   Minvt   OPinvt   OPpartt   warningst   nt   matvect   modet   M_matvect   Minv_matvect   params(   t   At   kt   ncvt   tolt   whicht   v0t   maxitert   return_singular_vectorst   nt   mt   hermt   eigensolvert   Xt   XHt   matvec_XH_Xt   XH_Xt   eigvalst   eigvect   st   vt   ut   vhscipy.sparse.linalg.eigen.lobpcg/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/lobpcg/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/lobpcg/__init__.py
Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)

LOBPCG is a preconditioned eigensolver for large symmetric positive definite
(SPD) generalized eigenproblems.

Call the function lobpcg - see help for lobpcg.lobpcg. See also lobpcg.as2d,
which can be used in the preconditioner (example below)

Acknowledgements
----------------

lobpcg.py code was written by Robert Cimrman. Many thanks belong to Andrew
Knyazev, the author of the algorithm, for lots of advice and support.


Examples
--------

>>> # Solve A x = lambda B x with constraints and preconditioning.
>>> n = 100
>>> vals = [nm.arange( n, dtype = nm.float64 ) + 1]
>>> # Matrix A.
>>> operatorA = spdiags( vals, 0, n, n )
>>> # Matrix B
>>> operatorB = nm.eye( n, n )
>>> # Constraints.
>>> Y = nm.eye( n, 3 )
>>> # Initial guess for eigenvectors, should have linearly independent
>>> # columns. Column dimension = number of requested eigenvalues.
>>> X = sc.rand( n, 3 )
>>> # Preconditioner - inverse of A.
>>> ivals = [1./vals[0]]
>>> def precond( x ):
    invA = spdiags( ivals, 0, n, n )
    y = invA  * x
    if sp.issparse( y ):
        y = y.toarray()

    return as2d( y )

>>> # Alternative way of providing the same preconditioner.
>>> #precond = spdiags( ivals, 0, n, n )

>>> tt = time.clock()
>>> eigs, vecs = lobpcg(X, operatorA, operatorB, blockVectorY=Y,
>>>                     operatorT=precond,
>>>                     residualTolerance=1e-4, maxIterations=40,
>>>                     largest=False, verbosityLevel=1)
>>> print 'solution time:', time.clock() - tt
>>> print eigs


Notes
-----

In the following ``n`` denotes the matrix size and ``m`` the number
of required eigenvalues (smallest or largest).

The LOBPCG code internally solves eigenproblems of the size 3``m`` on every
iteration by calling the "standard" dense eigensolver, so if ``m`` is not
small enough compared to ``n``, it does not make sense to call the LOBPCG
code, but rather one should use the "standard" eigensolver, e.g. scipy or symeig
function in this case. If one calls the LOBPCG algorithm for 5``m``>``n``,
it will most likely break internally, so the code tries to call the standard
function instead.

It is not that n should be large for the LOBPCG to work, but rather the
ratio ``n``/``m`` should be large. It you call the LOBPCG code with ``m``=1
and ``n``=10, it should work, though ``n`` is small. The method is intended
for extremely large ``n``/``m``, see e.g., reference [28] in
http://arxiv.org/abs/0705.2626

The convergence speed depends basically on two factors:

1.  How well relatively separated the seeking eigenvalues are from the rest of
    the eigenvalues. One can try to vary ``m`` to make this better.

2.  How well conditioned the problem is. This can be changed by using proper
    preconditioning. For example, a rod vibration test problem (under tests
    directory) is ill-conditioned for large ``n``, so convergence will be
    slow, unless efficient preconditioning is used. For this specific problem,
    a good simple preconditioner function would be a linear solve for A, which
    is easy to code since A is tridiagonal.


References
----------
A. V. Knyazev, Toward the Optimal Preconditioned Eigensolver: Locally Optimal
Block Preconditioned Conjugate Gradient Method. SIAM Journal on Scientific
Computing 23 (2001), no. 2,
pp. 517-541. http://dx.doi.org/10.1137/S1064827500366124

A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov, Block Locally
Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in hypre and PETSc
(2007). http://arxiv.org/abs/0705.2626

A. V. Knyazev's C and MATLAB implementations:
http://www-math.cudenver.edu/~aknyazev/software/BLOPEX/

wawwbpxapxawxbpxbwlohiA_denseB_densegramVBVgramXAXgramXBXgramYBVfailureFlagblockVectorRInternal.iteration %deigenvalue:Internal. Takes a dense numpy array or a sparse matrix or
    a function and makes an operator performing matrix * blockvector
    products.

    Examples
    --------
    >>> A = makeOperator( arrayA, (n, n) )
    >>> vectorB = A( vectorX )

    scipy.sparse.linalg.eigen.lobpcg.lobpcgX column dimension exceeds the row dimensionlambda:residual norms:Solve symmetric partial eigenproblems with optional preconditioning

    This function implements the Locally Optimal Block Preconditioned
    Conjugate Gradient Method (LOBPCG).

    Parameters
    ----------
    A : {sparse matrix, dense matrix, LinearOperator}
        The symmetric linear operator of the problem, usually a
        sparse matrix.  Often called the "stiffness matrix".
    X : array_like
        Initial approximation to the k eigenvectors. If A has
        shape=(n,n) then X should have shape shape=(n,k).
    B : {dense matrix, sparse matrix, LinearOperator}, optional
        the right hand side operator in a generalized eigenproblem.
        by default, B = Identity
        often called the "mass matrix"
    M : {dense matrix, sparse matrix, LinearOperator}, optional
        preconditioner to A; by default M = Identity
        M should approximate the inverse of A
    Y : array_like, optional
        n-by-sizeY matrix of constraints, sizeY < n
        The iterations will be performed in the B-orthogonal complement
        of the column-space of Y. Y must be full rank.

    Returns
    -------
    w : array
        Array of k eigenvalues
    v : array
        An array of k eigenvectors.  V has the same shape as X.

    Other Parameters
    ----------------
    tol : scalar, optional
        Solver tolerance (stopping criterion)
        by default: tol=n*sqrt(eps)
    maxiter : integer, optional
        maximum number of iterations
        by default: maxiter=min(n,20)
    largest : boolean, optional
        when True, solve for the largest eigenvalues, otherwise the smallest
    verbosityLevel : integer, optional
        controls solver output.  default: verbosityLevel = 0.
    retLambdaHistory : boolean, optional
        whether to return eigenvalue history
    retResidualNormsHistory : boolean, optional
        whether to return history of residual norms


    Notes
    -----
    If both retLambdaHistory and retResidualNormsHistory are True, the
    return tuple has the following format
    (lambda, V, lambda history, residual norms history)

    Internal. Changes blockVectorV in place.matrix size %d
operator has invalid shapeexpected rank-2 array for argument X%d constraints

/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/eigen/lobpcg/lobpcg.pyblock size %d


    If the input array is 2D return it, if it is 1D, append a dimension,
    making it a column vector.
    %d constraint

current block size:cannot handle linearly dependent constraintsfinal eigenvalue:
Pure SciPy implementation of Locally Optimal Block Preconditioned Conjugate
Gradient Method (LOBPCG), see
http://www-math.cudenver.edu/~aknyazev/software/BLOPEX/

License: BSD

Authors: Robert Cimrman, Andrew Knyazev

Examples in tests directory contributed by Nils Wagner.
 eigenvalue problem withfinal residual norms:No constraints

symeig does not support constraints(E   t   At   Xt   Bt   Mt   Yt   tolt   maxitert   largestt   verbosityLevelt   retLambdaHistoryt   retResidualNormsHistoryt   failureFlagt   slat   blockVectorXt   blockVectorYt   residualTolerancet   maxIterationst   sizeYt   nt   sizeXt   lohit   A_denset   B_denset   _lambdat   eigBlockVectort   auxt   blockVectorBYt   gramYBYt   blockVectorBXt   blockVectorAXt   gramXAXt   gramXBXt   iit
   activeMaskt   lambdaHistoryt   residualNormsHistoryt   previousBlockSizet   identt   ident0t   blockVectorPt   blockVectorAPt   blockVectorBPt   iterationNumbert   blockVectorRt   residualNormst   currentBlockSizet   activeBlockVectorRt   activeBlockVectorPt   activeBlockVectorAPt   activeBlockVectorBPt   activeBlockVectorBRt   activeBlockVectorARt   invRt   xawt   wawt   xbwt   xapt   wapt   papt   xbpt   wbpt   gramAt   gramBt   eigBlockVectorXt   eigBlockVectorRt   eigBlockVectorPt   ppt   appt   bppA_conjscalar expected as alphaunspecified dtypeDefault matrix-matrix multiplication handler.  Falls back on
        the user-defined matvec() routine, which is always provided.
        Common interface for performing matrix vector products

    Many iterative methods (e.g. cg, gmres) do not need to know the
    individual entries of a matrix to solve a linear system A*x=b.
    Such solvers only require the computation of matrix vector
    products, A*v where v is a dense vector.  This class serves as
    an abstract interface between iterative solvers and matrix-like
    objects.

    Parameters
    ----------
    shape : tuple
        Matrix dimensions (M,N)
    matvec : callable f(v)
        Returns returns A * v.

    Other Parameters
    ----------------
    rmatvec : callable f(v)
        Returns A^H * v, where A^H is the conjugate transpose of A.
    matmat : callable f(V)
        Returns A * V, where V is a dense matrix with dimensions (N,K).
    dtype : dtype
        Data type of the matrix.

    Attributes
    ----------
    args : tuple
        For linear operators describing products etc. of other linear
        operators, the operands of the binary operation.

    See Also
    --------
    aslinearoperator : Construct LinearOperators

    Notes
    -----
    The user-defined matvec() function must properly handle the case
    where v has shape (N,) as well as the (N,1) case.  The shape of
    the return type is handled internally by LinearOperator.

    LinearOperator instances can also be multiplied, added with each
    other and exponentiated, to produce a new linear operator.

    Examples
    --------
    >>> from scipy.sparse.linalg import LinearOperator
    >>> from scipy import *
    >>> def mv(v):
    ...     return array([ 2*v[0], 3*v[1]])
    ...
    >>> A = LinearOperator( (2,2), matvec=mv )
    >>> A
    <2x2 LinearOperator with unspecified dtype>
    >>> A.matvec( ones(2) )
    array([ 2.,  3.])
    >>> A * ones(2)
    array([ 2.,  3.])

    Matrix-vector multiplication

        Performs the operation y=A*x where A is an MxN linear
        operator and x is a column vector or rank-1 array.

        Parameters
        ----------
        x : {matrix, ndarray}
            An array with shape (N,) or (N,1).

        Returns
        -------
        y : {matrix, ndarray}
            A matrix or ndarray with shape (M,) or (M,1) depending
            on the type and shape of the x argument.

        Notes
        -----
        This matvec wraps the user-specified matvec routine to ensure that
        y has the correct shape and type.

        array must have rank <= 2square LinearOperator expected as Aexpected rank-2 ndarray or matrixrmatvec is not definedMatrix-matrix multiplication

        Performs the operation y=A*X where A is an MxN linear
        operator and X dense N*K matrix or ndarray.

        Parameters
        ----------
        X : {matrix, ndarray}
            An array with shape (N,K).

        Returns
        -------
        Y : {matrix, ndarray}
            A matrix or ndarray with shape (M,K) depending on
            the type of the X argument.

        Notes
        -----
        This matmat wraps any user-specified matmat routine to ensure that
        y has the correct type.

        Return A as a LinearOperator.

    'A' may be any of the following types:
     - ndarray
     - matrix
     - sparse matrix (e.g. csr_matrix, lil_matrix, etc.)
     - LinearOperator
     - An object with .shape and .matvec attributes

    See the LinearOperator documentation for additional information.

    Examples
    --------
    >>> from scipy import matrix
    >>> M = matrix( [[1,2,3],[4,5,6]], dtype='int32' )
    >>> aslinearoperator( M )
    <2x3 LinearOperator with dtype=int32>

    both operands have to be a LinearOperator<%dx%d %s with %s>expected rank-1 or rank-2 array or matrix/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/interface.pyinvalid shape returned by user-defined matvec()integer expected as p/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/__init__.pyIterative Solvers for Sparse Linear Systemsscipy.sparse.linalg.isolvework2revcomcgrevcom__enteredcgsrevcomqmrrevcomstoptest2bicgrevcomgmresrevcomleft_psolveleft_rpsolveright_psolveright_rpsolvebicgstabrevcom/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/iterative.pyUse Quasi-Minimal Residual iteration to solve A x = b

    Parameters
    ----------
    A : {sparse matrix, dense matrix, LinearOperator}
        The real-valued N-by-N matrix of the linear system.
        It is required that the linear operator can produce
        ``Ax`` and ``A^T x``.
    b : {array, matrix}
        Right hand side of the linear system. Has shape (N,) or (N,1).

    Returns
    -------
    x : {array, matrix}
        The converged solution.
    info : integer
        Provides convergence information:
            0  : successful exit
            >0 : convergence to tolerance not achieved, number of iterations
            <0 : illegal input or breakdown

    Other Parameters
    ----------------
    x0  : {array, matrix}
        Starting guess for the solution.
    tol : float
        Tolerance to achieve. The algorithm terminates when either the relative
        or the absolute residual is below `tol`.
    maxiter : integer
        Maximum number of iterations.  Iteration will stop after maxiter
        steps even if the specified tolerance has not been achieved.
    M1 : {sparse matrix, dense matrix, LinearOperator}
        Left preconditioner for A.
    M2 : {sparse matrix, dense matrix, LinearOperator}
        Right preconditioner for A. Used together with the left
        preconditioner M1.  The matrix M1*A*M2 should have better
        conditioned than A alone.
    callback : function
        User-supplied function to call after each iteration.  It is called
        as callback(xk), where xk is the current solution vector.
    xtype : {'f','d','F','D'}
        This parameter is DEPRECATED -- avoid using it.

        The type of the result.  If None, then it will be determined from
        A.dtype.char and b.  If A does not have a typecode method then it
        will compute A.matvec(x0) to get a typecode.   To save the extra
        computation when A does not have a typecode attribute use xtype=0
        for the same type as b or use xtype='f','d','F',or 'D'.
        This parameter has been superseded by LinearOperator.

    See Also
    --------
    LinearOperator

    %s is not re-entrant
    Use Generalized Minimal RESidual iteration to solve A x = b.

    Parameters
    ----------
    A : {sparse matrix, dense matrix, LinearOperator}
        The real or complex N-by-N matrix of the linear system.
    b : {array, matrix}
        Right hand side of the linear system. Has shape (N,) or (N,1).

    Returns
    -------
    x : {array, matrix}
        The converged solution.
    info : int
        Provides convergence information:
          * 0  : successful exit
          * >0 : convergence to tolerance not achieved, number of iterations
          * <0 : illegal input or breakdown

    Other parameters
    ----------------
    x0 : {array, matrix}
        Starting guess for the solution (a vector of zeros by default).
    tol : float
        Tolerance to achieve. The algorithm terminates when either the relative
        or the absolute residual is below `tol`.
    restart : int, optional
        Number of iterations between restarts. Larger values increase
        iteration cost, but may be necessary for convergence.
        Default is 20.
    maxiter : int, optional
        Maximum number of iterations (restart cycles).  Iteration will stop
        after maxiter steps even if the specified tolerance has not been
        achieved.
    xtype : {'f','d','F','D'}
        This parameter is DEPRECATED --- avoid using it.

        The type of the result.  If None, then it will be determined from
        A.dtype.char and b.  If A does not have a typecode method then it
        will compute A.matvec(x0) to get a typecode.   To save the extra
        computation when A does not have a typecode attribute use xtype=0
        for the same type as b or use xtype='f','d','F',or 'D'.
        This parameter has been superseded by LinearOperator.
    M : {sparse matrix, dense matrix, LinearOperator}
        Inverse of the preconditioner of A.  M should approximate the
        inverse of A and be easy to solve for (see Notes).  Effective
        preconditioning dramatically improves the rate of convergence,
        which implies that fewer iterations are needed to reach a given
        error tolerance.  By default, no preconditioner is used.
    callback : function
        User-supplied function to call after each iteration.  It is called
        as callback(rk), where rk is the current residual vector.
    restrt : int, optional
        DEPRECATED - use `restart` instead.

    See Also
    --------
    LinearOperator

    Notes
    -----
    A preconditioner, P, is chosen such that P is close to A but easy to solve
    for. The preconditioner parameter required by this routine is
    ``M = P^-1``. The inverse should preferably not be calculated
    explicitly.  Rather, use the following template to produce M::

      # Construct a linear operator that computes P^-1 * x.
      import scipy.sparse.linalg as spla
      M_x = lambda x: spla.spsolve(P, x)
      M = spla.LinearOperator((n, n), M_x)

    scipy.sparse.linalg.isolve.iterativeb : {array, matrix}
    Right hand side of the linear system. Has shape (N,) or (N,1).

Returns
-------
x : {array, matrix}
    The converged solution.
info : integer
    Provides convergence information:
        0  : successful exit
        >0 : convergence to tolerance not achieved, number of iterations
        <0 : illegal input or breakdown

Other Parameters
----------------
x0  : {array, matrix}
    Starting guess for the solution.
tol : float
    Tolerance to achieve. The algorithm terminates when either the relative
    or the absolute residual is below `tol`.
maxiter : integer
    Maximum number of iterations.  Iteration will stop after maxiter
    steps even if the specified tolerance has not been achieved.
M : {sparse matrix, dense matrix, LinearOperator}
    Preconditioner for A.  The preconditioner should approximate the
    inverse of A.  Effective preconditioning dramatically improves the
    rate of convergence, which implies that fewer iterations are needed
    to reach a given error tolerance.
callback : function
    User-supplied function to call after each iteration.  It is called
    as callback(xk), where xk is the current solution vector.
xtype : {'f','d','F','D'}
    This parameter is deprecated -- avoid using it.

    The type of the result.  If None, then it will be determined from
    A.dtype.char and b.  If A does not have a typecode method then it
    will compute A.matvec(x0) to get a typecode.   To save the extra
    computation when A does not have a typecode attribute use xtype=0
    for the same type as b or use xtype='f','d','F',or 'D'.
    This parameter has been superseded by LinearOperator.

The real or complex N-by-N matrix of the linear system
It is required that the linear operator can produce
``Ax`` and ``A^T x``.Cannot specify both restart and restrt keywords. Preferably use 'restart' only.Iterative methods for solving linear systemsThe real or complex N-by-N matrix of the linear system
``A`` must represent a hermitian, positive definite matrixscipy.lib.decorator
Parameters
----------
A : {sparse matrix, dense matrix, LinearOperator}($   t   At   bt   x0t   tolt   maxitert   xtypet   M1t   M2t   callbackt   A_t   Mt   xt   postprocesst   left_psolvet   right_psolvet   left_rpsolvet   right_rpsolvet   idt   nt   ltrt   revcomt   stoptestt   residt   ndx1t   ndx2t   workt   ijobt   infot   ftflagt   bnrm2t   iter_t   olditert   sclr1t   sclr2t   slice1t   slice2(    t   At   bt   x0t   tolt   maxitert   xtypet   Mt   callbackt   xt   postprocesst   nt   matvect   rmatvect   psolvet   rpsolvet   ltrt   revcomt   stoptestt   residt   ndx1t   ndx2t   workt   ijobt   infot   ftflagt   bnrm2t   iter_t   olditert   sclr1t   sclr2t   slice1t   slice2(%   t   At   bt   x0t   tolt   restartt   maxitert   xtypet   Mt   callbackt   restrtt   xt   postprocesst   nt   matvect   psolvet   ltrt   revcomt   stoptestt   residt   ndx1t   ndx2t   workt   work2t   ijobt   infot   ftflagt   bnrm2t   iter_t   old_ijobt
   first_passt   resid_readyt   iter_numt   olditert   sclr1t   sclr2t   slice1t   slice2(   t   At   bt   x0t   tolt   maxitert   xtypet   Mt   callbackt   xt   postprocesst   nt   matvect   psolvet   ltrt   revcomt   stoptestt   residt   ndx1t   ndx2t   workt   ijobt   infot   ftflagt   bnrm2t   iter_t   olditert   sclr1t   sclr2t   slice1t   slice2r_normbailoutk_outerscipy.sparse.linalg.isolve.lgmresRHS must contain only finite numbersPreconditioner returned a zero vector; |v| ~ %.1g, |M v| = 0/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/lgmres.py
    Solve a matrix equation using the LGMRES algorithm.

    The LGMRES algorithm [BJM]_ [BPh]_ is designed to avoid some problems
    in the convergence in restarted GMRES, and often converges in fewer
    iterations.

    Parameters
    ----------
    A : {sparse matrix, dense matrix, LinearOperator}
        The real or complex N-by-N matrix of the linear system.
    b : {array, matrix}
        Right hand side of the linear system. Has shape (N,) or (N,1).
    x0  : {array, matrix}
        Starting guess for the solution.
    tol : float
        Tolerance to achieve. The algorithm terminates when either the relative
        or the absolute residual is below `tol`.
    maxiter : int
        Maximum number of iterations.  Iteration will stop after maxiter
        steps even if the specified tolerance has not been achieved.
    M : {sparse matrix, dense matrix, LinearOperator}
        Preconditioner for A.  The preconditioner should approximate the
        inverse of A.  Effective preconditioning dramatically improves the
        rate of convergence, which implies that fewer iterations are needed
        to reach a given error tolerance.
    callback : function
        User-supplied function to call after each iteration.  It is called
        as callback(xk), where xk is the current solution vector.
    inner_m : int, optional
        Number of inner GMRES iterations per each outer iteration.
    outer_k : int, optional
        Number of vectors to carry between inner GMRES iterations.
        According to [BJM]_, good values are in the range of 1...3.
        However, note that if you want to use the additional vectors to
        accelerate solving multiple similar problems, larger values may
        be beneficial.
    outer_v : list of tuples, optional
        List containing tuples ``(v, Av)`` of vectors and corresponding
        matrix-vector products, used to augment the Krylov subspace, and
        carried between inner GMRES iterations. The element ``Av`` can
        be `None` if the matrix-vector product should be re-evaluated.
        This parameter is modified in-place by `lgmres`, and can be used
        to pass "guess" vectors in and out of the algorithm when solving
        similar problems.
    store_outer_Av : bool, optional
        Whether LGMRES should store also A*v in addition to vectors `v`
        in the `outer_v` list. Default is True.

    Returns
    -------
    x : array or matrix
        The converged solution.
    info : int
        Provides convergence information:

            - 0  : successful exit
            - >0 : convergence to tolerance not achieved, number of iterations
            - <0 : illegal input or breakdown

    Notes
    -----
    The LGMRES algorithm [BJM]_ [BPh]_ is designed to avoid the
    slowing of convergence in restarted GMRES, due to alternating
    residual vectors. Typically, it often outperforms GMRES(m) of
    comparable memory requirements by some measure, or at least is not
    much worse.

    Another advantage in this algorithm is that you can supply it with
    'guess' vectors in the `outer_v` argument that augment the Krylov
    subspace. If the solution lies close to the span of these vectors,
    the algorithm converges faster. This can be useful if several very
    similar matrices need to be inverted one after another, such as in
    Newton-Krylov iteration where the Jacobian matrix often changes
    little in the nonlinear steps.

    References
    ----------
    .. [BJM] A.H. Baker and E.R. Jessup and T. Manteuffel,
             SIAM J. Matrix Anal. Appl. 26, 962 (2005).
    .. [BPh] A.H. Baker, PhD thesis, University of Colorado (2003).
             http://amath.colorado.edu/activities/thesis/allisonb/Thesis.ps

    (2   t   At   bt   x0t   tolt   maxitert   Mt   callbackt   inner_mt   outer_kt   outer_vt   store_outer_Avt   lstsqt   xt   postprocesst   matvect   psolvet   axpyt   dott   scalt   b_normt   k_outert   r_outert   r_normt   vs0t   inner_res_0t   rnormt   hst   vst   wst   yt   jt   v_newt   zt   hcurt   vt   alphat   bailoutt   hesst   e1t   qt   residst   rankt   st	   inner_rest   dxt   wt   yct   nxt   axt   qc?taudminDimbetaacutebtol = %8.2e             maxiter = %8g
istop =%8g    normr =%8.1eLSMR finishedLSMR            Least-squares solution of  Ax = b
scipy.sparse.linalg.isolve.lsmritn   =%8g    condA =%8.1e    normA =%8.1e    normAr =%8.1e
Copyright (C) 2010 David Fong and Michael Saunders

LSMR uses an iterative method.

07 Jun 2010: Documentation updated
03 Jun 2010: First release version in Python

David Chin-lung Fong            clfong@stanford.edu
Institute for Computational and Mathematical Engineering
Stanford University

Michael Saunders                saunders@stanford.edu
Systems Optimization Laboratory
Dept of MS&E, Stanford University.

    normx =%8.1e   itn      x(1)       norm r    norm Aratol = %8.2e                 conlim = %8.2e
 compatible   LS      norm A   cond Adamp = %20.14e
Iterative solver for least-squares problems.

    lsmr solves the system of linear equations ``Ax = b``. If the system
    is inconsistent, it solves the least-squares problem ``min ||b - Ax||_2``.
    A is a rectangular matrix of dimension m-by-n, where all cases are
    allowed: m = n, m > n, or m < n. B is a vector of length m.
    The matrix A may be dense or sparse (usually sparse).

    .. versionadded:: 0.11.0

    Parameters
    ----------
    A : {matrix, sparse matrix, ndarray, LinearOperator}
        Matrix A in the linear system.
    b : (m,) ndarray
        Vector b in the linear system.
    damp : float
        Damping factor for regularized least-squares. `lsmr` solves
        the regularized least-squares problem::

         min ||(b) - (  A   )x||
             ||(0)   (damp*I) ||_2

        where damp is a scalar.  If damp is None or 0, the system
        is solved without regularization.
    atol, btol : float
        Stopping tolerances. `lsmr` continues iterations until a
        certain backward error estimate is smaller than some quantity
        depending on atol and btol.  Let ``r = b - Ax`` be the
        residual vector for the current approximate solution ``x``.
        If ``Ax = b`` seems to be consistent, ``lsmr`` terminates
        when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``.
        Otherwise, lsmr terminates when ``norm(A^{T} r) <=
        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (say),
        the final ``norm(r)`` should be accurate to about 6
        digits. (The final x will usually have fewer correct digits,
        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`
        or `btol` is None, a default value of 1.0e-6 will be used.
        Ideally, they should be estimates of the relative error in the
        entries of A and B respectively.  For example, if the entries
        of `A` have 7 correct digits, set atol = 1e-7. This prevents
        the algorithm from doing unnecessary work beyond the
        uncertainty of the input data.
    conlim : float
        `lsmr` terminates if an estimate of ``cond(A)`` exceeds
        `conlim`.  For compatible systems ``Ax = b``, conlim could be
        as large as 1.0e+12 (say).  For least-squares problems,
        `conlim` should be less than 1.0e+8. If `conlim` is None, the
        default value is 1e+8.  Maximum precision can be obtained by
        setting ``atol = btol = conlim = 0``, but the number of
        iterations may then be excessive.
    maxiter : int
        `lsmr` terminates if the number of iterations reaches
        `maxiter`.  The default is ``maxiter = min(m, n)``.  For
        ill-conditioned systems, a larger value of `maxiter` may be
        needed.
    show : bool
        Print iterations logs if ``show=True``.

    Returns
    -------
    x : ndarray of float
        Least-square solution returned.
    istop : int
        istop gives the reason for stopping::

          istop   = 0 means x=0 is a solution.
                  = 1 means x is an approximate solution to A*x = B,
                      according to atol and btol.
                  = 2 means x approximately solves the least-squares problem
                      according to atol.
                  = 3 means COND(A) seems to be greater than CONLIM.
                  = 4 is the same as 1 with atol = btol = eps (machine
                      precision)
                  = 5 is the same as 2 with atol = eps.
                  = 6 is the same as 3 with CONLIM = 1/eps.
                  = 7 means ITN reached maxiter before the other stopping
                      conditions were satisfied.

    itn : int
        Number of iterations used.
    normr : float
        ``norm(b-Ax)``
    normar : float
        ``norm(A^T (b - Ax))``
    norma : float
        ``norm(A)``
    conda : float
        Condition number of A.
    normx : float
        ``norm(x)``

    References
    ----------
    .. [1] D. C.-L. Fong and M. A. Saunders,
           "LSMR: An iterative algorithm for sparse least-squares problems",
           SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.
           http://arxiv.org/abs/1006.0758
    .. [2] LSMR Software, http://www.stanford.edu/~clfong/lsmr.html

    /usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/lsmr.py(L   t   At   bt   dampt   atolt   btolt   conlimt   maxitert   showt   msgt   hdg1t   hdg2t   pfreqt   pcountt   mt   nt   minDimt   ut   betat   vt   alphat   itnt   zetabart   alphabart   rhot   rhobart   cbart   sbart   ht   hbart   xt   betaddt   betadt   rhodoldt   tautildeoldt
   thetatildet   zetat   dt   normA2t   maxrbart   minrbart   normAt   condAt   normxt   normbt   istopt   ctolt   normrt   normart   test1t   test2t   str1t   str2t   str3t   chatt   shatt   alphahatt   rhooldt   ct   st   thetanewt	   rhobaroldt   zetaoldt   thetabart   rhotempt	   betaacutet	   betacheckt   betahatt   thetatildeoldt	   ctildeoldt	   stildeoldt   rhotildeoldt   taudt   test3t   t1t   rtolt   str4cs1sn1__xm__xnr1sqzbaracondhead1head2nstoparnormgambarr1normr2normrhobar1istop =%8g   r1norm =%8.1e Compatible    LS      Norm A   Cond Adamp = %20.14e   calc_var = %8gbtol = %8.2e               iter_lim = %8g
    Stable implementation of Givens rotation.

    Notes
    -----
    The routine 'SymOrtho' was added for numerical stability. This is
    recommended by S.-C. Choi in [1]_.  It removes the unpleasant potential of
    ``1/eps`` in some important places (see, for example text following
    "Compute the next plane rotation Qk" in minres.py).

    References
    ----------
    .. [1] S.-C. Choi, "Iterative Methods for Singular Linear Equations
           and Least-Squares Problems", Dissertation,
           http://www.stanford.edu/group/SOL/dissertations/sou-cheng-choi-thesis.pdf

       Itn      x[0]       r1norm     r2norm Find the least-squares solution to a large, sparse, linear system
    of equations.

    The function solves ``Ax = b``  or  ``min ||b - Ax||^2`` or
    ``min ||Ax - b||^2 + d^2 ||x||^2``.

    The matrix A may be square or rectangular (over-determined or
    under-determined), and may have any rank.

    ::

      1. Unsymmetric equations --    solve  A*x = b

      2. Linear least squares  --    solve  A*x = b
                                     in the least-squares sense

      3. Damped least squares  --    solve  (   A    )*x = ( b )
                                            ( damp*I )     ( 0 )
                                     in the least-squares sense

    Parameters
    ----------
    A : {sparse matrix, ndarray, LinearOperatorLinear}
        Representation of an m-by-n matrix.  It is required that
        the linear operator can produce ``Ax`` and ``A^T x``.
    b : (m,) ndarray
        Right-hand side vector ``b``.
    damp : float
        Damping coefficient.
    atol, btol : float
        Stopping tolerances. If both are 1.0e-9 (say), the final
        residual norm should be accurate to about 9 digits.  (The
        final x will usually have fewer correct digits, depending on
        cond(A) and the size of damp.)
    conlim : float
        Another stopping tolerance.  lsqr terminates if an estimate of
        ``cond(A)`` exceeds `conlim`.  For compatible systems ``Ax =
        b``, `conlim` could be as large as 1.0e+12 (say).  For
        least-squares problems, conlim should be less than 1.0e+8.
        Maximum precision can be obtained by setting ``atol = btol =
        conlim = zero``, but the number of iterations may then be
        excessive.
    iter_lim : int
        Explicit limitation on number of iterations (for safety).
    show : bool
        Display an iteration log.
    calc_var : bool
        Whether to estimate diagonals of ``(A'A + damp^2*I)^{-1}``.

    Returns
    -------
    x : ndarray of float
        The final solution.
    istop : int
        Gives the reason for termination.
        1 means x is an approximate solution to Ax = b.
        2 means x approximately solves the least-squares problem.
    itn : int
        Iteration number upon termination.
    r1norm : float
        ``norm(r)``, where ``r = b - Ax``.
    r2norm : float
        ``sqrt( norm(r)^2  +  damp^2 * norm(x)^2 )``.  Equal to `r1norm` if
        ``damp == 0``.
    anorm : float
        Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.
    acond : float
        Estimate of ``cond(Abar)``.
    arnorm : float
        Estimate of ``norm(A'*r - damp^2*x)``.
    xnorm : float
        ``norm(x)``
    var : ndarray of float
        If ``calc_var`` is True, estimates all diagonals of
        ``(A'A)^{-1}`` (if ``damp == 0``) or more generally ``(A'A +
        damp^2*I)^{-1}``.  This is well defined if A has full column
        rank or ``damp > 0``.  (Not sure what var means if ``rank(A)
        < n`` and ``damp = 0.``)

    Notes
    -----
    LSQR uses an iterative method to approximate the solution.  The
    number of iterations required to reach a certain accuracy depends
    strongly on the scaling of the problem.  Poor scaling of the rows
    or columns of A should therefore be avoided where possible.

    For example, in problem 1 the solution is unaltered by
    row-scaling.  If a row of A is very small or large compared to
    the other rows of A, the corresponding row of ( A  b ) should be
    scaled up or down.

    In problems 1 and 2, the solution x is easily recovered
    following column-scaling.  Unless better information is known,
    the nonzero columns of A should be scaled so that they all have
    the same Euclidean norm (e.g., 1.0).

    In problem 3, there is no freedom to re-scale if damp is
    nonzero.  However, the value of damp should be assigned only
    after attention has been paid to the scaling of A.

    The parameter damp is intended to help regularize
    ill-conditioned systems, by preventing the true solution from
    being very large.  Another aid to regularization is provided by
    the parameter acond, which may be used to terminate iterations
    before the computed solution becomes very large.

    If some initial estimate ``x0`` is known and if ``damp == 0``,
    one could proceed as follows:

      1. Compute a residual vector ``r0 = b - A*x0``.
      2. Use LSQR to solve the system  ``A*dx = r0``.
      3. Add the correction dx to obtain a final solution ``x = x0 + dx``.

    This requires that ``x0`` be available before and after the call
    to LSQR.  To judge the benefits, suppose LSQR takes k1 iterations
    to solve A*x = b and k2 iterations to solve A*dx = r0.
    If x0 is "good", norm(r0) will be smaller than norm(b).
    If the same stopping tolerances atol and btol are used for each
    system, k1 and k2 will be similar, but the final solution x0 + dx
    should be more accurate.  The only way to reduce the total work
    is to use a larger stopping tolerance for the second system.
    If some value btol is suitable for A*x = b, the larger value
    btol*norm(b)/norm(r0)  should be suitable for A*dx = r0.

    Preconditioning is another way to reduce the number of iterations.
    If it is possible to solve a related system ``M*x = b``
    efficiently, where M approximates A in some helpful way (e.g. M -
    A has low rank or its elements are small relative to those of A),
    LSQR may converge more rapidly on the system ``A*M(inverse)*z =
    b``, after which x can be recovered by solving M*x = z.

    If A is symmetric, LSQR should not be used!

    Alternatives are the symmetric conjugate-gradient method (cg)
    and/or SYMMLQ.  SYMMLQ is an implementation of symmetric cg that
    applies to any symmetric A and will converge more rapidly than
    LSQR.  If A is positive definite, there are other implementations
    of symmetric cg that require slightly less work per iteration than
    SYMMLQ (but will take the same number of iterations).

    References
    ----------
    .. [1] C. C. Paige and M. A. Saunders (1982a).
           "LSQR: An algorithm for sparse linear equations and
           sparse least squares", ACM TOMS 8(1), 43-71.
    .. [2] C. C. Paige and M. A. Saunders (1982b).
           "Algorithm 583.  LSQR: Sparse linear equations and least
           squares problems", ACM TOMS 8(2), 195-209.
    .. [3] M. A. Saunders (1995).  "Solution of sparse rectangular
           systems using LSQR and CRAIG", BIT 35, 588-604.

    Sparse Equations and Least Squares.

The original Fortran code was written by C. C. Paige and M. A. Saunders as
described in

C. C. Paige and M. A. Saunders, LSQR: An algorithm for sparse linear
equations and sparse least squares, TOMS 8(1), 43--71 (1982).

C. C. Paige and M. A. Saunders, Algorithm 583; LSQR: Sparse linear
equations and least-squares problems, TOMS 8(2), 195--209 (1982).

It is licensed under the following BSD license:

Copyright (c) 2006, Systems Optimization Laboratory
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.

    * Redistributions in binary form must reproduce the above
      copyright notice, this list of conditions and the following
      disclaimer in the documentation and/or other materials provided
      with the distribution.

    * Neither the name of Stanford University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

The Fortran code was translated to Python for use in CVXOPT by Jeffery
Kline with contributions by Mridul Aanjaneya and Bob Myhill.

Adapted for SciPy by Stefan van der Walt.

acond =%8.1e   xnorm  =%8.1eLSQR finisheditn   =%8g   r2norm =%8.1e/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/lsqr.pyanorm =%8.1e   arnorm =%8.1escipy.sparse.linalg.isolve.lsqrLSQR            Least-squares solution of  Ax = b(I   t   At   bt   dampt   atolt   btolt   conlimt   iter_limt   showt   calc_vart   mt   nt   vart   msgt   str1t   str2t   str3t   str4t   itnt   istopt   nstopt   ctolt   anormt   acondt   dampsqt   ddnormt   res2t   xnormt   xxnormt   zt   cs2t   sn2t   __xmt   __xnt   vt   ut   xt   alfat   betat   wt   rhobart   phibart   bnormt   rnormt   r1normt   r2normt   arnormt   head1t   head2t   test1t   test2t   rhobar1t   cs1t   sn1t   psit   cst   snt   rhot   thetat   phit   taut   t1t   t2t   dkt   deltat   gambart   rhst   zbart   gammat   res1t   r1sqt   test3t   rtolt   prntepsxoldepsqrnorm beta2 = 0.  If M = I, b and x are eigenvectors     beta1 = 0.  The exact solution is  x = 0           A solution to Ax = b was found, given rtol         A least-squares solution was found, given rtol     Reasonable accuracy achieved, given eps            x has converged to an eigenvector                  acond has exceeded 0.1/eps                         The iteration limit was reached                    A  does not define a symmetric matrix              M  does not define a symmetric matrix              M  does not define a pos-def preconditioner       The real symmetric N-by-N matrix of the linear system   Itn     x(1)     Compatible    LS       norm(A)  cond(A) gbar/|A| rnorm   =  %12.4e      ynorm =  %12.4e Anorm   =  %12.4e      Acond =  %12.4e %10.3eExit  minres.    Arnorm  =  %12.4e %8.1e %8.1e %8.1eEnter minres.   
Notes
-----
THIS FUNCTION IS EXPERIMENTAL AND SUBJECT TO CHANGE!

References
----------
Solution of sparse indefinite systems of linear equations,
    C. C. Paige and M. A. Saunders (1975),
    SIAM J. Numer. Anal. 12(4), pp. 617-629.
    http://www.stanford.edu/group/SOL/software/minres.html

This file is a translation of the following MATLAB implementation:
    http://www.stanford.edu/group/SOL/software/minres/matlab/
non-symmetric matrixUse MINimum RESidual iteration to solve Ax=b

MINRES minimizes norm(A*x - b) for a real symmetric matrix A.  Unlike
the Conjugate Gradient method, A can be indefinite or singular.

If shift != 0 then the method solves (A - shift*I)x = b
indefinite preconditionerscipy.sparse.linalg.isolve.minres%6g %12.5e %10.3e istop   =  %3g               itn   =%5g/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/minres.pyn      =  %3g     shift  =  %23.14eSolution of symmetric Ax = bnon-symmetric preconditioneritnlim =  %3g     rtol   =  %11.2e(I   t   At   bt   x0t   shiftt   tolt   maxitert   xtypet   Mt   callbackt   showt   checkt   xt   postprocesst   matvect   psolvet   firstt   lastt   nt   msgt   istopt   itnt   Anormt   Acondt   rnormt   ynormt   epst   yt   r1t   beta1t   wt   r2t   st   tt   zt   epsat   oldbt   betat   dbart   epslnt   qrnormt   phibart   rhs1t   rhs2t   tnorm2t   ynorm2t   cst   snt   w2t   vt   alfat   gmaxt   gmint   oldepst   deltat   gbart   roott   Arnormt   gammat   phit   denomt   w1t   epsxt   epsrt   diagt   test1t   test2t   t1t   t2t   prntt   str1t   str2t   str3t   info{(   t   dt   DR   (   R   t   FR   (   R   R   R   (   R   R    R   (   R    R    R    (   R   t   fR   (   R   R   R   (   R   R   R   (   R    R   R    (   R   R   R   (   R    R   R   (   R   R   R   (   R   R   R   (   R   R    R    (   R   R   R   (   R   R    R   0Use of xtype argument is deprecated. Use LinearOperator( ... , dtype=xtype) instead.A and b have incompatible dimensionsxtype must be 'f', 'd', 'F', or 'D'Make a linear system Ax=b

    Parameters
    ----------
    A : LinearOperator
        sparse or dense matrix (or any valid input to aslinearoperator)
    M : {LinearOperator, Nones}
        preconditioner
        sparse or dense matrix (or any valid input to aslinearoperator)
    x0 : {array_like, None}
        initial guess to iterative method
    b : array_like
        right hand side
    xtype : {'f', 'd', 'F', 'D', None}
        dtype of the x vector

    Returns
    -------
    (A, M, x, b, postprocess)
        A : LinearOperator
            matrix of the linear system
        M : LinearOperator
            preconditioner
        x : rank 1 ndarray
            initial guess
        b : rank 1 ndarray
            right hand side
        postprocess : function
            converts the solution vector to the appropriate
            type and dimensions (e.g. (N,1) matrix)

    scipy.sparse.linalg.isolve.utils/usr/lib/python2.7/dist-packages/scipy/sparse/linalg/isolve/utils.pyA and x have incompatible dimensionsmatrix and preconditioner have different shapesexpected square matrix, but got shape=%s      4@      E@      @      ?S?B4B6U2A10_A2_A4_A6_A8Ainv_A10eta_1eta_2eta_4eta_5d4_loosed4_tightd6_loosed6_tightd8_loosed8_tighttheta_13_d4_exact_d6_exact_d8_exactd10_loosed10_tight_d10_exact_d4_approx_d6_approx_d8_approxlower_part_d10_approxabs_c_recip|z@?d @A_abs_onenormpade13_scaledQi? ,?UUUUUU?log2_alpha_div_u_operator_sequence
    A helper function for expm_2009.

    Parameters
    ----------
    U : ndarray
        Pade numerator.
    V : ndarray
        Pade denominator.
    structure : str, optional
        A string describing the structure of both matrices `U` and `V`.
        Only `upper_triangular` is currently supported.

    Notes
    -----
    The `structure` argument is inspired by similar args
    for theano and cvxopt functions.

    
    Compute the 1-norm of a non-negative integer power of a non-negative matrix.

    Parameters
    ----------
    A : a square ndarray or matrix or sparse matrix
        Input matrix with non-negative entries.
    p : non-negative integer
        The power to which the matrix is to be raised.

    Returns
    -------
    out : float
        The 1-norm of the matrix power p of A.

    
    A helper function for expm_2009.

    Parameters
    ----------
    A : linear operator
        A linear operator whose norm of power we care about.
    m : int
        The power of the linear operator

    Returns
    -------
    value : int
        A value related to a bound.

    unsupported matrix structure: 
    Equation (10.42) of Functions of Matrices: Theory and Computation.

    Notes
    -----
    This is a helper function for _fragment_2_1 of expm_2009.
    Equation (10.42) is on page 251 in the section on Schur algorithms.
    In particular, section 10.4.3 explains the Schur-Parlett algorithm.
    expm([[lam_1, t_12], [0, lam_1])
    =
    [[exp(lam_1), t_12*exp((lam_1 + lam_2)/2)*sinch((lam_1 - lam_2)/2)],
    [0, exp(lam_2)]
    
    A matrix product that knows about sparse and structured matrices.

    Parameters
    ----------
    A : 2d ndarray
        First matrix.
    B : 2d ndarray
        Second matrix.
    alpha : float
        The matrix product will be scaled by this constant.
    structure : str, optional
        A string describing the structure of both matrices `A` and `B`.
        Only `upper_triangular` is currently supported.

    Returns
    -------
    M : 2d ndarray
        Matrix product of A and B.

    
    Help lazily evaluate a matrix exponential.

    The idea is to not do more work than we need for high expm precision,
    so we lazily compute matrix powers and store or precompute
    other properties of the matrix.

    expected non-negative integer p
    Compute the inverse of a sparse matrix

    .. versionadded:: 0.12.0

    Parameters
    ----------
    A : (M,M) ndarray or sparse matrix
        square matrix to be inverted

    Returns
    -------
    Ainv : (M,M) ndarray or sparse matrix
        inverse of `A`

    Notes
    -----
    This computes the sparse inverse of `A`.  If the inverse of `A` is expected
    to be non-sparse, it will likely be faster to convert `A` to dense and use
    scipy.linalg.inv.

    
        Initialize the object.

        Parameters
        ----------
        A : a dense or sparse square numpy matrix or ndarray
            The matrix to be exponentiated.
        structure : str, optional
            A string describing the structure of matrix `A`.
            Only `upper_triangular` is currently supported.
        use_exact_onenorm : bool, optional
            If True then only the exact one-norm of matrix powers and products
            will be used. Otherwise, the one-norm of powers and products
            may initially be estimated.
        /usr/lib/python2.7/dist-packages/scipy/sparse/linalg/matfuncs.py
    Stably evaluate sinch.

    Notes
    -----
    The strategy of falling back to a sixth order Taylor expansion
    was suggested by the Spallation Neutron Source docs
    which was found on the internet by google search.
    http://www.ornl.gov/~t6p/resources/xal/javadoc/gov/sns/tools/math/ElementaryFunction.html
    The details of the cutoff point and the Horner-like evaluation
    was picked without reference to anything in particular.

    Note that sinch is not currently implemented in scipy.special,
    whereas the "engineer's" definition of sinc is implemented.
    The implementation of sinc involves a scaling factor of pi
    that distinguishes it from the "mathematician's" version of sinc.

    
    Efficiently estimate the 1-norm of the matrix product of the args.

    Parameters
    ----------
    operator_seq : linear operator sequence
        Matrices whose 1-norm of product is to be computed.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.
        Larger values take longer and use more memory
        but give more accurate output.
    itmax : int, optional
        Use at most this many iterations.
    compute_v : bool, optional
        Request a norm-maximizing linear operator input vector if True.
    compute_w : bool, optional
        Request a norm-maximizing linear operator output vector if True.
    structure : str, optional
        A string describing the structure of all operators.
        Only `upper_triangular` is currently supported.

    Returns
    -------
    est : float
        An underestimate of the 1-norm of the sparse matrix.
    v : ndarray, optional
        The vector such that ||Av||_1 == est*||v||_1.
        It can be thought of as an input to the linear operator
        that gives an output with particularly large norm.
    w : ndarray, optional
        The vector Av which has relatively large 1-norm.
        It can be thought of as an output of the linear operator
        that is relatively large in norm compared to the input.

    The square matrices of the ProductOperator must all have the same shape.expected B to be a rectangular matrix
    A helper function for expm_2009.

    Notes
    -----
    The argument X is modified in-place, but this modification is not the same
    as the returned value of the function.
    This function also takes pains to do things in ways that are compatible
    with sparse matrices, for example by avoiding fancy indexing
    and by using methods of the matrices whenever possible instead of
    using functions of the numpy or scipy libraries themselves.

    For now, the ProductOperator implementation is limited to the product of multiple square matrices.scipy.sparse.linalg.matfuncs
Sparse matrix functions
expected A to be a rectangular matrix
    Compute the matrix exponential using Pade approximation.

    .. versionadded:: 0.12.0

    Parameters
    ----------
    A : (M,M) array_like or sparse matrix
        2D Array or Matrix (sparse or dense) to be exponentiated

    Returns
    -------
    expA : (M,M) ndarray
        Matrix exponential of `A`

    Notes
    -----
    This is algorithm (6.1) which is a simplification of algorithm (5.1).

    References
    ----------
    .. [1] Awad H. Al-Mohy and Nicholas J. Higham (2009)
           "A New Scaling and Squaring Algorithm for the Matrix Exponential."
           SIAM Journal on Matrix Analysis and Applications.
           31 (3). pp. 970-989. ISSN 1095-7162

    
    For now, this is limited to products of multiple square matrices.
    ffffff?e66extract_diagonalFor a given blocksize=(r,c) count the number of occupied
    blocks in a sparse matrix A
    r and c must be positiveuse .diagonal() instead/usr/lib/python2.7/dist-packages/scipy/sparse/spfuncs.py Functions that operate on sparse matrices
Attempt to determine the blocksize of a sparse matrix

    Returns a blocksize=(r,c) such that
        - A.nnz / A.tobsr( (r,c) ).nnz > efficiency
    scipy.sparse.spfuncsefficiency must satisfy 0.0 < efficiency < 1.0nslicecanCastint32max_check_boolean_slicetoarange_check_ellipsis_boolean_index_to_arrayProcess indices with Ellipsis. Returns modified index.object dtype is not supported by sparse matrices/usr/lib/python2.7/dist-packages/scipy/sparse/sputils.pyIs x a valid 2-tuple of dimensions?
    Is x appropriate as an index into a sparse matrix? Returns True
    if it can be cast safely to a machine int.
     Parse index. Always return a tuple of the form (row, col).
        Where row/col is a integer, slice, or array of integers.
        
    Bincount with minlength keyword added for Numpy 1.5.
    1.6.0-devReturns the nearest supported sparse dtype for the
    combination of one or more types.

    upcast(t0, t1, ..., tn) -> T  where T is a supported dtype

    Examples
    --------

    >>> upcast('int32')
    <type 'numpy.int32'>
    >>> upcast('bool')
    <type 'numpy.bool_'>
    >>> upcast('int32','float32')
    <type 'numpy.float64'>
    >>> upcast('bool',complex,float)
    <type 'numpy.complex128'>

    could not interpret data type
    Copy of numpy.unique() from Numpy 1.7.1.

    Earlier versions have bugs in how return_index behaves.
    no supported conversion for types: %rIs x either a scalar, an array scalar, or a 0-dim array?Function used to simplify argument processing.  If 'dtype' is not
    specified (is None), returns a.dtype; otherwise returns a np.dtype
    object created from the specified dtype argument.  If 'dtype' and 'a'
    are both None, construct a data type out of the 'default' parameter.
    Furthermore, 'dtype' must be in 'allowed' set.
    Determine data type for binary operation between an array of
    type `dtype` and a scalar.
    Indexing with sparse matrices is not supported except boolean indexing where matrix and index are equal shapes.Index dimension must be <= 21.7.0-dev
    Based on input (integer) arrays `a`, determine a suitable index data
    type that can hold the data in the arrays.

    Parameters
    ----------
    arrays : tuple of array_like
        Input arrays whose types/contents to check
    maxval : float, optional
        Maximum value needed
    check_contents : bool, optional
        Whether to check the values in the arrays and not just their types.
        Default: False (check only the types)

    Returns
    -------
    dtype : dtype
        Suitable index data type (int32 or int64)

     Given a slice object, use numpy arange to change it to a 1D
        array.
        index returns 3-dim structureCannot deal with arrays with indices larger than the machine maximum address size (e.g. 64-bit indices on 32-bit machine).Same as `upcast` but taking dtype.char as input (faster).
    Down-cast index array to np.intp dtype if it is of a larger dtype.

    Raise an error if the array contains a value that is too large for
    intp.
    
    This class simply exists to hold the methods necessary for fancy indexing.
    invalid index shapeinvalid number of indices Utility functions for sparse matrix module
/usr/lib/python2.7/dist-packages/scipy/special/__init__.py
========================================
Special functions (:mod:`scipy.special`)
========================================

.. module:: scipy.special

Nearly all of the functions below are universal functions and follow
broadcasting and automatic array-looping rules. Exceptions are noted.

Error handling
==============

Errors are handled by returning nans, or other appropriate values.
Some of the special function routines will emit warnings when an error
occurs.  By default this is disabled.  To enable such messages use
``errprint(1)``, and to disable such messages use ``errprint(0)``.

Example:

    >>> print scipy.special.bdtr(-1,10,0.3)
    >>> scipy.special.errprint(1)
    >>> print scipy.special.bdtr(-1,10,0.3)

.. autosummary::
   :toctree: generated/

   errprint

Available functions
===================

Airy functions
--------------

.. autosummary::
   :toctree: generated/

   airy     -- Airy functions and their derivatives.
   airye    -- Exponentially scaled Airy functions
   ai_zeros -- [+]Zeros of Airy functions Ai(x) and Ai'(x)
   bi_zeros -- [+]Zeros of Airy functions Bi(x) and Bi'(x)


Elliptic Functions and Integrals
--------------------------------

.. autosummary::
   :toctree: generated/

   ellipj    -- Jacobian elliptic functions
   ellipk    -- Complete elliptic integral of the first kind.
   ellipkm1  -- ellipkm1(x) == ellipk(1 - x)
   ellipkinc -- Incomplete elliptic integral of the first kind.
   ellipe    -- Complete elliptic integral of the second kind.
   ellipeinc -- Incomplete elliptic integral of the second kind.

Bessel Functions
----------------

.. autosummary::
   :toctree: generated/

   jn       -- Bessel function of integer order and real argument.
   jv       -- Bessel function of real-valued order and complex argument.
   jve      -- Exponentially scaled Bessel function.
   yn       -- Bessel function of second kind (integer order).
   yv       -- Bessel function of the second kind (real-valued order).
   yve      -- Exponentially scaled Bessel function of the second kind.
   kn       -- Modified Bessel function of the second kind (integer order).
   kv       -- Modified Bessel function of the second kind (real order).
   kve      -- Exponentially scaled modified Bessel function of the second kind.
   iv       -- Modified Bessel function.
   ive      -- Exponentially scaled modified Bessel function.
   hankel1  -- Hankel function of the first kind.
   hankel1e -- Exponentially scaled Hankel function of the first kind.
   hankel2  -- Hankel function of the second kind.
   hankel2e -- Exponentially scaled Hankel function of the second kind.

The following is not an universal function:

.. autosummary::
   :toctree: generated/

   lmbda       -- [+]Sequence of lambda functions with arbitrary order v.

Zeros of Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^^

These are not universal functions:

.. autosummary::
   :toctree: generated/

   jnjnp_zeros -- [+]Zeros of integer-order Bessel functions and derivatives sorted in order.
   jnyn_zeros  -- [+]Zeros of integer-order Bessel functions and derivatives as separate arrays.
   jn_zeros    -- [+]Zeros of Jn(x)
   jnp_zeros   -- [+]Zeros of Jn'(x)
   yn_zeros    -- [+]Zeros of Yn(x)
   ynp_zeros   -- [+]Zeros of Yn'(x)
   y0_zeros    -- [+]Complex zeros: Y0(z0)=0 and values of Y0'(z0)
   y1_zeros    -- [+]Complex zeros: Y1(z1)=0 and values of Y1'(z1)
   y1p_zeros   -- [+]Complex zeros of Y1'(z1')=0 and values of Y1(z1')

Faster versions of common Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. autosummary::
   :toctree: generated/

   j0       -- Bessel function of order 0.
   j1       -- Bessel function of order 1.
   y0       -- Bessel function of second kind of order 0.
   y1       -- Bessel function of second kind of order 1.
   i0       -- Modified Bessel function of order 0.
   i0e      -- Exponentially scaled modified Bessel function of order 0.
   i1       -- Modified Bessel function of order 1.
   i1e      -- Exponentially scaled modified Bessel function of order 1.
   k0       -- Modified Bessel function of the second kind of order 0.
   k0e      -- Exponentially scaled modified Bessel function of the second kind of order 0.
   k1       -- Modified Bessel function of the second kind of order 1.
   k1e      -- Exponentially scaled modified Bessel function of the second kind of order 1.

Integrals of Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. autosummary::
   :toctree: generated/

   itj0y0     -- Basic integrals of j0 and y0 from 0 to x.
   it2j0y0    -- Integrals of (1-j0(t))/t from 0 to x and y0(t)/t from x to inf.
   iti0k0     -- Basic integrals of i0 and k0 from 0 to x.
   it2i0k0    -- Integrals of (i0(t)-1)/t from 0 to x and k0(t)/t from x to inf.
   besselpoly -- Integral of a Bessel function: Jv(2* a* x) * x[+]lambda from x=0 to 1.

Derivatives of Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. autosummary::
   :toctree: generated/

   jvp     -- Nth derivative of Jv(v,z)
   yvp     -- Nth derivative of Yv(v,z)
   kvp     -- Nth derivative of Kv(v,z)
   ivp     -- Nth derivative of Iv(v,z)
   h1vp    -- Nth derivative of H1v(v,z)
   h2vp    -- Nth derivative of H2v(v,z)

Spherical Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^^^

These are not universal functions:

.. autosummary::
   :toctree: generated/

   sph_jn   -- [+]Sequence of spherical Bessel functions, jn(z)
   sph_yn   -- [+]Sequence of spherical Bessel functions, yn(z)
   sph_jnyn -- [+]Sequence of spherical Bessel functions, jn(z) and yn(z)
   sph_in   -- [+]Sequence of spherical Bessel functions, in(z)
   sph_kn   -- [+]Sequence of spherical Bessel functions, kn(z)
   sph_inkn -- [+]Sequence of spherical Bessel functions, in(z) and kn(z)

Riccati-Bessel Functions
^^^^^^^^^^^^^^^^^^^^^^^^

These are not universal functions:

.. autosummary::
   :toctree: generated/

   riccati_jn -- [+]Sequence of Ricatti-Bessel functions of first kind.
   riccati_yn -- [+]Sequence of Ricatti-Bessel functions of second kind.

Struve Functions
----------------

.. autosummary::
   :toctree: generated/

   struve       -- Struve function --- Hv(x)
   modstruve    -- Modified Struve function --- Lv(x)
   itstruve0    -- Integral of H0(t) from 0 to x
   it2struve0   -- Integral of H0(t)/t from x to Inf.
   itmodstruve0 -- Integral of L0(t) from 0 to x.


Raw Statistical Functions
-------------------------

.. seealso:: :mod:`scipy.stats`: Friendly versions of these functions.

.. autosummary::
   :toctree: generated/

   bdtr       -- Sum of terms 0 through k of the binomial pdf.
   bdtrc      -- Sum of terms k+1 through n of the binomial pdf.
   bdtri      -- Inverse of bdtr
   btdtr      -- Integral from 0 to x of beta pdf.
   btdtri     -- Quantiles of beta distribution
   fdtr       -- Integral from 0 to x of F pdf.
   fdtrc      -- Integral from x to infinity under F pdf.
   fdtri      -- Inverse of fdtrc
   gdtr       -- Integral from 0 to x of gamma pdf.
   gdtrc      -- Integral from x to infinity under gamma pdf.
   gdtria     -- Inverse with respect to `a` of gdtr.
   gdtrib     -- Inverse with respect to `b` of gdtr.
   gdtrix     -- Inverse with respect to `x` of gdtr.
   nbdtr      -- Sum of terms 0 through k of the negative binomial pdf.
   nbdtrc     -- Sum of terms k+1 to infinity under negative binomial pdf.
   nbdtri     -- Inverse of nbdtr
   pdtr       -- Sum of terms 0 through k of the Poisson pdf.
   pdtrc      -- Sum of terms k+1 to infinity of the Poisson pdf.
   pdtri      -- Inverse of pdtr
   stdtr      -- Integral from -infinity to t of the Student-t pdf.
   stdtridf   --
   stdtrit    --
   chdtr      -- Integral from 0 to x of the Chi-square pdf.
   chdtrc     -- Integral from x to infnity of Chi-square pdf.
   chdtri     -- Inverse of chdtrc.
   ndtr       -- Integral from -infinity to x of standard normal pdf
   ndtri      -- Inverse of ndtr (quantiles)
   smirnov    -- Kolmogorov-Smirnov complementary CDF for one-sided test statistic (Dn+ or Dn-)
   smirnovi   -- Inverse of smirnov.
   kolmogorov -- The complementary CDF of the (scaled) two-sided test statistic (Kn*) valid for large n.
   kolmogi    -- Inverse of kolmogorov
   tklmbda    -- Tukey-Lambda CDF
   logit      --
   expit      --
   boxcox     -- Compute the Box-Cox transformation.
   boxcox1p   -- Compute the Box-Cox transformation.

Gamma and Related Functions
---------------------------

.. autosummary::
   :toctree: generated/

   gamma        -- Gamma function.
   gammaln      -- Log of the absolute value of the gamma function.
   gammasgn     -- Sign of the gamma function.
   gammainc     -- Incomplete gamma integral.
   gammaincinv  -- Inverse of gammainc.
   gammaincc    -- Complemented incomplete gamma integral.
   gammainccinv -- Inverse of gammaincc.
   beta         -- Beta function.
   betaln       -- Log of the absolute value of the beta function.
   betainc      -- Incomplete beta integral.
   betaincinv   -- Inverse of betainc.
   psi          -- Logarithmic derivative of the gamma function.
   rgamma       -- One divided by the gamma function.
   polygamma    -- Nth derivative of psi function.
   multigammaln


Error Function and Fresnel Integrals
------------------------------------

.. autosummary::
   :toctree: generated/

   erf           -- Error function.
   erfc          -- Complemented error function (1- erf(x))
   erfcx         -- Scaled complemented error function exp(x**2)*erfc(x)
   erfi          -- Imaginary error function, -i erf(i x)
   erfinv        -- Inverse of error function
   erfcinv       -- Inverse of erfc
   wofz          -- Fadeeva function.
   dawsn         -- Dawson's integral.
   fresnel       -- Fresnel sine and cosine integrals.
   fresnel_zeros -- Complex zeros of both Fresnel integrals
   modfresnelp   -- Modified Fresnel integrals F_+(x) and K_+(x)
   modfresnelm   -- Modified Fresnel integrals F_-(x) and K_-(x)

These are not universal functions:

.. autosummary::
   :toctree: generated/

   erf_zeros      -- [+]Complex zeros of erf(z)
   fresnelc_zeros -- [+]Complex zeros of Fresnel cosine integrals
   fresnels_zeros -- [+]Complex zeros of Fresnel sine integrals

Legendre Functions
------------------

.. autosummary::
   :toctree: generated/

   lpmv     -- Associated Legendre Function of arbitrary non-negative degree v.
   sph_harm -- Spherical Harmonics (complex-valued) Y^m_n(theta,phi)

These are not universal functions:

.. autosummary::
   :toctree: generated/

   clpmn    -- [+]Associated Legendre Function of the first kind for complex arguments.
   lpn      -- [+]Legendre Functions (polynomials) of the first kind
   lqn      -- [+]Legendre Functions of the second kind.
   lpmn     -- [+]Associated Legendre Function of the first kind for real arguments.
   lqmn     -- [+]Associated Legendre Function of the second kind.

Orthogonal polynomials
----------------------

The following functions evaluate values of orthogonal polynomials:

.. autosummary::
   :toctree: generated/

   eval_legendre
   eval_chebyt
   eval_chebyu
   eval_chebyc
   eval_chebys
   eval_jacobi
   eval_laguerre
   eval_genlaguerre
   eval_hermite
   eval_hermitenorm
   eval_gegenbauer
   eval_sh_legendre
   eval_sh_chebyt
   eval_sh_chebyu
   eval_sh_jacobi

The functions below, in turn, return :ref:`orthopoly1d` objects, which
functions similarly as :ref:`numpy.poly1d`.  The :ref:`orthopoly1d`
class also has an attribute ``weights`` which returns the roots, weights,
and total weights for the appropriate form of Gaussian quadrature.
These are returned in an ``n x 3`` array with roots in the first column,
weights in the second column, and total weights in the final column.

.. autosummary::
   :toctree: generated/

   legendre    -- [+]Legendre polynomial P_n(x) (lpn -- for function).
   chebyt      -- [+]Chebyshev polynomial T_n(x)
   chebyu      -- [+]Chebyshev polynomial U_n(x)
   chebyc      -- [+]Chebyshev polynomial C_n(x)
   chebys      -- [+]Chebyshev polynomial S_n(x)
   jacobi      -- [+]Jacobi polynomial P^(alpha,beta)_n(x)
   laguerre    -- [+]Laguerre polynomial, L_n(x)
   genlaguerre -- [+]Generalized (Associated) Laguerre polynomial, L^alpha_n(x)
   hermite     -- [+]Hermite polynomial H_n(x)
   hermitenorm -- [+]Normalized Hermite polynomial, He_n(x)
   gegenbauer  -- [+]Gegenbauer (Ultraspherical) polynomials, C^(alpha)_n(x)
   sh_legendre -- [+]shifted Legendre polynomial, P*_n(x)
   sh_chebyt   -- [+]shifted Chebyshev polynomial, T*_n(x)
   sh_chebyu   -- [+]shifted Chebyshev polynomial, U*_n(x)
   sh_jacobi   -- [+]shifted Jacobi polynomial, J*_n(x) = G^(p,q)_n(x)

.. warning::

   Large-order polynomials obtained from these functions
   are numerically unstable.

   ``orthopoly1d`` objects are converted to ``poly1d``, when doing
   arithmetic.  ``numpy.poly1d`` works in power basis and cannot
   represent high-order polynomials accurately, which can cause
   significant inaccuracy.


Hypergeometric Functions
------------------------

.. autosummary::
   :toctree: generated/

   hyp2f1   -- Gauss hypergeometric function (2F1)
   hyp1f1   -- Confluent hypergeometric function (1F1)
   hyperu   -- Confluent hypergeometric function (U)
   hyp0f1   -- Confluent hypergeometric limit function (0F1)
   hyp2f0   -- Hypergeometric function (2F0)
   hyp1f2   -- Hypergeometric function (1F2)
   hyp3f0   -- Hypergeometric function (3F0)


Parabolic Cylinder Functions
----------------------------

.. autosummary::
   :toctree: generated/

   pbdv     -- Parabolic cylinder function Dv(x) and derivative.
   pbvv     -- Parabolic cylinder function Vv(x) and derivative.
   pbwa     -- Parabolic cylinder function W(a,x) and derivative.

These are not universal functions:

.. autosummary::
   :toctree: generated/

   pbdv_seq -- [+]Sequence of parabolic cylinder functions Dv(x)
   pbvv_seq -- [+]Sequence of parabolic cylinder functions Vv(x)
   pbdn_seq -- [+]Sequence of parabolic cylinder functions Dn(z), complex z

Mathieu and Related Functions
-----------------------------

.. autosummary::
   :toctree: generated/

   mathieu_a       -- Characteristic values for even solution (ce_m)
   mathieu_b       -- Characteristic values for odd solution (se_m)

These are not universal functions:

.. autosummary::
   :toctree: generated/

   mathieu_even_coef -- [+]sequence of expansion coefficients for even solution
   mathieu_odd_coef  -- [+]sequence of expansion coefficients for odd solution

The following return both function and first derivative:

.. autosummary::
   :toctree: generated/

   mathieu_cem     -- Even Mathieu function
   mathieu_sem     -- Odd Mathieu function
   mathieu_modcem1 -- Even modified Mathieu function of the first kind
   mathieu_modcem2 -- Even modified Mathieu function of the second kind
   mathieu_modsem1 -- Odd modified Mathieu function of the first kind
   mathieu_modsem2 -- Odd modified Mathieu function of the second kind

Spheroidal Wave Functions
-------------------------

.. autosummary::
   :toctree: generated/

   pro_ang1   -- Prolate spheroidal angular function of the first kind
   pro_rad1   -- Prolate spheroidal radial function of the first kind
   pro_rad2   -- Prolate spheroidal radial function of the second kind
   obl_ang1   -- Oblate spheroidal angular function of the first kind
   obl_rad1   -- Oblate spheroidal radial function of the first kind
   obl_rad2   -- Oblate spheroidal radial function of the second kind
   pro_cv     -- Compute characteristic value for prolate functions
   obl_cv     -- Compute characteristic value for oblate functions
   pro_cv_seq -- Compute sequence of prolate characteristic values
   obl_cv_seq -- Compute sequence of oblate characteristic values

The following functions require pre-computed characteristic value:

.. autosummary::
   :toctree: generated/

   pro_ang1_cv -- Prolate spheroidal angular function of the first kind
   pro_rad1_cv -- Prolate spheroidal radial function of the first kind
   pro_rad2_cv -- Prolate spheroidal radial function of the second kind
   obl_ang1_cv -- Oblate spheroidal angular function of the first kind
   obl_rad1_cv -- Oblate spheroidal radial function of the first kind
   obl_rad2_cv -- Oblate spheroidal radial function of the second kind

Kelvin Functions
----------------

.. autosummary::
   :toctree: generated/

   kelvin       -- All Kelvin functions (order 0) and derivatives.
   kelvin_zeros -- [+]Zeros of All Kelvin functions (order 0) and derivatives
   ber          -- Kelvin function ber x
   bei          -- Kelvin function bei x
   berp         -- Derivative of Kelvin function ber x
   beip         -- Derivative of Kelvin function bei x
   ker          -- Kelvin function ker x
   kei          -- Kelvin function kei x
   kerp         -- Derivative of Kelvin function ker x
   keip         -- Derivative of Kelvin function kei x

These are not universal functions:

.. autosummary::
   :toctree: generated/

   ber_zeros    -- [+]Zeros of Kelvin function bei x
   bei_zeros    -- [+]Zeros of Kelvin function ber x
   berp_zeros   -- [+]Zeros of derivative of Kelvin function ber x
   beip_zeros   -- [+]Zeros of derivative of Kelvin function bei x
   ker_zeros    -- [+]Zeros of Kelvin function kei x
   kei_zeros    -- [+]Zeros of Kelvin function ker x
   kerp_zeros   -- [+]Zeros of derivative of Kelvin function ker x
   keip_zeros   -- [+]Zeros of derivative of Kelvin function kei x

Combinatorics
-------------

.. autosummary::
    :toctree: generated/

    comb    -- [+]Combinations of N things taken k at a time, "N choose k"
    perm    -- [+]Permutations of N things taken k at a time, "k-permutations of N"

Other Special Functions
-----------------------

.. autosummary::
   :toctree: generated/

   binom        -- Binomial coefficient.
   expn         -- Exponential integral.
   exp1         -- Exponential integral of order 1 (for complex argument)
   expi         -- Another exponential integral -- Ei(x)
   factorial    -- The factorial function, n! = special.gamma(n+1)
   factorial2   -- Double factorial, (n!)!
   factorialk   -- [+](...((n!)!)!...)! where there are k '!'
   shichi       -- Hyperbolic sine and cosine integrals.
   sici         -- Integral of the sinc and "cosinc" functions.
   spence       -- Dilogarithm integral.
   lambertw     -- Lambert W function
   zeta         -- Riemann zeta function of two arguments.
   zetac        -- Standard Riemann zeta function minus 1.

Convenience Functions
---------------------

.. autosummary::
   :toctree: generated/

   cbrt     -- Cube root.
   exp10    -- 10 raised to the x power.
   exp2     -- 2 raised to the x power.
   radian   -- radian angle given degrees, minutes, and seconds.
   cosdg    -- cosine of the angle given in degrees.
   sindg    -- sine of the angle given in degrees.
   tandg    -- tangent of the angle given in degrees.
   cotdg    -- cotangent of the angle given in degrees.
   log1p    -- log(1+x)
   expm1    -- exp(x)-1
   cosm1    -- cos(x)-1
   round    -- round the argument to the nearest integer. If argument ends in 0.5 exactly, pick the nearest even integer.
   xlogy    -- x*log(y)
   xlog1py  -- x*log1p(y)

.. [+] in the description indicates a function which is not a universal
.. function and does not follow broadcasting and automatic
.. array-looping rules.

@      @      1@L@V@T ?fffff`@_vOn?pddclpnclqncyzofac2jdzojyzolamnlamvlqnbmaxLnd2end2ooddnrctjsegvsphisphjsphksphyxsubzsubcerzoclqmncond1cond2cpbdneulerevennfcoeffcszomask1mask2airyzobernobcsphikcsphjyeulerbklvnzodigammaPmn_derivbernoulliassoc_laguerre[U   s   agms   ai_zeross   assoc_laguerres	   bei_zeross
   beip_zeross	   ber_zeross	   bernoullis
   berp_zeross   bessel_diff_formulas   bi_zeross   clpmns   combs   digammas   dirics   ellipks	   erf_zeross   erfcinvs   erfinvs   errprints   eulers	   factorials
   factorialks
   factorial2s   fresnel_zeross   fresnelc_zeross   fresnels_zeross   gammas   gammalns   h1vps   h2vps   hankel1s   hankel2s   hyp0f1s   ivs   ivps   jn_zeross   jnjnp_zeross	   jnp_zeross
   jnyn_zeross   jvs   jvps	   kei_zeross
   keip_zeross   kelvin_zeross	   ker_zeross
   kerp_zeross   kvs   kvps   lmbdas   lpmns   lpns   lqmns   lqns	   mathieu_as	   mathieu_bs   mathieu_even_coefs   mathieu_odd_coefs   ndtris
   obl_cv_seqs   pbdn_seqs   pbdv_seqs   pbvv_seqs   perms	   polygammas
   pro_cv_seqs   psis
   riccati_jns
   riccati_yns   sincs   sph_harms   sph_ins   sph_inkns   sph_jns   sph_jnyns   sph_kns   sph_yns   y0_zeross   y1_zeross	   y1p_zeross   yn_zeross	   ynp_zeross   yvs   yvps   zetas   SpecialFunctionWarningargument must be > 0.Compute a sequence of characteristic values for the prolate
    spheroidal wave functions for mode m and n'=m..n and spheroidal
    parameter c.
    Argument must be positive scalar integer.m and q must be scalars.Compute nt zeros of the Kelvin function ber x
    Compute nt complex zeros of the sine Fresnel integral S(z).
    Associated Legendre function of the first kind, Pmn(z)

    Computes the (associated) Legendre function of the first kind
    of order m and degree n,::

        Pmn(z) = P_n^m(z)

    and its derivative, ``Pmn'(z)``.  Returns two arrays of size
    ``(m+1, n+1)`` containing ``Pmn(z)`` and ``Pmn'(z)`` for all
    orders from ``0..m`` and degrees from ``0..n``.

    Parameters
    ----------
    m : int
       ``|m| <= n``; the order of the Legendre function.
    n : int
       where ``n >= 0``; the degree of the Legendre function.  Often
       called ``l`` (lower case L) in descriptions of the associated
       Legendre function
    z : float or complex
        Input value.
    type : int
       takes values 2 or 3
       2: cut on the real axis |x|>1
       3: cut on the real axis -1<x<1 (default)

    Returns
    -------
    Pmn_z : (m+1, n+1) array
       Values for all orders 0..m and degrees 0..n
    Pmn_d_z : (m+1, n+1) array
       Derivatives for all orders 0..m and degrees 0..n

    See Also
    --------
    lpmn: associated Legendre functions of the first kind for real z

    Notes
    -----
    By default, i.e. for ``type=3``, phase conventions are chosen according
    to [1]_ such that the function is analytic. The cut lies on the interval
    (-1, 1). Approaching the cut from above or below in general yields a phase
    factor with respect to Ferrer's function of the first kind
    (cf. `lpmn`).

    For ``type=2`` a cut at |x|>1 is chosen. Approaching the real values
    on the interval (-1, 1) in the complex plane yields Ferrer's function
    of the first kind.

    References
    ----------
    .. [1] NIST Digital Library of Mathematical Functions
           http://dlmf.nist.gov/14.21

    m must be an integer >=0.Compute the Ricatti-Bessel function of the first kind and its
    derivative for all orders up to and including n.
    Compute nt zeros of the Bessel functions Jn(x), Jn'(x), Yn(x), and
    Yn'(x), respectively. Returns 4 arrays of length nt.

    See jn_zeros, jnp_zeros, yn_zeros, ynp_zeros to get separate arrays.
    Arithmetic, Geometric Mean

    Start with a_0=a and b_0=b and iteratively compute

    a_{n+1} = (a_n+b_n)/2
    b_{n+1} = sqrt(a_n*b_n)

    until a_n=b_n.   The result is agm(a,b)

    agm(a,b)=agm(b,a)
    agm(a,a) = a
    min(a,b) < agm(a,b) < max(a,b)
    Compute nt complex zeros of the error function erf(z).
    Compute nt complex zeros of the sine and cosine Fresnel integrals
    S(z) and C(z).
    Compute the spherical Bessel functions, in(z) and kn(z) and their
    derivatives for all orders up to and including n.
    Compute nt zeros of the Bessel function Jn(x).
    Compute sequence of Legendre functions of the second kind,
    Qn(z) and derivatives for all degrees from 0 to n (inclusive).
    Compute nt complex zeros of the cosine Fresnel integral C(z).
    Difference between n and m is too large.Compute nt zeros of the Kelvin function ker' x
    Compute sequence of parabolic cylinder functions Dv(x) and
    their derivatives for Dv0(x)..Dv(x) with v0=v-int(v).
    scipy.special.basic/usr/lib/python2.7/dist-packages/scipy/special/basic.pyArguments must be scalar positive integer.Polygamma function which is the nth derivative of the digamma (psi)
    function.

    Parameters
    ----------
    n : array_like of int
        The order of the derivative of `psi`.
    x : array_like
        Where to evaluate the polygamma function.

    Returns
    -------
    polygamma : ndarray
        The result.

    Examples
    --------
    >>> from scipy import special
    >>> x = [2, 3, 25.5]
    >>> special.polygamma(1, x)
    array([ 0.64493407,  0.39493407,  0.03999467])
    >>> special.polygamma(0, x) == special.psi(x)
    array([ True,  True,  True], dtype=bool)

    Number must be integer <= 1200.Compute the spherical Bessel functions, jn(z) and yn(z) and their
    derivatives for all orders up to and including n.
    m must be a non-negative integer.n must be an integer.nt must be positive integer scalar.Compute the spherical Bessel function jn(z) and its derivative for
    all orders up to and including n.
    Return an array of the Bernoulli numbers B0..Bn
    Compute sequence of Legendre functions of the first kind (polynomials),
    Pn(z) and derivatives for all degrees from 0 to n (inclusive).

    See also special.legendre  for polynomial class.
    Compute nt zeros of the Kelvin function ker x
    
    Double factorial.

    This is the factorial with every second value skipped, i.e.,
    ``7!! = 7 * 5 * 3 * 1``.  It can be approximated numerically as::

      n!! = special.gamma(n/2+1)*2**((m+1)/2)/sqrt(pi)  n odd
          = 2**(n/2) * (n/2)!                           n even

    Parameters
    ----------
    n : int or array_like
        Calculate ``n!!``.  Arrays are only supported with `exact` set
        to False.  If ``n < 0``, the return value is 0.
    exact : bool, optional
        The result can be approximated rapidly using the gamma-formula
        above (default).  If `exact` is set to True, calculate the
        answer exactly using integer arithmetic.

    Returns
    -------
    nff : float or int
        Double factorial of `n`, as an int or a float depending on
        `exact`.

    Examples
    --------
    >>> factorial2(7, exact=False)
    array(105.00000000000001)
    >>> factorial2(7, exact=True)
    105L

    
    The number of combinations of N things taken k at a time.

    This is often expressed as "N choose k".

    Parameters
    ----------
    N : int, ndarray
        Number of things.
    k : int, ndarray
        Number of elements taken.
    exact : bool, optional
        If `exact` is False, then floating point precision is used, otherwise
        exact long integer is computed.
    repetition : bool, optional
        If `repetition` is True, then the number of combinations with
        repetition is computed.

    Returns
    -------
    val : int, ndarray
        The total number of combinations.

    Notes
    -----
    - Array arguments accepted only for exact=False case.
    - If k > N, N < 0, or k < 0, then a 0 is returned.

    Examples
    --------
    >>> k = np.array([3, 4])
    >>> n = np.array([10, 10])
    >>> sc.comb(n, k, exact=False)
    array([ 120.,  210.])
    >>> sc.comb(10, 3, exact=True)
    120L
    >>> sc.comb(10, 3, exact=True, repetition=True)
    220L

    arguments must be scalars.q >=0Compute the spherical Bessel function yn(z) and its derivative for
    all orders up to and including n.
    Return the nth derivative of Kv(z) with respect to z.
    m must be an integer > 0Compute sequence of lambda functions with arbitrary order v
    and their derivatives.  Lv0(x)..Lv(x) are computed with v0=v-int(v).
    Compute the spherical Bessel function in(z) and its derivative for
    all orders up to and including n.
    Compute nt zeros of all the Kelvin functions returned in a
    length 8 tuple of arrays of length nt.
    The tuple containse the arrays of zeros of
    (ber, bei, ker, kei, ber', bei', ker', kei')
    Returns nt (complex or real) zeros of Y1(z), z1, and the value
    of Y1'(z1) = Y0(z1) at each zero.
    Compute the zeros of Airy Functions Bi(x) and Bi'(x), b and b'
    respectively, and the associated values of Ai(b') and Ai'(b).

    Returns
    -------
    b[l-1]   -- the lth zero of Bi(x)
    bp[l-1]  -- the lth zero of Bi'(x)
    bi[l-1]  -- Bi(bp[l-1])
    bip[l-1] -- Bi'(b[l-1])
    Associated Legendre function of the first kind, Pmn(z)

    Computes the associated Legendre function of the first kind
    of order m and degree n,::

        Pmn(z) = P_n^m(z)

    and its derivative, ``Pmn'(z)``.  Returns two arrays of size
    ``(m+1, n+1)`` containing ``Pmn(z)`` and ``Pmn'(z)`` for all
    orders from ``0..m`` and degrees from ``0..n``.

    This function takes a real argument ``z``. For complex arguments ``z``
    use clpmn instead.

    Parameters
    ----------
    m : int
       ``|m| <= n``; the order of the Legendre function.
    n : int
       where ``n >= 0``; the degree of the Legendre function.  Often
       called ``l`` (lower case L) in descriptions of the associated
       Legendre function
    z : float
        Input value.

    Returns
    -------
    Pmn_z : (m+1, n+1) array
       Values for all orders 0..m and degrees 0..n
    Pmn_d_z : (m+1, n+1) array
       Derivatives for all orders 0..m and degrees 0..n

    See Also
    --------
    clpmn: associated Legendre functions of the first kind for complex z

    Notes
    -----
    In the interval (-1, 1), Ferrer's function of the first kind is
    returned. The phase convention used for the intervals (1, inf)
    and (-inf, -1) is such that the result is always real.

    References
    ----------
    .. [1] NIST Digital Library of Mathematical Functions
           http://dlmf.nist.gov/14.3

    Compute nt zeros of the Kelvin function kei x
    Return the nth derivative of H2v(z) with respect to z.
    z must be scalar.Return the nth derivative of Yv(z) with respect to z.
    Compute the Ricatti-Bessel function of the second kind and its
    derivative for all orders up to and including n.
    m must be <= n.Returns nt (complex or real) zeros of Y1'(z), z1', and the value
    of Y1(z1') at each zero.
    
    Permutations of N things taken k at a time, i.e., k-permutations of N.

    It's also known as "partial permutations".

    Parameters
    ----------
    N : int, ndarray
        Number of things.
    k : int, ndarray
        Number of elements taken.
    exact : bool, optional
        If `exact` is False, then floating point precision is used, otherwise
        exact long integer is computed.

    Returns
    -------
    val : int, ndarray
        The number of k-permutations of N.

    Notes
    -----
    - Array arguments accepted only for exact=False case.
    - If k > N, N < 0, or k < 0, then a 0 is returned.

    Examples
    --------
    >>> k = np.array([3, 4])
    >>> n = np.array([10, 10])
    >>> perm(n, k)
    array([  720.,  5040.])
    >>> perm(10, 3, exact=True)
    720

    Compute a sequence of characteristic values for the oblate
    spheroidal wave functions for mode m and n'=m..n and spheroidal
    parameter c.
    Compute sequence of parabolic cylinder functions Dn(z) and
    their derivatives for D0(z)..Dn(z).
    nt > 0Compute nt zeros of the Kelvin function bei x
    Return an array of the Euler numbers E0..En (inclusive)
    
    Inverse function for erfc
    Return the nth derivative of H1v(z) with respect to z.
    type must be either 2 or 3.Compute expansion coefficients for even Mathieu functions and
    modified Mathieu functions.
    Arguments must be scalars.
    The factorial function, n! = special.gamma(n+1).

    If exact is 0, then floating point precision is used, otherwise
    exact long integer is computed.

    - Array argument accepted only for exact=False case.
    - If n<0, the return value is 0.

    Parameters
    ----------
    n : int or array_like of ints
        Calculate ``n!``.  Arrays are only supported with `exact` set
        to False.  If ``n < 0``, the return value is 0.
    exact : bool, optional
        The result can be approximated rapidly using the gamma-formula
        above.  If `exact` is set to True, calculate the
        answer exactly using integer arithmetic. Default is False.

    Returns
    -------
    nf : float or int
        Factorial of `n`, as an integer or a float depending on `exact`.

    Examples
    --------
    >>> arr = np.array([3,4,5])
    >>> sc.factorial(arr, exact=False)
    array([   6.,   24.,  120.])
    >>> sc.factorial(5, exact=True)
    120L

    Compute the zeros of Airy Functions Ai(x) and Ai'(x), a and a'
    respectively, and the associated values of Ai(a') and Ai'(a).

    Returns
    -------
    a[l-1]   -- the lth zero of Ai(x)
    ap[l-1]  -- the lth zero of Ai'(x)
    ai[l-1]  -- Ai(ap[l-1])
    aip[l-1] -- Ai'(a[l-1])
    Compute nt zeros of the Bessel function Yn'(x).
    Return the nth derivative of Jv(z) with respect to z.
    Compute nt (<=1200) zeros of the Bessel functions Jn and Jn'
    and arange them in order of their magnitudes.

    Returns
    -------
    zo[l-1] : ndarray
        Value of the lth zero of Jn(x) and Jn'(x). Of length `nt`.
    n[l-1] : ndarray
        Order of the Jn(x) or Jn'(x) associated with lth zero. Of length `nt`.
    m[l-1] : ndarray
        Serial number of the zeros of Jn(x) or Jn'(x) associated
        with lth zero. Of length `nt`.
    t[l-1] : ndarray
        0 if lth zero in zo is zero of Jn(x), 1 if it is a zero of Jn'(x). Of
        length `nt`.

    See Also
    --------
    jn_zeros, jnp_zeros : to get separated arrays of zeros.
    Compute nt zeros of the Bessel function Jn'(x).
    nt must be a positive integer scalar.Compute spherical harmonics.

    This is a ufunc and may take scalar or array arguments like any
    other ufunc.  The inputs will be broadcasted against each other.

    Parameters
    ----------
    m : int
       |m| <= n; the order of the harmonic.
    n : int
       where `n` >= 0; the degree of the harmonic.  This is often called
       ``l`` (lower case L) in descriptions of spherical harmonics.
    theta : float
       [0, 2*pi]; the azimuthal (longitudinal) coordinate.
    phi : float
       [0, pi]; the polar (colatitudinal) coordinate.

    Returns
    -------
    y_mn : complex float
       The harmonic $Y^m_n$ sampled at `theta` and `phi`

    Notes
    -----
    There are different conventions for the meaning of input arguments
    `theta` and `phi`.  We take `theta` to be the azimuthal angle and
    `phi` to be the polar angle.  It is common to see the opposite
    convention - that is `theta` as the polar angle and `phi` as the
    azimuthal angle.
    
    Inverse function for erf
    
    Computes the complete elliptic integral of the first kind.

    This function is defined as

    .. math:: K(m) = \int_0^{\pi/2} [1 - m \sin(t)^2]^{-1/2} dt

    Parameters
    ----------
    m : array_like
        The parameter of the elliptic integral.

    Returns
    -------
    K : array_like
        Value of the elliptic integral.

    Notes
    -----
    For more precision around point m = 1, use `ellipkm1`.

    Argument must be real. Use clpmn instead.Modes must be integers.Confluent hypergeometric limit function 0F1.

    Parameters
    ----------
    v, z : array_like
        Input values.

    Returns
    -------
    hyp0f1 : ndarray
        The confluent hypergeometric limit function.

    Notes
    -----
    This function is defined as:

    .. math:: _0F_1(v,z) = \sum_{k=0}^{\inf}\frac{z^k}{(v)_k k!}.

    It's also the limit as q -> infinity of ``1F1(q;v;z/q)``, and satisfies
    the differential equation :math:``f''(z) + vf'(z) = f(z)`.
    n must be a non-negative integer.Arguments must be integers.Warning, too many predicted coefficients.Returns the periodic sinc function, also called the Dirichlet function:

    diric(x) = sin(x *n / 2) / (n sin(x / 2))

    where n is a positive integer.
    Compute nt zeros of the Kelvin function ber' x
    
    n(!!...!)  = multifactorial of order k
    k times

    Parameters
    ----------
    n : int
        Calculate multifactorial. If `n` < 0, the return value is 0.
    exact : bool, optional
        If exact is set to True, calculate the answer exactly using
        integer arithmetic.

    Returns
    -------
    val : int
        Multi factorial of `n`.

    Raises
    ------
    NotImplementedError
        Raises when exact is False

    Examples
    --------
    >>> sc.factorialk(5, 1, exact=True)
    120L
    >>> sc.factorialk(5, 3, exact=True)
    10L

    Compute the spherical Bessel function kn(z) and its derivative for
    all orders up to and including n.
    Compute nt zeros of the Bessel function Yn(x).
    Associated Legendre functions of the second kind, Qmn(z) and its
    derivative, ``Qmn'(z)`` of order m and degree n.  Returns two
    arrays of size ``(m+1, n+1)`` containing ``Qmn(z)`` and ``Qmn'(z)`` for
    all orders from ``0..m`` and degrees from ``0..n``.

    z can be complex.
    Compute nt zeros of the Kelvin function kei' x
    Compute nt zeros of the Kelvin function bei' x
    Return the nth derivative of Iv(z) with respect to z.
    Returns nt (complex or real) zeros of Y0(z), z0, and the value
    of Y0'(z0) = -Y1(z0) at each zero.
    (   t   pit   asarrayt   floort   isscalart	   iscomplext   realt   imagt   sqrtt   wheret   mgridt   cost   sint   expt   placet   seterrt
   issubdtypet   extractt   lesst	   vectorizet   inexactt   nant   zerost   sometruet
   atleast_1dt   sinc/usr/lib/python2.7/dist-packages/scipy/special/lambertw.pyscipy.special.lambertw
    lambertw(z, k=0, tol=1e-8)

    Lambert W function [1]_.

    The Lambert W function `W(z)` is defined as the inverse function
    of ``w * exp(w)``. In other words, the value of ``W(z)`` is
    such that ``z = W(z) * exp(W(z))`` for any complex number
    ``z``.

    The Lambert W function is a multivalued function with infinitely
    many branches. Each branch gives a separate solution of the
    equation ``z = w exp(w)``. Here, the branches are indexed by the
    integer `k`.

    Parameters
    ----------
    z : array_like
        Input argument.
    k : int, optional
        Branch index.
    tol : float, optional
        Evaluation tolerance.

    Returns
    -------
    w : array
        `w` will have the same shape as `z`.

    Notes
    -----
    All branches are supported by `lambertw`:

    * ``lambertw(z)`` gives the principal solution (branch 0)
    * ``lambertw(z, k)`` gives the solution on branch `k`

    The Lambert W function has two partially real branches: the
    principal branch (`k = 0`) is real for real ``z > -1/e``, and the
    ``k = -1`` branch is real for ``-1/e < z < 0``. All branches except
    ``k = 0`` have a logarithmic singularity at ``z = 0``.

    **Possible issues**

    The evaluation can become inaccurate very close to the branch point
    at ``-1/e``. In some corner cases, `lambertw` might currently
    fail to converge, or can end up on the wrong branch.

    **Algorithm**

    Halley's iteration is used to invert ``w * exp(w)``, using a first-order
    asymptotic approximation (O(log(w)) or `O(w)`) as the initial estimate.

    The definition, implementation and choice of branches is based on [2]_.

    References
    ----------
    .. [1] http://en.wikipedia.org/wiki/Lambert_W_function
    .. [2] Corless et al, "On the Lambert W function", Adv. Comp. Math. 5
       (1996) 329-359.
       http://www.apmaths.uwo.ca/~djeffrey/Offprints/W-adv-cm.pdf

    Examples
    --------
    The Lambert W function is the inverse of ``w exp(w)``:

    >>> from scipy.special import lambertw
    >>> w = lambertw(1)
    >>> w
    (0.56714329040978384+0j)
    >>> w*exp(w)
    (1.0+0j)

    Any branch gives a valid inverse:

    >>> w = lambertw(1, k=3)
    >>> w
    (-2.8535817554090377+17.113535539412148j)
    >>> w*np.exp(w)
    (1.0000000000000002+1.609823385706477e-15j)

    **Applications to equation-solving**

    The Lambert W function may be used to solve various kinds of
    equations, such as finding the value of the infinite power
    tower :math:`z^{z^{z^{\ldots}}}`:

    >>> def tower(z, n):
    ...     if n == 0:
    ...         return z
    ...     return z ** tower(z, n-1)
    ...
    >>> tower(0.5, 100)
    0.641185744504986
    >>> -lambertw(-np.log(0.5)) / np.log(0.5)
    (0.64118574450498589+0j)
    an_Jan_Jsan_Lasbn_Jsbn_Jssbn_Lasortindu_rootscg_rootsnormcoefts_rootsus_roots_eval_funcweight_func[/   s   legendres   chebyts   chebyus   chebycs   chebyss   jacobis   laguerres   genlaguerres   hermites   hermitenorms
   gegenbauers   sh_legendres	   sh_chebyts	   sh_chebyus	   sh_jacobis   p_rootss   ps_rootss   j_rootss   js_rootss   l_rootss   la_rootss   he_rootss   ts_rootss   us_rootss   s_rootss   t_rootss   u_rootss   c_rootss   cg_rootss   h_rootss   eval_legendres   eval_chebyts   eval_chebyus   eval_chebycs   eval_chebyss   eval_jacobis   eval_laguerres   eval_genlaguerres   eval_hermites   eval_hermitenorms   eval_gegenbauers   eval_sh_legendres   eval_sh_chebyts   eval_sh_chebyus   eval_sh_jacobis   pochs   binom[x,w] = p_roots(n)

    Returns the roots (x) of the nth order Legendre polynomial, P_n(x),
    and weights (w) to use in Gaussian Quadrature over [-1,1] with weighting
    function 1.
    [x,w] = la_roots(n,alpha)

    Returns the roots (x) of the nth order generalized (associated) Laguerre
    polynomial, L^(alpha)_n(x), and weights (w) to use in Gaussian quadrature over
    [0,inf] with weighting function exp(-x) x**alpha with alpha > -1.
    Compute the roots and weights for Gaussian-Hermite quadrature.
    Internal function.
    [x,w] = j_roots(n,alpha,beta)

    Returns the roots (x) of the nth order Jacobi polynomial, P^(alpha,beta)_n(x)
    and weights (w) to use in Gaussian Quadrature over [-1,1] with weighting
    function (1-x)**alpha (1+x)**beta with alpha,beta > -1.
    Return nth order shifted Chebyshev polynomial of first kind, Tn(x).
    Orthogonal over [0,1] with weight function (x-x**2)**(-1/2).
    Return the nth order Laguerre polynoimal, L_n(x), orthogonal over
    [0,inf) with weighting function exp(-x)
    Return nth order Chebyshev polynomial of second kind, Sn(x).  Orthogonal
    over [-2,2] with weight function (1-(x/)**2)**(1/2).
    [x,w] = cg_roots(n,alpha)

    Returns the roots (x) of the nth order Ultraspherical (Gegenbauer)
    polynomial, C^(alpha)_n(x), and weights (w) to use in Gaussian Quadrature
    over [-1,1] with weighting function (1-x**2)**(alpha-1/2) with alpha>-1/2.
    [x,w] = l_roots(n)

    Returns the roots (x) of the nth order Laguerre polynomial, L_n(x),
    and weights (w) to use in Gaussian Quadrature over [0,inf] with weighting
    function exp(-x).
    n must be nonnegative.Returns the nth order Jacobi polynomial, G_n(p,q,x)
    orthogonal over [0,1] with weighting function
    (1-x)**(p-q) (x)**(q-1) with p>q-1 and q > 0.
    [x,w] = t_roots(n)

    Returns the roots (x) of the nth order Chebyshev (of the first kind)
    polynomial, T_n(x), and weights (w) to use in Gaussian Quadrature
    over [-1,1] with weighting function (1-x**2)**(-1/2).
    [x,w] = he_roots(n)

    Returns the roots (x) of the nth order Hermite polynomial,
    He_n(x), and weights (w) to use in Gaussian Quadrature over
    [-inf,inf] with weighting function exp(-(x/2)**2).
    Returns the nth order Jacobi polynomial, P^(alpha,beta)_n(x)
    orthogonal over [-1,1] with weighting function
    (1-x)**alpha (1+x)**beta with alpha,beta > -1.
    (p - q) > -1 and q > 0 please.Return the nth order normalized Hermite polynomial, He_n(x), orthogonal
    over (-inf,inf) with weighting function exp(-(x/2)**2)
    Return the nth order Gegenbauer (ultraspherical) polynomial,
    C^(alpha)_n(x), orthogonal over [-1,1] with weighting function
    (1-x**2)**(alpha-1/2) with alpha > -1/2
    
A collection of functions to find the weights and abscissas for
Gaussian Quadrature.

These calculations are done by finding the eigenvalues of a
tridiagonal matrix whose entries are dependent on the coefficients
in the recursion formula for the orthogonal polynomials with the
corresponding weighting function over the interval.

Many recursion relations for orthogonal polynomials are given:

.. math::

    a1n f_{n+1} (x) = (a2n + a3n x ) f_n (x) - a4n f_{n-1} (x)

The recursion relation of interest is

.. math::

    P_{n+1} (x) = (x - A_n) P_n (x) - B_n P_{n-1} (x)

where :math:`P` has a different normalization than :math:`f`.

The coefficients can be found as:

.. math::

    A_n = -a2n / a3n
    \qquad
    B_n = ( a4n / a3n \sqrt{h_n-1 / h_n})^2

where

.. math::

    h_n = \int_a^b w(x) f_n(x)^2

assume:

.. math::

    P_0 (x) = 1
    \qquad
    P_{-1} (x) == 0

For the mathematical background, see [golub.welsch-1969-mathcomp]_ and
[abramowitz.stegun-1965]_.

Functions::

  gen_roots_and_weights  -- Generic roots and weights.
  j_roots                -- Jacobi
  js_roots               -- Shifted Jacobi
  la_roots               -- Generalized Laguerre
  h_roots                -- Hermite
  he_roots               -- Hermite (unit-variance)
  cg_roots               -- Ultraspherical (Gegenbauer)
  t_roots                -- Chebyshev of the first kind
  u_roots                -- Chebyshev of the second kind
  c_roots                -- Chebyshev of the first kind ([-2,2] interval)
  s_roots                -- Chebyshev of the second kind ([-2,2] interval)
  ts_roots               -- Shifted Chebyshev of the first kind.
  us_roots               -- Shifted Chebyshev of the second kind.
  p_roots                -- Legendre
  ps_roots               -- Shifted Legendre
  l_roots                -- Laguerre


.. [golub.welsch-1969-mathcomp]
   Golub, Gene H, and John H Welsch. 1969. Calculation of Gauss
   Quadrature Rules. *Mathematics of Computation* 23, 221-230+s1--s10.

.. [abramowitz.stegun-1965]
   Abramowitz, Milton, and Irene A Stegun. (1965) *Handbook of
   Mathematical Functions: with Formulas, Graphs, and Mathematical
   Tables*. Gaithersburg, MD: National Bureau of Standards.
   http://www.math.sfu.ca/~cbm/aands/

[x,w] = us_roots(n)

    Returns the roots (x) of the nth order shifted Chebyshev (of the second kind)
    polynomial, U^*_n(x), and weights (w) to use in Gaussian Quadrature
    over [0,1] with weighting function (x-x**2)**1/2.
    alpha and beta must be greater than -1.[x,w] = js_roots(n,p,q)

    Returns the roots (x) of the nth order shifted Jacobi polynomial, G_n(p,q,x),
    and weights (w) to use in Gaussian Quadrature over [0,1] with weighting
    function (1-x)**(p-q) x**(q-1) with p-q > -1 and q > 0.
    [x,w] = h_roots(n)

    Returns the roots (x) of the nth order Hermite polynomial,
    H_n(x), and weights (w) to use in Gaussian Quadrature over
    [-inf,inf] with weighting function exp(-x**2).
    Returns the nth order shifted Legendre polynomial, P^*_n(x), orthogonal
    over [0,1] with weighting function 1.
    [x,w] = gen_roots_and_weights(n,an_func,sqrt_bn_func,mu)

    Returns the roots (x) of an nth order orthogonal polynomial,
    and weights (w) to use in appropriate Gaussian quadrature with that
    orthogonal polynomial.

    The polynomials have the recurrence relation
          P_n+1(x) = (x - A_n) P_n(x) - B_n P_n-1(x)

    an_func(n)          should return A_n
    sqrt_bn_func(n)     should return sqrt(B_n)
    mu ( = h_0 )        is the integral of the weight over the orthogonal interval
    Return nth order Chebyshev polynomial of first kind, Tn(x).  Orthogonal
    over [-1,1] with weight function (1-x**2)**(-1/2).
    Returns the nth order Legendre polynomial, P_n(x), orthogonal over
    [-1,1] with weight function 1.
    Return nth order Chebyshev polynomial of second kind, Un(x).  Orthogonal
    over [-1,1] with weight function (1-x**2)**(1/2).
    [x,w] = c_roots(n)

    Returns the roots (x) of the nth order Chebyshev (of the first kind)
    polynomial, C_n(x), and weights (w) to use in Gaussian Quadrature
    over [-2,2] with weighting function (1-(x/2)**2)**(-1/2).
    Return the nth order Hermite polynomial, H_n(x), orthogonal over
    (-inf,inf) with weighting function exp(-x**2)
    alpha must be > -1Returns the nth order generalized (associated) Laguerre polynomial,
    L^(alpha)_n(x), orthogonal over [0,inf) with weighting function
    exp(-x) x**alpha with alpha > -1
    [x,w] = ps_roots(n)

    Returns the roots (x) of the nth order shifted Legendre polynomial, P^*_n(x),
    and weights (w) to use in Gaussian Quadrature over [0,1] with weighting
    function 1.
    /usr/lib/python2.7/dist-packages/scipy/special/orthogonal.py[x,w] = ts_roots(n)

    Returns the roots (x) of the nth order shifted Chebyshev (of the first kind)
    polynomial, T^*_n(x), and weights (w) to use in Gaussian Quadrature
    over [0,1] with weighting function (x-x**2)**(-1/2).
    Return nth order shifted Chebyshev polynomial of second kind, Un(x).
    Orthogonal over [0,1] with weight function (x-x**2)**(1/2).
    Return nth order Chebyshev polynomial of first kind, Cn(x).  Orthogonal
    over [-2,2] with weight function (1-(x/2)**2)**(-1/2).
    [x,w] = s_roots(n)

    Returns the roots (x) of the nth order Chebyshev (of the second kind)
    polynomial, S_n(x), and weights (w) to use in Gaussian Quadrature
    over [-2,2] with weighting function (1-(x/2)**2)**1/2.
    [x,w] = u_roots(n)

    Returns the roots (x) of the nth order Chebyshev (of the second kind)
    polynomial, U_n(x), and weights (w) to use in Gaussian Quadrature
    over [-1,1] with weighting function (1-x**2)**1/2.
    n must be positive./usr/lib/python2.7/dist-packages/scipy/special/spfun_stats.pySome more special functions which may be useful for multivariate statistical
analysis.condition a (%f) > 0.5 * (d-1) (%f) not metscipy.special.spfun_statsReturns the log of multivariate gamma, also sometimes called the
    generalized gamma.

    Parameters
    ----------
    a : ndarray
        The multivariate gamma is computed for each item of `a`.
    d : int
        The dimension of the space of integration.

    Returns
    -------
    res : ndarray
        The values of the log multivariate gamma at the given points `a`.

    Notes
    -----
    The formal definition of the multivariate gamma of dimension d for a real a
    is::

        \Gamma_d(a) = \int_{A>0}{e^{-tr(A)\cdot{|A|}^{a - (m+1)/2}dA}}

    with the condition ``a > (d-1)/2``, and ``A > 0`` being the set of all the
    positive definite matrices of dimension s.  Note that a is a scalar: the
    integrand only is multivariate, the argument is not (the function is
    defined over a subset of the real set).

    This can be proven to be equal to the much friendlier equation::

        \Gamma_d(a) = \pi^{d(d-1)/4}\prod_{i=1}^{d}{\Gamma(a - (i-1)/2)}.

    References
    ----------
    R. J. Muirhead, Aspects of multivariate statistical theory (Wiley Series in
    probability and mathematical statistics).

    d should be a positive integer (dimension)/usr/lib/python2.7/dist-packages/scipy/version.pyf2ec91c4908f9d67b5445fbfacce7f47518b35d1do_not_openhandler_moduleserial_for_url%s.protocol_%s    Get an instance of the Serial class, depending on port/url. The port is not
    opened when the keyword parameter 'do_not_open' is true, by default it
    is. All other parameters are directly passed to the __init__ method when
    the port is instantiated.

    The list of package names that is searched for protocol handlers is kept in
    ``protocol_handler_packages``.

    e.g. we want to support a URL ``foobar://``. A module
    ``my_handlers.protocol_foobar`` is provided by the user. Then
    ``protocol_handler_packages.append("my_handlers")`` would extend the search
    path so that ``serial_for_url("foobar://"))`` would work.
    serial.urlhandlerinvalid URL, protocol %r not known/usr/lib/python2.7/dist-packages/serial/usr/lib/python2.7/dist-packages/serial/__init__.pyPortsXOnXOffDataBitsReadByteCDHoldingDtrEnableHandshakeRtsEnableserialcliBreakStateCtsHoldingDsrHoldingBytesToReadReadTimeoutGetPortNamesOnePointFiveWriteTimeout_port_handleRequestToSendDiscardInBufferInfiniteTimeoutDiscardOutBufferRequestToSendXOnXOffInvalidOperationExceptionSystem.IO.PortsSerial port implemenation for .NET/Mono./usr/lib/python2.7/dist-packages/serial/serialcli.pyisCDisRIisCTSisDSRsPortportIdgetName_instreamDATABITS_5DATABITS_6DATABITS_7DATABITS_8STOPBITS_1STOPBITS_2_jstopbits_outstreamserialjavaPORT_SERIALgetPortTypenextElementSTOPBITS_1_5getInputStreamgetOutputStreamhasMoreElementsgetPortIdentifierCommPortIdentifiergetPortIdentifierssetFlowControlModesetSerialPortParamsenableReceiveTimeoutFLOWCONTROL_RTSCTS_INdisableReceiveTimeoutFLOWCONTROL_RTSCTS_OUTFLOWCONTROL_XONXOFF_INFLOWCONTROL_XONXOFF_OUTjavax.commgnu.iounsupported bytesize: %rThe setBreak function is not implemented in java.Could not open port: %sNo Java Communications API implementation foundSerial port class, implemented with Java Communications API and
       thus usable with jython and the appropriate java extension.unsupported parity type: %rpython serial module/usr/lib/python2.7/dist-packages/serial/serialjava.pytry given list of modules and return that importsunsupported number of stopbits: %rCS5CS6CS7CS8ECHOISIGIXONVMINpollCREADCSIZEECHOEECHOKICRNLIGNCRINLCRINPCKIUCLCIXANYIXOFFOPOSTTCIONVTIMEioctlB38400CLOCALCSTOPBEAGAINECHOKEECHONLICANONIEXTENIGNBRKISTRIPO_RDWRPARENBPARMRKPARODDPOLLINTCIOFFtcflowCRTSCTSECHOCTLF_SETFLPOLLERRPOLLHUPTCSANOWtcdraintcflushFIONREADO_NOCTTYPOLLNVALTCIFLUSHTCOFLUSHTIOCMSETtimelefttcgetattrtcsetattrO_NONBLOCKCNEW_RTSCTSIOSSIOSPEEDTIOCGSERIALTIOCSSERIALdrainOutputflowControlnonblockingserialposixtcsendbreakPosixPollSerial{i 	= i  i  i  i   i   i   i   i  i
   i   i  i`	  i   i  i  i@B i  i    i    i  i  i  i	  i i  i,  i   i2   i   i  i	   i%  i   i   i   i- i  i  i   i  i  i  i  i   i   iK   i   i  i  iX  i   i K  i   ig5 i  i` i
  in   i   i%& i  0[    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    i    internal - not portable!Could not configure port: %swrite failed: %sInvalid parity: %rpoll based read implementation. not all systems support poll properly.
    however this one has better handling of errors, such as a device
    disconnecting while it's in use (e.g. USB-serial unplugged)For easier use of the serial port instance with select.
           WARNING: this function is not portable to different platforms!/dev/tty%dp0Serial port class POSIX implementation. Serial port configuration is 
    done with termios and fcntl. Runs on Linux and many other Un*x like
    systems.Invalid vmin: %r /usr/lib/python2.7/dist-packages/serial/serialposix.pydevice reports error (poll)/dev/com%ddon't know how to number ttys on this system.
! Use an explicit path (eg /dev/ttyS1) or send this information to
! the author of this module:

sys.platform = %r
os.name = %r
serialposix.py version = %s

also add the device name of the serial port and where the
counting starts for the first serial port.
e.g. 'first serial port: /dev/ttyS0'
and with a bit luck you can get this module running...
Invalid baud rate: %rsorry don't know how to handle non standard baud rate on this platformInvalid stop bit specification: %r/dev/ttyp%ddevice reports readiness to read but returned no data (device disconnected?)baud rate not supported/dev/tty%cFailed to set custom baud rate: %r/dev/dty%02dInvalid char len: %rmanually control flow - when hardware or software flow control is
        enabled/dev/ttyf%dCan only operate on a valid file descriptor/dev/cuad%dB%s/dev/ttyS%dFlush of file like objects. In this case, wait until all data
           is written.Set break: Controls TXD. When active, no transmitting is possible.Invalid vtime: %risOpensetPortPARITIESseekablewas_openBYTESIZES_SETTINGSgetDsrDtrgetParitygetRtsCtssetDsrDtrsetParitysetRtsCtsgetTimeoutgetXonXoffserialutilsetTimeoutsetXonXoffxreadlinesgetBaudrategetByteSizegetStopbitssetBaudratesetByteSizesetStopbitsgetSettingsDictgetWriteTimeoutsetWriteTimeoutapplySettingsDictgetInterCharTimeoutsetInterCharTimeoutgetSupportedParitiesgetSupportedStopbitsgetSupportedBaudratesgetSupportedByteSizesBaud rate settingXON/XOFF settingParity settingRTS/CTS flow control settingTimeout setting for write()Inter-character timeout setting for read()Timeout setting for read()Port settingStop bits settingByte size settingDSR/DTR flow control settingNot a valid baudrate: %rGet the current parity setting.Get current port settings as a dictionary. For use with
        applySettingsDictGet the current inter-character timeout setting./usr/lib/python2.7/dist-packages/serial/serialutil.pyGet the current DSR/DTR flow control setting.Not a valid parity: %rChange byte size.Serial port base class. Provides __init__ function and properties to
       get/set port settings.apply stored settings from a dictionary returned from
        getSettingsDict. it's allowed to delete keys from the dictionary. these
        values will simply left unchanged.Change parity setting.An abstract file like class.

    This class implements readline and readlines based on read and
    writelines based on write.
    This class is used to provide the above functions for to Serial
    port objects.

    Note that when the serial port was opened with _NO_ timeout that
    readline blocks until it sees a newline (or the specified size is
    reached) and that readlines would never return and therefore
    refuses to work (it raises an exception in this case)!
    Get the current baud rate setting.Get the current XON/XOFF setting.read a line which is terminated with end-of-line (eol) character
        ('
' by default) or until timeout.Get the current timeout setting.flush of file like objectsChange baud rate. It raises a ValueError if the port is open and the
        baud rate is not possible. If the port is closed, then the value is
        accepted and the exception is raised when the port is opened.bytearray(%r)Initialize comm port object. If a port is given, then the port will be
           opened immediately. Otherwise a Serial port object in closed state
           is returned.Get the current stop bits setting.Change DsrDtr flow control setting.Not a valid stop bit size: %rCheck if the port is opened.Destructor.  Calls close().Change timeout setting.Attempting to use a port that is not openGet the current port setting. The value that was passed on init or using
           setPort() is passed back. See also the attribute portstr which contains
           the name of the port as a string.Change RTS/CTS flow control setting.Read lines, implemented as generator. It will raise StopIteration on
        timeout (empty read). sizehint is ignored.Change the port. The attribute portstr is set to a string that
           contains the name of the port.%s<id=0x%x, open=%s>(port=%r, baudrate=%r, bytesize=%r, parity=%r, stopbits=%r, timeout=%r, xonxoff=%r, rtscts=%r, dsrdtr=%r)Serial port MUST have enabled timeout for this function!Get the current byte size setting.convert a sequence to a bytes typeString representation of the current port settings and its state.Not a valid byte size: %rread a list of lines, until timeout.
        sizehint is ignored.Change inter-character timeout setting.file is not seekableGet the current RTS/CTS flow control setting.Change stop bits size.Change XON/XOFF setting.Write timeouts give an exceptionNot a valid timeout: %rBase class for serial port related exceptions.(   i2   iK   in   i   i   i   i,  iX  i  i  i`	  i  i%  i K  i   i   i  i  i  i  i  i  i@B i  i` i i%& i- ig5 i 	= comDCBsetXONcomstathComPort_dtrState_rtsState_rtsToggleoutWaitingserialwin32_orgTimeoutsgetRtsTogglesetRtsToggle_overlappedRead_overlappedWrite_GetCommModemStatuscreate_string_bufferRTS toggle control settingWriteFile failed (%s)Serial port implementation for Win32 based on ctypes.Platform specific - set flow state.Cannot configure port, some setting was wrong. Original message: %sGet the current RTS toggle control setting.return how many characters the in the outgoing bufferChange RTS toggle control setting.ReadFile failed (%s)call to ClearCommError failedCOM%d/usr/lib/python2.7/dist-packages/serial/serialwin32.py\\.\/usr/lib/python2.7/dist-packages/serial/tools/__init__.pyserial.toolsstore_const%prog [options] [<regexp>]Miniterm - A simple terminal program for the serial port.suppress all messagesprint debug messages and tracebacks (development mode)show more messages (can be given multiple times)    desc: %sThis module will provide a function called comports that returns an
iterable (generator or list) that will enumerate available com ports. Note that
on some systems non-existent ports may be listed.

Additionally a grep function is supplied that can be used to search for ports
based on their descriptions or hardware ID.
Filtered list with regexp: %r    Search for ports using a regular expression. Port name, description and
    hardware ID are searched. The function returns an iterable that returns the
    same tuples as comport() would do.
    %d ports found/usr/lib/python2.7/dist-packages/serial/tools/list_ports.pyno ports found%-20smore than one regexp not supported    hwid: %sSTDOUTpopen4ttyACMsnr_txtsys_usbidVendorsys_id_pathsys_dev_pathlist_ports_posix/dev/cuad*/dev/tty*p0Try to get a HW identification using sysfslsusb failed/dev/tty*c/dev/ttyp*/dev/tty.* SNR=%s/idVendorgiven a path to a usb device in sysfs, return a string describing itiProduct\s+\w+ (.+)/idProduct/usr/lib/python2.7/dist-packages/serial/tools/list_ports_posix.pyhelp function to read a single line from a file. returns nonesearch for regexp in text, return 1st group on matchdon't know how to enumerate ttys on this system.
! I you know how the serial ports are named send this information to
! the author of this module:

sys.platform = %r
os.name = %r
pySerial version = %s

also add the naming scheme of the serial ports and with a bit luck you can get
this module running...
/dev/ttyS*/sys/class/tty/%s/device/driver/%sUSB VID:PID=%s:%s%sidVendor\s+0x\w+ (.+)iManufacturer\s+\w+ (.+)/dev/ttyACM*idProduct\s+0x\w+ (.+)        Get a human readable description.
        For USB-Serial devices try to run lsusb to get a human readable description.
        For USB-CDC devices read the description from sysfs.
        /sys/class/tty/%s/device/interface/dev/dty*/dev/ttyf*scan for available ports. return a list of device names./dev/ttyUSB*/dev/com*/sys/class/tty/%s/device/idiSerial\s+\w+ (.+)hkeyData1Data2Data3Data4PHKEYREG_SZcbSizewindllDevInstdevinfodwIndexAdvapi32c_char_perrcheckClassGuidDevicePathLoadLibraryszHardwareIDszFriendlyNameRegQueryValueExAport_name_bufferport_name_lengthInterfaceClassGuidlist_ports_windowsSetupDiGetClassDevsASetupDiGetDeviceInterfaceDetailAClassGuid:%s DevInst:%s{%08x-%04x-%04x-%s-%s}InterfaceClassGuid:%s Flags:%s%02x/usr/lib/python2.7/dist-packages/serial/tools/list_ports_windows.pyThis generator scans the device registry for com ports and yields port, desc, hwidDevicePath:%sGet a buffer for a stringSetupDiGetDeviceRegistryPropertyAfEoffTximEV_CTSEV_DSRXonLimEV_PERREV_RINGEV_RLSDEofCharEvtCharXoffLimfDummy2nLengthEV_BREAKfCtsHoldfDsrHoldkernel32DCBlengthEV_EVENT1EV_EVENT2EV_RXCHAREV_RXFLAGErrorCharfReservedfRlsdHoldfXoffHoldfXoffSentwReservedEV_TXEMPTYOffsetHighwReserved1EV_RX80FULL_anonymous_InternalHighbInheritHandlefDsrSensitivityfTXContinueOnXoffReadIntervalTimeoutlpSecurityDescriptorReadTotalTimeoutConstantWriteTotalTimeoutConstantReadTotalTimeoutMultiplierWriteTotalTimeoutMultiplier[R   s   GetLastErrors	   MS_CTS_ONs   FILE_ATTRIBUTE_NORMALs   DTR_CONTROL_ENABLEs   _COMSTATs
   MS_RLSD_ONs   GetOverlappedResults   SETXONs   PURGE_TXABORTs	   PurgeComms   N11_OVERLAPPED4DOLLAR_48Es   EV_RINGs
   ONESTOPBITs   SETXOFFs   PURGE_RXABORTs   GetCommStates   RTS_CONTROL_ENABLEs   _DCBs   CreateEvents   _COMMTIMEOUTSs   _SECURITY_ATTRIBUTESs   EV_DSRs   EV_PERRs	   EV_RXFLAGs   OPEN_EXISTINGs   DCBs   FILE_FLAG_OVERLAPPEDs   EV_CTSs	   SetupComms   LPOVERLAPPEDs
   EV_TXEMPTYs   ClearCommBreaks   LPSECURITY_ATTRIBUTESs   SetCommBreaks   SetCommTimeoutss   COMMTIMEOUTSs	   ODDPARITYs   EV_RLSDs   GetCommModemStatuss	   EV_EVENT2s   PURGE_TXCLEARs   EV_BREAKs
   EVENPARITYs   LPCVOIDs   COMSTATs   ReadFiles   PVOIDs   _OVERLAPPEDs	   WriteFiles   GetCommTimeoutss
   ResetEvents	   EV_RXCHARs	   LPCOMSTATs   ClearCommErrors   ERROR_IO_PENDINGs   EscapeCommFunctions   GENERIC_READs   RTS_CONTROL_HANDSHAKEs
   OVERLAPPEDs   DTR_CONTROL_HANDSHAKEs   PURGE_RXCLEARs   GENERIC_WRITEs   LPDCBs   CreateEventWs   SetCommMasks	   EV_EVENT1s   SetCommStates   LPVOIDs   CreateFileWs   LPDWORDs   EV_RX80FULLs   TWOSTOPBITSs   LPCOMMTIMEOUTSs   MAXDWORDs	   MS_DSR_ONs
   MS_RING_ONs#   N11_OVERLAPPED4DOLLAR_484DOLLAR_49Es   EV_ERRs	   ULONG_PTRs
   CreateFiles   NOPARITYs   CloseHandle/usr/lib/python2.7/dist-packages/serial/win32.pyReturns true when running on a 64 bit systemez_setup_all_dirsfollowlinks_build_filterrequire_parentsPEP420PackageFinder_find_packages_iter_looks_like_packagerun_2to3_on_doctestslib2to3_fixer_packagesPYTHONDONTWRITEBYTECODE_PackageFinder__iterator
        Return all dirs in base_path, relative to base_path
        lib2to3.fixes
        Given a list of patterns, return a callable that will be true only if
        the input matches one of the patterns.
        Return a list all Python packages found within directory 'where'

        'where' should be supplied as a "cross-platform" (i.e. URL-style)
        path; it will be converted to the appropriate local path syntax.
        'exclude' is a sequence of package names to exclude; '*' can be used
        as a wildcard in the names, such that 'foo.*' will exclude all
        subpackages of 'foo' (but not 'foo' itself).

        'include' is a sequence of package names to include.  If it's
        specified, only the named packages will be included.  If it's not
        specified, all found packages will be included.  'include' can contain
        shell style wildcard patterns just like 'exclude'.

        The list of included packages is built up first and then any
        explicitly excluded packages are removed from it.
        /usr/lib/python2.7/dist-packages/setuptools/__init__.py*__pycache__
        Exclude any apparent package that apparently doesn't include its
        parent.

        For example, exclude 'foo.bar' if 'foo' is not present.
        Extensions to the 'distutils' for large or complex distributionsFind all files under 'dir' and return the list of full filenames
    (relative to 'dir').
    islnkissymTarErrorcopystatlinknamelinkpathfinal_dstis_zipfileExtractErrorarchive_utilexternal_attr_extract_memberunix_attributesCouldn't recognize the archive typeThe default progress/filter callback; returns True for all filesUnpack tar/tar.gz/tar.bz2 `filename` to `extract_dir`

    Raises ``UnrecognizedFormat`` if `filename` is not a tarfile (as determined
    by ``tarfile.open()``).  See ``unpack_archive()`` for an explanation
    of the `progress_filter` argument.
    Unpack `filename` to `extract_dir`, or raise ``UnrecognizedFormat``

    `progress_filter` is a function taking two arguments: a source path
    internal to the archive ('/'-separated), and a filesystem path where it
    will be extracted.  The callback must return the desired extract path
    (which may be the same as the one passed in), or else ``None`` to skip
    that file or directory.  The callback can thus be used to report on the
    progress of the extraction, as well as to filter the items extracted or
    alter their extraction paths.

    `drivers`, if supplied, must be a non-empty sequence of functions with the
    same signature as this function (minus the `drivers` argument), that raise
    ``UnrecognizedFormat`` if they do not support extracting the designated
    archive type.  The `drivers` are tried in sequence until one is found that
    does not raise an error, or until all are exhausted (in which case
    ``UnrecognizedFormat`` is raised).  If you do not supply a sequence of
    drivers, the module's ``extraction_drivers`` constant will be used, which
    means that ``unpack_zipfile`` and ``unpack_tarfile`` will be tried, in that
    order.
    /usr/lib/python2.7/dist-packages/setuptools/archive_util.py"Unpack" a directory, using the same interface as for archives

    Raises ``UnrecognizedFormat`` if `filename` is not a directory
    %s is not a compressed or uncompressed tar fileUtilities for extracting common archive formatsNot a recognized archive type: %s%s is not a zip file%s is not a directoryUnpack zip `filename` to `extract_dir`

    Raises ``UnrecognizedFormat`` if `filename` is not a zipfile (as determined
    by ``zipfile.is_zipfile()``).  See ``unpack_archive()`` for an explanation
    of the `progress_filter` argument.
    format_commandformat_commands[   s   aliass	   bdist_eggs	   bdist_rpms	   build_exts   build_pys   develops   easy_installs   egg_infos   installs   install_libs   rotates   saveoptss   sdists   setopts   tests   install_egg_infos   install_scriptss   registers   bdist_wininsts   upload_docs/usr/lib/python2.7/dist-packages/setuptools/command/usr/lib/python2.7/dist-packages/setuptools/command/__init__.pyPython .egg fileepmwarn_dirbdist_dirkeep_templibs_fileplat_namebdist_basefindsourcegen_headergetabsfileskip_buildgetcommentszap_pyfilesarchive_rootcall_commandeggsecutablenorm_egg_info_stub_templategetinnerframesdo_install_dataget_ext_outputscopy_metadata_toexclude_source_filesgetfilegetsourcelinesskip-buildexclude-source-filesWARNING: 'depends.txt' will not be used by setuptools 0.6!
Use the install_requires/extras_require setup() args instead.keep the pseudo-installation tree around after creating the distribution archivedl-skip rebuilding everything (for testing/debugging)create an "egg" distributioncreating '%s' and adding '%s' to itsetuptools.command.bdist_egg

Build .egg distributionsInvoke reinitialized command `cmdname` with keyword argsdirectory to put final built distributions ineggsecutable entry point (%r) cannot have 'extras' or refer to a moduleCreate a zip file from all the files under 'base_dir'.  The output
    zip file will be named 'base_dir' + ".zip".  Uses either the "zipfile"
    Python module (if available) or the InfoZIP "zip" utility (if installed
    and found on the default search path).  If neither tool is available,
    raises DistutilsExecError.  Returns the name of the output zip file.
    .dll .so .dylib .pydplat-name=/usr/lib/python2.7/dist-packages/setuptools/command/bdist_egg.pyzip_safe flag not set; analyzing archive contents...Get a list of relative paths to C extensions in the output distroremove all .py files from the generated eggPlease ask the author to include a 'zip_safe' setting (either True or False) in the package's setup.pyRemoving .py files from temporary directoryCheck whether module possibly uses unsafe-for-zipfile stuff%s: module references %sinstalling scripts to %ssetuptools.installation%s: top-level module may be 'python -m' scriptremoving %sYield names and strings used by `code` and its nested code objectsinstalling package data to %sbdist-dir=Walk an unpacked egg's contents, skipping the metadata directorytemporary directory for creating the distribution%s: module MAY be using inspect.%splatform name to embed in generated filenames (default: %s)Copy metadata (egg info) to the target_dir
        def __bootstrap__():
            global __bootstrap__, __loader__, __file__
            import sys, pkg_resources, imp
            __file__ = pkg_resources.resource_filename(__name__, %r)
            __loader__ = None; del __bootstrap__, __loader__
            imp.load_dynamic(__name__,__file__)
        __bootstrap__()
        Unable to analyze compiled code on this platform.#!/bin/sh
if [ `basename $0` = "%(basename)s" ]
then exec python%(pyver)s -c "import sys, os; sys.path.insert(0, os.path.abspath('$0')); from %(pkg)s import %(base)s; sys.exit(%(full)s())" "$@"
else
  echo $0 is not the correct name for this egg file.
  echo Please rename it back to %(basename)s and try again.
  exec false
fi
installing library code to %screating stub loader for %sinsert_locrpmversionunmangled_versionSource0: %{name}-%{version}.tar%setup
    Override the default bdist_rpm behavior to do the following:

    1. Run egg_info to ensure the name and version are properly calculated.
    2. Always run 'install' using --single-version-externally-managed to
       disable eggs in RPM distributions.
    3. Replace dash with underscore in the version numbers for better RPM
       compatibility.
    setup.py install --single-version-externally-managed Source0: %{name}-%{unmangled_version}.tar%define unmangled_version %define version %setup -n %{name}-%{unmangled_version}/usr/lib/python2.7/dist-packages/setuptools/command/bdist_rpm.pybpy_cmduse_2to3build_pathsetup_pathscript_pathuninstall_linkUninstall this source packageegg-path=Set the path to be used in the .egg-link file--egg-path must be a relative path from the install directory to Can't get a consistent path to setup script from installation directoryCreating %s (link to %s)Removing %s (link to %s)install package in 'development mode'Note: you must uninstall or replace scripts manually!Please rename %r to %r before using 'develop'/usr/lib/python2.7/dist-packages/setuptools/command/develop.pySet up package for developmentLink points to %s: uninstall abortedbmlenMovingaltsepegglocendrecos2emxreadfpriscossetupssitepyzip_okCopyingPATHEXTPLATLIBPURELIBST_MODES_ISDIRei_optsnorm_p1norm_p2S_IWRITE__pypy___dry_runabiflagscopytreehelp_msgsite_libtestfileuserbaseusersitewhereamiUSER_BASEUSER_SITEfile_utilis_scriptlib_pathsnull_byteok_existsraw_bytesunix_userPYTHONPATH_show_helpadd_outputdeb_systemexe_to_eggget_writermaybe_movepattern_obsys_prefixunix_local_EndRecDatagetPropertyinstall_exelauncher_fnposix_localreal_prefixshadow_pathtest_existscfg_filenameclean_headercommon_usagecreate_indexdist_versionexpand_pathsinstall_eggsinstall_itemnot_editableshould_unzip_expand_attrsall_site_dirsdist_fullnamemake_relativeno_find_linksold_gen_usageselect_schemewriter_lookupDEFAULT_SCHEME_adjust_header_load_templatecheck_editablecheck_site_dirinstall_layouttarget_versiondelete_blockersinstall_platlibinstall_purelibpseudo_tempnamereport_editablesys_exec_prefixunpack_progressENABLE_USER_SITE_get_script_argscreate_home_pathegg_distributioninstall_platbaseinstall_userbaseinstall_usersitepy_version_nodotpy_version_shortsitepy_installedbuild_and_installinstalled_projectslocal_snapshots_okunpack_and_compileSETUPTOOLS_LAUNCHER__PYVENV_LAUNCHER__installation_reportpath_importer_cache_set_command_options_set_fetcher_optionsbuiltin_module_namescant_write_to_targetcheck_pth_processingno_default_version_msgalways-unzipzip-okeasy_install-$base/lib/python$py_version_short/site-packages$base/bin$base/Lib/site-packages$base/Scriptsmulti-versionexclude-scriptsalways-copyno-depslocal-snapshots-okforce-installation-into-system-dirPURELIB/PLATLIB/pywin32_system32SCRIPTS/EGG-INFO/scripts/DATA/lib/site-packages--dist-dir-script.py[   (   s   prefix=Ns   installation prefix(   s   zip-okt   zs   install package as a zipfile(   s   multi-versiont   ms%   make apps have to require() a version(   s   upgradet   Us1   force upgrade (searches PyPI for latest versions)(   s   install-dir=t   ds   install package to DIR(   s   script-dir=t   ss   install scripts to DIR(   s   exclude-scriptst   xs   Don't install scripts(   s   always-copyt   as'   Copy all needed packages to install dir(   s
   index-url=t   is    base URL of Python Package Index(   s   find-links=t   fs(   additional URL(s) to search for packages(   s   build-directory=t   bs/   download/extract/build in DIR; keep the results(   s	   optimize=t   Osl   also compile with optimization: -O1 for "python -O", -O2 for "python -OO", and -O0 to disable [default: -O0](   s   record=Ns3   filename in which to record list of installed files(   s   always-unzipt   Zs*   don't install as a zipfile, no matter what(   s
   site-dirs=t   Ss)   list of directories where .pth files work(   s   editablet   es+   Install specified packages in editable form(   s   no-depst   Ns   don't install dependencies(   s   allow-hosts=t   Hs$   pattern(s) that hostnames must match(   s   local-snapshots-okt   ls(   allow building eggs from local checkouts(   s   versionNs"   print version information and exit(   s   install-layout=Ns1   installation layout to choose (known values: deb)(   s"   force-installation-into-system-dirt   0s   force installation into /usr(   s   no-find-linksNs9   Don't load find-links defined in packages being installed
    Update zipimporter cache data for a given normalized path.

    Any sub-path entries are processed as well, i.e. those corresponding to zip
    archives embedded in other zip archives.

    Given updater is a callable taking a cache entry key and the original entry
    (after already removing the entry from the cache), and expected to update
    the entry and possibly return a new one to be inserted in its place.
    Returning None indicates that the entry should not be replaced with a new
    one. If no updater is given, the cache entries are simply removed without
    any additional processing, the same as if the updater simply returned None.

    setuptools %sEmpirically verify whether .pth files are supported in inst. dirFor Windows, add a .py extension.tmplSets the install directories by applying the install schemes.setuptools.pthdef __boot():#!%(executable)s%(options)s
Recursively delete a directory tree.

    This code is taken from the Python 2.4 version of 'shutil', because
    the 2.3 version doesn't really work right.
    /usr/bin/env %sscript.tmpl%s is not a setuptools-generated site.py; please remove it.$base/lib/python3/%sVerify that self.install_dir is .pth-capable dir, if neededchanging mode of %s to %oCreate a #! line, getting options (if any) from script_text (dev).tmpldistutils.spawnPython.frameworkWARNING: Unable to adapt shebang line for Jython, the following script is NOT executable
         see http://bugs.jython.org/issue1112 for more information.Manage a download/build/install process
        Make sure 'pythonw' is used for gui and and 'python' is used for
        console (regardless of what sys.executable is).
        
        Get a script writer suitable for Windows
        egg-dist-tmp-python.exe--optimize must be 0, 1, or 2installation into /usr

Trying to install into the system managed parts of the file system. Please
consider to install to another location, or use the option
--force-installation-into-system-dir to overwrite this warning.
Get exe->egg path translations for a given .exe fileNo urls, filenames, or requirements specified (see --help)Calls `os.path.expanduser` on install dirs.
Extracted editable version of %(spec)s to %(dirname)s

If it uses setuptools in its setup script, you can activate it in
"development" mode by going to that directory and running::

    %(python)s setup.py develop

See the setuptools documentation for the "develop" command for more info.
.exe.manifestSetup script exited with %sInstalled distribution %s conflicts with requirement %sSaving %simport sys; sys.__plen = len(sys.path)
%s
import sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new)


Because this distribution was installed --multi-version, before you can
import modules from this package in an application, you will need to
'import pkg_resources' and then use a 'require()' call similar to one of
these examples, in order to select the desired version:

    pkg_resources.require("%(name)s")  # latest installed version
    pkg_resources.require("%(name)s==%(version)s")  # this exact version
    pkg_resources.require("%(name)s>=%(version)s")  # this version or higher
replace_cached_zip_archive_directory_dataTEST PASSED: %s appears to support .pth filesRemove `dist` from the distribution map%r already exists in %s; build directory %s will not be kept$base/local/lib/python$py_version_short/%sos.makedirs('%s', 0o700) (--always-copy skips system and development eggs)
Easy Install
------------

A tool for doing automatic download/extract/build of distutils-based Python
packages.  For detailed documentation, see the accompanying EasyInstall.txt
file, or visit the `EasyInstall home page`__.

__ https://pythonhosted.org/setuptools/easy_install.html

chmod failed: %s%r already exists in %s; can't do a checkout there-nspkg.pthCould not find required distribution %sWrite changed .pth file back to diskCould not find suitable distribution for %rWrite all the scripts for `dist`, unless scripts are excludedWARNING: can't process %s%s not listed in PATHEXT; scripts will not be recognized as executables.Couldn't find a setup script in %s-32.<iii%s is already the active version in easy-install.pthinstall in user site-package '%s'Skipping dependencies for %simport os; f = open(%r, 'w'); f.write('OK'); f.close()
dependency_links.txtChecking .pth file support in %s
    Encapsulates behavior around writing entry point scripts for console and
    gui apps.
    Is this string a valid Python script?Is this text, as a whole, a Python script? (as opposed to shell/bat/etc.
    Metadata-Version: 1.0
Removing %s from easy-install.pth fileYield sys.path directories that might contain "old-style" packages
        There are a couple of template scripts in the package. This
        function loads one of them and prepares it for use.
        $base/local/binA .pth file with Distribution paths in itProcessing dependencies for %sHelpful installation message for display to package users.ok
        When easy_install is about to run bdist_egg on a source dist, that
        source dist might have 'setup_requires' directives, requiring
        additional fetching. Ensure the fetcher options given to easy_install
        are available to that command as well.
        Unpacking %s to %s%s is not a valid distutils Windows .exeFinished processing dependencies for %sMake sure there's a site.py in the target dir, if neededCreate directories under ~.distutils.command.bdist_eggFind/get/install Python packages-64.Return a pseudo-tempname base in the install directory.
        This code is intentionally naive; if a malicious party can write to
        the target directory you're already in deep doodoo.
        %s (in --site-dirs) does not existusage: %(script)s [options] requirement_or_url ...
   or: %(script)s --help
Must specify a build directory (-b) when using --editableChecking existing site.py in %s
%(what)s %(eggloc)s%(extras)sbad install directory or PYTHONPATH

You are attempting to install a package to a directory that is not
on PYTHONPATH and which Python does not read ".pth" files from.  The
installation directory you specified (via --install-dir, --prefix, or
the distutils default setting) was:

    %s

and your PYTHONPATH environment variable currently contains:

    %r

Here are some of your options for correcting the problem:

* You can choose a different installation directory, i.e., one that is
  on PYTHONPATH or supports .pth files

* You can add the installation directory to the PYTHONPATH environment
  variable.  (It must then also be on PYTHONPATH whenever you run
  Python and want to use the package(s) you are installing.)

* You can set up the installation directory to support ".pth" files by
  using one of the approaches described here:

  https://pythonhosted.org/setuptools/easy_install.html#custom-installation-locations

Please make the appropriate changes for your system and try again.Processing %slauncher manifest.xmlDetermine if the specified executable is a .sh (contains a #! line)%s/%s/Extract a bdist_wininst to the directories an egg would use

Note also that the installation directory must be on sys.path at runtime for
this to work.  (e.g. by being the application's script directory, by being on
PYTHONPATH, or by being added to sys.path by your code.)

    Load the Windows launcher (executable) suitable for launching a script.

    `type` should be either 'cli' or 'gui'

    Returns the executable as a byte string.
    
        For Windows, add a .py extension and an .exe launcher
        
Perhaps your account does not have write access to this directory?  If the
installation directory is a system-owned directory, you may need to sign in
as the administrator or "root" account.  If you do not have administrative
access to this machine, you may wish to choose a different installation
directory, preferably one that is listed in your PYTHONPATH environment
variable.

For information on other options, you may wish to consult the
documentation at:

  https://pythonhosted.org/setuptools/easy_install.html

Please make the appropriate changes for your system and try again.
byte-compiling is disabled, skipping.-script.pywunknown value for --install-layoutAdd `dist` to the distribution map (in --site-dirs) is not on sys.pathCalls `os.path.expanduser` on install_base, install_platbase and
        root.Generate a legacy script wrapper and install it
    Return zipimporter cache entry keys related to a given normalized path.

    Alternative path spellings (e.g. those using different character case or
    those using alternative path separators) related to the same path are
    included. Any sub-path entries are included as well, i.e. those
    corresponding to zip archives embedded in other zip archives.

    Multiple setup scripts in %s%s: %s
site-pythonUser base directory is not specifiedcan't create or remove files in install directory

The following error occurred while trying to add or remove files in the
installation directory:

    %s

The installation directory you specified (via --install-dir, --prefix, or
the distutils default setting) was:

    %s
TEST FAILED: %s does NOT support .pth files.write-testtest-easy-install-%sNo eggs found in %s (setup script problem?)clear_and_remove_cached_zip_archive_directory_data
    Fix any globally cached `dist_path` related data

    `dist_path` should be a path of a newly installed egg distribution (zipped
    or unzipped).

    sys.path_importer_cache contains finder objects that have been cached when
    importing data from the original distribution. Any such finders need to be
    cleared since the replacement distribution might be packaged differently,
    e.g. a zipped egg distribution might get replaced with an unzipped egg
    folder or vice versa. Having the old finders cached may then cause Python
    to attempt loading modules from the replacement distribution using an
    incorrect loader.

    zipimport.zipimporter objects are Python loaders charged with importing
    data packaged inside zip archives. If stale loaders referencing the
    original distribution, are left behind, they can fail to load modules from
    the replacement distribution. E.g. if an old zipimport.zipimporter instance
    is used to load data from a new zipped egg archive, it may cause the
    operation to attempt to locate the requested data in the wrong location -
    one indicated by the original distribution's zip archive directory
    information. Such an operation may then fail outright, e.g. report having
    read a 'bad local file header', or even worse, it may fail silently &
    return invalid data.

    zipimport._zip_directory_cache contains cached zip archive directory
    information for all existing zipimport.zipimporter instances and all such
    instances connected to the same archive share the same cached directory
    information.

    If asked, and the underlying Python implementation allows it, we can fix
    all existing zipimport.zipimporter instances instead of having to track
    them down and remove them one by one, by updating their shared cached zip
    archive directory information. This, of course, assumes that the
    replacement distribution is packaged as a zipped egg.

    If not asked to fix existing zipimport.zipimporter instances, we still do
    our best to clear any remaining zipimport.zipimporter related cached data
    that might somehow later get used when attempting to load data from the new
    distribution and thus cause such load operations to fail. Note that when
    tracking down such remaining stale data, we can not catch every conceivable
    usage from here, and we clear only those that we know of and have found to
    cause problems if left alive. Any remaining caches should be updated by
    whomever is in charge of maintaining them, i.e. they should be ready to
    handle us replacing their zip archives with new distributions at runtime.

    Adding %s to easy-install.pth fileQuote a command line argument according to Windows parsing rulessite-patch.pyDeleting empty %s-arm.
        Yield write_script() argument tuples for a distribution's entrypoints
        Extract configuration data from a bdist_wininst .exe

    Returns a ConfigParser.RawConfigParser, or None
    
This directory does not currently exist.  Please create it and try again, or
choose a different installation directory (using the -d or --install-dir
option).

        # EASY-INSTALL-ENTRY-SCRIPT: %(spec)r,%(group)r,%(name)r
        __requires__ = %(spec)r
        import sys
        from pkg_resources import load_entry_point

        if __name__ == '__main__':
            sys.exit(
                load_entry_point(%(spec)r, %(group)r, %(name)r)()
            )
    Running %s %sInvalid argument %r: you can't use filenames or URLs with --editable (except via the --find-links option).
    Return a regular expression based on first_line_re suitable for matching
    strings.
    pythonw.exe/usr/lib/python2.7/dist-packages/setuptools/command/easy_install.py%s.exeforce_installation_into_system_dirpkgsvtagsu_path_repairrcfilesis_regexstrftimetag_dateappend_crtag_buildutf8_path_safe_pathdelete_filefind_sourcesuse_defaultsmanifest_onlyoverwrite_argwrite_entriesensure_dirnameforce_manifesttagged_versionwrite_manifestexclude_patterninclude_patternprune_file_listtag_svn_revisionmanifest_filenameremove_duplicates_manifest_normalizewrite_or_delete_filewrite_toplevel_namescheck_broken_egg_infoget_pkg_info_revisionwarn_depends_obsoleteno-datetag-dateno-svn-revisiontag-svn-revisionegg-base=directory containing .egg-info directories (default: top of the source tree)Add subversion revision ID to version numberAdd date stamp (e.g. 20050528) to version numbertag-build=Specify explicit tag to add to version numberDon't add subversion revision ID [default]Don't include date stamp [default]Invalid distribution name or version syntax: %s-%sstandard file not found:-r%sCreate a file with the specified name and write 'contents' (a
    sequence of strings without line terminators) to it.
    create a distribution's .egg-info directory-%Y%m%d
        Replace self.files with only safe paths

        Because some owners of FileList manipulate the underlying
        ``files`` attribute directly, this method must be called to
        repair those paths.
        Version:.*-r(\d+)\s*$)(RCS|CVS|\.svn)'%s' in unexpected encoding -- skippingwriting %s to %sGenerate SOURCES.txt manifest file
[{extra}]
Delete `filename` (if not a dry run) after announcing itMANIFEST.inegg_info.writersWrite `data` to `filename` (if not a dry run) after announcing it

        `what` is used in a log message to identify what is being written
        to the file.
        %s not set in setup(), but %s existssetuptools.command.egg_info

Create a distribution's .egg-info directory and contentsWARNING: 'depends.txt' is not used by setuptools 0.6!
Use the install_requires/extras_require setup() args instead.writing manifest file '%s'(^|File list that accepts only existing, platform-independent pathsWrite `data` to `filename` or delete if empty

        If `data` is non-empty, this routine is the same as ``write_file()``.
        If `data` is empty but not ``None``, this is the same as calling
        ``delete_file(filename)`.  If `data` is ``None``, then this is a no-op
        unless `filename` exists, in which case a warning is issued about the
        orphaned file (if `force` is false), or deleted (if `force` is true).
        deleting %s'%s' not %s encodable -- skipping[%s]
%s

/usr/lib/python2.7/dist-packages/setuptools/command/egg_info.py
        Write the file list in 'self.filelist' to the manifest file
        named by 'self.manifest'.
        ------------------------------------------------------------------------------
Note: Your current .egg-info directory has a '-' in its name;
this will not work correctly with "setup.py develop".

Please rename %s to %s to correct this problem.
path_fileIronPythonextra_dirscurrentframenew_commandshandle_extra_path_called_from_setupold-and-unmanageableTry not to use this!used by system package builders to create 'flat' eggsFor best results, pass -X:Frames to enable call stack.
        Attempt to detect whether run() was called from setup() or by another
        command.  If called by setup(), the parent caller will be the
        'run_command' method in 'distutils.dist', and *its* caller will be
        the 'run_commands' method.  If called any other way, the
        immediate caller *might* be 'run_command', but it won't have been
        called by 'run_commands'. Return True in that case or if a call stack
        is unavailable. Return False otherwise.
        /usr/lib/python2.7/dist-packages/setuptools/command/install.pyUse easy_install to install the package, w/dependenciesYou must specify --record or --root when building system packagesCall stack not available. bdist_* commands may fail.bs_cmdis_wininst_is_runningDo normal script install, plus any egg_info wrapper scripts/usr/lib/python2.7/dist-packages/setuptools/command/install_scripts.pysetuptools.command.install_scriptsdistutils.command.install_scriptstb_nextcmd_namestandardshas_scriptscheck_readmeentries_patharchive_filescheck_metadata_default_revctrlget_sub_commandshas_pure_modulesmake_distributionmake_release_treeinclude_package_data_manifest_is_not_generated_sdist__read_template_hacktest/test*.pyformats for source distribution (comma-separated list)keep the distribution tree around after creating archive file(s)directory to put the source distribution archive(s) in [default: dist]README.txt# file GENERATED by distutils, do NOT edit
%r not UTF-8 decodable -- skippingreading manifest file '%s'/usr/lib/python2.7/dist-packages/setuptools/command/sdist.pyPrimary svn_cvs entry pointREADME.rststandard file '%s' not foundFind all files under revision controlstandard file not found: should have one of Read the manifest file (named by 'self.manifest') and use it to
        fill in 'self.filelist', the list of files to include in the source
        distribution.
        Smart sdist that finds anything supported by revision control^\w?/([^/]+)/CVS/Entries
    Finder that locates files based on entries in a file matched by a
    regular expression.
    setuptools.file_findersset_valueuser_configglobal_configremove_optionremove_sectionglobal-configuser-configcommand=command to set an option foroption=option to setset-value=value of the optionremove (unset) the valuesave options to the site-wide distutils.cfg filesave options to the current user's pydistutils.cfg filefilename=configuration file to use (default=setup.cfg)Edit a configuration file to include `settings`

    `settings` is a dictionary of dictionaries or ``None`` values, keyed by
    command/section name.  A ``None`` value means to delete the entire section,
    while a dictionary lists settings to be changed or deleted in that section.
    A setting of ``None`` means to delete that setting.
    Deleting section [%s] from %sSetting %s.%s to %r in %sconfig_file() type must be 'local', 'global', or 'user'Adding new section [%s] to %sSave command-line options to a fileReading configuration from %sGet the filename of the distutils, local, global, or per-user config

    `kind` must be one of "local", "global", or "user"
    Must specify --set-value or --remove/usr/lib/python2.7/dist-packages/setuptools/command/setopt.pyset an option in setup.cfg or another config fileMust specify only one configuration file optionMust specify --command *and* --optionDeleting empty [%s] section from %sWriting %sDeleting %s.%s from %s~/%spydistutils.cfgAbstract base class for commands that mess with config filesHTTPServerBaseHTTPRequestHandlerSimpleHTTPRequestHandler/usr/lib/python2.7/dist-packages/setuptools/compat.pydef reraise(tp, value, tb=None):
    raise tp, value, tbis_presentversion_okget_frozen_objectExtract the constant value of 'symbol' from 'code'

    If the name 'symbol' is bound to a constant value by the Python code
    object 'code', return that value.  If 'symbol' is bound to an expression,
    return 'default'.  Otherwise, return 'None'.

    Return value is based on the first assignment to 'symbol'.  'symbol' must
    be a global, or at least a non-"fast" local in the code block.  That is,
    only 'STORE_NAME' and 'STORE_GLOBAL' opcodes are checked, and 'symbol'
    must be present in 'code.co_names'.
    Return full package/distribution name, w/versionJust like 'imp.find_module()', but with package support/usr/lib/python2.7/dist-packages/setuptools/depends.pyA prerequisite to building or installing a distribution
    Patch the globals to remove the objects not available on some platforms.

    XXX it'd be better to test assertions about bytecode instead.
    Is 'version' sufficiently up-to-date?Find 'module' by searching 'paths', and extract 'symbol'

    Return 'None' if 'module' does not exist on 'paths', or it does not define
    'symbol'.  If the module defines 'symbol' as a constant, return the
    constant.  Otherwise, return 'default'.Return true if dependency is present and up-to-date on 'paths'Yield '(op,arg)' pair for each operation in code object 'code'Get version number of installed module, 'None', or 'default'

        Search 'paths' for module.  If not found, return 'None'.  If found,
        return the extracted version attribute, or 'default' if no version
        attribute was specified, or the value cannot be determined without
        importing the module.  The version is formatted according to the
        requirement's version format (if any), unless it is 'None' or the
        supplied 'default'.
        Return true if dependency is present on 'paths'Can't find %r in %scmdobjdetachneg_optsrc_root_exclude_check_nspcmd_classinclude_inassert_bool_egg_fetcher_set_featurecheck_extrasexclude_fromTextIOWrapper_exclude_misc_include_mischelp_commandscheck_packagesfeature_negoptglobal_optionsline_bufferingprint_commandsresolved_distsexclude_packagefeature_optionsinclude_featurewarn_deprecatedcheck_importablecheck_test_suitefetch_build_eggshas_contents_for_exclude_packages_feature_attrnameenvironment_localhave_package_data_finalize_featurescheck_entry_pointscheck_package_datacheck_requirementsinclude_by_default_parse_command_optsfeature_is_includedget_cmdline_optionsDistributionMetadataconvert_2to3_doctestshandle_display_optionspatch_missing_pkg_info_set_global_opts_from_featuresVerify that namespace packages are validProtect against re-patching the distutils if reloaded

    Also ensures that no other distutils extension monkeypatched the distutils
    first.
    Add --with-X/--without-X options based on optional featuresDistribution with support for features, tests, and package data

    This is an enhanced version of 'distutils.dist.Distribution' that
    effectively adds the following new optional keyword arguments to 'setup()':

     'install_requires' -- a string or sequence of strings specifying project
        versions that the distribution requires when installed, in the format
        used by 'pkg_resources.require()'.  They will be installed
        automatically when the package is installed.  If you wish to use
        packages that are not available in PyPI, or want to give your users an
        alternate download location, you can add a 'find_links' option to the
        '[easy_install]' section of your project's 'setup.cfg' file, and then
        setuptools will scan the listed web pages for links that satisfy the
        requirements.

     'extras_require' -- a dictionary mapping names of optional "extras" to the
        additional requirement(s) that using those extras incurs. For example,
        this::

            extras_require = dict(reST = ["docutils>=0.3", "reSTedit"])

        indicates that the distribution can optionally provide an extra
        capability called "reST", but it can only be used if docutils and
        reSTedit are installed.  If the user installs your package using
        EasyInstall and requests one of your extras, the corresponding
        additional requirements will be installed if needed.

     'features' **deprecated** -- a dictionary mapping option names to
        'setuptools.Feature'
        objects.  Features are a portion of the distribution that can be
        included or excluded based on user options, inter-feature dependencies,
        and availability on the current system.  Excluded features are omitted
        from all setup commands, including source and binary distributions, so
        you can create multiple distributions from the same source tree.
        Feature names should be valid Python identifiers, except that they may
        contain the '-' (minus) sign.  Features can be included or excluded
        via the command line options '--with-X' and '--without-X', where 'X' is
        the name of the feature.  Whether a feature is included by default, and
        whether you are allowed to control this from the command line, is
        determined by the Feature object.  See the 'Feature' class for more
        information.

     'test_suite' -- the name of a test suite to run for the 'test' command.
        If the user runs 'python setup.py test', the package will be installed,
        and the named test suite will be run.  The format is the same as
        would be used on a 'unittest.py' command line.  That is, it is the
        dotted name of an object to import and call to generate a test suite.

     'package_data' -- a dictionary mapping package names to lists of filenames
        or globs to use to find data files contained in the named packages.
        If the dictionary has filenames or globs listed under '""' (the empty
        string), those names will be searched for in every package, in addition
        to any names for the specific package.  Data files found using these
        names/globs will be installed along with the package, in the same
        location as the package.  Note that globs are allowed to reference
        the contents of non-package subdirectories, as long as you use '/' as
        a path separator.  (Globs are automatically converted to
        platform-specific paths at runtime.)

    In addition to these new keywords, this class also has several new methods
    for manipulating the distribution's contents.  For example, the 'include()'
    and 'exclude()' methods can be thought of as in-place add and subtract
    commands that add or remove packages, modules, extensions, and so on from
    the distribution.  They are used by the feature subsystem to configure the
    distribution for the included and excluded features.
    Verify that extras_require mapping is validIf there were any non-global "display-only" options
        (--help-commands or the metadata display options) on the command
        line, display the requested info and return true; else return
        false.
        %s: No such distribution setting%r must be a boolean value (got %r)%s wants to be able to remove %s, but the distribution doesn't contain any packages or modules under %sFetch an egg needed for buildingWARNING: %r not a valid package name; please use only.-separated package names in setup.pyReturn a '{cmd: {opt:val}}' map of all command-line options

        Option names are all long, but do not include the leading '--', and
        contain dashes rather than underscores.  If the option doesn't take
        an argument (e.g. '--quiet'), the 'val' is 'None'.

        Note that options provided by config files are intentionally excluded.
        Verify that value is a string list or NoneReturn true if 'exclude_package(package)' would do something%s: setting must be a list or tuple (%r)Set feature's inclusion statusResolve pre-setup requirementstest_suite must be a stringReturn 1 if feature is included, 0 if excluded, 'None' if unknownAdd items to distribution that are named in keyword arguments

        For example, 'dist.exclude(py_modules=["x"])' would add 'x' to
        the distribution's 'py_modules' attribute, if it was not already
        there.

        Currently, this method only supports inclusion for attributes that are
        lists or tuples.  If you need to add support for adding to other
        attributes in this or a subclass, you can add an '_include_X' method,
        where 'X' is the name of the attribute.  The method will be called with
        the value passed to 'include()'.  So, 'dist.include(foo={"bar":"baz"})'
        will try to call 'dist._include_foo({"bar":"baz"})', which can then
        handle whatever special inclusion logic is needed.
        WARNING: %r is declared as a package namespace, but %r is not: please correct this in setup.pydistutils.commandsEnsure feature is excluded from distribution

        You may override this in a subclass to perform additional operations on
        the distribution.  This method will be called at most once per
        feature, and only after all included features have been asked to
        include themselves.
        Handle 'include()' for list/tuple attrs without a special handlerWrite the PKG-INFO file into the release tree.
        Pluggable version of get_command_class()/usr/lib/python2.7/dist-packages/setuptools/dist.py%s: setting must be a list (%r)Process features after parsing command line optionsdistutils.setup_keywordsShould this feature be included by default? is required, but was excluded or is not availableVerify that feature makes sense in context of distribution

        This method is called by the distribution just before it parses its
        command line.  It checks to ensure that the 'remove' attribute, if any,
        contains only valid package/module names that are present in the base
        distribution when 'setup()' is called.  You may override it in a
        subclass to perform any other required validation of the feature
        against a target distribution.
        Add/remove features and resolve dependencies between themVerify that value is a dictionary of package names to glob listsFeatures are deprecated and will be removed in a future version. See http://bitbucket.org/pypa/setuptools/65.'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.Distribution contains no modules or packages for packages: setting must be a list or tuple (%r)Ensure feature and its requirements are included in distribution

        You may override this in a subclass to perform additional operations on
        the distribution.  Note that this method may be called more than once
        per feature, and so should be idempotent.

        %r must be a list of strings (got %r) is required,but is not available on this platformVerify that install_requires is a valid requirements listConvert feature name to corresponding option attribute nameRequest inclusion of feature named 'name'distutils has already been patched by %rFeature %s: must define 'require_features', 'remove', or at least one of 'packages', 'py_modules', etc.Yield all packages, modules, and extension names in distributionRemove items from distribution that are named in keyword arguments

        For example, 'dist.exclude(py_modules=["x"])' would remove 'x' from
        the distribution's 'py_modules' attribute.  Excluding packages uses
        the 'exclude_package()' method, so all of the package's contained
        packages, modules, and extensions are also excluded.

        Currently, this method only supports exclusion from attributes that are
        lists or tuples.  If you need to add support for excluding from other
        attributes in this or a subclass, you can add an '_exclude_X' method,
        where 'X' is the name of the attribute.  The method will be called with
        the value passed to 'exclude()'.  So, 'dist.exclude(foo={"bar":"baz"})'
        will try to call 'dist._exclude_foo({"bar":"baz"})', which can then
        handle whatever special exclusion logic is needed.
        
    Workaround issue #197 - Python 3 prior to 3.2.2 uses an environment-local
    encoding to save the pkg_info. Monkey-patch its write_pkg_info method to
    correct this undesirable behavior.
    %r must be importable 'module:attrs' string (got %r)%r must be a string or list of strings containing valid project/version requirement specifiersVerify that entry_points map is parseablenamespace package %rShouldn't be able to get here: this setting cannot be changed via include/excludeHandle 'exclude()' for list/tuple attrs without a special handler must be a dictionary mapping package names to lists of wildcard patterns
    **deprecated** -- The `Feature` facility was never completely implemented
    or supported, `has reported issues
    <https://bitbucket.org/pypa/setuptools/issue/58>`_ and will be removed in
    a future version.

    A subset of the distribution that can be excluded if unneeded/wanted

    Features are created using these keyword arguments:

      'description' -- a short, human readable description of the feature, to
         be used in error messages, and option help messages.

      'standard' -- if true, the feature is included by default if it is
         available on the current system.  Otherwise, the feature is only
         included if requested via a command line '--with-X' option, or if
         another included feature requires it.  The default setting is 'False'.

      'available' -- if true, the feature is available for installation on the
         current system.  The default setting is 'True'.

      'optional' -- if true, the feature's inclusion can be controlled from the
         command line, using the '--with-X' or '--without-X' options.  If
         false, the feature's inclusion status is determined automatically,
         based on 'availabile', 'standard', and whether any other feature
         requires it.  The default setting is 'True'.

      'require_features' -- a string or sequence of strings naming features
         that should also be included if this feature is included.  Defaults to
         empty list.  May also contain 'Require' objects that should be
         added/removed from the distribution.

      'remove' -- a string or list of strings naming packages to be removed
         from the distribution if this feature is *not* included.  If the
         feature *is* included, this argument is ignored.  This argument exists
         to support removing features that "crosscut" a distribution, such as
         defining a 'tests' feature that removes all the 'tests' subpackages
         provided by other features.  The default for this argument is an empty
         list.  (Note: the named package(s) or modules must exist in the base
         distribution when the 'setup()' function is initially called.)

      other keywords -- any other keyword arguments are saved, and passed to
         the distribution's 'include()' and 'exclude()' methods when the
         feature is included or excluded, respectively.  So, for example, you
         could pass 'packages=["a","b"]' to cause packages 'a' and 'b' to be
         added or removed from the distribution as appropriate.

    A feature must include at least one 'requires', 'remove', or other
    keyword argument.  Otherwise, it can't affect the distribution in any way.
    Note also that you can subclass 'Feature' to create your own specialized
    feature types that modify the distribution in other ways when included or
    excluded.  See the docstrings for the various methods here for more detail.
    Aside from the methods, the only feature attributes that distributions look
    at are 'description' and 'optional'.
    Remove packages, modules, and extensions in named packageVerify that value is True, False, 0, or 1Invalid environment marker: pyrex_implpyrex_impls_convert_pyx_sources_to_lang/usr/lib/python2.7/dist-packages/setuptools/extension.py.pyx$
    Return True if Cython or Pyrex can be imported.
    Just like a regular Extension, but built as a library insteadPyrex.Distutils.build_extCython.Distutils.build_extExtension that uses '.c' files in place of '.pyx' files
        Replace sources with .pyx extensions to sources with the target
        language extension. This mechanism allows language authors to supply
        pre-converted sources but to prefer the .pyx sources.
        relsauth_surl_okblksizeprescanfrom_urlopen_urlscan_allscan_urlgen_setuphexdigestInvalidURLauth_bytescheck_hashfix_sf_urlpop_prefixreporthookold_timeoutprocess_url_download_hg_download_todl_blocksizeencodestringfetched_urlsscanned_urlsAuthorizationBadStatusLineHTTPException_download_git_download_svn_download_urlencoded_bytespackage_pagesprocess_indexscan_egg_link__downloaded___download_html_get_repo_cred_socket_timeoutfind_credentialprocess_filename_attempt_downloadgetdefaulttimeoutneed_version_infosetdefaulttimeoutnot_found_in_indexcreds_by_repository_vcs_split_rev_from_urlcontent-typetext/html.win32-py/usr/lib/python2.7/dist-packages/setuptools/package_index.pyGenerate alternative interpretations of a source distro name

    Note: if `location` is a filesystem filename, you should call
    ``pkg_resources.normalize_path()`` on it before passing it to this
    routine!
    
        Feed a block of data to the hash.
        Can't download %s: %s %sRead a local path, with special support for directoriesA distribution index that scans web pages for download URLs.pypirc<a href=%r>%s</a>href\s*=\s*['"]?([^'"> ]+)Path not foundLocate and/or download `spec` to `tmpdir`, returning a local path

        `spec` may be a ``Requirement`` object, or a string containing a URL,
        an existing local filename, or a project/version requirement spec
        (i.e. the string form of a ``Requirement`` object).  If it is the URL
        of a .py file with an unambiguous ``#egg=name-version`` tag (i.e., one
        that escapes ``-`` as ``_`` throughout), a trivial ``setup.py`` is
        automatically created alongside the downloaded file.

        If `spec` is a ``Requirement`` object or a string containing a
        project/version requirement spec, this method returns the location of
        a matching distribution (possibly after downloading it to `tmpdir`).
        If `spec` is a locally existing file or directory name, it is simply
        returned unchanged.  If `spec` is a URL, it is downloaded to a subpath
        of `tmpdir`, and the local filename is returned.  Various errors may be
        raised if a problem occurs during downloading.
        
    Wrap a function returning an iterable such that the resulting iterable
    only ever yields unique items.
    ([-+.a-z0-9]{2,}):Download error for %s: %sCouldn't find index page for %r (maybe misspelled?)svn checkout%s -q %s %s</head><body>%s</body></html>Found: %sObtain a file suitable for fulfilling `requirement`

        DEPRECATED; use the ``fetch_distribution()`` method now instead.  For
        backward compatibility, this routine is identical but returns the
        ``location`` of the downloaded distribution instead of a distribution
        object.
        PyPI and direct package downloadingSearching for %sFind rel="homepage" and rel="download" links in `page`, yielding URLsUpdating to %sScan urls scheduled for prescanning (e.g. --find-links)#egg=%s-%sOpen a urllib2 request, handling HTTP authenticationsvn+hg+Page at %s links to .py file(s) without version info; an index scan is required.Reading %s
        Check the hash. Return False if validation fails.
        (?P<hash_name>sha1|sha224|sha384|sha256|sha512|md5)=(?P<expected>[a-f0-9]+)<th>Home PageObtain a distribution suitable for fulfilling `requirement`

        `requirement` must be a ``pkg_resources.Requirement`` instance.
        If necessary, or if the `force_scan` flag is set, the requirement is
        searched for in the (online) package index as well as the locally
        installed packages.  If a distribution matching `requirement` is found,
        the returned distribution's ``location`` is the value you would have
        gotten from calling the ``download()`` method with the matching
        distribution's URL or filename.  If no matching distribution is found,
        ``None`` is returned.

        If the `source` flag is set, only source distributions and source
        checkout links will be considered.  Unless the `develop_ok` flag is
        set, development and system eggs (i.e., those using the ``.egg-info``
        format) will be ignored.
        Doing git clone from %s to %s
    A function compatible with Python 2.3-3.3 that will encode
    auth from a URL suitable for an HTTP header.
    >>> str(_encode_auth('username%3Apassword'))
    'dXNlcm5hbWU6cGFzc3dvcmQ='

    Long auth strings should not cause a newline to be inserted.
    >>> long_auth = 'username:' + 'password'*10
    >>> chr(10) in str(_encode_auth(long_auth))
    False
    ^egg=([-A-Za-z0-9_.]+)$a source distribution of Can't process plain .py files without an '#egg=name-version' suffix to enable automatic setup script generation.%(username)s:%(password)spy2.hg clone --quiet %s %sfrom setuptools import setup
setup(name=%r, version=%r, py_modules=[%r])
Decode HTML entities in the given text.Yield egg or source distribution objects based on basenameEvaluate a URL as a possible download, and maybe retrieve itFound link: %sAdd `urls` to the list that will be prescanned for searchesSkipping development or system egg: %sYield possible egg or source distribution objects based on a filename.tar.gz .tar.bz2 .tar .zip .tgz --username=Couldn't retrieve index page for %rValidating %%s checksum for %sContent-Lengthcontent-length
        Call reporter with information about the checker (hash name)
        substituted into the template.
        Python-urllib/%s setuptools/%swin-amd64
    A null content checker that defines the interface for checking content
    git+<([^>]*\srel\s*=\s*['"]?([^'">]+)[^>]*)>svn:.win32.exeNot found<html><head><title>%s</title>&(#(\d+|x[\da-fA-F]+)|[\w.:-]+);?Checking out %sScanning index of all packages (this may take a while)Best match: %s.egg.zipNot found: %sList unique elements, preserving order. Remember all elements ever seen.(cd %s && hg up -C -r %s >&-)nonnumeric port: ''Yield egg or source distribution objects that might be found at a URL
        checker is a ContentChecker
        No local packages or download links found for %s%s<a href="%s#md5=%s">%s</a><title>([^- ]+ - )?Revision \d+:Unexpected HTML page found at Return (base,pyversion) or (None,None) for possible .exe name
    A username/password pair. Use like a namedtuple.
    .win-amd64-py
        Load from ~/.pypirc
        Doing hg clone from %s to %s --username=%s --password=%s<a href="([^"#]+)">([^<]+)</a>
\s+\(<a (?:title="MD5 hash"
\s+)href="[^?]+\?:action=show_md5&amp;digest=([0-9a-f]{32})">md5</a>\)Doing subversion checkout from %s to %s
        If the URL indicated appears to be a repository defined in this
        config, return the credential for that repository.
        
Note: Bypassing %s (disallowed host; see http://bit.ly/1dg9ijs for details).
Process the contents of a PyPI pageDownload error on %s: %%s -- Some packages may not be found!Authenticating as %s for %s (from .pypirc)Construct a (possibly null) ContentChecker from a URLDownloading %s%s does not match %s<th>Download URL(cd %s && git checkout --quiet %s)Can't unambiguously interpret project/version identifier %r; any dashes in the name or version should be escaped using underscores. %r.win-amd64.exegit clone --quiet %s %sUser-Agent%s validation failed for %s; possible download problem?%s returned a bad status line. The server might be down, %s(   t   urlt   openert   schemet   netloct   patht   paramst   queryt   fragt   autht   hostt   credt   infot   new_urlt   requestt   fpt   s2t   h2t   path2t   param2t   query2t   frag2py26compat/usr/lib/python2.7/dist-packages/setuptools/py26compat.py
Compatibility Support for Python 2.6 and earlier

	In `Python 8280 <http://bugs.python.org/issue8280>`_, Python 2.7 and
	later was patched to disregard the fragment when making URL requests.
	Do the same for Python 2.6 and earlier.
	getheaderspy27compat/usr/lib/python2.7/dist-packages/setuptools/py27compat.py
	Given an HTTPMessage, return all headers matching a given key.
	
Compatibility Support for Python 2.7 and earlier
exctraceexcvaluepy31compatunittest_main"
        Very simple temporary directory context manager.
        Will try to delete afterward, but will also ignore OS and similar
        errors on deletion.
        /usr/lib/python2.7/dist-packages/setuptools/py31compat.pyName must be purelib or platlibmknodchrootlchownmkfifosymlink_sandboxpathconfreadlink_exemptedsetup_dirstartfilewrite_ops_violationPosixModule_remap_pair_remap_input_remap_outputstart_matches_validate_pathpattern_matches_exception_patterns_DirectorySandbox__iterator/usr/lib/python2.7/dist-packages/setuptools/sandbox.pyCalled for low-level os.open()A setup script attempted to modify the filesystem outside the sandboxCalled for path pairs like rename, link, and symlink operationsCalled for path outputs-from
    Python 3 implementation of execfile.
    .*lib2to3.*\.pickle$O_WRONLY O_RDWR O_APPEND O_CREAT O_TRUNC O_TEMPORARYRun 'func' under os sandboxingRestrict operations to a single subdirectory - pseudo-chrootwin32com.client.gencacheencodings.Called to remap or validate any path, whether input or outputRun a distutils setup script, sandboxed in its directoryWrap 'os' module and 'open()' builtin for virtualizing setup scriptsSandboxViolation: %s%r %s

The package setup script has attempted to modify files on your system
that are not within the EasyInstall build area, and has been aborted.

This package cannot be safely installed by EasyInstall, and may not
support alternate installation locations even if you run its setup
script by hand.  Please inform the package's author and the EasyInstall
maintainers to find out if a fix or workaround is available.Called for path inputsorg.python.modules.posix.PosixModuleDNS_tunnelcertifiaddcertsaddstoreca_certsshutdownSHUT_RDWRcert_reqscommonNamehttps_opengetpeercertwrap_socket_tunnel_hostwincertstoreCERT_REQUIREDsource_addresssubjectAltNamecreate_connectionno appropriate commonName or subjectAltName fields were found[^.]+Matching according to RFC 6125, section 6.4.3

        http://tools.ietf.org/html/rfc6125#section-6.4.3
        empty or no certificateSimple verifying connection: no auth, subclasses, timeouts, etc.too many wildcards in certificate DNS name: /usr/lib/python2.7/dist-packages/setuptools/ssl_support.pyhostname %r doesn't match either of %s[^.]*Verify that *cert* (in decoded format as returned by
        SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
        rules are followed, but IP addresses are not accepted for *hostname*.

        CertificateError is raised on failure. On success, the function
        returns nothing.
        cacert.pemGet a urlopen() replacement that uses ca_bundle for verificationhostname %r doesn't match %r
/etc/pki/tls/certs/ca-bundle.crt
/etc/ssl/certs/ca-certificates.crt
/usr/share/ssl/certs/ca-bundle.crt
/usr/local/share/certs/ca-root.crt
/etc/ssl/cert.pem
/System/Library/OpenSSL/certs/cert.pem
Simple verifying handler: no auth, subclasses, timeouts, etc.backports.ssl_match_hostnamexn--setuptools.ssl_supportReturn an existing CA bundle path, or NoneNFCrevreurlreis_osxis_xmlget_urlpulldomsvn_dirall_revsext_propnodeNamenodeTypesub_infosub_pathTEXT_NODE_walk_svniter_dirsnodeValuerel_partschildNodesexpandNodeiter_filesget_entriesparseStringrevision_regetAttributeget_sectionsSTART_ELEMENTget_externalsproperty_text_build_entriesiter_externalsparse_revisionSECTION_DIVIDERentries_patternget_svn_version_SvnInfo__iteratorknown_svn_versionsgetElementsByTagNamegetpreferredencoding__get_cached_sectionsget_undeleted_recordsparse_revision_numbers1.6.xUS-ASCIIsvn:externalsdir-propsdir-prop-basemac-
        Iterate over the svn:external references in the repository path.
        
Parse the entries from a recursive info xmlxml.dom.pulldom/usr/lib/python2.7/dist-packages/setuptools/svn_utils.pyGet repository URLurl="([^"]+)"
    Generic svn_info object.  No has little knowledge of how to extract
    information.  Use cls.load to instatiate according svn version.

    Paths are not filesystem encoded.
    setuptools.svn_utilscommitted-rev="(\d+)"
        Iterate over the non-deleted file entries in the repository path
        
    Parse the value of a retrieved svn:externals entry.

    possible token setups (with quotng and backscaping in laters versions)
        URL[@#] EXT_FOLDERNAME
        [-r#] URL EXT_FOLDERNAME
        EXT_FOLDERNAME [-r#] URL
    xml.sax.saxutilssvnversion failed--xmlsvn info failedUnknown subversion verson %d
    Decode the console or file output explicitly using getpreferredencoding.
    The text paraemeter should be a encoded string, if not no decode occurs
    If no encoding is given, getpreferredencoding is used.  If encoding is
    specified, that is used instead.  This would be needed for SVN --xml
    output.  Unicode is explicitly put in composed NFC form.

    --xml should be UTF-8 (SVN Issue 2938) the discussion on the Subversion
    DEV List from 2007 seems to indicate the same.
    Parse a propget svn:externals xml--config-dirNo SVN 1.3+ command found: falling back on pre 1.7 .svn parsingRetrieve the directory revision informatino using svnversionsvn propget failed(?:([\-0-9]+):)?(\d+)([a-z]*)\s*$name="([^"]+)"(?![^>]+deleted="true")_SVNEntriesFileText__get_cached_sectionsNFDfs_encturn unicode encoding into a functional routine/usr/lib/python2.7/dist-packages/setuptools/unicode_utils.py
    Ensure that the given path is decoded,
    NONE when no expected encoding works
    5.5.1/usr/lib/python2.7/dist-packages/setuptools/version.pyTixttkgdbmimapQueueTkdndCookieDialogtkFontMAXSIZETkinteraddbaseaddinfodbm_gnuifilterreprlibtkinterUserDictUserListadd_movebyte2intget_codeint2byteparse_qsClassTypeURLopener__slots__cookielibiterbytesmeta_pathparse_qslraw_inputslots_vartext_typeurldefragxmlrpclibFTPHandlerFileDialogHTMLParserUserStringaddinfourlget_sourcegetproxiesindexbytesis_packagequote_plussplitquerythis_basesurlcleanupBaseHandlerFileHandlerHTTPHandlerParseResultSplitResultTkconstants__closure____package____weakref___add_module_get_modulebinary_typeclass_typeshtml_parserhttp_clientremove_movetkinter_dndtkinter_tixtkinter_ttkurlretrievezip_longestProxyHandlerScrolledTextSimpleDialogSocketServer__get_moduleaddclosehookdummy_threadhttp_cookiesizip_longestmethodcallerproxy_bypasssocketservertkFileDialogtkMessageBoxtkinter_fontunquote_plusCGIHTTPServer_dummy_threadadd_metaclasshtml_entitiesknown_modulesreload_modulexmlrpc_clientxmlrpc_serverFancyURLopenerOpenerDirectorUnknownHandlerhttp_cookiejarinstall_openertkColorChoosertkCommonDialogtkSimpleDialogtkinter_dialogwith_metaclassCacheFTPHandlerHTTPPasswordMgrRobotFileParseremail_mime_baseemail_mime_textget_method_selftemporary_classget_function_codetkinter_constantsHTTPErrorProcessorSimpleXMLRPCServertkinter_filedialogtkinter_messageboxHTTPCookieProcessorHTTPRedirectHandlercreate_bound_methodget_method_functionContentTooShortErrorHTTPBasicAuthHandleremail_mime_multipartget_function_closureget_function_globalstkinter_colorchoosertkinter_commondialogtkinter_scrolledtexttkinter_simpledialogtkinter_tkfiledialogHTTPDigestAuthHandlerProxyBasicAuthHandlerget_function_defaultsProxyDigestAuthHandlertkinter_tksimpledialogHTTPDefaultErrorHandlerAbstractBasicAuthHandlerAbstractDigestAuthHandlersubmodule_search_locationsHTTPPasswordMgrWithDefaultRealm_SixMetaPathImporter__get_moduletkinter.scrolledtextsix.moves.urllibhttp.cookiesUtilities for writing code that runs on Python 2 and 3moves.urllib.errorexec _code_ in _globs_, _locs_tkinter.messageboxmoves.urllib_parsemoves.urllib_errortkinter.constantsmoves.urllib.responseLazy loading of moved objects in six.moves.urllib_responsetkinter.filedialogLazy loading of moved objects in six.moves.urllib_parseRemove item from six.moves.tkinter.tixmoves.urllib.requesthtml.parserno such move, %rsix.moves.urllib.errorLazy loading of moved objects in six.moves.urllib_errorAdd documentation to a function.Return an iterator over the (key, value) pairs of a dictionary.def reraise(tp, value, tb=None):
    raise tp, value, tb
Lazy loading of moved objects in six.moves.urllib_requestinvalid keyword arguments to print()six.moves.urllib.requestemail.MIMEBaseReraise an exception.moves.urllib.parsemoves.urllib.robotparsermoves.urllib_robotparserCreate a six.moves.urllib namespace that resembles the Python 3 namespaceLazy loading of moved objects in six.moves.urllib_robotparseremail.mime.texttkinter.dialogtkinter.colorchoosertkinter.dndtkinter.commondialogText literalByte literaltkinter.ttkReturn an iterator over the (key, [values]) pairs of a dictionary.six.moves.urllib.responseBenjamin Peterson <benjamin@python.org>tkinter.font
    A meta path importer to import six.moves and its submodules.

    This class implements a PEP302 finder and loader. It should be compatible
    with Python 2.5 and all existing versions of Python3
    sep must be None or a stringsix.moves.urllib.robotparseremail.mime.multipartemail.MIMETextReturn None

        Required, if is_package is implemented1.7.3Class decorator for creating a class with a metaclass.Execute code in a namespace.Add an item to six.moves.\\\\dbm.gnuend must be None or a stringxmlrpc.client/usr/lib/python2.7/dist-packages/six.pyThis loader does not know module email.mime.baseReturn an iterator over the keys of a dictionary.Create a base class with a metaclass.
        Return true, if the named module is a package.

        We need this method to get correct spec objects with
        Python 3.4 (see PEP451)
        xmlrpc.serverImport module, returning the module after the last dot.tkinter.simpledialogReturn an iterator over the values of a dictionary.The new-style print function for Python 2.4 and 2.5.Get the function out of a possibly unbound functionemail.MIMEMultiparthttp.cookiejarc__builtin__
complex
G        G        R.c__builtin__
complex
G        G?      R.NO_ATLAS_INFOIntegration successful.Excess work done on this call (perhaps wrong Dfun type).Internal workspace insufficient to finish (internal error).Repeated convergence failures (perhaps bad Jacobian or tolerances).Repeated error test failures (internal error).Illegal input detected (internal error).Excess accuracy requested (tolerances too small).numpy.ufunc size changednumpy.dtype size changed{Gz??      ?UUUUUU?      ?    A    .A     @@      Y@  "5B      $@     @ 	eC      ^@ JXB      (@   pA     @     @     @    ~pA   ynB     f@    @t>A      ?      <"\O>      ?}%ITh>>:0yE>V<#B;    A    ~@A     @    @A       @     @   @
A    2|A      >@   \L8B     @@     @      @ D`\C    syA     @z@      @      L@      N@  /cB D`lC `=Hb;C    ~`A   yn B     V@    S-A            _le__ge_\begin{description}\end{description}specify the Fortran compiler type<genexpr><lambda><string><?xmlscipy.linalg.miscnumpy.lib.scimathThe exact solution is  x = 0                              Pierre GF Gerard-Marchant ($Author: jarrod.millman $)index pointer should start with 0setuptools.command.sdistAx - b is small enough for this machine                   serial.win32numpy.core.umathPIL._util-[*]-\s*f90\s*-[*]-numpy.distutils.environmentThe estimate of cond(Abar) has exceeded conlim            html.entitiesfrom %s import %sserial.tools.list_portsillegal input names %sThe matrix A has %8g rows  and %8g colsI;16Ssetuptools.command.easy_installCan only operate on a valid port handle.*[.](cpp|cxx|cc)\Zcould not open port %s: %sRead terminal status line: Clear To Sendargument must be 'real', or 'complex'numpy.distutils.conv_templateReturns a matrix with the same sparsity structure as self,
        but with different data.  By default the structure arrays
        (i.e. .indptr and .indices) are copied.
        setuptools.extensionfname must be a string or file handleCheck if file is in free format Fortran.scipy.linalg._matfuncs_inv_ssqctypes.wintypesscipy.sparse.linalg.interfacedegrees must be non-negative integersReturns the main diagonal of the matrix
        expected 1D vector for wNot a URL, existing file, or requirement spec: %rLast value of index pointer should be less than the size of index and data arraysnot-zip-safenumpy.distutils.ccompilerarray must not contain infs or NaNsscipy.lib._utilInternal function that builds a new MaskedArray from the
    information stored in a pickle.

    ?bBhHiIlLqQpP\item[]{{}\verb@#pydocsignout#@{}}SVD did not converge in Linear Least SquaresGet the count of explicitly-stored values (nonzeros)

        Parameters
        ----------
        axis : None, 0, or 1
            Select between the number of values across the whole matrix, in
            each column, or in each row.
        Series must have maximum degree of at least 1.numpy.dualThe iteration limit has been reached                      scipy.linalg._matfuncs_sqrtmnumpy.__config__lib%s.ause %s, only : %sUnsupported parity mode: %rnumpy.lib.function_base
    Efficiently estimate the 1-norm of A^p.

    Parameters
    ----------
    A : ndarray
        Matrix whose 1-norm of a power is to be computed.
    p : int
        Non-negative integer power.
    t : int, optional
        A positive parameter controlling the tradeoff between
        accuracy versus time and memory usage.
        Larger values take longer and use more memory
        but give more accurate output.
    itmax : int, optional
        Use at most this many iterations.
    compute_v : bool, optional
        Request a norm-maximizing linear operator input vector if True.
    compute_w : bool, optional
        Request a norm-maximizing linear operator output vector if True.

    Returns
    -------
    est : float
        An underestimate of the 1-norm of the sparse matrix.
    v : ndarray, optional
        The vector such that ||Av||_1 == est*||v||_1.
        It can be thought of as an input to the linear operator
        that gives an output with particularly large norm.
    w : ndarray, optional
        The vector Av which has relatively large 1-norm.
        It can be thought of as an output of the linear operator
        that is relatively large in norm compared to the input.

    setuptools.compatPower must be a non-negative integer.scipy.sparse.csrnumpy.distutils.command.config_compilerRead terminal status line: Data Set Readyslicing with step != 1 not supportedunable to infer matrix dimensionsnumpy.version  %8.1e %8.1e--- #note#expected %s or bytearray, got %sindex pointer has invalid lengthrecord array has no attribute %s\noindent Optional arguments:serial.serialjava\item[]{{}\verb@%s@{}}The axis is out of rangesetuptools.versioncompiling Fortran 90 module sources1;RMask and data not compatible: data size is %i, mask size is %i.Port is already open.axis out of boundsnumpy.lib._compiled_baseReturns a copy of row i of the matrix, as a (1 x n)
        CSR matrix (row vector).
        Too many integration constantsexpected deg >= 0numpy.distutils.mingw32ccompilerscipy.special.orthogonalexpected w and y to have the same lengthPort must be configured before it can be used.Set communication parameters on opened port.Return a submatrix of this matrix (new matrix is created)./*decl*/http.clientI;16BSnative_libs.txtscipy.linalg.matfuncscompiling C++ sourcescould not find library %r in directories %skeep-temp-[*]-\s*fortran\s*-[*]-deg must be a non-negative integerhttp.serverRead terminal status line: Ring Indicatorhttps://pypi.python.org/simpleThe order of derivation must be non-negativeRead size bytes from the serial port. If a timeout is set it may
           return less characters as requested. With no timeout it will block
           until the requested number of bytes is read.%s(len=%sexpected x and y to have same lengthThe fit may be poorly conditioned(:)Xlib.xobject.fontable	%s(f2pyinit%s,F2PYINIT%s)(f2py_setup_%s);x, y are incompatiblenumpy.distutils.command.autodistClear output buffer, aborting the current output and
        discarding all that is in the buffer.indptr array has non-integer dtype (%s)shape mismatch in assignmentClear input buffer, discarding all that is in the buffer.scipy.sparse.baseSet terminal status line: Request To Sendswap the members of x if this is a column-oriented matrix
        Sum the matrix over the given axis.  If the axis is None, sum
        over both rows and columns, returning a scalar.
        Xlib.xobject.resource%s got multiple values for keyword argument '%s'Unsupported number of data bits: %rk exceeds matrix dimensionsscipy.lib.sixsetuptools.py31compatOpen port with current settings. This may throw a SerialException
           if the port cannot be opened.sort parameter must be None, a callable, or one of ('lhp','rhp','iuc','ouc')serial.serialutilReshaping not implemented for %s.numpy.distutils.from_templateexpected non-empty vector for x\noindent Return objects:%s argument after ** must be a mapping, not %snumpy.lib.utilscompiling Fortran sourcesThe axis must be integer*.eggexpected p to be a non-negative integerunrecognized form for %s_matrix constructor--- See above.*.modindex pointer size (%d) should be (%d)Xlib.xobject.drawableSet terminal status line: Data Terminal Readyindices array has non-integer dtype (%s)Installing %s script to %sXlib.display ...
... Stop listening for keyboard input events.bad palette filedeg must be integer/*frompyobj*/list available Fortran compilersrestructuredtext enscipy.linalg.decomp_schurexpected 1D vector for xdistutils.unixccompilerSort the indices of this matrix *in place*
        See the docstring for `spmatrix.toarray`.input must be a square arraynumpy.numarray.utilend interfacesetuptools.unicode_utilsnumpy.core.fromnumeric%s*(%s)'encoding' is an invalid keyword argument for this function\item[]{{}\verb@#pydocsign#@{}}scipy.__config__setuptools.command.bdist_rpmcompiling C sourcesnumpy.distutils.numpy_distributionscipy.versionserial.serialposixnumpy.distutils.__version__$Date: 2007-10-29 17:18:13 +0200 (Mon, 29 Oct 2007) $distutils.file_utilSend break condition. Timed, returns to idle state after given duration.No warning raised when calling %snumpy.distutils.compatlen..scipy.linalg.basicexpected x and w to have same lengthClose portserial.serialwin32The order of integration must be integerdistutils.dir_utilillegal value in %d-th argument of internal %sexpected A to be like a square matrixinternal inconsistencysetuptools.command.developillegal value in %d-th argument of internal gesv|posvOnly two-dimensional sparse arrays are supported.serial.tools.list_ports_posixnumpy.distutils.exec_commandnumpy.ma.mrecordsAx - b is small enough, given atol, btol                  fortranobject.csetuptools.py27compatnumpy.testing.utilsThe least-squares solution is good enough, given atol     scipy.sparse.sputilsx, y, z are incompatibleunknown color specifier: %rexpected 1D or 2D array for ynumpy.distutils.unixccompilernumpy.distutils.extensionnumpy.distutils.__config__\noindent Call-back functions:Xlib.ext.xtestWrite an executable file to the scripts directoryaxis must be less than arr.ndim; axis=%d, rank=%d.PIL.JpegPresetsRead terminal status line: Carrier DetectThe order of integration must be non-negativenumpy.distutils.system_info/*freemem*/I;32Ssetuptools.depends\noindent Required arguments:%s argument after * must be a sequence, not %snumpy.lib.type_check.*[.](for|ftn|f77|f)\ZPower is too largePIL._binaryindex pointer values must form a non-decreasing sequenceThe order of derivation must be integersetuptools.package_indexIncluding fileUnsupported number of stop bits: %rexpected a 1-d array for weightsfailed to move %r to %rdistutils.coredistutils.filelist.*[.](f90|f95|f77|for|ftn|f|pyf)\Zstatic FortranDataDef f2py_%s_def[] = {numpy.distutils.command.build_src#docsign#[#docsignopt#]serial.serialcliThe least-squares solution is good enough for this machinenumpy.lib.twodim_baseReturn a 3-tuple for pickling a MaskedArray.

        Return the number of characters currently in the input buffer.unknown file type '%s' (from '%s')--versionSet break: Controls TXD. When active, to transmitting is possible.I;32BS%d-th leading minor not positive definitesetuptools.py26compatTurn a port number into a device namedistutils.dep_utilexpected matrixdistutils.msvccompilerserial.tools.list_ports_windowsexpected a square matrix$Revision: 3473 $setuptools.sandboxnumpy.core.records%s
      %s%s.libinvalid input formatCond(Abar) seems to be too large for this machine         #rname#,numpy.distutils.infosetuptools.archive_utillatin-1skipping %s (up-to-date)Xlib.xobject.colormapstatic void f2py_init_%s(void) {encoder error %d when writing image fileXlib.xobject.cursornumpy.distutils.misc_utildistutils.errorsSee `f2py -v`utf-8exponent must be an integercannot load this image%s,kind=%s)Upper level handler of keyboard events.	f2py_%s_def[i_f2py++].data = %s;numpy.distutils.core%(major)d.%(minor)d.%(micro)dscipy.sparse.constructMM *_markerlib.markers-[*]-\s*fix\s*-[*]-	{"%s",%s,{{%s}},%s},/*pyobjfrom*/indices and data should have the same sizeBegin listening for keyboard input events. %10.3e %10.3esetuptools.distsetuptools.command.setoptincompatible dimensions.Sorry: no implementation for your platform ('%s') availableOutput the given string over the serial port.ATOMAboveAllClientsAllFloatAllocAllAllocNoneAllowExposuresAnyEventArcChordArcPieSliceBAUDRATESBGRXBLURBZ2FileBaseHTTPServerBaudRateBottomIfCLRDTRCLRRTSCONTOURCapButtCapNotLastCapProjectingCapRoundCard32ObjCard8Card8ObjCatchErrorCenterGravityCharInfoClipByChildrenColorItemColormapObjConnectionClosedErrorControlMapIndexConvexCoordModeOriginCoordModePreviousCopyFromParentCursorShapeDTR_CONTROL_DISABLEDataOffsetDefaultBlankingDefaultExposuresDisplayConnectionErrorDontAllowExposuresDontPreferBlankingEDGE_ENHANCEEDGE_ENHANCE_MOREEMBOSSEastGravityEvenOddRuleEventFieldFIND_EDGESFillOpaqueStippledFillSolidFillStippledFillTiledFixedStringForgetGravityFunctionTypeGCValuesGXandGXandInvertedGXandReverseGXclearGXcopyGXcopyInvertedGXequivGXinvertGXnandGXnoopGXnorGXorGXorInvertedGXorReverseGXsetGXxorGrabModeAsyncGrabModeSyncHAVE_ARGUMENTIGNORECASEINFINITEINVALID_HANDLE_VALUEIconicStateIncludeInferiorsInputOnlyInputOutputJoinBevelJoinMiterJoinRoundK1K2KeyPressMaskKeyReleaseMaskLineDoubleDashLineOnOffDashLineSolidLockMapIndexLowerHighestMARKPARITYMINMAXMULTIARCHMappingKeyboardMenuMethodTypeMingw32CCompilerMod2MapIndexMod3MapIndexMod4MapIndexMod5MapIndexModuleTypeNonconvexNormalStateNorthEastGravityNorthGravityNorthWestGravityNotUsefulNumpyDoctestONE5STOPBITSOddLengthOpcodeOppositeOptionParserPropModeAppendPropModePrependPropModeReplaceRECORDRGBaRTS_CONTROL_DISABLERTS_CONTROL_TOGGLERaiseLowestRawIOBaseReplyCodeReplyLengthRequestLengthSETDTRSETRTSSHARPENSMOOTHSMOOTH_MORESOABISPACEPARITYSetModeDeleteSetModeInsertSimpleHTTPServerSouthEastGravitySouthGravitySouthWestGravityStaticGravityStippleShapeStopBitsTAGSTextElements16TextTestRunnerTileShapeTimeCoordTopIfUnsignedIntegerUnsortedValueListWEXITSTATUSWINDIRWMHintsWMIconSizeWMNormalHintsWMStateWM_CLASSWM_CLIENT_MACHINEWM_HINTSWM_ICON_NAMEWM_ICON_SIZEWM_NAMEWM_NORMAL_HINTSWM_SIZE_HINTSWM_TRANSIENT_FORWhenMappedWinErrorWindingRuleWindowObjWindowValuesWithdrawnStateXTESTXYBitmapXYPixmapXoffCharXonCharYSortedYXBandedYXSortedZHZIP_DEFLATEDZIP_STOREDZPixmap_BLNK___abs____array_finalize____author____bases____cmp____colormap____contains____cursor____date____del____delattr____delitem____dir____docformat____drawable____enter____exit____font____fontable____func____gc____ge____get____getattr____getattribute____getnewargs____globals____gt____iadd____idiv____import____imul____internal____ipow____isub____itruediv____le____lt____metaclass____module____mro____next____pixmap____resource____revision____rpow____self____setattr____setmask____traceback____window____wrapped___amax_amin_binopt_break_bytesize_check_compiler_checked_decoder_divide_sparse_dsrdtr_dump_fields__fix_object_args_get_single_element_get_submatrix_hardmask_index_to_arrays_interCharTimeout_isOpen_isfield_loose_call_make_spec_file_minor_reduce_need_link_optinfo_parity_parse_response_parsed_version_patched_dist_process_toarray_args_reconfigurePort_response_lock_rtscts_safe_read_set_error_set_self_setup_distribution_stopbits_ufuncs_unpack_index_update_from_winreg_writeTimeout_xonxoffaccept_keyaccprodadd_defaultsadd_extension_eventadd_find_linksadd_optionadd_sectionallocate_lockallow_hostsalt_l_keyalt_r_keyalways_copyalways_copy_fromapps_keyas_requirementasformatasfptypeassubrattrgetterbacking_pixelbacking_storebackspace_keybegin_keybit_gravitybitmap_format_bit_orderbitmap_format_scanline_padbitmap_format_scanline_unitblue_maskbool_arbool_opsboolean_optionsbootstrap_install_frombreak_keybuild_basebuild_directorybuild_openerbuildcallbacksbuildcfuncsbuildusevarsbyrefbyte_compilebytes_aftercStringIOc_contiguouscalcsizecaller_modulecaller_namecancel_keycapital_keycbInQuecbOutQuecb_routsign2mapcb_sign2mapcffichdircheck_callcheck_extensions_listcheck_formatcheck_outputclassmethodclient_diedclient_startedcmapscommand_consumes_argumentscommunicatecompile_switchcompiler_soconfigparsercontractioncontrol_keycontrol_l_keycontrol_r_keyconvert_keycopy2core_repliescore_requestsctxcygpathdash_offsetdecoderconfigdedentdefault_colormapdefault_screendelete_keydelivered_eventsdevice_eventsdevnulldistclassdo_egg_installdo_not_propagate_maskdocshortdown_keydst_drawabledst_gcdst_widdst_windowegg_baseegg_nameegg_outputegg_versionencoderconfigencoderinfoend_keyensure_finalizedenter_keyentry_fileescape_keyestimate_blocksizeevent_classevent_classesexc_infoexc_tracebackexc_typeexc_valueexclude_scriptsexe_extensionexecute_keyexpand_basedirsexpand_dirsexpandptrext_repliesext_requestsf2py_optsf2py_wrapper_outputf2pymultilinesfAbortOnErrorfBinaryfDtrControlfErrorCharfInXfNullfOutXfOutxCtsFlowfOutxDsrFlowfParityfRtsControlf_backf_codef_contiguousf_globalsf_localsfdFDfilesys_decodefilterwarningsfinal_keyfinalize_optionsfind_keyfinditerflag2flushInputflushOutputformat_descriptionfrom_locationfromkeysfunction_keysgetCDgetCTSgetDSRgetRIget_command_objget_default_screenget_display_nameget_errorget_ext_filenameget_ext_fullnameget_extension_majorget_finalized_commandget_fullnameget_librariesget_metadata_linesget_modifier_mappingget_nameget_numarray_include_dirsget_option_dictget_outputsget_package_dirget_revisionget_shapeget_source_filesgetcwdgetdefaultlocalegetextremagetfilesystemencodinggetframeinfogetouterframesgetpidgetpixelgetsizegetsourcefilegrab_keyboardgrab_windowgreen_maskgroupdicthEventhangeul_keyhangul_keyhanja_keyhas_c_librarieshas_ext_moduleshas_metadatahas_sectionhelp_keyhelp_optionshexversionhiddenhome_keyhtmlentitydefshyper_l_keyhyper_r_keyi16bei16lei32bei32leifilterfalseimage_byte_orderinWaitinginfolistinitialize_optionsinsert_keyinstall_egg_scriptsinstall_for_developmentinstall_libbaseinstall_site_pyinstall_wrapper_scriptsinstalled_librariesinstalled_pkg_configipermis_availableis_char_shiftedisabsisattyislinkismatrixiter_distribution_namesiterupgradejunjua_keykana_keykanji_keykeycode_to_keysymkeypad_keyslc1lc2left_keylen1libfilelibfile2library_filenamelinefeed_keyload_endload_prepareload_readload_seeklong_descriptionlong_lengthlong_offsetlong_typemajor_indicesmajor_versionmakeDeviceNamemap_buffermarker_fnmax_indexmax_keycodemax_request_lengthmaxintmedia_play_pause_keymenu_keymeta_l_keymeta_r_keymetadata_isdirmetadata_listdirmin_keycodeminor_indicesminor_versionmodechange_keymodule_optionsmove_filemulti_versionn_vecsnamelistnegative_optnetbsdnext_keyno_depsno_epno_reportnonconvert_keynormcasenum2strnumpad_keyso16beo16leo32beo32leobj_extensionobject_switchold_and_unmanageableopen_memmapopenbsdopenbsd3opener_foroptparseout_shapeoutfilesoverride_redirectpage_down_keypage_up_keyparse_argsparse_command_lineparse_config_filesparse_flagsparse_groupparse_mappathname2urlpathseppending_eventsplat_specifierpress_keyprint_excprint_keyprint_screen_keyprior_keyprocess_distributionproperty_typepy_modules_dictpypy_version_infor_keysrbUread_manifestreadintorecord_create_contextrecord_disable_contextrecord_enable_contextrecord_free_contextred_maskredo_keyregister_extensionregister_mimeregister_openregister_savereinitialize_commandrelease_keyrequestorresource_classesretcodereturn_keyreturncoderight_keyroot_xroot_yrun_module_suitesame_screensave_version_infosaved_resultsscan_egg_linksscript_switch_keyscroll_lock_keyselect_keysendBreaksend_requestsent_requestsseparatorsforsetDTRsetRTSset_error_handlerset_extension_majorset_librariesset_library_dirsset_shapeset_undefined_optionssetimageshift_keyshift_l_keyshift_r_keyshort_versionshortlatexsingle_version_externally_managedsnapshot_keyspecial_key_assignmentsplitdrivesrc_extensionsst_modestack_modestatic_sizestore_truesuper_l_keysuper_r_keysvn_findersys_req_keytab_keytap_keytb_frametemp_filestestRunnertile_prefixto_scantodoktry_compiletry_encodeundo_keyungrab_keyboardunicode_escapeunsafe_nameupdate_pthuse_distributionuser_optionsversion_patternvolume_down_keyvolume_mute_keyvolume_up_keyvzwarn_deprecated_optionswin_gravitywindows_l_keywindows_r_keywith_tracebackxerror_class